[
  {
    "id": "2511.03924v1",
    "title": "On Predicting Sociodemographics from Mobility Signals",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ekin Uğurel",
      "Cynthia Chen",
      "Brian H. Y. Lee",
      "Filipe Rodrigues"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03924v1",
    "abstract": "Inferring sociodemographic attributes from mobility data could help transportation planners better leverage passively collected datasets, but this task remains difficult due to weak and inconsistent relationships between mobility patterns and sociodemographic traits, as well as limited generalization across contexts. We address these challenges from three angles. First, to improve predictive accuracy while retaining interpretability, we introduce a behaviorally grounded set of higher-order mobility descriptors based on directed mobility graphs. These features capture structured patterns in trip sequences, travel modes, and social co-travel, and significantly improve prediction of age, gender, income, and household structure over baselines features. Second, we introduce metrics and visual diagnostic tools that encourage evenness between model confidence and accuracy, enabling planners to quantify uncertainty. Third, to improve generalization and sample efficiency, we develop a multitask learning framework that jointly predicts multiple sociodemographic attributes from a shared representation. This approach outperforms single-task models, particularly when training data are limited or when applying models across different time periods (i.e., when the test set distribution differs from the training set).",
    "fetched_at": "2025-11-09T02:21:28.189228Z"
  },
  {
    "id": "2511.03928v1",
    "title": "SynQuE: Estimating Synthetic Dataset Quality Without Annotations",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Arthur Chen",
      "Victor Zhong"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03928v1",
    "abstract": "We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE) problem: ranking synthetic datasets by their expected real-world task performance using only limited unannotated real data. This addresses a critical and open challenge where data is scarce due to collection costs or privacy constraints. We establish the first comprehensive benchmarks for this problem by introducing and evaluating proxy metrics that choose synthetic data for training to maximize task performance on real data. We introduce the first proxy metrics for SynQuE by adapting distribution and diversity-based distance measures to our context via embedding models. To address the shortcomings of these metrics on complex planning tasks, we propose LENS, a novel proxy that leverages large language model reasoning. Our results show that SynQuE proxies correlate with real task performance across diverse tasks, including sentiment analysis, Text2SQL, web navigation, and image classification, with LENS consistently outperforming others on complex tasks by capturing nuanced characteristics. For instance, on text-to-SQL parsing, training on the top-3 synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to 38.4 (+8.1)% on average compared to selecting data indiscriminately. This work establishes SynQuE as a practical framework for synthetic data selection under real-data scarcity and motivates future research on foundation model-based data characterization and fine-grained data selection.",
    "fetched_at": "2025-11-09T02:21:28.189099Z"
  },
  {
    "id": "2511.03929v1",
    "title": "NVIDIA Nemotron Nano V2 VL",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "NVIDIA",
      ":",
      "Amala Sanjay Deshmukh",
      "Kateryna Chumachenko",
      "Tuomas Rintamaki",
      "Matthieu Le",
      "Tyler Poon",
      "Danial Mohseni Taheri",
      "Ilia Karmanov",
      "Guilin Liu",
      "Jarno Seppanen",
      "Guo Chen",
      "Karan Sapra",
      "Zhiding Yu",
      "Adi Renduchintala",
      "Charles Wang",
      "Peter Jin",
      "Arushi Goel",
      "Mike Ranzinger",
      "Lukas Voegtle",
      "Philipp Fischer",
      "Timo Roman",
      "Wei Ping",
      "Boxin Wang",
      "Zhuolin Yang",
      "Nayeon Lee",
      "Shaokun Zhang",
      "Fuxiao Liu",
      "Zhiqi Li",
      "Di Zhang",
      "Greg Heinrich",
      "Hongxu",
      "Yin",
      "Song Han",
      "Pavlo Molchanov",
      "Parth Mannan",
      "Yao Xu",
      "Jane Polak Scowcroft",
      "Tom Balough",
      "Subhashree Radhakrishnan",
      "Paris Zhang",
      "Sean Cha",
      "Ratnesh Kumar",
      "Zaid Pervaiz Bhat",
      "Jian Zhang",
      "Darragh Hanley",
      "Pritam Biswas",
      "Jesse Oliver",
      "Kevin Vasques",
      "Roger Waleffe",
      "Duncan Riach",
      "Oluwatobi Olabiyi",
      "Ameya Sunil Mahabaleshwarkar",
      "Bilal Kartal",
      "Pritam Gundecha",
      "Khanh Nguyen",
      "Alexandre Milesi",
      "Eugene Khvedchenia",
      "Ran Zilberstein",
      "Ofri Masad",
      "Natan Bagrov",
      "Nave Assaf",
      "Tomer Asida",
      "Daniel Afrimi",
      "Amit Zuker",
      "Netanel Haber",
      "Zhiyu Cheng",
      "Jingyu",
      "Xin",
      "Di",
      "Wu",
      "Nik Spirin",
      "Maryam Moosaei",
      "Roman Ageev",
      "Vanshil Atul Shah",
      "Yuting Wu",
      "Daniel Korzekwa",
      "Unnikrishnan Kizhakkemadam Sreekumar",
      "Wanli Jiang",
      "Padmavathy Subramanian",
      "Alejandra Rico",
      "Sandip Bhaskar",
      "Saeid Motiian",
      "Kedi Wu",
      "Annie Surla",
      "Chia-Chih Chen",
      "Hayden Wolff",
      "Matthew Feinberg",
      "Melissa Corpuz",
      "Marek Wawrzos",
      "Eileen Long",
      "Aastha Jhunjhunwala",
      "Paul Hendricks",
      "Farzan Memarian",
      "Benika Hall",
      "Xin-Yu Wang",
      "David Mosallanezhad",
      "Soumye Singhal",
      "Luis Vega",
      "Katherine Cheung",
      "Krzysztof Pawelec",
      "Michael Evans",
      "Katherine Luna",
      "Jie Lou",
      "Erick Galinkin",
      "Akshay Hazare",
      "Kaustubh Purandare",
      "Ann Guan",
      "Anna Warno",
      "Chen Cui",
      "Yoshi Suhara",
      "Shibani Likhite",
      "Seph Mard",
      "Meredith Price",
      "Laya Sleiman",
      "Saori Kaji",
      "Udi Karpas",
      "Kari Briski",
      "Joey Conway",
      "Michael Lightstone",
      "Jan Kautz",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Jonathen Cohen",
      "Oleksii Kuchaiev",
      "Andrew Tao",
      "Bryan Catanzaro"
    ],
    "institution": "Allan, Danny, Justin",
    "link": "http://arxiv.org/pdf/2511.03929v1",
    "abstract": "We introduce Nemotron Nano V2 VL, the latest model of the Nemotron vision-language series designed for strong real-world document understanding, long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers significant improvements over our previous model, Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major enhancements in model architecture, datasets, and training recipes. Nemotron Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and innovative token reduction techniques to achieve higher inference throughput in long document and video scenarios. We are releasing model checkpoints in BF16, FP8, and FP4 formats and sharing large parts of our datasets, recipes and training code.",
    "fetched_at": "2025-11-09T02:21:28.189058Z"
  },
  {
    "id": "2511.03938v1",
    "title": "LogHD: Robust Compression of Hyperdimensional Classifiers via   Logarithmic Class-Axis Reduction",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sanggeon Yun",
      "Hyunwoo Oh",
      "Ryozo Masukawa",
      "Pietro Mercati",
      "Nathaniel D. Bastian",
      "Mohsen Imani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03938v1",
    "abstract": "Hyperdimensional computing (HDC) suits memory, energy, and reliability-constrained systems, yet the standard \"one prototype per class\" design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior compaction reduces $D$ (feature axis), improving storage/compute but weakening robustness. We introduce LogHD, a logarithmic class-axis reduction that replaces the $C$ per-class prototypes with $n\\!\\approx\\!\\lceil\\log_k C\\rceil$ bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional activation space, cutting memory to $O(D\\log_k C)$ while preserving $D$. LogHD uses a capacity-aware codebook and profile-based decoding, and composes with feature-axis sparsification. Across datasets and injected bit flips, LogHD attains competitive accuracy with smaller models and higher resilience at matched memory. Under equal memory, it sustains target accuracy at roughly $2.5$-$3.0\\times$ higher bit-flip rates than feature-axis compression; an ASIC instantiation delivers $498\\times$ energy efficiency and $62.6\\times$ speedup over an AMD Ryzen 9 9950X and $24.3\\times$/$6.58\\times$ over an NVIDIA RTX 4090, and is $4.06\\times$ more energy-efficient and $2.19\\times$ faster than a feature-axis HDC ASIC baseline.",
    "fetched_at": "2025-11-09T02:21:28.188563Z"
  },
  {
    "id": "2511.03939v1",
    "title": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency   Alignment Methods",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Raghav Sharma",
      "Manan Mehta",
      "Sai Tiger Raina"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03939v1",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is the standard for aligning Large Language Models (LLMs), yet recent progress has moved beyond canonical text-based methods. This survey synthesizes the new frontier of alignment research by addressing critical gaps in multi-modal alignment, cultural fairness, and low-latency optimization. To systematically explore these domains, we first review foundational algo- rithms, including PPO, DPO, and GRPO, before presenting a detailed analysis of the latest innovations. By providing a comparative synthesis of these techniques and outlining open challenges, this work serves as an essential roadmap for researchers building more robust, efficient, and equitable AI systems.",
    "fetched_at": "2025-11-09T02:21:28.188503Z"
  },
  {
    "id": "2511.03942v1",
    "title": "MIDI-LLM: Adapting Large Language Models for Text-to-MIDI Music   Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.SD",
      "SD",
      "cs.CL",
      "CL",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Shih-Lun Wu",
      "Yoon Kim",
      "Cheng-Zhi Anna Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03942v1",
    "abstract": "We present MIDI-LLM, an LLM for generating multitrack MIDI music from free-form text prompts. Our approach expands a text LLM's vocabulary to include MIDI tokens, and uses a two-stage training recipe to endow text-to-MIDI abilities. By preserving the original LLM's parameter structure, we can directly leverage the vLLM library for accelerated inference. Experiments show that MIDI-LLM achieves higher quality, better text control, and faster inference compared to the recent Text2midi model. Live demo at https://midi-llm-demo.vercel.app.",
    "fetched_at": "2025-11-09T02:21:28.188459Z"
  },
  {
    "id": "2511.03948v1",
    "title": "Extracting Causal Relations in Deep Knowledge Tracing",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "I.2.6; K.3.1",
      "1"
    ],
    "authors": [
      "Kevin Hong",
      "Kia Karbasi",
      "Gregory Pottie"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03948v1",
    "abstract": "A longstanding goal in computational educational research is to develop explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which leverages a Recurrent Neural Network (RNN) to predict student knowledge and performance on exercises, has been proposed as a major advancement over traditional KT methods. Several studies suggest that its performance gains stem from its ability to model bidirectional relationships between different knowledge components (KCs) within a course, enabling the inference of a student's understanding of one KC from their performance on others. In this paper, we challenge this prevailing explanation and demonstrate that DKT's strength lies in its implicit ability to model prerequisite relationships as a causal structure, rather than bidirectional relationships. By pruning exercise relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal subsets of the Assistments dataset, we show that DKT's predictive capabilities align strongly with these causal structures. Furthermore, we propose an alternative method for extracting exercise relation DAGs using DKT's learned representations and provide empirical evidence supporting our claim. Our findings suggest that DKT's effectiveness is largely driven by its capacity to approximate causal dependencies between KCs rather than simple relational mappings.",
    "fetched_at": "2025-11-09T02:21:28.188377Z"
  },
  {
    "id": "2511.03950v1",
    "title": "Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh   Joint Optimization",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhejia Cai",
      "Puhua Jiang",
      "Shiwei Mao",
      "Hongkun Cao",
      "Ruqi Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03950v1",
    "abstract": "Reconstructing real-world objects from multi-view images is essential for applications in 3D editing, AR/VR, and digital content creation. Existing methods typically prioritize either geometric accuracy (Multi-View Stereo) or photorealistic rendering (Novel View Synthesis), often decoupling geometry and appearance optimization, which hinders downstream editing tasks. This paper advocates an unified treatment on geometry and appearance optimization for seamless Gaussian-mesh joint optimization. More specifically, we propose a novel framework that simultaneously optimizes mesh geometry (vertex positions and faces) and vertex colors via Gaussian-guided mesh differentiable rendering, leveraging photometric consistency from input images and geometric regularization from normal and depth maps. The obtained high-quality 3D reconstruction can be further exploit in down-stream editing tasks, such as relighting and shape deformation. The code will be publicly available upon acceptance.",
    "fetched_at": "2025-11-09T02:21:28.188330Z"
  },
  {
    "id": "2511.03952v1",
    "title": "High-dimensional limit theorems for SGD: Momentum and Adaptive   Step-sizes",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aukosh Jagannath",
      "Taj Jones-McCormick",
      "Varnan Sarangian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03952v1",
    "abstract": "We develop a high-dimensional scaling limit for Stochastic Gradient Descent with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework to rigourously compare online SGD with some of its popular variants. We show that the scaling limits of SGD-M coincide with those of online SGD after an appropriate time rescaling and a specific choice of step-size. However, if the step-size is kept the same between the two algorithms, SGD-M will amplify high-dimensional effects, potentially degrading performance relative to online SGD. We demonstrate our framework on two popular learning problems: Spiked Tensor PCA and Single Index Models. In both cases, we also examine online SGD with an adaptive step-size based on normalized gradients. In the high-dimensional regime, this algorithm yields multiple benefits: its dynamics admit fixed points closer to the population minimum and widens the range of admissible step-sizes for which the iterates converge to such solutions. These examples provide a rigorous account, aligning with empirical motivation, of how early preconditioners can stabilize and improve dynamics in settings where online SGD fails.",
    "fetched_at": "2025-11-09T02:21:28.188280Z"
  },
  {
    "id": "2511.03953v1",
    "title": "Conditional Score Learning for Quickest Change Detection in Markov   Transition Kernels",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Wuxia Chen",
      "Taposh Banerjee",
      "Vahid Tarokh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03953v1",
    "abstract": "We address the problem of quickest change detection in Markov processes with unknown transition kernels. The key idea is to learn the conditional score $\\nabla_{\\mathbf{y}} \\log p(\\mathbf{y}|\\mathbf{x})$ directly from sample pairs $( \\mathbf{x},\\mathbf{y})$, where both $\\mathbf{x}$ and $\\mathbf{y}$ are high-dimensional data generated by the same transition kernel. In this way, we avoid explicit likelihood evaluation and provide a practical way to learn the transition dynamics. Based on this estimation, we develop a score-based CUSUM procedure that uses conditional Hyvarinen score differences to detect changes in the kernel. To ensure bounded increments, we propose a truncated version of the statistic. With Hoeffding's inequality for uniformly ergodic Markov processes, we prove exponential lower bounds on the mean time to false alarm. We also prove asymptotic upper bounds on detection delay. These results give both theoretical guarantees and practical feasibility for score-based detection in high-dimensional Markov models.",
    "fetched_at": "2025-11-09T02:21:28.188235Z"
  },
  {
    "id": "2511.03963v1",
    "title": "Robust inference using density-powered Stein operators",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shinto Eguchi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03963v1",
    "abstract": "We introduce a density-power weighted variant for the Stein operator, called the $\\gamma$-Stein operator. This is a novel class of operators derived from the $\\gamma$-divergence, designed to build robust inference methods for unnormalized probability models. The operator's construction (weighting by the model density raised to a positive power $\\gamma$ inherently down-weights the influence of outliers, providing a principled mechanism for robustness. Applying this operator yields a robust generalization of score matching that retains the crucial property of being independent of the model's normalizing constant. We extend this framework to develop two key applications: the $\\gamma$-kernelized Stein discrepancy for robust goodness-of-fit testing, and $\\gamma$-Stein variational gradient descent for robust Bayesian posterior approximation. Empirical results on contaminated Gaussian and quartic potential models show our methods significantly outperform standard baselines in both robustness and statistical efficiency.",
    "fetched_at": "2025-11-09T02:21:28.188131Z"
  },
  {
    "id": "2511.03966v1",
    "title": "PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in   Cognitive Diagnosis",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mingliang Hou",
      "Yinuo Wang",
      "Teng Guo",
      "Zitao Liu",
      "Wenzhou Dou",
      "Jiaqi Zheng",
      "Renqiang Luo",
      "Mi Tian",
      "Weiqi Luo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03966v1",
    "abstract": "The need to remove specific student data from cognitive diagnosis (CD) models has become a pressing requirement, driven by users' growing assertion of their \"right to be forgotten\". However, existing CD models are largely designed without privacy considerations and lack effective data unlearning mechanisms. Directly applying general purpose unlearning algorithms is suboptimal, as they struggle to balance unlearning completeness, model utility, and efficiency when confronted with the unique heterogeneous structure of CD models. To address this, our paper presents the first systematic study of the data unlearning problem for CD models, proposing a novel and efficient algorithm: hierarchical importanceguided forgetting (HIF). Our key insight is that parameter importance in CD models exhibits distinct layer wise characteristics. HIF leverages this via an innovative smoothing mechanism that combines individual and layer, level importance, enabling a more precise distinction of parameters associated with the data to be unlearned. Experiments on three real world datasets show that HIF significantly outperforms baselines on key metrics, offering the first effective solution for CD models to respond to user data removal requests and for deploying high-performance, privacy preserving AI systems",
    "fetched_at": "2025-11-09T02:21:28.188089Z"
  },
  {
    "id": "2511.03972v1",
    "title": "Non-Asymptotic Optimization and Generalization Bounds for Stochastic   Gauss-Newton in Overparameterized Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Semih Cayci"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03972v1",
    "abstract": "An important question in deep learning is how higher-order optimization methods affect generalization. In this work, we analyze a stochastic Gauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch sampling for training overparameterized deep neural networks with smooth activations in a regression setting. Our theoretical contributions are twofold. First, we establish finite-time convergence bounds via a variable-metric analysis in parameter space, with explicit dependencies on the batch size, network width and depth. Second, we derive non-asymptotic generalization bounds for SGN using uniform stability in the overparameterized regime, characterizing the impact of curvature, batch size, and overparameterization on generalization performance. Our theoretical results identify a favorable generalization regime for SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along the optimization path yields tighter stability bounds.",
    "fetched_at": "2025-11-09T02:21:28.188024Z"
  },
  {
    "id": "2511.03976v1",
    "title": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation   Prediction",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.GN",
      "GN"
    ],
    "authors": [
      "Xu Zou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03976v1",
    "abstract": "Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable evolutionary trajectory, characterized by the continual emergence of immune-evasive variants. This poses persistent challenges to public health and vaccine development.   While large-scale generative pre-trained transformers (GPTs) have revolutionized the modeling of sequential data, their direct applications to noisy viral genomic sequences are limited. In this paper, we introduce PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based on evolutionary trajectories derived from phylogenetic trees rather than raw RNA sequences. This method effectively mitigates sequencing noise and captures the hierarchical structure of viral evolution.   With a weighted training framework to address substantial geographical and temporal imbalances in global sequence data, PETRA excels in predicting future SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide mutations and 17.10\\% for spike amino-acid mutations, compared to 0.49% and 6.64% respectively for the best baseline. PETRA also demonstrates its ability to aid in the real-time mutation prediction of major clades like 24F(XEC) and 25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra",
    "fetched_at": "2025-11-09T02:21:28.187983Z"
  },
  {
    "id": "2511.03980v1",
    "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit   Cultural Framing",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bram Bulté",
      "Ayla Rigouts Terryn"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03980v1",
    "abstract": "Large Language Models (LLMs) are rapidly being adopted by users across the globe, who interact with them in a diverse range of languages. At the same time, there are well-documented imbalances in the training data and optimisation objectives of this technology, raising doubts as to whether LLMs can represent the cultural diversity of their broad user base. In this study, we look at LLMs and cultural values and examine how prompt language and cultural framing influence model responses and their alignment with human values in different countries. We probe 10 LLMs with 63 items from the Hofstede Values Survey Module and World Values Survey, translated into 11 languages, and formulated as prompts with and without different explicit cultural perspectives. Our study confirms that both prompt language and cultural perspective produce variation in LLM outputs, but with an important caveat: While targeted prompting can, to a certain extent, steer LLM responses in the direction of the predominant values of the corresponding countries, it does not overcome the models' systematic bias toward the values associated with a restricted set of countries in our dataset: the Netherlands, Germany, the US, and Japan. All tested models, regardless of their origin, exhibit remarkably similar patterns: They produce fairly neutral responses on most topics, with selective progressive stances on issues such as social tolerance. Alignment with cultural values of human respondents is improved more with an explicit cultural perspective than with a targeted prompt language. Unexpectedly, combining both approaches is no more effective than cultural framing with an English prompt. These findings reveal that LLMs occupy an uncomfortable middle ground: They are responsive enough to changes in prompts to produce variation, but too firmly anchored to specific cultural defaults to adequately represent cultural diversity.",
    "fetched_at": "2025-11-09T02:21:28.187942Z"
  },
  {
    "id": "2511.03981v1",
    "title": "Structural Priors and Modular Adapters in the Composable Fine-Tuning   Algorithm of Large-Scale Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuxiao Wang",
      "Di Wu",
      "Feng Liu",
      "Zhimin Qiu",
      "Chenrui Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03981v1",
    "abstract": "This paper proposes a composable fine-tuning method that integrates graph structural priors with modular adapters to address the high computational cost and structural instability faced by large-scale pre-trained models in multi-task adaptation. The method introduces a relation matrix to model dependencies among tasks, explicitly encoding correlations between nodes and paths into graph structural priors, which provide unified structural constraints for adapter weight allocation and path selection. Modular adapters are embedded into different layers through low-rank mapping and a pluggable mechanism, enabling efficient cross-task composition and reuse under prior guidance. This mechanism not only improves parameter efficiency and training stability but also alleviates path conflicts and redundant computation in multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity, environmental sensitivity, and data sensitivity are conducted to systematically analyze key factors such as routing temperature, gating thresholds, and relation matrix regularization strength, verifying the consistency and superior performance of the method under structural constraints. The results demonstrate that the proposed framework significantly enhances task prediction accuracy, adapter weight allocation precision, and overall computational efficiency while maintaining model lightweight design, highlighting the synergistic advantages of graph priors and modular mechanisms in composable fine-tuning.",
    "fetched_at": "2025-11-09T02:21:28.187893Z"
  },
  {
    "id": "2511.03983v1",
    "title": "TwIST: Rigging the Lottery in Transformers with Independent Subnetwork   Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Michael Menezes",
      "Barbara Su",
      "Xinze Feng",
      "Yehya Farhat",
      "Hamza Shili",
      "Anastasios Kyrillidis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03983v1",
    "abstract": "We introduce TwIST, a distributed training framework for efficient large language model (LLM) sparsification. TwIST trains multiple subnetworks in parallel, periodically aggregates their parameters, and resamples new subnetworks during training. This process identifies high-quality subnetworks (\"golden tickets\") without requiring post-training procedures such as calibration or Hessian-based recovery. As a result, TwIST enables zero-cost pruning at deployment time while achieving perplexity competitive with state-of-the-art post-training sparsification methods. The benefits are most pronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly outperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64 for the closest prior approach. Unlike unstructured pruning, TwIST produces structured, dense matrices that offer practical inference speedups and memory reductions on commodity hardware (e.g., CPUs) that do not support efficient sparse computation. TwIST provides an efficient training-time path to deployable sparse LLMs without additional fine-tuning or recovery overhead.",
    "fetched_at": "2025-11-09T02:21:28.187840Z"
  },
  {
    "id": "2511.03986v1",
    "title": "Use of Continuous Glucose Monitoring with Machine Learning to Identify   Metabolic Subphenotypes and Inform Precision Lifestyle Changes",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Ahmed A. Metwally",
      "Heyjun Park",
      "Yue Wu",
      "Tracey McLaughlin",
      "Michael P. Snyder"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03986v1",
    "abstract": "The classification of diabetes and prediabetes by static glucose thresholds obscures the pathophysiological dysglycemia heterogeneity, primarily driven by insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This review demonstrates that continuous glucose monitoring and wearable technologies enable a paradigm shift towards non-invasive, dynamic metabolic phenotyping. We show evidence that machine learning models can leverage high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance tests to accurately predict gold-standard measures of muscle IR and beta-cell function. This personalized characterization extends to real-world nutrition, where an individual's unique postprandial glycemic response (PPGR) to standardized meals, such as the relative glucose spike to potatoes versus grapes, could serve as a biomarker for their metabolic subtype. Moreover, integrating wearable data reveals that habitual diet, sleep, and physical activity patterns, particularly their timing, are uniquely associated with specific metabolic dysfunctions, informing precision lifestyle interventions. The efficacy of dietary mitigators in attenuating PPGR is also shown to be phenotype-dependent. Collectively, this evidence demonstrates that CGM can deconstruct the complexity of early dysglycemia into distinct, actionable subphenotypes. This approach moves beyond simple glycemic control, paving the way for targeted nutritional, behavioral, and pharmacological strategies tailored to an individual's core metabolic defects, thereby paving the way for a new era of precision diabetes prevention.",
    "fetched_at": "2025-11-09T02:21:28.187726Z"
  },
  {
    "id": "2511.03993v1",
    "title": "Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible   Intelligence in Anomaly Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Berk Iskar",
      "Michael Taynnan Barros"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03993v1",
    "abstract": "Network anomaly detection systems encounter several challenges with traditional detectors trained offline. They become susceptible to concept drift and new threats such as zero-day or polymorphic attacks. To address this limitation, we propose a Ca$^{2+}$-modulated learning framework that draws inspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid, context-sensitive adaptation enables robust information processing. Our approach couples a multicellular astrocyte dynamics simulator with a deep neural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics through three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump uptake, and conductance-aware diffusion through gap junctions between cells. Evaluation of our proposed network on CTU-13 (Neris) network traffic data demonstrates the effectiveness of our biologically plausible approach. The Ca$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to $\\sim$98\\% accuracy with reduced false positives and negatives across multiple train/test splits. Importantly, this improved performance comes with negligible runtime overhead once Ca$^{2+}$ trajectories are precomputed. While demonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated learning framework offers a generic solution for streaming detection tasks that require rapid, biologically grounded adaptation to evolving data patterns.",
    "fetched_at": "2025-11-09T02:21:28.187671Z"
  },
  {
    "id": "2511.03995v1",
    "title": "Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shiyin Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03995v1",
    "abstract": "Software fuzzing has become a cornerstone in automated vulnerability discovery, yet existing mutation strategies often lack semantic awareness, leading to redundant test cases and slow exploration of deep program states. In this work, I present a hybrid fuzzing framework that integrates static and dynamic analysis with Large Language Model (LLM)-guided input mutation and semantic feedback. Static analysis extracts control-flow and data-flow information, which is transformed into structured prompts for the LLM to generate syntactically valid and semantically diverse inputs. During execution, I augment traditional coverage-based feedback with semantic feedback signals-derived from program state changes, exception types, and output semantics-allowing the fuzzer to prioritize inputs that trigger novel program behaviors beyond mere code coverage. I implement our approach atop AFL++, combining program instrumentation with embedding-based semantic similarity metrics to guide seed selection. Evaluation on real-world open-source targets, including libpng, tcpdump, and sqlite, demonstrates that our method achieves faster time-to-first-bug, higher semantic diversity, and a competitive number of unique bugs compared to state-of-the-art fuzzers. This work highlights the potential of combining LLM reasoning with semantic-aware feedback to accelerate and deepen vulnerability discovery.",
    "fetched_at": "2025-11-09T02:21:28.187628Z"
  },
  {
    "id": "2511.04000v1",
    "title": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via   Synthetic Model Generations",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Kyaw Hpone Myint",
      "Zhe Wu",
      "Alexandre G. R. Day",
      "Giri Iyengar"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04000v1",
    "abstract": "Decision trees are widely used in high-stakes fields like finance and healthcare due to their interpretability. This work introduces an efficient, scalable method for generating synthetic pre-training data to enable meta-learning of decision trees. Our approach samples near-optimal decision trees synthetically, creating large-scale, realistic datasets. Using the MetaTree transformer architecture, we demonstrate that this method achieves performance comparable to pre-training on real-world data or with computationally expensive optimal decision trees. This strategy significantly reduces computational costs, enhances data generation flexibility, and paves the way for scalable and efficient meta-learning of interpretable decision tree models.",
    "fetched_at": "2025-11-09T02:21:28.187589Z"
  },
  {
    "id": "2511.04001v1",
    "title": "Accelerating scientific discovery with the common task framework",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "J. Nathan Kutz",
      "Peter Battaglia",
      "Michael Brenner",
      "Kevin Carlberg",
      "Aric Hagberg",
      "Shirley Ho",
      "Stephan Hoyer",
      "Henning Lange",
      "Hod Lipson",
      "Michael W. Mahoney",
      "Frank Noe",
      "Max Welling",
      "Laure Zanna",
      "Francis Zhu",
      "Steven L. Brunton"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04001v1",
    "abstract": "Machine learning (ML) and artificial intelligence (AI) algorithms are transforming and empowering the characterization and control of dynamic systems in the engineering, physical, and biological sciences. These emerging modeling paradigms require comparative metrics to evaluate a diverse set of scientific objectives, including forecasting, state reconstruction, generalization, and control, while also considering limited data scenarios and noisy measurements. We introduce a common task framework (CTF) for science and engineering, which features a growing collection of challenge data sets with a diverse set of practical and common objectives. The CTF is a critically enabling technology that has contributed to the rapid advance of ML/AI algorithms in traditional applications such as speech recognition, language processing, and computer vision. There is a critical need for the objective metrics of a CTF to compare the diverse algorithms being rapidly developed and deployed in practice today across science and engineering.",
    "fetched_at": "2025-11-09T02:21:28.187544Z"
  },
  {
    "id": "2511.04002v1",
    "title": "Memory- and Latency-Constrained Inference of Large Language Models via   Adaptive Split Computing",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mingyu Sung",
      "Vikas Palakonda",
      "Suhwan Im",
      "Sunghwan Moon",
      "Il-Min Kim",
      "Sangseok Yun",
      "Jae-Mo Kang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04002v1",
    "abstract": "Large language models (LLMs) have achieved near-human performance across diverse reasoning tasks, yet their deployment on resource-constrained Internet-of-Things (IoT) devices remains impractical due to massive parameter footprints and memory-intensive autoregressive decoding. While split computing offers a promising solution by partitioning model execution between edge devices and cloud servers, existing approaches fail to address the unique challenges of autoregressive inference, particularly the iterative token generation process and expanding key-value (KV) cache requirements. This work introduces the first autoregressive-aware split computing framework designed explicitly for LLM deployment on edge devices. Our approach makes three key contributions. First, we develop one-point split compression (OPSC), a mixed-precision quantization scheme that prevents out-of-memory failures by strategically partitioning models into front-end and back-end segments with different precision levels. Second, we propose a two-stage intermediate compression pipeline that combines threshold splitting (TS) and token-wise adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations while dramatically reducing communication overhead. Third, we formulate a unified optimization framework that jointly selects optimal split points, quantization settings, and sequence lengths to satisfy strict memory and latency constraints. Extensive evaluations across diverse LLMs and hardware platforms demonstrate superior performance compared to state-of-the-art quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework achieves a 1.49 inference speedup and significant communication overhead reduction while maintaining or improving model accuracy.",
    "fetched_at": "2025-11-09T02:21:28.187460Z"
  },
  {
    "id": "2511.04020v1",
    "title": "Abductive Inference in Retrieval-Augmented Language Models: Generating   and Validating Missing Premises",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shiyin Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04020v1",
    "abstract": "Large Language Models (LLMs) enhanced with retrieval -- commonly referred to as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved evidence is incomplete, leaving gaps in the reasoning process. In such cases, \\emph{abductive inference} -- the process of generating plausible missing premises to explain observations -- offers a principled approach to bridge these gaps. In this paper, we propose a framework that integrates abductive inference into retrieval-augmented LLMs. Our method detects insufficient evidence, generates candidate missing premises, and validates them through consistency and plausibility checks. Experimental results on abductive reasoning and multi-hop QA benchmarks show that our approach improves both answer accuracy and reasoning faithfulness. This work highlights abductive inference as a promising direction for enhancing the robustness and explainability of RAG systems.",
    "fetched_at": "2025-11-09T02:21:28.187395Z"
  },
  {
    "id": "2511.04035v1",
    "title": "WST: Weakly Supervised Transducer for Automatic Speech Recognition",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Dongji Gao",
      "Chenda Liao",
      "Changliang Liu",
      "Matthew Wiesner",
      "Leibny Paola Garcia",
      "Daniel Povey",
      "Sanjeev Khudanpur",
      "Jian Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04035v1",
    "abstract": "The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily on large-scale, high-quality annotated data, which are often costly and difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised Transducer (WST), which integrates a flexible training graph designed to robustly handle errors in the transcripts without requiring additional confidence estimation or auxiliary pre-trained models. Empirical evaluations on synthetic and industrial datasets reveal that WST effectively maintains performance even with transcription error rates of up to 70%, consistently outperforming existing Connectionist Temporal Classification (CTC)-based weakly supervised approaches, such as Bypass Temporal Classification (BTC) and Omni-Temporal Classification (OTC). These results demonstrate the practical utility and robustness of WST in realistic ASR settings. The implementation will be publicly available.",
    "fetched_at": "2025-11-09T02:21:28.187309Z"
  },
  {
    "id": "2511.04040v1",
    "title": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch   Dynamic Selection with Reconstructive Pre-Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NE",
      "NE",
      "q-bio.BM",
      "BM"
    ],
    "authors": [
      "Xiaoling Luo",
      "Peng Chen",
      "Chengliang Liu",
      "Xiaopeng Jin",
      "Jie Wen",
      "Yumeng Liu",
      "Junsong Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04040v1",
    "abstract": "Multimodal protein features play a crucial role in protein function prediction. However, these features encompass a wide range of information, ranging from structural data and sequence features to protein attributes and interaction networks, making it challenging to decipher their complex interconnections. In this work, we propose a multimodal protein function prediction method (DSRPGO) by utilizing dynamic selection and reconstructive pre-training mechanisms. To acquire complex protein information, we introduce reconstructive pre-training to mine more fine-grained information with low semantic levels. Moreover, we put forward the Bidirectional Interaction Module (BInM) to facilitate interactive learning among multimodal features. Additionally, to address the difficulty of hierarchical multi-label classification in this task, a Dynamic Selection Module (DSM) is designed to select the feature representation that is most conducive to current protein function prediction. Our proposed DSRPGO model improves significantly in BPO, MFO, and CCO on human datasets, thereby outperforming other benchmark models.",
    "fetched_at": "2025-11-09T02:21:28.187251Z"
  },
  {
    "id": "2511.04042v1",
    "title": "An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster   Search and Rescue",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kailun Ji",
      "Xiaoyu Hu",
      "Xinyu Zhang",
      "Jun Chen"
    ],
    "institution": "School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China",
    "link": "http://arxiv.org/pdf/2511.04042v1",
    "abstract": "Large-scale disaster Search And Rescue (SAR) operations are persistently challenged by complex terrain and disrupted communications. While Unmanned Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area search and supply delivery, yet their effective coordination places a significant cognitive burden on human operators. The core human-machine collaboration bottleneck lies in the ``intention-to-action gap'', which is an error-prone process of translating a high-level rescue objective into a low-level swarm command under high intensity and pressure. To bridge this gap, this study proposes a novel LLM-CRF system that leverages Large Language Models (LLMs) to model and augment human-swarm teaming cognition. The proposed framework initially captures the operator's intention through natural and multi-modal interactions with the device via voice or graphical annotations. It then employs the LLM as a cognitive engine to perform intention comprehension, hierarchical task decomposition, and mission planning for the UAV swarm. This closed-loop framework enables the swarm to act as a proactive partner, providing active feedback in real-time while reducing the need for manual monitoring and control, which considerably advances the efficacy of the SAR task. We evaluate the proposed framework in a simulated SAR scenario. Experimental results demonstrate that, compared to traditional order and command-based interfaces, the proposed LLM-driven approach reduced task completion time by approximately $64.2\\%$ and improved task success rate by $7\\%$. It also leads to a considerable reduction in subjective cognitive workload, with NASA-TLX scores dropping by $42.9\\%$. This work establishes the potential of LLMs to create more intuitive and effective human-swarm collaborations in high-stakes scenarios.",
    "fetched_at": "2025-11-09T02:21:28.187191Z"
  },
  {
    "id": "2511.04048v1",
    "title": "Explorability in Pushdown Automata",
    "date": "2025-11-06",
    "tags": [
      "cs.FL",
      "FL",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ayaan Bedi",
      "Karoliina Lehtinen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04048v1",
    "abstract": "We study explorability, a measure of nondeterminism in pushdown automata, which generalises history-determinism. An automaton is k-explorable if, while reading the input, it suffices to follow k concurrent runs, built step-by-step based only on the input seen so far, to construct an accepting one, if it exists. We show that the class of explorable PDAs lies strictly between history-deterministic and fully nondeterministic PDAs in terms of both expressiveness and succinctness. In fact increasing explorability induces an infinite hierarchy: each level k defines a strictly more expressive class than level k-1, yet the entire class remains less expressive than general nondeterministic PDAs. We then introduce a parameterized notion of explorability, where the number of runs may depend on input length, and show that exponential explorability precisely captures the context-free languages. Finally, we prove that explorable PDAs can be doubly exponentially more succinct than history-deterministic ones, and that the succinctness gap between deterministic and 2-explorable PDAs is not recursively enumerable. These results position explorability as a robust and operationally meaningful measure of nondeterminism for pushdown systems.",
    "fetched_at": "2025-11-09T02:21:28.187150Z"
  },
  {
    "id": "2511.04053v1",
    "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in   Large Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hirohane Takagi",
      "Gouki Minegishi",
      "Shota Kizawa",
      "Issey Sukeda",
      "Hitomi Yanaka"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04053v1",
    "abstract": "Although behavioral studies have documented numerical reasoning errors in large language models (LLMs), the underlying representational mechanisms remain unclear. We hypothesize that numerical attributes occupy shared latent subspaces and investigate two questions:(1) How do LLMs internally integrate multiple numerical attributes of a single entity? (2)How does irrelevant numerical context perturb these representations and their downstream outputs? To address these questions, we combine linear probing with partial correlation analysis and prompt-based vulnerability tests across models of varying sizes. Our results show that LLMs encode real-world numerical correlations but tend to systematically amplify them. Moreover, irrelevant context induces consistent shifts in magnitude representations, with downstream effects that vary by model size. These findings reveal a vulnerability in LLM decision-making and lay the groundwork for fairer, representation-aware control under multi-attribute entanglement.",
    "fetched_at": "2025-11-09T02:21:28.187105Z"
  },
  {
    "id": "2511.04063v1",
    "title": "DartQuant: Efficient Rotational Distribution Calibration for LLM   Quantization",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yuantian Shao",
      "Yuanteng Chen",
      "Peisong Wang",
      "Jianlin Yu",
      "Jing Lin",
      "Yiwu Yao",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04063v1",
    "abstract": "Quantization plays a crucial role in accelerating the inference of large-scale models, and rotational matrices have been shown to effectively improve quantization performance by smoothing outliers. However, end-to-end fine-tuning of rotational optimization algorithms incurs high computational costs and is prone to overfitting. To address this challenge, we propose an efficient distribution-aware rotational calibration method, DartQuant, which reduces the complexity of rotational optimization by constraining the distribution of the activations after rotation. This approach also effectively reduces reliance on task-specific losses, thereby mitigating the risk of overfitting. Additionally, we introduce the QR-Orth optimization scheme, which replaces expensive alternating optimization with a more efficient solution. In a variety of model quantization experiments, DartQuant demonstrates superior performance. Compared to existing methods, it achieves 47$\\times$ acceleration and 10$\\times$ memory savings for rotational optimization on a 70B model. Furthermore, it is the first to successfully complete rotational calibration for a 70B model on a single 3090 GPU, making quantization of large language models feasible in resource-constrained environments. Code is available at https://github.com/CAS-CLab/DartQuant.git.",
    "fetched_at": "2025-11-09T02:21:28.187058Z"
  },
  {
    "id": "2511.04070v1",
    "title": "T-FIX: Text-Based Explanations with Features Interpretable to eXperts",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shreya Havaldar",
      "Helen Jin",
      "Chaehyeon Kim",
      "Anton Xue",
      "Weiqiu You",
      "Marco Gatti",
      "Bhuvnesh Jain",
      "Helen Qu",
      "Daniel A Hashimoto",
      "Amin Madani",
      "Rajat Deo",
      "Sameed Ahmed M. Khatana",
      "Gary E. Weissman",
      "Lyle Ungar",
      "Eric Wong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04070v1",
    "abstract": "As LLMs are deployed in knowledge-intensive settings (e.g., surgery, astronomy, therapy), users expect not just answers, but also meaningful explanations for those answers. In these settings, users are often domain experts (e.g., doctors, astrophysicists, psychologists) who require explanations that reflect expert-level reasoning. However, current evaluation schemes primarily emphasize plausibility or internal faithfulness of the explanation, which fail to capture whether the content of the explanation truly aligns with expert intuition. We formalize expert alignment as a criterion for evaluating explanations with T-FIX, a benchmark spanning seven knowledge-intensive domains. In collaboration with domain experts, we develop novel metrics to measure the alignment of LLM explanations with expert judgment.",
    "fetched_at": "2025-11-09T02:21:28.187000Z"
  },
  {
    "id": "2511.04069v1",
    "title": "Pediatric Appendicitis Detection from Ultrasound Images",
    "date": "2025-11-06",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04069v1",
    "abstract": "Pediatric appendicitis remains one of the most common causes of acute abdominal pain in children, and its diagnosis continues to challenge clinicians due to overlapping symptoms and variable imaging quality. This study aims to develop and evaluate a deep learning model based on a pretrained ResNet architecture for automated detection of appendicitis from ultrasound images. We used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound scans, laboratory data, and clinical scores from pediatric patients admitted with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each subject had 1 to 15 ultrasound views covering the right lower quadrant, appendix, lymph nodes, and related structures. For the image based classification task, ResNet was fine tuned to distinguish appendicitis from non-appendicitis cases. Images were preprocessed by normalization, resizing, and augmentation to enhance generalization. The proposed ResNet model achieved an overall accuracy of 93.44, precision of 91.53, and recall of 89.8, demonstrating strong performance in identifying appendicitis across heterogeneous ultrasound views. The model effectively learned discriminative spatial features, overcoming challenges posed by low contrast, speckle noise, and anatomical variability in pediatric imaging.",
    "fetched_at": "2025-11-09T02:21:28.186924Z"
  },
  {
    "id": "2511.04071v1",
    "title": "Left Atrial Segmentation with nnU-Net Using MRI",
    "date": "2025-11-06",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04071v1",
    "abstract": "Accurate segmentation of the left atrium (LA) from cardiac MRI is critical for guiding atrial fibrillation (AF) ablation and constructing biophysical cardiac models. Manual delineation is time-consuming, observer-dependent, and impractical for large-scale or time-sensitive clinical workflows. Deep learning methods, particularly convolutional architectures, have recently demonstrated superior performance in medical image segmentation tasks. In this study, we applied the nnU-Net framework, an automated, self-configuring deep learning segmentation architecture, to the Left Atrial Segmentation Challenge 2013 dataset. The dataset consists of thirty MRI scans with corresponding expert-annotated masks. The nnU-Net model automatically adapted its preprocessing, network configuration, and training pipeline to the characteristics of the MRI data. Model performance was quantitatively evaluated using the Dice similarity coefficient (DSC), and qualitative results were compared against expert segmentations. The proposed nnUNet model achieved a mean Dice score of 93.5, demonstrating high overlap with expert annotations and outperforming several traditional segmentation approaches reported in previous studies. The network exhibited robust generalization across variations in left atrial shape, contrast, and image quality, accurately delineating both the atrial body and proximal pulmonary veins.",
    "fetched_at": "2025-11-09T02:21:28.186884Z"
  },
  {
    "id": "2511.04072v1",
    "title": "Plan of Knowledge: Retrieval-Augmented Large Language Models for   Temporal Knowledge Graph Question Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xinying Qian",
      "Ying Zhang",
      "Yu Zhao",
      "Baohang Zhou",
      "Xuhui Sui",
      "Xiaojie Yuan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04072v1",
    "abstract": "Temporal Knowledge Graph Question Answering (TKGQA) aims to answer time-sensitive questions by leveraging factual information from Temporal Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG embeddings or graph neural networks to inject temporal knowledge, they fail to fully understand the complex semantic information of time constraints. Recently, Large Language Models (LLMs) have shown remarkable progress, benefiting from their strong semantic understanding and reasoning generalization capabilities. However, their temporal reasoning ability remains limited. LLMs frequently suffer from hallucination and a lack of knowledge. To address these limitations, we propose the Plan of Knowledge framework with a contrastive temporal retriever, which is named PoK. Specifically, the proposed Plan of Knowledge module decomposes a complex temporal question into a sequence of sub-objectives from the pre-defined tools, serving as intermediate guidance for reasoning exploration. In parallel, we construct a Temporal Knowledge Store (TKS) with a contrastive retrieval framework, enabling the model to selectively retrieve semantically and temporally aligned facts from TKGs. By combining structured planning with temporal knowledge retrieval, PoK effectively enhances the interpretability and factual consistency of temporal reasoning. Extensive experiments on four benchmark TKGQA datasets demonstrate that PoK significantly improves the retrieval precision and reasoning accuracy of LLMs, surpassing the performance of the state-of-the-art TKGQA methods by 56.0% at most.",
    "fetched_at": "2025-11-09T02:21:28.186842Z"
  },
  {
    "id": "2511.04073v1",
    "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with   Multiple Filters",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.DB",
      "DB",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Ananya Sutradhar",
      "Suryansh Gupta",
      "Ravishankar Krishnaswamy",
      "Haiyang Xu",
      "Aseem Rastogi",
      "Gopal Srinivasa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04073v1",
    "abstract": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest vectors for a query vector from a dataset. It enforces that a specified set of discrete labels $S$ for the query must be included in the labels of each retrieved vector. Existing graph-based methods typically incorporate filter awareness by assigning fixed penalties or prioritizing nodes based on filter satisfaction. However, since these methods use fixed, data in- dependent penalties, they often fail to generalize across datasets with diverse label and vector distributions. In this work, we propose a principled alternative that learns the optimal trade-off between vector distance and filter match directly from the data, rather than relying on fixed penalties. We formulate this as a constrained linear optimization problem, deriving weights that better reflect the underlying filter distribution and more effectively address the filtered ANN search problem. These learned weights guide both the search process and index construction, leading to graph structures that more effectively capture the underlying filter distribution and filter semantics. Our experiments demonstrate that adapting the distance function to the data significantly im- proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible and generalizable framework for the filtered ANN search problem.",
    "fetched_at": "2025-11-09T02:21:28.186786Z"
  },
  {
    "id": "2511.04077v1",
    "title": "The truth is no diaper: Human and AI-generated associations to emotional   words",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Špela Vintar",
      "Jan Jona Javoršek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04077v1",
    "abstract": "Human word associations are a well-known method of gaining insight into the internal mental lexicon, but the responses spontaneously offered by human participants to word cues are not always predictable as they may be influenced by personal experience, emotions or individual cognitive styles. The ability to form associative links between seemingly unrelated concepts can be the driving mechanisms of creativity. We perform a comparison of the associative behaviour of humans compared to large language models. More specifically, we explore associations to emotionally loaded words and try to determine whether large language models generate associations in a similar way to humans. We find that the overlap between humans and LLMs is moderate, but also that the associations of LLMs tend to amplify the underlying emotional load of the stimulus, and that they tend to be more predictable and less creative than human ones.",
    "fetched_at": "2025-11-09T02:21:28.186681Z"
  },
  {
    "id": "2511.04079v1",
    "title": "Improving the Performance of Radiology Report De-identification with   Large-Scale Training and Benchmarking Against Cloud Vendor Methods",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Eva Prakash",
      "Maayane Attias",
      "Pierre Chambon",
      "Justin Xu",
      "Steven Truong",
      "Jean-Benoit Delbrouck",
      "Tessa Cook",
      "Curtis Langlotz"
    ],
    "institution": "Stanford",
    "link": "http://arxiv.org/pdf/2511.04079v1",
    "abstract": "Objective: To enhance automated de-identification of radiology reports by scaling transformer-based models through extensive training datasets and benchmarking performance against commercial cloud vendor systems for protected health information (PHI) detection. Materials and Methods: In this retrospective study, we built upon a state-of-the-art, transformer-based, PHI de-identification pipeline by fine-tuning on two large annotated radiology corpora from Stanford University, encompassing chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports and introducing an additional PHI category (AGE) into the architecture. Model performance was evaluated on test sets from Stanford and the University of Pennsylvania (Penn) for token-level PHI detection. We further assessed (1) the stability of synthetic PHI generation using a \"hide-in-plain-sight\" method and (2) performance against commercial systems. Precision, recall, and F1 scores were computed across all PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining the previous state-of-the-art model performance. Synthetic PHI evaluation showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50 independently de-identified Penn datasets. Our model outperformed all vendor systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754). Discussion: Large-scale, multimodal training improved cross-institutional generalization and robustness. Synthetic PHI generation preserved data utility while ensuring privacy. Conclusion: A transformer-based de-identification model trained on diverse radiology datasets outperforms prior academic and commercial systems in PHI detection and establishes a new benchmark for secure clinical text processing.",
    "fetched_at": "2025-11-09T02:21:28.186644Z"
  },
  {
    "id": "2511.04086v1",
    "title": "DeNoise: Learning Robust Graph Representations for Unsupervised   Graph-Level Anomaly Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qingfeng Chen",
      "Haojin Zeng",
      "Jingyi Jie",
      "Shichao Zhang",
      "Debo Cheng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04086v1",
    "abstract": "With the rapid growth of graph-structured data in critical domains, unsupervised graph-level anomaly detection (UGAD) has become a pivotal task. UGAD seeks to identify entire graphs that deviate from normal behavioral patterns. However, most Graph Neural Network (GNN) approaches implicitly assume that the training set is clean, containing only normal graphs, which is rarely true in practice. Even modest contamination by anomalous graphs can distort learned representations and sharply degrade performance. To address this challenge, we propose DeNoise, a robust UGAD framework explicitly designed for contaminated training data. It jointly optimizes a graph-level encoder, an attribute decoder, and a structure decoder via an adversarial objective to learn noise-resistant embeddings. Further, DeNoise introduces an encoder anchor-alignment denoising mechanism that fuses high-information node embeddings from normal graphs into all graph embeddings, improving representation quality while suppressing anomaly interference. A contrastive learning component then compacts normal graph embeddings and repels anomalous ones in the latent space. Extensive experiments on eight real-world datasets demonstrate that DeNoise consistently learns reliable graph-level representations under varying noise intensities and significantly outperforms state-of-the-art UGAD baselines.",
    "fetched_at": "2025-11-09T02:21:28.186581Z"
  },
  {
    "id": "2511.04090v1",
    "title": "Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for   Latin American Contexts",
    "date": "2025-11-06",
    "tags": [
      "cs.SI",
      "SI",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Brigitte A. Mora-Reyes",
      "Jennifer A. Drewyor",
      "Abel A. Reyes-Angulo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04090v1",
    "abstract": "Artificial intelligence (AI) systems often reflect biases from economically advanced regions, marginalizing contexts in economically developing regions like Latin America due to imbalanced datasets. This paper examines AI representations of diverse Latin American contexts, revealing disparities between data from economically advanced and developing regions. We highlight how the dominance of English over Spanish, Portuguese, and indigenous languages such as Quechua and Nahuatl perpetuates biases, framing Latin American perspectives through a Western lens. To address this, we introduce a culturally aware dataset rooted in Latin American history and socio-political contexts, challenging Eurocentric models. We evaluate six language models on questions testing cultural context awareness, using a novel Cultural Expressiveness metric, statistical tests, and linguistic analyses. Our findings show that some models better capture Latin American perspectives, while others exhibit significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our dataset improves its cultural expressiveness by 42.9%, advancing equitable AI development. We advocate for equitable AI by prioritizing datasets that reflect Latin American history, indigenous knowledge, and diverse languages, while emphasizing community-centered approaches to amplify marginalized voices.",
    "fetched_at": "2025-11-09T02:21:28.186527Z"
  },
  {
    "id": "2511.04092v1",
    "title": "An Automated Theorem Generator with Theoretical Foundation Based on   Rectangular Standard Contradiction",
    "date": "2025-11-06",
    "tags": [
      "cs.LO",
      "LO",
      "cs.AI",
      "AI",
      "math.LO"
    ],
    "authors": [
      "Yang Xu",
      "Peiyao Liu",
      "Shuwei Chen",
      "Jun Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04092v1",
    "abstract": "Currently, there is a lack of rigorous theoretical system for systematically generating non-trivial and logically valid theorems. Addressing this critical gap, this paper conducts research to propose a novel automated theorem generation theory and tool. Based on the concept of standard contradiction which possesses unique deductive advantages, this paper defines and proves, for the first time, a new logical structure known as rectangular standard contradiction. Centered on this structure, a complete Automated Theorem Generation (ATG) theory is put forward. Theoretical proofs clarify two core properties of rectangular standard contradiction: first, it is a standard contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy (the remaining clause set becomes satisfiable after removing any clause). Leveraging these properties, this paper proves that partitioning a rectangular standard contradiction into a premise subset $A$ and negation of its complement $H$, a valid theorem $A \\vdash \\neg H$ can be formed, and all such theorems are logically equivalent. To implement this theory, an efficient template-based ATG algorithm is designed, and a Rectangular Automated Theorem Generator is developed. This research enables machines to transition from \"verifiers\" to \"discoverers\", opening up new avenues for fundamental research in the fields of logic and artificial intelligence.",
    "fetched_at": "2025-11-09T02:21:28.186482Z"
  },
  {
    "id": "2511.04093v1",
    "title": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question   Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuanning Cui",
      "Zequn Sun",
      "Wei Hu",
      "Zhangjie Fu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04093v1",
    "abstract": "Large language models (LLMs) excel at reasoning but struggle with knowledge-intensive questions due to limited context and parametric knowledge. However, existing methods that rely on finetuned LLMs or GNN retrievers are limited by dataset-specific tuning and scalability on large or unseen graphs. We propose the LLM-KGFR collaborative framework, where an LLM works with a structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR encodes relations using LLM-generated descriptions and initializes entities based on their roles in the question, enabling zero-shot generalization to unseen KGs. To handle large graphs efficiently, it employs Asymmetric Progressive Propagation (APP)- a stepwise expansion that selectively limits high-degree nodes while retaining informative paths. Through node-, edge-, and path-level interfaces, the LLM iteratively requests candidate answers, supporting facts, and reasoning paths, forming a controllable reasoning loop. Experiments demonstrate that LLM-KGFR achieves strong performance while maintaining scalability and generalization, providing a practical solution for KG-augmented reasoning.",
    "fetched_at": "2025-11-09T02:21:28.186433Z"
  },
  {
    "id": "2511.04094v1",
    "title": "KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and   Governance in Korea",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hyungjong Na",
      "Wonho Song",
      "Seungyong Han",
      "Donghyeon Jo",
      "Sejin Myung",
      "Hyungjoon Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04094v1",
    "abstract": "This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011 and 2024. After excluding financial firms, firms with non-December fiscal year ends, capital impairment, and negative pre-tax income, the final dataset consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed to treat corporate tax avoidance as a predictor variable and link it to multiple domains, including earnings management (accrual- and activity-based), profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE, INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance itself is measured using complementary indicators cash effective tax rate (CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA, TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is its balanced panel structure with standardized variables and its consistency with international literature on the distribution and correlation of core indicators. At the same time, it reflects distinctive institutional features of Korean firms, such as concentrated ownership, high foreign shareholding, and elevated liquidity ratios, providing both international comparability and contextual uniqueness. KoTaP enables applications in benchmarking econometric and deep learning models, external validity checks, and explainable AI analyses. It further supports policy evaluation, audit planning, and investment analysis, making it a critical open resource for accounting, finance, and interdisciplinary research.",
    "fetched_at": "2025-11-09T02:21:28.186389Z"
  },
  {
    "id": "2511.04103v1",
    "title": "A Characterization of List Language Identification in the Limit",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Moses Charikar",
      "Chirag Pabbaraju",
      "Ambuj Tewari"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04103v1",
    "abstract": "We study the problem of language identification in the limit, where given a sequence of examples from a target language, the goal of the learner is to output a sequence of guesses for the target language such that all the guesses beyond some finite time are correct. Classical results of Gold showed that language identification in the limit is impossible for essentially any interesting collection of languages. Later, Angluin gave a precise characterization of language collections for which this task is possible. Motivated by recent positive results for the related problem of language generation, we revisit the classic language identification problem in the setting where the learner is given the additional power of producing a list of $k$ guesses at each time step. The goal is to ensure that beyond some finite time, one of the guesses is correct at each time step.   We give an exact characterization of collections of languages that can be $k$-list identified in the limit, based on a recursive version of Angluin's characterization (for language identification with a list of size $1$). This further leads to a conceptually appealing characterization: A language collection can be $k$-list identified in the limit if and only if the collection can be decomposed into $k$ collections of languages, each of which can be identified in the limit (with a list of size $1$). We also use our characterization to establish rates for list identification in the statistical setting where the input is drawn as an i.i.d. stream from a distribution supported on some language in the collection. Our results show that if a collection is $k$-list identifiable in the limit, then the collection can be $k$-list identified at an exponential rate, and this is best possible. On the other hand, if a collection is not $k$-list identifiable in the limit, then it cannot be $k$-list identified at any rate that goes to zero.",
    "fetched_at": "2025-11-09T02:21:28.186335Z"
  },
  {
    "id": "2511.04106v1",
    "title": "Sub-exponential Growth in Online Word Usage: A Piecewise Power-Law Model",
    "date": "2025-11-06",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Hayafumi Watanabe"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04106v1",
    "abstract": "The diffusion of ideas and language in society has conventionally been described by S-shaped models, such as the logistic curve. However, the role of sub-exponential growth -a slower than exponential pattern known in epidemiology- has been largely overlooked in broader social phenomena. Here, we present a piecewise power-law model to characterize complex growth curves with a few parameters. We systematically analyzed a large-scale dataset of approximately one billion Japanese blog articles linked to Wikipedia vocabulary, and observed consistent patterns in web search trend data (English, Spanish, and Japanese). Our analysis of the 2,965 selected items reveals that about 55% (1,625 items) were found to have no abrupt jumps and were well captured by one or two segments. For single-segment curves, we found that (i) the mode of the shape parameter alpha was near 0.5, indicating prevalent sub-exponential growth; (ii) the ultimate diffusion scale is primarily determined by the growth rate R, with minor contributions from alpha or the duration T; and (iii) alpha showed a tendency to vary with the nature of the topic, being smaller for niche/local topics and larger for widely shared ones. Furthermore, a micro-behavioral model distinguishing outward contact with strangers from inward interaction within their community suggests that alpha can be interpreted as an index of the preference for outward-oriented communication. These findings suggest that sub-exponential growth is a common pattern of social diffusion, and our model provides a practical framework for consistently describing, comparing, and interpreting complex and diverse growth curves.",
    "fetched_at": "2025-11-09T02:21:28.186285Z"
  },
  {
    "id": "2511.04108v1",
    "title": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How   Batch Prompting Suppresses Overthinking in Reasoning Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Wenmo Qiu",
      "Saurabh Srivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04108v1",
    "abstract": "Recent work has explored batch prompting as a strategy to amortize inference cost in large language models (LLMs). In this paper, we show that batching offers an additional, underappreciated benefit: it regularizes model behavior during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a comprehensive study across 13 diverse benchmarks and observe that batching improves accuracy while substantially reducing reasoning token usage, often by 3x-5x. Through detailed behavioral analysis, we find that batching suppresses overthinking, reduces hedging language (e.g., repetitive self-corrections), and encourages more decisive answers. Surprisingly, we also observe emergent collective effects in batched inference: models often generalize patterns from earlier examples to solve harder ones in the same batch. These findings position batching not just as a throughput optimization, but as a powerful inference-time regularizer for more efficient and reliable LLM reasoning.",
    "fetched_at": "2025-11-09T02:21:28.186242Z"
  },
  {
    "id": "2511.04114v1",
    "title": "Automated and Explainable Denial of Service Analysis for AI-Driven   Intrusion Detection Systems",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Paul Badu Yakubu",
      "Lesther Santana",
      "Mohamed Rahouti",
      "Yufeng Xin",
      "Abdellah Chehri",
      "Mohammed Aledhari"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04114v1",
    "abstract": "With the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks, it has become critical to develop more efficient and interpretable detection methods. Traditional detection systems often struggle with scalability and transparency, hindering real-time response and understanding of attack vectors. This paper presents an automated framework for detecting and interpreting DDoS attacks using machine learning (ML). The proposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to automate the selection and optimization of ML models and features, reducing the need for manual experimentation. SHapley Additive exPlanations (SHAP) is incorporated to enhance model interpretability, providing detailed insights into the contribution of individual features to the detection process. By combining TPOT's automated pipeline selection with SHAP interpretability, this approach improves the accuracy and transparency of DDoS detection. Experimental results demonstrate that key features such as mean backward packet length and minimum forward packet header length are critical in detecting DDoS attacks, offering a scalable and explainable cybersecurity solution.",
    "fetched_at": "2025-11-09T02:21:28.186205Z"
  },
  {
    "id": "2511.04120v1",
    "title": "RIDE: Difficulty Evolving Perturbation with Item Response Theory for   Mathematical Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xinyuan Li",
      "Murong Xu",
      "Wenbiao Tao",
      "Hanlun Zhu",
      "Yike Zhao",
      "Jipeng Zhang",
      "Yunshi Lan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04120v1",
    "abstract": "Large language models (LLMs) achieve high performance on mathematical reasoning, but these results can be inflated by training data leakage or superficial pattern matching rather than genuine reasoning. To this end, an adversarial perturbation-based evaluation is needed to measure true mathematical reasoning ability. Current rule-based perturbation methods often generate ill-posed questions and impede the systematic evaluation of question difficulty and the evolution of benchmarks. To bridge this gap, we propose RIDE, a novel adversarial question-rewriting framework that leverages Item Response Theory (IRT) to rigorously measure question difficulty and to generate intrinsically more challenging, well-posed variations of mathematical problems. We employ 35 LLMs to simulate students and build a difficulty ranker from their responses. This ranker provides a reward signal during reinforcement learning and guides a question-rewriting model to reformulate existing questions across difficulty levels. Applying RIDE to competition-level mathematical benchmarks yields perturbed versions that degrade advanced LLM performance, with experiments showing an average 21.73% drop across 26 models, thereby exposing limited robustness in mathematical reasoning and confirming the validity of our evaluation approach.",
    "fetched_at": "2025-11-09T02:21:28.186149Z"
  },
  {
    "id": "2511.04124v1",
    "title": "Decomposable Neuro Symbolic Regression",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04124v1",
    "abstract": "Symbolic regression (SR) models complex systems by discovering mathematical expressions that capture underlying relationships in observed data. However, most SR methods prioritize minimizing prediction error over identifying the governing equations, often producing overly complex or inaccurate expressions. To address this, we present a decomposable SR method that generates interpretable multivariate expressions leveraging transformer models, genetic algorithms (GAs), and genetic programming (GP). In particular, our explainable SR method distills a trained ``opaque'' regression model into mathematical expressions that serve as explanations of its computed function. Our method employs a Multi-Set Transformer to generate multiple univariate symbolic skeletons that characterize how each variable influences the opaque model's response. We then evaluate the generated skeletons' performance using a GA-based approach to select a subset of high-quality candidates before incrementally merging them via a GP-based cascade procedure that preserves their original skeleton structure. The final multivariate skeletons undergo coefficient optimization via a GA. We evaluated our method on problems with controlled and varying degrees of noise, demonstrating lower or comparable interpolation and extrapolation errors compared to two GP-based methods, three neural SR methods, and a hybrid approach. Unlike them, our approach consistently learned expressions that matched the original mathematical structure.",
    "fetched_at": "2025-11-09T02:21:28.186086Z"
  },
  {
    "id": "2511.04126v1",
    "title": "Automated Tennis Player and Ball Tracking with Court Keypoints Detection   (Hawk Eye System)",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Venkata Manikanta Desu",
      "Syed Fawaz Ali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04126v1",
    "abstract": "This study presents a complete pipeline for automated tennis match analysis. Our framework integrates multiple deep learning models to detect and track players and the tennis ball in real time, while also identifying court keypoints for spatial reference. Using YOLOv8 for player detection, a custom-trained YOLOv5 model for ball tracking, and a ResNet50-based architecture for court keypoint detection, our system provides detailed analytics including player movement patterns, ball speed, shot accuracy, and player reaction times. The experimental results demonstrate robust performance in varying court conditions and match scenarios. The model outputs an annotated video along with detailed performance metrics, enabling coaches, broadcasters, and players to gain actionable insights into the dynamics of the game.",
    "fetched_at": "2025-11-09T02:21:28.186044Z"
  },
  {
    "id": "2511.04128v1",
    "title": "DMSORT: An efficient parallel maritime multi-object tracking   architecture for unmanned vessel platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shengyu Tang",
      "Zeyuan Lu",
      "Jiazhi Dong",
      "Changdong Yu",
      "Xiaoyu Wang",
      "Yaohui Lyu",
      "Weihao Xia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04128v1",
    "abstract": "Accurate perception of the marine environment through robust multi-object tracking (MOT) is essential for ensuring safe vessel navigation and effective maritime surveillance. However, the complicated maritime environment often causes camera motion and subsequent visual degradation, posing significant challenges to MOT. To address this challenge, we propose an efficient Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the framework is a parallel tracker with affine compensation, which incorporates an object detection and re-identification (ReID) branch, along with a dedicated branch for dynamic camera motion estimation. Specifically, a Reversible Columnar Detection Network (RCDN) is integrated into the detection module to leverage multi-level visual features for robust object detection. Furthermore, a lightweight Transformer-based appearance extractor (Li-TAE) is designed to capture global contextual information and generate robust appearance features. Another branch decouples platform-induced and target-intrinsic motion by constructing a projective transformation, applying platform-motion compensation within the Kalman filter, and thereby stabilizing true object trajectories. Finally, a clustering-optimized feature fusion module effectively combines motion and appearance cues to ensure identity consistency under noise, occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT attains the fastest runtime among existing ReID-based MOT frameworks while maintaining high identity consistency and robustness to jitter and occlusion. Code is available at: https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.",
    "fetched_at": "2025-11-09T02:21:28.186008Z"
  },
  {
    "id": "2511.04132v1",
    "title": "Exploring the Feasibility of End-to-End Large Language Model as a   Compiler",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hongbin Zhang",
      "Shihao Gao",
      "Yang Liu",
      "Mingjie Xing",
      "Yanjun Wu",
      "Chen Zhao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04132v1",
    "abstract": "In recent years, end-to-end Large Language Model (LLM) technology has shown substantial advantages across various domains. As critical system software and infrastructure, compilers are responsible for transforming source code into target code. While LLMs have been leveraged to assist in compiler development and maintenance, their potential as an end-to-end compiler remains largely unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and its future directions. We designed the CompilerEval dataset and framework specifically to evaluate the capabilities of mainstream LLMs in source code comprehension and assembly code generation. In the evaluation, we analyzed various errors, explored multiple methods to improve LLM-generated code, and evaluated cross-platform compilation capabilities. Experimental results demonstrate that LLMs exhibit basic capabilities as compilers but currently achieve low compilation success rates. By optimizing prompts, scaling up the model, and incorporating reasoning methods, the quality of assembly code generated by LLMs can be significantly enhanced. Based on these findings, we maintain an optimistic outlook for LaaC and propose practical architectural designs and future research directions. We believe that with targeted training, knowledge-rich prompts, and specialized infrastructure, LaaC has the potential to generate high-quality assembly code and drive a paradigm shift in the field of compilation.",
    "fetched_at": "2025-11-09T02:21:28.185945Z"
  },
  {
    "id": "2511.04137v1",
    "title": "Learning from Online Videos at Inference Time for Computer-Use Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yujian Liu",
      "Ze Wang",
      "Hao Chen",
      "Ximeng Sun",
      "Xiaodong Yu",
      "Jialian Wu",
      "Jiang Liu",
      "Emad Barsoum",
      "Zicheng Liu",
      "Shiyu Chang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04137v1",
    "abstract": "Computer-use agents can operate computers and automate laborious tasks, but despite recent rapid progress, they still lag behind human users, especially when tasks require domain-specific procedural knowledge about particular applications, platforms, and multi-step workflows. Humans can bridge this gap by watching video tutorials: we search, skim, and selectively imitate short segments that match our current subgoal. In this paper, we study how to enable computer-use agents to learn from online videos at inference time effectively. We propose a framework that retrieves and filters tutorial videos, converts them into structured demonstration trajectories, and dynamically selects trajectories as in-context guidance during execution. Particularly, using a VLM, we infer UI actions, segment videos into short subsequences of actions, and assign each subsequence a textual objective. At inference time, a two-stage selection mechanism dynamically chooses a single trajectory to add in context at each step, focusing the agent on the most helpful local guidance for its next decision. Experiments on two widely used benchmarks show that our framework consistently outperforms strong base agents and variants that use only textual tutorials or transcripts. Analyses highlight the importance of trajectory segmentation and selection, action filtering, and visual information, suggesting that abundant online videos can be systematically distilled into actionable guidance that improves computer-use agents at inference time. Our code is available at https://github.com/UCSB-NLP-Chang/video_demo.",
    "fetched_at": "2025-11-09T02:21:28.185830Z"
  },
  {
    "id": "2511.04139v1",
    "title": "CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource   Cantonese",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Dazhong Chen",
      "Yi-Cheng Lin",
      "Yuchen Huang",
      "Ziwei Gong",
      "Di Jiang",
      "Zeying Xie",
      "Yi R.",
      "Fung"
    ],
    "institution": "May",
    "link": "http://arxiv.org/pdf/2511.04139v1",
    "abstract": "Automatic speech recognition (ASR) is critical for language accessibility, yet low-resource Cantonese remains challenging due to limited annotated data, six lexical tones, tone sandhi, and accent variation. Existing ASR models, such as Whisper, often suffer from high word error rates. Large audio-language models (LALMs), in contrast, can leverage broader contextual reasoning but still require explicit tonal and prosodic acoustic cues. We introduce CantoASR, a collaborative ASR-LALM error correction framework that integrates forced alignment for acoustic feature extraction, a LoRA-finetuned Whisper for improved tone discrimination, and an instruction-tuned Qwen-Audio for prosody-aware correction. Evaluations on spontaneous Cantonese data show substantial CER gains over Whisper-Large-V3. These findings suggest that integrating acoustic cues with LALM reasoning provides a scalable strategy for low-resource tonal and dialectal ASR.",
    "fetched_at": "2025-11-09T02:21:28.185764Z"
  },
  {
    "id": "2511.04144v1",
    "title": "Scaffolding Metacognition in Programming Education: Understanding   Student-AI Interactions and Design Implications",
    "date": "2025-11-06",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Boxuan Ma",
      "Huiyong Li",
      "Gen Li",
      "Li Chen",
      "Cheng Tang",
      "Yinjie Xie",
      "Chenghao Gu",
      "Atsushi Shimada",
      "Shin'ichi Konomi"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04144v1",
    "abstract": "Generative AI tools such as ChatGPT now provide novice programmers with unprecedented access to instant, personalized support. While this holds clear promise, their influence on students' metacognitive processes remains underexplored. Existing work has largely focused on correctness and usability, with limited attention to whether and how students' use of AI assistants supports or bypasses key metacognitive processes. This study addresses that gap by analyzing student-AI interactions through a metacognitive lens in university-level programming courses. We examined more than 10,000 dialogue logs collected over three years, complemented by surveys of students and educators. Our analysis focused on how prompts and responses aligned with metacognitive phases and strategies. Synthesizing these findings across data sources, we distill design considerations for AI-powered coding assistants that aim to support rather than supplant metacognitive engagement. Our findings provide guidance for developing educational AI tools that strengthen students' learning processes in programming education.",
    "fetched_at": "2025-11-09T02:21:28.185715Z"
  },
  {
    "id": "2511.04147v1",
    "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe   Reinforcement Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jiaming Zhang",
      "Yujie Yang",
      "Haoning Wang",
      "Liping Zhang",
      "Shengbo Eben Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04147v1",
    "abstract": "Safe reinforcement learning (safe RL) aims to respect safety requirements while optimizing long-term performance. In many practical applications, however, the problem involves an infinite number of constraints, known as semi-infinite safe RL (SI-safe RL). Such constraints typically appear when safety conditions must be enforced across an entire continuous parameter space, such as ensuring adequate resource distribution at every spatial location. In this paper, we propose exchange policy optimization (EPO), an algorithmic framework that achieves optimal policy performance and deterministic bounded safety. EPO works by iteratively solving safe RL subproblems with finite constraint sets and adaptively adjusting the active set through constraint expansion and deletion. At each iteration, constraints with violations exceeding the predefined tolerance are added to refine the policy, while those with zero Lagrange multipliers are removed after the policy update. This exchange rule prevents uncontrolled growth of the working set and supports effective policy training. Our theoretical analysis demonstrates that, under mild assumptions, strategies trained via EPO achieve performance comparable to optimal solutions with global constraint violations strictly remaining within a prescribed bound.",
    "fetched_at": "2025-11-09T02:21:28.185654Z"
  },
  {
    "id": "2511.04155v1",
    "title": "Learning to Land Anywhere: Transferable Generative Models for Aircraft   Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "I.2.6; I.5.1",
      "1"
    ],
    "authors": [
      "Olav Finne Praesteng Larsen",
      "Massimiliano Ruocco",
      "Michail Spitieris",
      "Abdulmajid Murad",
      "Martina Ragosta"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04155v1",
    "abstract": "Access to trajectory data is a key requirement for developing and validating Air Traffic Management (ATM) solutions, yet many secondary and regional airports face severe data scarcity. This limits the applicability of machine learning methods and the ability to perform large-scale simulations or \"what-if\" analyses. In this paper, we investigate whether generative models trained on data-rich airports can be efficiently adapted to data-scarce airports using transfer learning. We adapt state-of-the-art diffusion- and flow-matching-based architectures to the aviation domain and evaluate their transferability between Zurich (source) and Dublin (target) landing trajectory datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying amounts of local data, ranging from 0% to 100%. Results show that diffusion-based models achieve competitive performance with as little as 5% of the Dublin data and reach baseline-level performance around 20%, consistently outperforming models trained from scratch across metrics and visual inspections. Latent flow matching and latent diffusion models also benefit from pretraining, though with more variable gains, while flow matching models show weaker generalization. Despite challenges in capturing rare trajectory patterns, these findings demonstrate the potential of transfer learning to substantially reduce data requirements for trajectory generation in ATM, enabling realistic synthetic data generation even in environments with limited historical records.",
    "fetched_at": "2025-11-09T02:21:28.185524Z"
  },
  {
    "id": "2511.04157v1",
    "title": "Are We Aligned? A Preliminary Investigation of the Alignment of   Responsible AI Values between LLMs and Human Judgment",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Asma Yamani",
      "Malak Baslyman",
      "Moataz Ahmed"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04157v1",
    "abstract": "Large Language Models (LLMs) are increasingly employed in software engineering tasks such as requirements elicitation, design, and evaluation, raising critical questions regarding their alignment with human judgments on responsible AI values. This study investigates how closely LLMs' value preferences align with those of two human groups: a US-representative sample and AI practitioners. We evaluate 23 LLMs across four tasks: (T1) selecting key responsible AI values, (T2) rating their importance in specific contexts, (T3) resolving trade-offs between competing values, and (T4) prioritizing software requirements that embody those values. The results show that LLMs generally align more closely with AI practitioners than with the US-representative sample, emphasizing fairness, privacy, transparency, safety, and accountability. However, inconsistencies appear between the values that LLMs claim to uphold (Tasks 1-3) and the way they prioritize requirements (Task 4), revealing gaps in faithfulness between stated and applied behavior. These findings highlight the practical risk of relying on LLMs in requirements engineering without human oversight and motivate the need for systematic approaches to benchmark, interpret, and monitor value alignment in AI-assisted software development.",
    "fetched_at": "2025-11-09T02:21:28.185470Z"
  },
  {
    "id": "2511.04158v1",
    "title": "Deep Learning Approach for Clinical Risk Identification Using   Transformer Modeling of Heterogeneous EHR Data",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anzhuo Xie",
      "Wei-Chen Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04158v1",
    "abstract": "This study proposes a Transformer-based longitudinal modeling method to address challenges in clinical risk classification with heterogeneous Electronic Health Record (EHR) data, including irregular temporal patterns, large modality differences, and complex semantic structures. The method takes multi-source medical features as input and employs a feature embedding layer to achieve a unified representation of structured and unstructured data. A learnable temporal encoding mechanism is introduced to capture dynamic evolution under uneven sampling intervals. The core model adopts a multi-head self-attention structure to perform global dependency modeling on longitudinal sequences, enabling the aggregation of long-term trends and short-term fluctuations across different temporal scales. To enhance semantic representation, a semantic-weighted pooling module is designed to assign adaptive importance to key medical events, improving the discriminative ability of risk-related features. Finally, a linear mapping layer generates individual-level risk scores. Experimental results show that the proposed model outperforms traditional machine learning and temporal deep learning models in accuracy, recall, precision, and F1-Score, achieving stable and precise risk identification in multi-source heterogeneous EHR environments and providing an efficient and reliable framework for clinical intelligent decision-making.",
    "fetched_at": "2025-11-09T02:21:28.185425Z"
  },
  {
    "id": "2511.04160v1",
    "title": "On Joint Regularization and Calibration in Deep Ensembles",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Laurits Fredsgaard",
      "Mikkel N. Schmidt"
    ],
    "institution": "Department of Applied Mathematics and Computer Science, Technical University of Denmark",
    "link": "http://arxiv.org/pdf/2511.04160v1",
    "abstract": "Deep ensembles are a powerful tool in machine learning, improving both model performance and uncertainty calibration. While ensembles are typically formed by training and tuning models individually, evidence suggests that jointly tuning the ensemble can lead to better performance. This paper investigates the impact of jointly tuning weight decay, temperature scaling, and early stopping on both predictive performance and uncertainty quantification. Additionally, we propose a partially overlapping holdout strategy as a practical compromise between enabling joint evaluation and maximizing the use of data for training. Our results demonstrate that jointly tuning the ensemble generally matches or improves performance, with significant variation in effect size across different tasks and metrics. We highlight the trade-offs between individual and joint optimization in deep ensemble training, with the overlapping holdout strategy offering an attractive practical solution. We believe our findings provide valuable insights and guidance for practitioners looking to optimize deep ensemble models. Code is available at: https://github.com/lauritsf/ensemble-optimality-gap",
    "fetched_at": "2025-11-09T02:21:28.185383Z"
  },
  {
    "id": "2511.04161v1",
    "title": "Seeing Straight: Document Orientation Detection for Efficient OCR",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Suranjan Goswami",
      "Abhinav Ravi",
      "Raja Kolla",
      "Ali Faraz",
      "Shaharukh Khan",
      "Akash",
      "Chandra Khatri",
      "Shubham Agarwal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04161v1",
    "abstract": "Despite significant advances in document understanding, determining the correct orientation of scanned or photographed documents remains a critical pre-processing step in the real world settings. Accurate rotation correction is essential for enhancing the performance of downstream tasks such as Optical Character Recognition (OCR) where misalignment commonly arises due to user errors, particularly incorrect base orientations of the camera during capture. In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from rotation-transformed structured and free-form English OCR datasets, and (ii) ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource languages. We also present a fast, robust and lightweight rotation classification pipeline built on the vision encoder of Phi-3.5-Vision model with dynamic image cropping, fine-tuned specifically for 4-class rotation task in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy on identifying the rotations respectively on both the datasets. Beyond classification, we demonstrate the critical role of our module in boosting OCR performance: closed-source (up to 14%) and open-weights models (up to 4x) in the simulated real-world setting.",
    "fetched_at": "2025-11-09T02:21:28.185354Z"
  },
  {
    "id": "2511.04162v1",
    "title": "ScaleDL: Towards Scalable and Efficient Runtime Prediction for   Distributed Deep Learning Workloads",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiaokai Wang",
      "Shaoyuan Huang",
      "Yuting Li",
      "Xiaofei Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04162v1",
    "abstract": "Deep neural networks (DNNs) form the cornerstone of modern AI services, supporting a wide range of applications, including autonomous driving, chatbots, and recommendation systems. As models increase in size and complexity, DNN workloads like training and inference tasks impose unprecedented demands on distributed computing resources, making the accurate prediction of runtime essential for optimizing development and resource allocation. Traditional methods rely on additive computational unit models, limiting their accuracy and generalizability. In contrast, graph-enhanced modeling improves performance but significantly increases data collection costs. Therefore, there is a critical need for a method that strikes a balance between accuracy, generalizability, and the costs of data collection. To address these challenges, we propose ScaleDL, a novel runtime prediction framework that combines nonlinear layer-wise modeling with graph neural network (GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime prediction and hierarchical generalizability across different network architectures. Additionally, we employ the D-optimal method to reduce data collection costs. Experiments on the workloads of five popular DNN models prove that ScaleDL enhances runtime prediction accuracy and generalizability, achieving 6$\\times$ lower MRE and 5$\\times$ lower RMSE compared to baseline models.",
    "fetched_at": "2025-11-09T02:21:28.185295Z"
  },
  {
    "id": "2511.04171v1",
    "title": "Systematic Evaluation of Preprocessing Techniques for Accurate Image   Registration in Digital Pathology",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fatemehzahra Darzi",
      "Rodrigo Escobar Diaz Guerrero",
      "Thomas Bocklitz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04171v1",
    "abstract": "Image registration refers to the process of spatially aligning two or more images by mapping them into a common coordinate system, so that corresponding anatomical or tissue structures are matched across images. In digital pathology, registration enables direct comparison and integration of information from different stains or imaging modalities, sup-porting applications such as biomarker analysis and tissue reconstruction. Accurate registration of images from different modalities is an essential step in digital pathology. In this study, we investigated how various color transformation techniques affect image registration between hematoxylin and eosin (H&E) stained images and non-linear multimodal images. We used a dataset of 20 tissue sample pairs, with each pair undergoing several preprocessing steps, including different color transformation (CycleGAN, Macenko, Reinhard, Vahadane), inversion, contrast adjustment, intensity normalization, and denoising. All images were registered using the VALIS registration method, which first applies rigid registration and then performs non-rigid registration in two steps on both low and high-resolution images. Registration performance was evaluated using the relative Target Registration Error (rTRE). We reported the median of median rTRE values (MMrTRE) and the average of median rTRE values (AMrTRE) for each method. In addition, we performed a custom point-based evaluation using ten manually selected key points. Registration was done separately for two scenarios, using either the original or inverted multimodal images. In both scenarios, CycleGAN color transformation achieved the lowest registration errors, while the other methods showed higher errors. These findings show that applying color transformation before registration improves alignment between images from different modalities and supports more reliable analysis in digital pathology.",
    "fetched_at": "2025-11-09T02:21:28.185245Z"
  },
  {
    "id": "2511.04172v1",
    "title": "Transforming Mentorship: An AI Powered Chatbot Approach to University   Guidance",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mashrur Rahman",
      "Mantaqa abedin",
      "Monowar Zamil Abir",
      "Faizul Islam Ansari",
      "Adib Reza",
      "Farig Yousuf Sadeque",
      "Niloy Farhan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04172v1",
    "abstract": "University students face immense challenges during their undergraduate lives, often being deprived of personalized on-demand guidance that mentors fail to provide at scale. Digital tools exist, but there is a serious lack of customized coaching for newcomers. This paper presents an AI-powered chatbot that will serve as a mentor for the students of BRAC University. The main component is a data ingestion pipeline that efficiently processes and updates information from diverse sources, such as CSV files and university webpages. The chatbot retrieves information through a hybrid approach, combining BM25 lexical ranking with ChromaDB semantic retrieval, and uses a Large Language Model, LLaMA-3.3-70B, to generate conversational responses. The generated text was found to be semantically highly relevant, with a BERTScore of 0.831 and a METEOR score of 0.809. The data pipeline was also very efficient, taking 106.82 seconds for updates, compared to 368.62 seconds for new data. This chatbot will be able to help students by responding to their queries, helping them to get a better understanding of university life, and assisting them to plan better routines for their semester in the open-credit university.",
    "fetched_at": "2025-11-09T02:21:28.185192Z"
  },
  {
    "id": "2511.04177v1",
    "title": "When Empowerment Disempowers",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Claire Yang",
      "Maya Cakmak",
      "Max Kleiman-Weiner"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04177v1",
    "abstract": "Empowerment, a measure of an agent's ability to control its environment, has been proposed as a universal goal-agnostic objective for motivating assistive behavior in AI agents. While multi-human settings like homes and hospitals are promising for AI assistance, prior work on empowerment-based assistance assumes that the agent assists one human in isolation. We introduce an open source multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we empirically show that assistive RL agents optimizing for one human's empowerment can significantly reduce another human's environmental influence and rewards - a phenomenon we formalize as disempowerment. We characterize when disempowerment occurs in these environments and show that joint empowerment mitigates disempowerment at the cost of the user's reward. Our work reveals a broader challenge for the AI alignment community: goal-agnostic objectives that seem aligned in single-agent settings can become misaligned in multi-agent contexts.",
    "fetched_at": "2025-11-09T02:21:28.185105Z"
  },
  {
    "id": "2511.04179v1",
    "title": "Explaining Software Vulnerabilities with Large Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oshando Johnson",
      "Alexandra Fomina",
      "Ranjith Krishnamurthy",
      "Vaibhav Chaudhari",
      "Rohith Kumar Shanmuganathan",
      "Eric Bodden"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04179v1",
    "abstract": "The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. Nevertheless, these tools frequently exhibit usability limitations, as their generic warning messages do not sufficiently communicate important information to developers, resulting in misunderstandings or oversight of critical findings. In light of recent developments in Large Language Models (LLMs) and their text generation capabilities, our work investigates a hybrid approach that uses LLMs to tackle the SAST explainability challenges. In this paper, we present SAFE, an Integrated Development Environment (IDE) plugin that leverages GPT-4o to explain the causes, impacts, and mitigation strategies of vulnerabilities detected by SAST tools. Our expert user study findings indicate that the explanations generated by SAFE can significantly assist beginner to intermediate developers in understanding and addressing security vulnerabilities, thereby improving the overall usability of SAST tools.",
    "fetched_at": "2025-11-09T02:21:28.185062Z"
  },
  {
    "id": "2511.04183v1",
    "title": "A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing",
    "date": "2025-11-06",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Leszek Sliwko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04183v1",
    "abstract": "This paper presents a reinforced genetic approach to a defined d-resource system optimization problem. The classical evolution schema was ineffective due to a very strict feasibility function in the studied problem. Hence, the presented strategy has introduced several modifications and adaptations to standard genetic routines, e.g.: a migration operator which is an analogy to the biological random genetic drift.",
    "fetched_at": "2025-11-09T02:21:28.185013Z"
  },
  {
    "id": "2511.04192v1",
    "title": "AStF: Motion Style Transfer via Adaptive Statistics Fusor",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hanmo Chen",
      "Chenghao Xu",
      "Jiexi Yan",
      "Cheng Deng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04192v1",
    "abstract": "Human motion style transfer allows characters to appear less rigidity and more realism with specific style. Traditional arbitrary image style transfer typically process mean and variance which is proved effective. Meanwhile, similar methods have been adapted for motion style transfer. However, due to the fundamental differences between images and motion, relying on mean and variance is insufficient to fully capture the complex dynamic patterns and spatiotemporal coherence properties of motion data. Building upon this, our key insight is to bring two more coefficient, skewness and kurtosis, into the analysis of motion style. Specifically, we propose a novel Adaptive Statistics Fusor (AStF) which consists of Style Disentanglement Module (SDM) and High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in conjunction with a Motion Consistency Regularization (MCR) discriminator. Experimental results show that, by providing a more comprehensive model of the spatiotemporal statistical patterns inherent in dynamic styles, our proposed AStF shows proficiency superiority in motion style transfers over state-of-the-arts. Our code and model are available at https://github.com/CHMimilanlan/AStF.",
    "fetched_at": "2025-11-09T02:21:28.184934Z"
  },
  {
    "id": "2511.04195v1",
    "title": "Computational Turing Test Reveals Systematic Differences Between Human   and AI Language",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.MA",
      "MA",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Nicolò Pagan",
      "Petter Törnberg",
      "Christopher A. Bail",
      "Anikó Hannák",
      "Christopher Barrie"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04195v1",
    "abstract": "Large language models (LLMs) are increasingly used in the social sciences to simulate human behavior, based on the assumption that they can generate realistic, human-like text. Yet this assumption remains largely untested. Existing validation efforts rely heavily on human-judgment-based evaluations -- testing whether humans can distinguish AI from human output -- despite evidence that such judgments are blunt and unreliable. As a result, the field lacks robust tools for assessing the realism of LLM-generated text or for calibrating models to real-world data. This paper makes two contributions. First, we introduce a computational Turing test: a validation framework that integrates aggregate metrics (BERT-based detectability and semantic similarity) with interpretable linguistic features (stylistic markers and topical patterns) to assess how closely LLMs approximate human language within a given dataset. Second, we systematically compare nine open-weight LLMs across five calibration strategies -- including fine-tuning, stylistic prompting, and context retrieval -- benchmarking their ability to reproduce user interactions on X (formerly Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the literature. Even after calibration, LLM outputs remain clearly distinguishable from human text, particularly in affective tone and emotional expression. Instruction-tuned models underperform their base counterparts, and scaling up model size does not enhance human-likeness. Crucially, we identify a trade-off: optimizing for human-likeness often comes at the cost of semantic fidelity, and vice versa. These results provide a much-needed scalable framework for validation and calibration in LLM simulations -- and offer a cautionary note about their current limitations in capturing human communication.",
    "fetched_at": "2025-11-09T02:21:28.184888Z"
  },
  {
    "id": "2511.04205v1",
    "title": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for   the Member of the Polish National Board of Appeal",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Michał Karp",
      "Anna Kubaszewska",
      "Magdalena Król",
      "Robert Król",
      "Aleksander Smywiński-Pohl",
      "Mateusz Szymański",
      "Witold Wydmański"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04205v1",
    "abstract": "This study provides an empirical assessment of whether current large language models (LLMs) can pass the official qualifying examination for membership in Poland's National Appeal Chamber (Krajowa Izba Odwo{\\l}awcza). The authors examine two related ideas: using LLM as actual exam candidates and applying the 'LLM-as-a-judge' approach, in which model-generated answers are automatically evaluated by other models. The paper describes the structure of the exam, which includes a multiple-choice knowledge test on public procurement law and a written judgment, and presents the hybrid information recovery and extraction pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4 Sonnet and Bielik-11B-v2.6) were tested in closed-book and various Retrieval-Augmented Generation settings. The results show that although the models achieved satisfactory scores in the knowledge test, none met the passing threshold in the practical written part, and the evaluations of the 'LLM-as-a-judge' often diverged from the judgments of the official examining committee. The authors highlight key limitations: susceptibility to hallucinations, incorrect citation of legal provisions, weaknesses in logical argumentation, and the need for close collaboration between legal experts and technical teams. The findings indicate that, despite rapid technological progress, current LLMs cannot yet replace human judges or independent examiners in Polish public procurement adjudication.",
    "fetched_at": "2025-11-09T02:21:28.184831Z"
  },
  {
    "id": "2511.04214v1",
    "title": "Block Rotation is All You Need for MXFP4 Quantization",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yuantian Shao",
      "Peisong Wang",
      "Yuanteng Chen",
      "Chang Xu",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04214v1",
    "abstract": "Large language models (LLMs) have achieved remarkable success, but their rapidly growing scale imposes prohibitive costs in memory, computation, and energy. Post-training quantization (PTQ) is a promising solution for efficient deployment, yet achieving accurate W4A4 quantization remains an open challenge. While most existing methods are designed for INT4 formats, the emergence of MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)-- raises questions about the applicability of current techniques. In this work, we establish a comprehensive benchmark of PTQ methods under the MXFP4 format. Through systematic evaluation, we find that methods like GPTQ consistently deliver strong performance, whereas rotation-based approaches, which are almost used by all state-of-the-art approaches, suffer from severe incompatibility with MXFP4. We further provide the first in-depth analysis of this conflict, tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two) block scaling and the redistribution of outlier energy via global rotation. Building on this insight, we propose a simple yet effective block rotation strategy that adapts rotation-based methods to MXFP4, leading to substantial accuracy improvements across diverse LLMs. Our findings not only offer clear guidance for practitioners but also set a foundation for advancing PTQ research under emerging low-precision formats.",
    "fetched_at": "2025-11-09T02:21:28.184773Z"
  },
  {
    "id": "2511.04215v1",
    "title": "Black-Box Guardrail Reverse-engineering Attack",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Hongwei Yao",
      "Yun Xia",
      "Shuo Shao",
      "Haoran Shi",
      "Tong Qiao",
      "Cong Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04215v1",
    "abstract": "Large language models (LLMs) increasingly employ guardrails to enforce ethical, legal, and application-specific constraints on their outputs. While effective at mitigating harmful responses, these guardrails introduce a new class of vulnerabilities by exposing observable decision patterns. In this work, we present the first study of black-box LLM guardrail reverse-engineering attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement learning-based framework that leverages genetic algorithm-driven data augmentation to approximate the decision-making policy of victim guardrails. By iteratively collecting input-output pairs, prioritizing divergence cases, and applying targeted mutations and crossovers, our method incrementally converges toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3, and demonstrate that it achieves an rule matching rate exceeding 0.92 while requiring less than $85 in API costs. These findings underscore the practical feasibility of guardrail extraction and highlight significant security risks for current LLM safety mechanisms. Our findings expose critical vulnerabilities in current guardrail designs and highlight the urgent need for more robust defense mechanisms in LLM deployment.",
    "fetched_at": "2025-11-09T02:21:28.184719Z"
  },
  {
    "id": "2511.04217v1",
    "title": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Yasuyuki Okoshi",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04217v1",
    "abstract": "The strong lottery ticket hypothesis (SLTH) conjectures that high-performing subnetworks, called strong lottery tickets (SLTs), are hidden in randomly initialized neural networks. Although recent theoretical studies have established the SLTH across various neural architectures, the SLTH for transformer architectures still lacks theoretical understanding. In particular, the current theory of the SLTH does not yet account for the multi-head attention (MHA) mechanism, a core component of transformers. To address this gap, we introduce a theoretical analysis of the existence of SLTs within MHAs. We prove that, if a randomly initialized MHA of $H$ heads and input dimension $d$ has the hidden dimension $O(d\\log(Hd^{3/2}))$ for the key and value, it contains an SLT that approximates an arbitrary MHA with the same input dimension with high probability. Furthermore, by leveraging this theory for MHAs, we extend the SLTH to transformers without normalization layers. We empirically validate our theoretical findings, demonstrating that the approximation error between the SLT within a source model (MHA and transformer) and an approximate target counterpart decreases exponentially by increasing the hidden dimension of the source model.",
    "fetched_at": "2025-11-09T02:21:28.184666Z"
  },
  {
    "id": "2511.04220v1",
    "title": "Opus: A Quantitative Framework for Workflow Evaluation",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Alan Seroul",
      "Théo Fagnoni",
      "Inès Adnani",
      "Dana O. Mohamed",
      "Phillip Kingston"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04220v1",
    "abstract": "This paper introduces the Opus Workflow Evaluation Framework, a probabilistic-normative formulation for quantifying Workflow quality and efficiency. It integrates notions of correctness, reliability, and cost into a coherent mathematical model that enables direct comparison, scoring, and optimization of Workflows. The framework combines the Opus Workflow Reward, a probabilistic function estimating expected performance through success likelihood, resource usage, and output gain, with the Opus Workflow Normative Penalties, a set of measurable functions capturing structural and informational quality across Cohesion, Coupling, Observability, and Information Hygiene. It supports automated Workflow assessment, ranking, and optimization within modern automation systems such as Opus and can be integrated into Reinforcement Learning loops to guide Workflow discovery and refinement. In this paper, we introduce the Opus Workflow Reward model that formalizes Workflow success as a probabilistic expectation over costs and outcomes. We define measurable Opus Workflow Normative Penalties capturing structural, semantic, and signal-related properties of Workflows. Finally, we propose a unified optimization formulation for identifying and ranking optimal Workflows under joint Reward-Penalty trade-offs.",
    "fetched_at": "2025-11-09T02:21:28.184593Z"
  },
  {
    "id": "2511.04228v1",
    "title": "REMIND: Input Loss Landscapes Reveal Residual Memorization in   Post-Unlearning LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "I.2.7; I.2.6; K.4.1",
      "1"
    ],
    "authors": [
      "Liran Cohen",
      "Yaniv Nemcovesky",
      "Avi Mendelson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04228v1",
    "abstract": "Machine unlearning aims to remove the influence of specific training data from a model without requiring full retraining. This capability is crucial for ensuring privacy, safety, and regulatory compliance. Therefore, verifying whether a model has truly forgotten target data is essential for maintaining reliability and trustworthiness. However, existing evaluation methods often assess forgetting at the level of individual inputs. This approach may overlook residual influence present in semantically similar examples. Such influence can compromise privacy and lead to indirect information leakage. We propose REMIND (Residual Memorization In Neighborhood Dynamics), a novel evaluation method aiming to detect the subtle remaining influence of unlearned data and classify whether the data has been effectively forgotten. REMIND analyzes the model's loss over small input variations and reveals patterns unnoticed by single-point evaluations. We show that unlearned data yield flatter, less steep loss landscapes, while retained or unrelated data exhibit sharper, more volatile patterns. REMIND requires only query-based access, outperforms existing methods under similar constraints, and demonstrates robustness across different models, datasets, and paraphrased inputs, making it practical for real-world deployment. By providing a more sensitive and interpretable measure of unlearning effectiveness, REMIND provides a reliable framework to assess unlearning in language models. As a result, REMIND offers a novel perspective on memorization and unlearning.",
    "fetched_at": "2025-11-09T02:21:28.184540Z"
  },
  {
    "id": "2511.04234v1",
    "title": "Reusing Pre-Training Data at Test Time is a Compute Multiplier",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alex Fang",
      "Thomas Voice",
      "Ruoming Pang",
      "Ludwig Schmidt",
      "Tom Gunter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04234v1",
    "abstract": "Large language models learn from their vast pre-training corpora, gaining the ability to solve an ever increasing variety of tasks; yet although researchers work to improve these datasets, there is little effort to understand how efficient the pre-training apparatus is at extracting ideas and knowledge from the data. In this work, we use retrieval augmented generation along with test-time compute as a way to quantify how much dataset value was left behind by the process of pre-training, and how this changes across scale. We demonstrate that pre-training then retrieving from standard and largely open-sourced datasets results in significant accuracy gains in MMLU, Math-500, and SimpleQA, which persist through decontamination. For MMLU we observe that retrieval acts as a ~5x compute multiplier versus pre-training alone. We show that these results can be further improved by leveraging additional compute at test time to parse the retrieved context, demonstrating a 10 percentage point improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results suggest that today's pre-training methods do not make full use of the information in existing pre-training datasets, leaving significant room for progress.",
    "fetched_at": "2025-11-09T02:21:28.184493Z"
  },
  {
    "id": "2511.04237v1",
    "title": "Denoised Recommendation Model with Collaborative Signal Decoupling",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zefeng Li",
      "Ning Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04237v1",
    "abstract": "Although the collaborative filtering (CF) algorithm has achieved remarkable performance in recommendation systems, it suffers from suboptimal recommendation performance due to noise in the user-item interaction matrix. Numerous noise-removal studies have improved recommendation models, but most existing approaches conduct denoising on a single graph. This may cause attenuation of collaborative signals: removing edges between two nodes can interrupt paths between other nodes, weakening path-dependent collaborative information. To address these limitations, this study proposes a novel GNN-based CF model called DRCSD for denoising unstable interactions. DRCSD includes two core modules: a collaborative signal decoupling module (decomposes signals into distinct orders by structural characteristics) and an order-wise denoising module (performs targeted denoising on each order). Additionally, the information aggregation mechanism of traditional GNN-based CF models is modified to avoid cross-order signal interference until the final pooling operation. Extensive experiments on three public real-world datasets show that DRCSD has superior robustness against unstable interactions and achieves statistically significant performance improvements in recommendation accuracy metrics compared to state-of-the-art baseline models.",
    "fetched_at": "2025-11-09T02:21:28.184388Z"
  },
  {
    "id": "2511.04239v1",
    "title": "seqme: a Python library for evaluating biological sequence design",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T01"
    ],
    "authors": [
      "Rasmus Møller-Larsen",
      "Adam Izdebski",
      "Jan Olszewski",
      "Pankhil Gawade",
      "Michal Kmicikiewicz",
      "Wojciech Zarzecki",
      "Ewa Szczurek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04239v1",
    "abstract": "Recent advances in computational methods for designing biological sequences have sparked the development of metrics to evaluate these methods performance in terms of the fidelity of the designed sequences to a target distribution and their attainment of desired properties. However, a single software library implementing these metrics was lacking. In this work we introduce seqme, a modular and highly extendable open-source Python library, containing model-agnostic metrics for evaluating computational methods for biological sequence design. seqme considers three groups of metrics: sequence-based, embedding-based, and property-based, and is applicable to a wide range of biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins. The library offers a number of embedding and property models for biological sequences, as well as diagnostics and visualization functions to inspect the results. seqme can be used to evaluate both one-shot and iterative computational design methods.",
    "fetched_at": "2025-11-09T02:21:28.184347Z"
  },
  {
    "id": "2511.04243v1",
    "title": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum   Machine Learning Ansatzes",
    "date": "2025-11-06",
    "tags": [
      "quant-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Valter Uotila",
      "Väinö Mehtola",
      "Ilmo Salmenperä",
      "Bo Zhao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04243v1",
    "abstract": "Leveraging data symmetries has been a key driver of performance gains in geometric deep learning and geometric and equivariant quantum machine learning. While symmetrization appears to be a promising method, its practical overhead, such as additional gates, reduced expressibility, and other factors, is not well understood in quantum machine learning. In this work, we develop an automated pipeline to measure various characteristics of quantum machine learning ansatzes with respect to symmetries that can appear in the learning task. We define the degree of symmetry in the learning problem as the size of the subgroup it admits. Subgroups define partial symmetries, which have not been extensively studied in previous research, which has focused on symmetries defined by whole groups. Symmetrizing the 19 common ansatzes with respect to these varying-sized subgroup representations, we compute three classes of metrics that describe how the common ansatz structures behave under varying amounts of symmetries. The first metric is based on the norm of the difference between the original and symmetrized generators, while the second metric counts depth, size, and other characteristics from the symmetrized circuits. The third class of metrics includes expressibility and entangling capability. The results demonstrate varying gate overhead across the studied ansatzes and confirm that increased symmetry reduces expressibility of the circuits. In most cases, increased symmetry increases entanglement capability. These results help select sufficiently expressible and computationally efficient ansatze patterns for geometric quantum machine learning applications.",
    "fetched_at": "2025-11-09T02:21:28.184292Z"
  },
  {
    "id": "2511.04244v1",
    "title": "Guided by Stars: Interpretable Concept Learning Over Time Series via   Temporal Logic Semantics",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Irene Ferfoglia",
      "Simone Silvetti",
      "Gaia Saveri",
      "Laura Nenzi",
      "Luca Bortolussi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04244v1",
    "abstract": "Time series classification is a task of paramount importance, as this kind of data often arises in safety-critical applications. However, it is typically tackled with black-box deep learning methods, making it hard for humans to understand the rationale behind their output. To take on this challenge, we propose a novel approach, STELLE (Signal Temporal logic Embedding for Logically-grounded Learning and Explanation), a neuro-symbolic framework that unifies classification and explanation through direct embedding of trajectories into a space of temporal logic concepts. By introducing a novel STL-inspired kernel that maps raw time series to their alignment with predefined STL formulae, our model jointly optimises accuracy and interpretability, as each prediction is accompanied by the most relevant logical concepts that characterise it. This yields (i) local explanations as human-readable STL conditions justifying individual predictions, and (ii) global explanations as class-characterising formulae. Experiments demonstrate that STELLE achieves competitive accuracy while providing logically faithful explanations, validated on diverse real-world benchmarks.",
    "fetched_at": "2025-11-09T02:21:28.184242Z"
  },
  {
    "id": "2511.04247v1",
    "title": "On the Brittleness of CLIP Text Encoders",
    "date": "2025-11-06",
    "tags": [
      "cs.MM",
      "MM",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Allie Tran",
      "Luca Rossetto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04247v1",
    "abstract": "Multimodal co-embedding models, especially CLIP, have advanced the state of the art in zero-shot classification and multimedia information retrieval in recent years by aligning images and text in a shared representation space. However, such modals trained on a contrastive alignment can lack stability towards small input perturbations. Especially when dealing with manually expressed queries, minor variations in the query can cause large differences in the ranking of the best-matching results. In this paper, we present a systematic analysis of the effect of multiple classes of non-semantic query perturbations in an multimedia information retrieval scenario. We evaluate a diverse set of lexical, syntactic, and semantic perturbations across multiple CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video collection. Across models, we find that syntactic and semantic perturbations drive the largest instabilities, while brittleness is concentrated in trivial surface edits such as punctuation and case. Our results highlight robustness as a critical dimension for evaluating vision-language models beyond benchmark accuracy.",
    "fetched_at": "2025-11-09T02:21:28.184193Z"
  },
  {
    "id": "2511.04248v1",
    "title": "Efficient Topic Extraction via Graph-Based Labeling: A Lightweight   Alternative to Deep Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Salma Mekaoui",
      "Hiba Sofyan",
      "Imane Amaaz",
      "Imane Benchrif",
      "Arsalane Zarghili",
      "Ilham Chaker",
      "Nikola S. Nikolov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04248v1",
    "abstract": "Extracting topics from text has become an essential task, especially with the rapid growth of unstructured textual data. Most existing works rely on highly computational methods to address this challenge. In this paper, we argue that probabilistic and statistical approaches, such as topic modeling (TM), can offer effective alternatives that require fewer computational resources. TM is a statistical method that automatically discovers topics in large collections of unlabeled text; however, it produces topics as distributions of representative words, which often lack clear interpretability. Our objective is to perform topic labeling by assigning meaningful labels to these sets of words. To achieve this without relying on computationally expensive models, we propose a graph-based approach that not only enriches topic words with semantically related terms but also explores the relationships among them. By analyzing these connections within the graph, we derive suitable labels that accurately capture each topic's meaning. We present a comparative study between our proposed method and several benchmarks, including ChatGPT-3.5, across two different datasets. Our method achieved consistently better results than traditional benchmarks in terms of BERTScore and cosine similarity and produced results comparable to ChatGPT-3.5, while remaining computationally efficient. Finally, we discuss future directions for topic labeling and highlight potential research avenues for enhancing interpretability and automation.",
    "fetched_at": "2025-11-09T02:21:28.184154Z"
  },
  {
    "id": "2511.04255v1",
    "title": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Marawan Elbatel",
      "Anbang Wang",
      "Keyuan Liu",
      "Kaouther Mouheb",
      "Enrique Almar-Munoz",
      "Lizhuo Lin",
      "Yanqi Yang",
      "Karim Lekadir",
      "Xiaomeng Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04255v1",
    "abstract": "This paper does not introduce a novel architecture; instead, it revisits a fundamental yet overlooked baseline: adapting human-centric foundation models for anatomical landmark detection in medical imaging. While landmark detection has traditionally relied on domain-specific models, the emergence of large-scale pre-trained vision models presents new opportunities. In this study, we investigate the adaptation of Sapiens, a human-centric foundation model designed for pose estimation, to medical imaging through multi-dataset pretraining, establishing a new state of the art across multiple datasets. Our proposed model, MedSapiens, demonstrates that human-centric foundation models, inherently optimized for spatial pose localization, provide strong priors for anatomical landmark detection, yet this potential has remained largely untapped. We benchmark MedSapiens against existing state-of-the-art models, achieving up to 5.26% improvement over generalist models and up to 21.81% improvement over specialist models in the average success detection rate (SDR). To further assess MedSapiens adaptability to novel downstream tasks with few annotations, we evaluate its performance in limited-data settings, achieving 2.69% improvement over the few-shot state of the art in SDR. Code and model weights are available at https://github.com/xmed-lab/MedSapiens .",
    "fetched_at": "2025-11-09T02:21:28.184089Z"
  },
  {
    "id": "2511.04256v1",
    "title": "SSPO: Subsentence-level Policy Optimization",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kun Yang",
      "Zikang chen",
      "Yanmeng Wang",
      "Zhigen Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04256v1",
    "abstract": "As a significant part of post-training of the Large Language Models (LLMs), Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs' reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative Policy Optimization) and GSPO (Group Sequence Policy Optimization), are observed to suffer from unstable policy updates and low usage of sampling data, respectively. The importance ratio of GRPO is calculated at the token level, which focuses more on optimizing a single token. This will be easily affected by outliers, leading to model training collapse. GSPO proposed the calculation of the response level importance ratio, which solves the problem of high variance and training noise accumulation in the calculation of the GRPO importance ratio. However, since all the response tokens share a common importance ratio, extreme values can easily raise or lower the overall mean, leading to the entire response being mistakenly discarded, resulting in a decrease in the utilization of sampled data. This paper introduces SSPO, which applies sentence-level importance ratio, taking the balance between GRPO and GSPO. SSPO not only avoids training collapse and high variance, but also prevents the whole response tokens from being abandoned by the clipping mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily adjust the clipping bounds, encouraging high-entropy tokens to explore and narrow the clipping range of low-entropy tokens. In particular, SSPO achieves an average score of 46.57 across five datasets, surpassing GRPO (43.01) and GSPO (44.42), and wins state-of-the-art performance on three datasets. These results highlight SSPO's effectiveness in leveraging generated data by taking the essence of GSPO but rejecting its shortcomings.",
    "fetched_at": "2025-11-09T02:21:28.184026Z"
  },
  {
    "id": "2511.04260v1",
    "title": "Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human   Face Imagery",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Claudio Giusti",
      "Luca Guarnera",
      "Sebastiano Battiato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04260v1",
    "abstract": "The growing sophistication of synthetic image and deepfake generation models has turned source attribution and authenticity verification into a critical challenge for modern computer vision systems. Recent studies suggest that diffusion pipelines unintentionally imprint persistent statistical traces, known as signal leaks, within their outputs, particularly in latent representations. Building on this observation, we propose Proto-LeakNet, a signal-leak-aware and interpretable attribution framework that integrates closed-set classification with a density-based open-set evaluation on the learned embeddings, enabling analysis of unseen generators without retraining. Operating in the latent domain of diffusion models, our method re-simulates partial forward diffusion to expose residual generator-specific cues. A temporal attention encoder aggregates multi-step latent features, while a feature-weighted prototype head structures the embedding space and enables transparent attribution. Trained solely on closed data and achieving a Macro AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under post-processing, surpassing state-of-the-art methods, and achieves strong separability between known and unseen generators. These results demonstrate that modeling signal-leak bias in latent space enables reliable and interpretable AI-image and deepfake forensics. The code for the whole work will be available upon submission.",
    "fetched_at": "2025-11-09T02:21:28.183972Z"
  },
  {
    "id": "2511.04275v1",
    "title": "Online Conformal Inference with Retrospective Adjustment for Faster   Adaptation to Distribution Shift",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jungbin Jun",
      "Ilsang Ohn"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04275v1",
    "abstract": "Conformal prediction has emerged as a powerful framework for constructing distribution-free prediction sets with guaranteed coverage assuming only the exchangeability assumption. However, this assumption is often violated in online environments where data distributions evolve over time. Several recent approaches have been proposed to address this limitation, but, typically, they slowly adapt to distribution shifts because they update predictions only in a forward manner, that is, they generate a prediction for a newly observed data point while previously computed predictions are not updated. In this paper, we propose a novel online conformal inference method with retrospective adjustment, which is designed to achieve faster adaptation to distributional shifts. Our method leverages regression approaches with efficient leave-one-out update formulas to retroactively adjust past predictions when new data arrive, thereby aligning the entire set of predictions with the most recent data distribution. Through extensive numerical studies performed on both synthetic and real-world data sets, we show that the proposed approach achieves faster coverage recalibration and improved statistical efficiency compared to existing online conformal prediction methods.",
    "fetched_at": "2025-11-09T02:21:28.183925Z"
  },
  {
    "id": "2511.04285v1",
    "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with   Iterative Policy Initialization",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zeng Zhiyuan",
      "Jiashuo Liu",
      "Zhangyue Yin",
      "Ge Zhang",
      "Wenhao Huang",
      "Xipeng Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04285v1",
    "abstract": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for training large reasoning models, its training dynamics harbor a critical challenge: RL overfitting, where models gain training rewards but lose generalization. Our analysis reveals this is driven by policy over-specialization and catastrophic forgetting of diverse solutions generated during training. Standard optimization discards this valuable inter-step policy diversity. To address this, we introduce RLoop, a self-improving framework built on iterative policy initialization. RLoop transforms the standard training process into a virtuous cycle: it first uses RL to explore the solution space from a given policy, then filters the successful trajectories to create an expert dataset. This dataset is used via Rejection-sampling Fine-Tuning (RFT) to refine the initial policy, creating a superior starting point for the next iteration. This loop of exploration and exploitation via iterative re-initialization effectively converts transient policy variations into robust performance gains. Our experiments show RLoop mitigates forgetting and substantially improves generalization, boosting average accuracy by 9% and pass@32 by over 15% compared to vanilla RL.",
    "fetched_at": "2025-11-09T02:21:28.183886Z"
  },
  {
    "id": "2511.04286v1",
    "title": "Efficient Reinforcement Learning from Human Feedback via Bayesian   Preference Inference",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Matteo Cercola",
      "Valeria Capretti",
      "Simone Formentin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04286v1",
    "abstract": "Learning from human preferences is a cornerstone of aligning machine learning models with subjective human judgments. Yet, collecting such preference data is often costly and time-consuming, motivating the need for more efficient learning paradigms. Two established approaches offer complementary advantages: RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning, while PBO achieves greater sample efficiency through active querying. We propose a hybrid framework that unifies RLHF's scalability with PBO's query efficiency by integrating an acquisition-driven module into the RLHF pipeline, thereby enabling active and sample-efficient preference gathering. We validate the proposed approach on two representative domains: (i) high-dimensional preference optimization and (ii) LLM fine-tuning. Experimental results demonstrate consistent improvements in both sample efficiency and overall performance across these tasks.",
    "fetched_at": "2025-11-09T02:21:28.183833Z"
  },
  {
    "id": "2511.04291v1",
    "title": "Robustness of Minimum-Volume Nonnegative Matrix Factorization under an   Expanded Sufficiently Scattered Condition",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "eess.SP",
      "SP",
      "math.NA"
    ],
    "authors": [
      "Giovanni Barbarino",
      "Nicolas Gillis",
      "Subhayan Saha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04291v1",
    "abstract": "Minimum-volume nonnegative matrix factorization (min-vol NMF) has been used successfully in many applications, such as hyperspectral imaging, chemical kinetics, spectroscopy, topic modeling, and audio source separation. However, its robustness to noise has been a long-standing open problem. In this paper, we prove that min-vol NMF identifies the groundtruth factors in the presence of noise under a condition referred to as the expanded sufficiently scattered condition which requires the data points to be sufficiently well scattered in the latent simplex generated by the basis vectors.",
    "fetched_at": "2025-11-09T02:21:28.183793Z"
  },
  {
    "id": "2511.04304v1",
    "title": "Deep learning-based object detection of offshore platforms on Sentinel-1   Imagery and the impact of synthetic training data",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Robin Spanier",
      "Thorsten Hoeser",
      "Claudia Kuenzer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04304v1",
    "abstract": "The recent and ongoing expansion of marine infrastructure, including offshore wind farms, oil and gas platforms, artificial islands, and aquaculture facilities, highlights the need for effective monitoring systems. The development of robust models for offshore infrastructure detection relies on comprehensive, balanced datasets, but falls short when samples are scarce, particularly for underrepresented object classes, shapes, and sizes. By training deep learning-based YOLOv10 object detection models with a combination of synthetic and real Sentinel-1 satellite imagery acquired in the fourth quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of Guinea, and Coast of Brazil), this study investigates the use of synthetic training data to enhance model performance. We evaluated this approach by applying the model to detect offshore platforms in three unseen regions (Gulf of Mexico, North Sea, Persian Gulf) and thereby assess geographic transferability. This region-holdout evaluation demonstrated that the model generalises beyond the training areas. In total, 3,529 offshore platforms were detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and 1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which improved to 0.90 upon incorporating synthetic data. We analysed how synthetic data enhances the representation of unbalanced classes and overall model performance, taking a first step toward globally transferable detection of offshore infrastructure. This study underscores the importance of balanced datasets and highlights synthetic data generation as an effective strategy to address common challenges in remote sensing, demonstrating the potential of deep learning for scalable, global offshore infrastructure monitoring.",
    "fetched_at": "2025-11-09T02:21:28.183753Z"
  },
  {
    "id": "2511.04309v1",
    "title": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems",
    "date": "2025-11-06",
    "tags": [
      "math.NA",
      "NA",
      "cs.LG",
      "LG",
      "cs.NA"
    ],
    "authors": [
      "Michael Ludkovski",
      "Changgen Xie",
      "Zimu Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04309v1",
    "abstract": "We consider numerical resolution of principal-agent (PA) problems in continuous time. We formulate a generic PA model with continuous and lump payments and a multi-dimensional strategy of the agent. To tackle the resulting Hamilton-Jacobi-Bellman equation with an implicit Hamiltonian we develop a novel deep learning method: the Deep Principal-Agent Actor Critic (DeepPAAC) Actor-Critic algorithm. DeepPAAC is able to handle multi-dimensional states and controls, as well as constraints. We investigate the role of the neural network architecture, training designs, loss functions, etc. on the convergence of the solver, presenting five different case studies.",
    "fetched_at": "2025-11-09T02:21:28.183613Z"
  },
  {
    "id": "2511.04312v1",
    "title": "Probing the Probes: Methods and Metrics for Concept Alignment",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jacob Lysnæs-Larsen",
      "Marte Eggen",
      "Inga Strümke"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04312v1",
    "abstract": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained by training linear classifier probes to detect human-understandable concepts as directions in the activation space of deep neural networks. It is widely assumed that a high probe accuracy indicates a CAV faithfully representing its target concept. However, we show that the probe's classification accuracy alone is an unreliable measure of concept alignment, i.e., the degree to which a CAV captures the intended concept. In fact, we argue that probes are more likely to capture spurious correlations than they are to represent only the intended concept. As part of our analysis, we demonstrate that deliberately misaligned probes constructed to exploit spurious correlations, achieve an accuracy close to that of standard probes. To address this severe problem, we introduce a novel concept localization method based on spatial linear attribution, and provide a comprehensive comparison of it to existing feature visualization techniques for detecting and mitigating concept misalignment. We further propose three classes of metrics for quantitatively assessing concept alignment: hard accuracy, segmentation scores, and augmentation robustness. Our analysis shows that probes with translation invariance and spatial alignment consistently increase concept alignment. These findings highlight the need for alignment-based evaluation metrics rather than probe accuracy, and the importance of tailoring probes to both the model architecture and the nature of the target concept.",
    "fetched_at": "2025-11-09T02:21:28.183572Z"
  },
  {
    "id": "2511.04316v1",
    "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Tim Beyer",
      "Jonas Dornbusch",
      "Jakob Steimle",
      "Moritz Ladenburger",
      "Leo Schwinn",
      "Stephan Günnemann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04316v1",
    "abstract": "The rapid expansion of research on Large Language Model (LLM) safety and robustness has produced a fragmented and oftentimes buggy ecosystem of implementations, datasets, and evaluation methods. This fragmentation makes reproducibility and comparability across studies challenging, hindering meaningful progress. To address these issues, we introduce AdversariaLLM, a toolbox for conducting LLM jailbreak robustness research. Its design centers on reproducibility, correctness, and extensibility. The framework implements twelve adversarial attack algorithms, integrates seven benchmark datasets spanning harmfulness, over-refusal, and utility evaluation, and provides access to a wide range of open-weight LLMs via Hugging Face. The implementation includes advanced features for comparability and reproducibility such as compute-resource tracking, deterministic results, and distributional evaluation techniques. \\name also integrates judging through the companion package JudgeZoo, which can also be used independently. Together, these components aim to establish a robust foundation for transparent, comparable, and reproducible research in LLM safety.",
    "fetched_at": "2025-11-09T02:21:28.183525Z"
  },
  {
    "id": "2511.04321v1",
    "title": "AIM: Software and Hardware Co-design for Architecture-level IR-drop   Mitigation in High-performance PIM",
    "date": "2025-11-06",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuanpeng Zhang",
      "Xing Hu",
      "Xi Chen",
      "Zhihang Yuan",
      "Cong Li",
      "Jingchen Zhu",
      "Zhao Wang",
      "Chenguang Zhang",
      "Xin Si",
      "Wei Gao",
      "Qiang Wu",
      "Runsheng Wang",
      "Guangyu Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04321v1",
    "abstract": "SRAM Processing-in-Memory (PIM) has emerged as the most promising implementation for high-performance PIM, delivering superior computing density, energy efficiency, and computational precision. However, the pursuit of higher performance necessitates more complex circuit designs and increased operating frequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly degrade chip performance and even threaten reliability. Conventional circuit-level IR-drop mitigation methods, such as back-end optimizations, are resource-intensive and often compromise power, performance, and area (PPA). To address these challenges, we propose AIM, comprehensive software and hardware co-design for architecture-level IR-drop mitigation in high-performance PIM. Initially, leveraging the bit-serial and in-situ dataflow processing properties of PIM, we introduce Rtog and HR, which establish a direct correlation between PIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS, enabling extensive exploration of architecture-level IR-drop mitigation while maintaining computational accuracy through software optimization. Subsequently, we develop IR-Booster, a dynamic adjustment mechanism that integrates software-level HR information with hardware-based IR-drop monitoring to adapt the V-f pairs of the PIM macro, achieving enhanced energy efficiency and performance. Finally, we propose the HR-aware task mapping method, bridging software and hardware designs to achieve optimal improvement. Post-layout simulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up to 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement and 1.152x speedup.",
    "fetched_at": "2025-11-09T02:21:28.183472Z"
  },
  {
    "id": "2511.04328v1",
    "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language   Models in Simulated Consultation",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiahao Zhao",
      "Luxin Xu",
      "Minghuan Tan",
      "Lichao Zhang",
      "Ahmadreza Argha",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04328v1",
    "abstract": "Numerous medical systems powered by Large Language Models (LLMs) have achieved remarkable progress in diverse healthcare tasks. However, research on their medication safety remains limited due to the lack of real world datasets, constrained by privacy and accessibility issues. Moreover, evaluation of LLMs in realistic clinical consultation settings, particularly regarding medication safety, is still underexplored. To address these gaps, we propose a framework that simulates and evaluates clinical consultations to systematically assess the medication safety capabilities of LLMs. Within this framework, we generate inquiry diagnosis dialogues with embedded medication risks and construct a dedicated medication safety database, RxRisk DB, containing 6,725 contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs. A two-stage filtering strategy ensures clinical realism and professional quality, resulting in the benchmark RxSafeBench with 2,443 high-quality consultation scenarios. We evaluate leading open-source and proprietary LLMs using structured multiple choice questions that test their ability to recommend safe medications under simulated patient contexts. Results show that current LLMs struggle to integrate contraindication and interaction knowledge, especially when risks are implied rather than explicit. Our findings highlight key challenges in ensuring medication safety in LLM-based systems and provide insights into improving reliability through better prompting and task-specific tuning. RxSafeBench offers the first comprehensive benchmark for evaluating medication safety in LLMs, advancing safer and more trustworthy AI-driven clinical decision support.",
    "fetched_at": "2025-11-09T02:21:28.183392Z"
  },
  {
    "id": "2511.04332v1",
    "title": "Differentially Private In-Context Learning with Nearest Neighbor Search",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Antti Koskela",
      "Tejas Kulkarni",
      "Laith Zumot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04332v1",
    "abstract": "Differentially private in-context learning (DP-ICL) has recently become an active research topic due to the inherent privacy risks of in-context learning. However, existing approaches overlook a critical component of modern large language model (LLM) pipelines: the similarity search used to retrieve relevant context data. In this work, we introduce a DP framework for in-context learning that integrates nearest neighbor search of relevant examples in a privacy-aware manner. Our method outperforms existing baselines by a substantial margin across all evaluated benchmarks, achieving more favorable privacy-utility trade-offs. To achieve this, we employ nearest neighbor retrieval from a database of context data, combined with a privacy filter that tracks the cumulative privacy cost of selected samples to ensure adherence to a central differential privacy budget. Experimental results on text classification and document question answering show a clear advantage of the proposed method over existing baselines.",
    "fetched_at": "2025-11-09T02:21:28.183330Z"
  },
  {
    "id": "2511.04333v1",
    "title": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in   Intensive Care",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Federico Pirola",
      "Fabio Stella",
      "Marco Grzegorczyk"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04333v1",
    "abstract": "Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to their ability to model complex temporal relationships in patient data while maintaining interpretability, an essential feature for clinical decision-making. However, existing approaches to handling missing data in longitudinal clinical datasets are largely derived from static Bayesian networks literature, failing to properly account for the temporal nature of the data. This gap limits the ability to quantify uncertainty over time, which is particularly critical in settings such as intensive care, where understanding the temporal dynamics is fundamental for model trustworthiness and applicability across diverse patient groups. Despite the potential of DBNs, a full Bayesian framework that integrates missing data handling remains underdeveloped. In this work, we propose a novel Gibbs sampling-based method for learning DBNs from incomplete data. Our method treats each missing value as an unknown parameter following a Gaussian distribution. At each iteration, the unobserved values are sampled from their full conditional distributions, allowing for principled imputation and uncertainty estimation. We evaluate our method on both simulated datasets and real-world intensive care data from critically ill patients. Compared to standard model-agnostic techniques such as MICE, our Bayesian approach demonstrates superior reconstruction accuracy and convergence properties. These results highlight the clinical relevance of incorporating full Bayesian inference in temporal models, providing more reliable imputations and offering deeper insight into model behavior. Our approach supports safer and more informed clinical decision-making, particularly in settings where missing data are frequent and potentially impactful.",
    "fetched_at": "2025-11-09T02:21:28.183288Z"
  },
  {
    "id": "2511.04334v1",
    "title": "Submanifold Sparse Convolutional Networks for Automated 3D Segmentation   of Kidneys and Kidney Tumours in Computed Tomography",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Saúl Alonso-Monsalve",
      "Leigh H. Whitehead",
      "Adam Aurisano",
      "Lorena Escudero Sanchez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04334v1",
    "abstract": "The accurate delineation of tumours in radiological images like Computed Tomography is a very specialised and time-consuming task, and currently a bottleneck preventing quantitative analyses to be performed routinely in the clinical setting. For this reason, developing methods for the automated segmentation of tumours in medical imaging is of the utmost importance and has driven significant efforts in recent years. However, challenges regarding the impracticality of 3D scans, given the large amount of voxels to be analysed, usually requires the downsampling of such images or using patches thereof when applying traditional convolutional neural networks. To overcome this problem, in this paper we propose a new methodology that uses, divided into two stages, voxel sparsification and submanifold sparse convolutional networks. This method allows segmentations to be performed with high-resolution inputs and a native 3D model architecture, obtaining state-of-the-art accuracies while significantly reducing the computational resources needed in terms of GPU memory and time. We studied the deployment of this methodology in the context of Computed Tomography images of renal cancer patients from the KiTS23 challenge, and our method achieved results competitive with the challenge winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7% for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also offers significant computational improvements, achieving up to a 60% reduction in inference time and up to a 75\\% reduction in VRAM usage compared to an equivalent dense architecture, across both CPU and various GPU cards tested.",
    "fetched_at": "2025-11-09T02:21:28.183239Z"
  },
  {
    "id": "2511.04341v1",
    "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for   Language Model Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nick Oh",
      "Fernand Gobet"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04341v1",
    "abstract": "Test-time reasoning architectures such as those following the Generate-Verify paradigm -- where a model iteratively refines or verifies its own generated outputs -- prioritise generation and verification but exclude the monitoring processes that determine when and how reasoning should begin. This omission may contribute to the prefix dominance trap, in which models commit early to suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy loss. We address this architectural gap by formalising Flavell's and Nelson and Narens' metacognitive theories into computational specifications, proposing the Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify paradigm by adding explicit monitoring that captures metacognitive experiences (from difficulty assessments to confidence judgements) before generation begins and refines future monitoring through verification feedback. Though we present no empirical validation, this work provides the first systematic computational translation of foundational metacognitive theories, offering a principled vocabulary for understanding reasoning system failures and suggesting specific architectural interventions for future test-time reasoning designs.",
    "fetched_at": "2025-11-09T02:21:28.183188Z"
  },
  {
    "id": "2511.04355v1",
    "title": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation   Benchmarks",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Amir Molzam Sharifloo",
      "Maedeh Heydari",
      "Parsa Kazerooni",
      "Daniel Maninger",
      "Mira Mezini"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04355v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in code generation, and the race to improve their performance has become a central focus of AI research. Benchmarks and leaderboards are increasingly popular, offering quantitative rankings of LLMs. However, they provide limited insight into the tasks that LLMs consistently fail to solve - information that is crucial for understanding current limitations and guiding the development of more capable models. To address this gap, we examined code generation tasks across four popular benchmarks, identifying those that major LLMs are most likely to fail. To understand the causes of these failures, we investigated whether the static complexity of solution code contributes to them, followed by a systematic inspection of 114 tasks that LLMs consistently struggled with. Our analysis revealed four recurring patterns of weaknesses in LLMs, as well as common complications within benchmark tasks that most often lead to failure.",
    "fetched_at": "2025-11-09T02:21:28.183148Z"
  },
  {
    "id": "2511.04361v1",
    "title": "Causal Regime Detection in Energy Markets With Augmented Time Series   Structural Causal Models",
    "date": "2025-11-06",
    "tags": [
      "q-fin.CP",
      "CP",
      "cs.LG",
      "LG",
      "stat.OT",
      "OT"
    ],
    "authors": [
      "Dennis Thumm"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04361v1",
    "abstract": "Energy markets exhibit complex causal relationships between weather patterns, generation technologies, and price formation, with regime changes occurring continuously rather than at discrete break points. Current approaches model electricity prices without explicit causal interpretation or counterfactual reasoning capabilities. We introduce Augmented Time Series Causal Models (ATSCM) for energy markets, extending counterfactual reasoning frameworks to multivariate temporal data with learned causal structure. Our approach models energy systems through interpretable factors (weather, generation mix, demand patterns), rich grid dynamics, and observable market variables. We integrate neural causal discovery to learn time-varying causal graphs without requiring ground truth DAGs. Applied to real-world electricity price data, ATSCM enables novel counterfactual queries such as \"What would prices be under different renewable generation scenarios?\".",
    "fetched_at": "2025-11-09T02:21:28.183094Z"
  },
  {
    "id": "2511.04376v1",
    "title": "MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion   Transformers",
    "date": "2025-11-06",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Ali Boudaghi",
      "Hadi Zare"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04376v1",
    "abstract": "Music editing has emerged as an important and practical area of artificial intelligence, with applications ranging from video game and film music production to personalizing existing tracks according to user preferences. However, existing models face significant limitations, such as being restricted to editing synthesized music generated by their own models, requiring highly precise prompts, or necessitating task-specific retraining, thus lacking true zero-shot capability. Leveraging recent advances in rectified flow and diffusion transformers, we introduce MusRec, the first zero-shot text-to-music editing model capable of performing diverse editing tasks on real-world music efficiently and effectively. Experimental results demonstrate that our approach outperforms existing methods in preserving musical content, structural consistency, and editing fidelity, establishing a strong foundation for controllable music editing in real-world scenarios.",
    "fetched_at": "2025-11-09T02:21:28.183058Z"
  },
  {
    "id": "2511.04384v1",
    "title": "Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal   VQA",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Itbaan Safwan",
      "Muhammad Annas Shaikh",
      "Muhammad Haaris",
      "Ramail Khan",
      "Muhammad Atif Tahir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04384v1",
    "abstract": "We present a multi-task framework for the MediaEval Medico 2025 challenge, leveraging a LoRA-tuned Florence-2 model for simultaneous visual question answering (VQA), explanation generation, and visual grounding. The proposed system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer learning, (2) a synthetically enriched explanation dataset offering structured medical reasoning, and (3) text-to-region pairs linking visual features with segmentation masks. This multi-task setup enables the model to jointly learn visual grounding, reasoning, and interpretation, producing responses that are both accurate and interpretable. Extensive evaluation demonstrates that our approach substantially improves over single-task baselines in both answer accuracy and visual localization, highlighting the effectiveness of grounded multi-task learning for medical VQA applications.",
    "fetched_at": "2025-11-09T02:21:28.183018Z"
  },
  {
    "id": "2511.04401v1",
    "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group   Robustness",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Subeen Park",
      "Joowang Kim",
      "Hakyung Lee",
      "Sunjae Yoo",
      "Kyungwoo Song"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04401v1",
    "abstract": "Deep learning models achieve strong performance across various domains but often rely on spurious correlations, making them vulnerable to distribution shifts. This issue is particularly severe in subpopulation shift scenarios, where models struggle in underrepresented groups. While existing methods have made progress in mitigating this issue, their performance gains are still constrained. They lack a rigorous theoretical framework connecting the embedding space representations with worst-group error. To address this limitation, we propose Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER), a novel approach that directly regularizes feature representations to suppress spurious cues. We show theoretically that worst-group error is influenced by how strongly the classifier relies on spurious versus core directions, identified from differences in group-wise mean embeddings across domains and classes. By imposing theoretical constraints at the embedding level, SCER encourages models to focus on core features while reducing sensitivity to spurious patterns. Through systematic evaluation on multiple vision and language, we show that SCER outperforms prior state-of-the-art studies in worst-group accuracy. Our code is available at \\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.",
    "fetched_at": "2025-11-09T02:21:28.182921Z"
  },
  {
    "id": "2511.04403v1",
    "title": "Online Bayesian Experimental Design for Partially Observed Dynamical   Systems",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.CO",
      "CO"
    ],
    "authors": [
      "Sara Pérez-Vieites",
      "Sahel Iqbal",
      "Simo Särkkä",
      "Dominik Baumann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04403v1",
    "abstract": "Bayesian experimental design (BED) provides a principled framework for optimizing data collection, but existing approaches do not apply to crucial real-world settings such as dynamical systems with partial observability, where only noisy and incomplete observations are available. These systems are naturally modeled as state-space models (SSMs), where latent states mediate the link between parameters and data, making the likelihood -- and thus information-theoretic objectives like the expected information gain (EIG) -- intractable. In addition, the dynamical nature of the system requires online algorithms that update posterior distributions and select designs sequentially in a computationally efficient manner. We address these challenges by deriving new estimators of the EIG and its gradient that explicitly marginalize latent states, enabling scalable stochastic optimization in nonlinear SSMs. Our approach leverages nested particle filters (NPFs) for efficient online inference with convergence guarantees. Applications to realistic models, such as the susceptible-infected-recovered (SIR) and a moving source location task, show that our framework successfully handles both partial observability and online computation.",
    "fetched_at": "2025-11-09T02:21:28.182870Z"
  },
  {
    "id": "2511.04406v1",
    "title": "Dynamic Jointly Batch Selection for Data Efficient Machine Translation   Fine-Tuning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mohammad Amin Ghanizadeh",
      "Mohammad Javad Dousti"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04406v1",
    "abstract": "Data quality and its effective selection are fundamental to improving the performance of machine translation models, serving as cornerstones for achieving robust and reliable translation systems. This paper presents a data selection methodology specifically designed for fine-tuning machine translation systems, which leverages the synergy between a learner model and a pre-trained reference model to enhance overall training effectiveness. By defining a learnability score, our approach systematically evaluates the utility of data points for training, ensuring that only the most relevant and impactful examples contribute to the fine-tuning process. Furthermore, our method employs a batch selection strategy which considers interdependencies among data points, optimizing the efficiency of the training process while maintaining a focus on data relevance. Experiments on English to Persian and several other language pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that our method can achieve up to a fivefold improvement in data efficiency compared to an iid baseline. Experimental results indicate that our approach improves computational efficiency by 24 when utilizing cached embeddings, as it requires fewer training data points. Additionally, it enhances generalization, resulting in superior translation performance compared to random selection method.",
    "fetched_at": "2025-11-09T02:21:28.182821Z"
  },
  {
    "id": "2511.04418v1",
    "title": "The Illusion of Certainty: Uncertainty quantification for LLMs fails   under ambiguity",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tim Tomov",
      "Dominik Fuchsgruber",
      "Tom Wollschläger",
      "Stephan Günnemann"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04418v1",
    "abstract": "Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is critical for trustworthy deployment. While real-world language is inherently ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically benchmarked against tasks with no ambiguity. In this work, we demonstrate that while current uncertainty estimators perform well under the restrictive assumption of no ambiguity, they degrade to close-to-random performance on ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first ambiguous question-answering (QA) datasets equipped with ground-truth answer distributions estimated from factual co-occurrence. We find this performance deterioration to be consistent across different estimation paradigms: using the predictive distribution itself, internal representations throughout the model, and an ensemble of models. We show that this phenomenon can be theoretically explained, revealing that predictive-distribution and ensemble-based estimators are fundamentally limited under ambiguity. Overall, our study reveals a key shortcoming of current UQ methods for LLMs and motivates a rethinking of current modeling paradigms.",
    "fetched_at": "2025-11-09T02:21:28.182778Z"
  },
  {
    "id": "2511.04422v1",
    "title": "On the Equivalence of Regression and Classification",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "68T05, 68T10, 68Q32",
      "I.2.6; I.5.1; I.5.2",
      "2"
    ],
    "authors": [
      "Jayadeva",
      "Naman Dwivedi",
      "Hari Krishnan",
      "N. M. Anoop Krishnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04422v1",
    "abstract": "A formal link between regression and classification has been tenuous. Even though the margin maximization term $\\|w\\|$ is used in support vector regression, it has at best been justified as a regularizer. We show that a regression problem with $M$ samples lying on a hyperplane has a one-to-one equivalence with a linearly separable classification task with $2M$ samples. We show that margin maximization on the equivalent classification task leads to a different regression formulation than traditionally used. Using the equivalence, we demonstrate a ``regressability'' measure, that can be used to estimate the difficulty of regressing a dataset, without needing to first learn a model for it. We use the equivalence to train neural networks to learn a linearizing map, that transforms input variables into a space where a linear regressor is adequate.",
    "fetched_at": "2025-11-09T02:21:28.182730Z"
  },
  {
    "id": "2511.04432v1",
    "title": "If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning   Task for LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Lars Bungum",
      "Charles Yijia Huang",
      "Abeer Kashar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04432v1",
    "abstract": "In this study, we experiment with the ability of LLMs to do temporal reasoning. Using a Norwegian book from 1940 containing trivia questions, we prompt the LLMs to answer the questions as if it were 1940. We also pose the questions in both English and Norwegian. Correct answers are often presented as sentences, and grading is done by means of LLM-as-judge, with sampled checks by a native speaker. Prompting in English consistently gave better results than in Norwegian, an unexpected result. In contrast, using larger LLMs improved results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families, and also the largest available LLM especially crafted for Norwegian.",
    "fetched_at": "2025-11-09T02:21:28.182631Z"
  },
  {
    "id": "2511.04437v1",
    "title": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Patrik Valábek",
      "Michaela Horváthová",
      "Martin Klaučo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04437v1",
    "abstract": "This paper presents a deep Koopman-based Economic Model Predictive Control (EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU). The method uses Koopman operator theory to transform the complex, nonlinear system dynamics into a linear representation, enabling the application of convex optimization while representing the complex PU accurately. The deep Koopman model utilizes neural networks to learn the linear dynamics from experimental data, achieving a 45% improvement in open-loop prediction accuracy over conventional N4SID subspace identification. Both analyzed models were employed in the EMPC formulation that includes interpretable economic costs, such as energy consumption, material losses due to inadequate pasteurization, and actuator wear. The feasibility of EMPC is ensured using slack variables. The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear model of multivariable PU under external disturbance. The disturbances include feed pump fail-to-close scenario and the introduction of a cold batch to be pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a 32% reduction in total economic cost compared to the N4SID baseline. This improvement is mainly due to the reductions in material losses and energy consumption. Furthermore, the steady-state operation via Koopman-based EMPC requires 10.2% less electrical energy. The results highlight the practical advantages of integrating deep Koopman representations with economic optimization to achieve resource-efficient control of thermal-intensive plants.",
    "fetched_at": "2025-11-09T02:21:28.182594Z"
  },
  {
    "id": "2511.04439v1",
    "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anisha Garg",
      "Ganesh Venkatesh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04439v1",
    "abstract": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly desirable for adapting LLMs to become experts at specific tasks. But this simplicity also makes it ill-specified as we seek to enhance RL training with richer, non-binary feedback. When using ordinal rewards to give partial credit, GRPO's simplicity starts to hurt, as its group-average baseline often assigns a positive advantage to failed trajectories and reinforces incorrect behavior.   We introduce Correctness Relative Policy Optimization (CoRPO), a new formulation that solves this flaw. CoRPO uses an adaptive baseline that enforces a minimum quality threshold, ensuring failed solutions are never positively reinforced. Once the policy consistently meets this threshold, the baseline automatically transitions to a relative preference mode, pushing the model to find optimal solutions rather than just \"acceptable\" ones. We empirically validate CoRPO on a code verification task, where it demonstrates more stable convergence and better out-of-domain generalization.   This work represents a critical step in our broader research program to enable LLMs to learn genuinely new capabilities through reinforcement learning. We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback - progressing from binary to ordinal rewards in this work, and onward to denser, per-step supervision.",
    "fetched_at": "2025-11-09T02:21:28.182545Z"
  },
  {
    "id": "2511.04445v1",
    "title": "ForecastGAN: A Decomposition-Based Adversarial Framework for   Multi-Horizon Time Series Forecasting",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Syeda Sitara Wishal Fatima",
      "Afshin Rahimi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04445v1",
    "abstract": "Time series forecasting is essential across domains from finance to supply chain management. This paper introduces ForecastGAN, a novel decomposition based adversarial framework addressing limitations in existing approaches for multi-horizon predictions. Although transformer models excel in long-term forecasting, they often underperform in short-term scenarios and typically ignore categorical features. ForecastGAN operates through three integrated modules: a Decomposition Module that extracts seasonality and trend components; a Model Selection Module that identifies optimal neural network configurations based on forecasting horizon; and an Adversarial Training Module that enhances prediction robustness through Conditional Generative Adversarial Network training. Unlike conventional approaches, ForecastGAN effectively integrates both numerical and categorical features. We validate our framework on eleven benchmark multivariate time series datasets that span various forecasting horizons. The results show that ForecastGAN consistently outperforms state-of-the-art transformer models for short-term forecasting while remaining competitive for long-term horizons. This research establishes a more generalizable approach to time series forecasting that adapts to specific contexts while maintaining strong performance across diverse data characteristics without extensive hyperparameter tuning.",
    "fetched_at": "2025-11-09T02:21:28.182504Z"
  },
  {
    "id": "2511.04451v1",
    "title": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear   System with Input Delay",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Patrik Valábek",
      "Marek Wadinger",
      "Michal Kvasnica",
      "Martin Klaučo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04451v1",
    "abstract": "Nonlinear dynamical systems with input delays pose significant challenges for prediction, estimation, and control due to their inherent complexity and the impact of delays on system behavior. Traditional linear control techniques often fail in these contexts, necessitating innovative approaches. This paper introduces a novel approach to approximate the Koopman operator using an LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear systems with time delays. By incorporating Long Short-Term Memory (LSTM) layers, the proposed framework captures historical dependencies and efficiently encodes time-delayed system dynamics into a latent space. Unlike traditional extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which mitigates the problems with the underlying dynamics being known and incorporated into the dictionary. Quantitative comparisons with extended eDMD on a simulated system demonstrate highly significant performance gains in prediction accuracy in cases where the true nonlinear dynamics are unknown and achieve comparable results to eDMD with known dynamics of a system.",
    "fetched_at": "2025-11-09T02:21:28.182461Z"
  },
  {
    "id": "2511.04454v1",
    "title": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits",
    "date": "2025-11-06",
    "tags": [
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "q-bio.NC",
      "NC",
      "90C25, 90C59, 90C90"
    ],
    "authors": [
      "Hao Zhu",
      "Jasper Hoffmann",
      "Baohe Zhang",
      "Joschka Boedecker"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04454v1",
    "abstract": "We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization.",
    "fetched_at": "2025-11-09T02:21:28.182413Z"
  },
  {
    "id": "2511.04456v1",
    "title": "Federated Stochastic Minimax Optimization under Heavy-Tailed Noises",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinwen Zhang",
      "Hongchang Gao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04456v1",
    "abstract": "Heavy-tailed noise has attracted growing attention in nonconvex stochastic optimization, as numerous empirical studies suggest it offers a more realistic assumption than standard bounded variance assumption. In this work, we investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which integrates normalized gradients, and FedMuon-DA, which leverages the Muon optimizer for local updates. Both algorithms are designed to effectively address heavy-tailed noise in federated minimax optimization, under a milder condition. We theoretically establish that both algorithms achieve a convergence rate of $O({1}/{(TNp)^{\\frac{s-1}{2s}}})$. To the best of our knowledge, these are the first federated minimax optimization algorithms with rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments further validate their effectiveness.",
    "fetched_at": "2025-11-09T02:21:28.182365Z"
  },
  {
    "id": "2511.04461v1",
    "title": "Data-driven uncertainty-aware seakeeping prediction of the Delft 372   catamaran using ensemble Hankel dynamic mode decomposition",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Giorgio Palma",
      "Andrea Serani",
      "Matteo Diez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04461v1",
    "abstract": "In this study, we present and validate an ensemble-based Hankel Dynamic Mode Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions of a high-speed catamaran, namely the Delft 372 model. Experimental measurements (time histories) of wave elevation at the longitudinal center of gravity, heave, pitch, notional flight-deck velocity, notional bridge acceleration, and total resistance were collected from irregular wave basin tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5 conditions at Fr = 0.425, and organized into training, validation, and test sets. The HDMDc algorithm constructs an equation-free linear reduced-order model of the seakeeping vessel by augmenting states and inputs with their time-lagged copies to capture nonlinear and memory effects. Two ensembling strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters considered stochastic variables with prior distribution to produce posterior mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which aggregates multiple model obtained over data subsets, are compared in providing seakeeping prediction and uncertainty quantification. The FHDMDc approach is found to improve the accuracy of the predictions compared to the deterministic counterpart, also providing robust uncertainty estimation; whereas the application of BHDMDc to the present test case is not found beneficial in comparison to the deterministic model. FHDMDc-derived probability density functions for the motions closely match both experimental data and URANS results, demonstrating reliable and computationally efficient seakeeping prediction for design and operational support.",
    "fetched_at": "2025-11-09T02:21:28.182330Z"
  },
  {
    "id": "2511.04465v1",
    "title": "Fraud-Proof Revenue Division on Subscription Platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.GT",
      "GT",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "econ.TH",
      "TH"
    ],
    "authors": [
      "Abheek Ghosh",
      "Tzeh Yuan Neoh",
      "Nicholas Teh",
      "Giannis Tyrovolas"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04465v1",
    "abstract": "We study a model of subscription-based platforms where users pay a fixed fee for unlimited access to content, and creators receive a share of the revenue. Existing approaches to detecting fraud predominantly rely on machine learning methods, engaging in an ongoing arms race with bad actors. We explore revenue division mechanisms that inherently disincentivize manipulation. We formalize three types of manipulation-resistance axioms and examine which existing rules satisfy these. We show that a mechanism widely used by streaming platforms, not only fails to prevent fraud, but also makes detecting manipulation computationally intractable. We also introduce a novel rule, ScaledUserProp, that satisfies all three manipulation-resistance axioms. Finally, experiments with both real-world and synthetic streaming data support ScaledUserProp as a fairer alternative compared to existing rules.",
    "fetched_at": "2025-11-09T02:21:28.182230Z"
  },
  {
    "id": "2511.04469v1",
    "title": "Towards Causal Market Simulators",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "q-fin.CP",
      "CP",
      "stat.OT",
      "OT"
    ],
    "authors": [
      "Dennis Thumm",
      "Luis Ontaneda Mijares"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04469v1",
    "abstract": "Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.",
    "fetched_at": "2025-11-09T02:21:28.182184Z"
  },
  {
    "id": "2511.04473v1",
    "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge   Graph Augmented LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Alberto Cattaneo",
      "Carlo Luschi",
      "Daniel Justus"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04473v1",
    "abstract": "Retrieval of information from graph-structured knowledge bases represents a promising direction for improving the factuality of LLMs. While various solutions have been proposed, a comparison of methods is difficult due to the lack of challenging QA datasets with ground-truth targets for graph retrieval. We present SynthKGQA, a framework for generating high-quality synthetic Knowledge Graph Question Answering datasets from any Knowledge Graph, providing the full set of ground-truth facts in the KG to reason over each question. We show how, in addition to enabling more informative benchmarking of KG retrievers, the data produced with SynthKGQA also allows us to train better models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset designed to test zero-shot generalization abilities of KG retrievers with respect to unseen graph structures and relation types, and benchmark popular solutions for KG-augmented LLMs on it.",
    "fetched_at": "2025-11-09T02:21:28.182144Z"
  },
  {
    "id": "2511.04476v1",
    "title": "Probabilistic Textual Time Series Depression Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Fabian Schmidt",
      "Seyedehmoniba Ravan",
      "Vladimir Vlassov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04476v1",
    "abstract": "Accurate and interpretable predictions of depression severity are essential for clinical decision support, yet existing models often lack uncertainty estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time Series Depression Detection framework that predicts PHQ-8 scores from utterance-level clinical interviews while modeling uncertainty over time. PTTSD includes sequence-to-sequence and sequence-to-one variants, both combining bidirectional LSTMs, self-attention, and residual connections with Gaussian or Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated prediction intervals. Ablations confirm the value of attention and probabilistic modeling, while comparisons with MentalBERT establish generality. A three-part calibration analysis and qualitative case studies further highlight the interpretability and clinical relevance of uncertainty-aware forecasting.",
    "fetched_at": "2025-11-09T02:21:28.182096Z"
  },
  {
    "id": "2511.04478v1",
    "title": "Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop   Refinement of LLM Judges",
    "date": "2025-11-06",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hyo Jin Do",
      "Zahra Ashktorab",
      "Jasmina Gajcin",
      "Erik Miehling",
      "Martín Santillán Cooper",
      "Qian Pan",
      "Elizabeth M. Daly",
      "Werner Geyer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04478v1",
    "abstract": "The LLM-as-a-judge paradigm enables flexible, user-defined evaluation, but its effectiveness is often limited by the scarcity of diverse, representative data for refining criteria. We present a tool that integrates synthetic data generation into the LLM-as-a-judge workflow, empowering users to create tailored and challenging test cases with configurable domains, personas, lengths, and desired outcomes, including borderline cases. The tool also supports AI-assisted inline editing of existing test cases. To enhance transparency and interpretability, it reveals the prompts and explanations behind each generation. In a user study (N=24), 83% of participants preferred the tool over manually creating or selecting test cases, as it allowed them to rapidly generate diverse synthetic data without additional workload. The generated synthetic data proved as effective as hand-crafted data for both refining evaluation criteria and aligning with human preferences. These findings highlight synthetic data as a promising alternative, particularly in contexts where efficiency and scalability are critical.",
    "fetched_at": "2025-11-09T02:21:28.182053Z"
  },
  {
    "id": "2511.04479v1",
    "title": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding   in Thai",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Surapon Nonesung",
      "Teetouch Jaknamon",
      "Sirinya Chaiophat",
      "Natapong Nitarach",
      "Chanakan Wittayasakpan",
      "Warit Sirichotedumrong",
      "Adisai Na-Thalang",
      "Kunat Pipatanakul"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04479v1",
    "abstract": "We present ThaiOCRBench, the first comprehensive benchmark for evaluating vision-language models (VLMs) on Thai text-rich visual understanding tasks. Despite recent progress in multimodal modeling, existing benchmarks predominantly focus on high-resource languages, leaving Thai underrepresented, especially in tasks requiring document structure understanding. ThaiOCRBench addresses this gap by offering a diverse, human-annotated dataset comprising 2,808 samples across 13 task categories. We evaluate a wide range of state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and open-source systems. Results show a significant performance gap, with proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source counterparts. Notably, fine-grained text recognition and handwritten content extraction exhibit the steepest performance drops among open-source models. Through detailed error analysis, we identify key challenges such as language bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a standardized framework for assessing VLMs in low-resource, script-complex settings, and provides actionable insights for improving Thai-language document understanding.",
    "fetched_at": "2025-11-09T02:21:28.181996Z"
  },
  {
    "id": "2511.04484v1",
    "title": "Online Algorithms for Repeated Optimal Stopping: Achieving Both   Competitive Ratio and Regret Bounds",
    "date": "2025-11-06",
    "tags": [
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tsubasa Harada",
      "Yasushi Kawase",
      "Hanna Sumita"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04484v1",
    "abstract": "We study the repeated optimal stopping problem, which generalizes the classical optimal stopping problem with an unknown distribution to a setting where the same problem is solved repeatedly over $T$ rounds. In this framework, we aim to design algorithms that guarantee a competitive ratio in each round while also achieving sublinear regret across all rounds.   Our primary contribution is a general algorithmic framework that achieves these objectives simultaneously for a wide array of repeated optimal stopping problems. The core idea is to dynamically select an algorithm for each round, choosing between two candidates: (1) an empirically optimal algorithm derived from the history of observations, and (2) a sample-based algorithm with a proven competitive ratio guarantee. Based on this approach, we design an algorithm that performs no worse than the baseline sample-based algorithm in every round, while ensuring that the total regret is bounded by $\\tilde{O}(\\sqrt{T})$.   We demonstrate the broad applicability of our framework to canonical problems, including the prophet inequality, the secretary problem, and their variants under adversarial, random, and i.i.d. input models. For example, for the repeated prophet inequality problem, our method achieves a $1/2$-competitive ratio from the second round on and an $\\tilde{O}(\\sqrt{T})$ regret. Furthermore, we establish a regret lower bound of $\\Omega(\\sqrt{T})$ even in the i.i.d. model, confirming that our algorithm's performance is almost optimal with respect to the number of rounds.",
    "fetched_at": "2025-11-09T02:21:28.181893Z"
  },
  {
    "id": "2511.04485v1",
    "title": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank   Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Ipsita Ghosh",
      "Ethan Nguyen",
      "Christian Kümmerle"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04485v1",
    "abstract": "Parameter-efficient training, based on low-rank optimization, has become a highly successful tool for fine-tuning large deep-learning models. However, these methods fail at low-rank pre-training tasks where maintaining the low-rank structure and the objective remains a challenging task. We propose the Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel low-rank inducing training strategy inspired by the iteratively reweighted least squares (IRLS) framework. Q3R is based on a quadratic regularizer term which majorizes a smoothed log determinant serving as rank surrogate objective. Unlike other low-rank training techniques, Q3R is able to train weight matrices with prescribed, low target ranks of models that achieve comparable predictive performance as dense models, with small computational overhead, while remaining fully compatible with existing architectures. For example, we demonstrated one experiment where we are able to truncate $60\\%$ and $80\\%$ of the parameters of a ViT-Tiny model with $~1.3\\%$ and $~4\\%$ accuracy drop in CIFAR-10 performance respectively. The efficacy of Q3R is confirmed on Transformers across both image and language tasks, including for low-rank fine-tuning.",
    "fetched_at": "2025-11-09T02:21:28.181846Z"
  },
  {
    "id": "2511.04491v1",
    "title": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within   Structured Tables",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nikhil Abhyankar",
      "Purvi Chaurasia",
      "Sanchit Kabra",
      "Ananya Srivastava",
      "Vivek Gupta",
      "Chandan K. Reddy"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04491v1",
    "abstract": "Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models' (LLMs) reasoning abilities. Real tables are long, heterogeneous, and domain-specific, mixing structured fields with free text and requiring multi-hop reasoning across thousands of tokens. To address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from 2031 real-world tables spanning two domains: i) RB-Science (NSF grant records) and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates LLMs jointly across scale, heterogeneity, domain specificity, and reasoning complexity. Experiments with open-source and proprietary models show that LLMs struggle with heterogeneous schemas and complex multi-hop inference, revealing persistent weaknesses in current architectures and prompting strategies. RUST-BENCH establishes a challenging new testbed for advancing tabular reasoning research.",
    "fetched_at": "2025-11-09T02:21:28.181801Z"
  },
  {
    "id": "2511.04494v1",
    "title": "Distribution-Aware Tensor Decomposition for Compression of Convolutional   Neural Networks",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Alper Kalle",
      "Theo Rudkiewicz",
      "Mohamed-Oumar Ouerfelli",
      "Mohamed Tamaazousti"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2511.04494v1",
    "abstract": "Neural networks are widely used for image-related tasks but typically demand considerable computing power. Once a network has been trained, however, its memory- and compute-footprint can be reduced by compression. In this work, we focus on compression through tensorization and low-rank representations. Whereas classical approaches search for a low-rank approximation by minimizing an isotropic norm such as the Frobenius norm in weight-space, we use data-informed norms that measure the error in function space. Concretely, we minimize the change in the layer's output distribution, which can be expressed as $\\lVert (W - \\widetilde{W}) \\Sigma^{1/2}\\rVert_F$ where $\\Sigma^{1/2}$ is the square root of the covariance matrix of the layer's input and $W$, $\\widetilde{W}$ are the original and compressed weights. We propose new alternating least square algorithms for the two most common tensor decompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike conventional compression pipelines, which almost always require post-compression fine-tuning, our data-informed approach often achieves competitive accuracy without any fine-tuning. We further show that the same covariance-based norm can be transferred from one dataset to another with only a minor accuracy drop, enabling compression even when the original training dataset is unavailable. Experiments on several CNN architectures (ResNet-18/50, and GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100) confirm the advantages of the proposed method.",
    "fetched_at": "2025-11-09T02:21:28.181747Z"
  },
  {
    "id": "2511.04495v1",
    "title": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code   Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Cuong Huynh",
      "Jie Cao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04495v1",
    "abstract": "This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task (Alva-Manchego et al., 2025), designed for readability-controlled text simplification using LLM-prompting-based generation. Based on the analysis of prompt-based text simplification methods, we discovered an interesting finding that text simplification performance is highly related to the gap between the source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by this finding, we propose two multi-round simplification methods and generate them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams. Later improvements with MRS-Joint show that taking the LLM simplified candidates as the starting point could further boost the multi-round simplification performance.",
    "fetched_at": "2025-11-09T02:21:28.181696Z"
  },
  {
    "id": "2511.04499v1",
    "title": "Decoding Emergent Big Five Traits in Large Language Models:   Temperature-Dependent Expression and Architectural Clustering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Christos-Nikolaos Zacharopoulos",
      "Revekka Kyriakoglou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04499v1",
    "abstract": "As Large Language Models (LLMs) become integral to human-centered applications, understanding their personality-like behaviors is increasingly important for responsible development and deployment. This paper systematically evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to assess trait expressions under varying sampling temperatures. We find significant differences across four of the five personality dimensions, with Neuroticism and Extraversion susceptible to temperature adjustments. Further, hierarchical clustering reveals distinct model clusters, suggesting that architectural features may predispose certain models toward stable trait profiles. Taken together, these results offer new insights into the emergence of personality-like patterns in LLMs and provide a new perspective on model tuning, selection, and the ethical governance of AI systems. We share the data and code for this analysis here: https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1",
    "fetched_at": "2025-11-09T02:21:28.181660Z"
  },
  {
    "id": "2511.04500v1",
    "title": "Large language models replicate and predict human cooperation across   experiments in game theory",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.GT",
      "GT",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Andrea Cera Palatsi",
      "Samuel Martin-Gutierrez",
      "Ana S. Cardenal",
      "Max Pellert"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04500v1",
    "abstract": "Large language models (LLMs) are increasingly used both to make decisions in domains such as health, education and law, and to simulate human behavior. Yet how closely LLMs mirror actual human decision-making remains poorly understood. This gap is critical: misalignment could produce harmful outcomes in practical applications, while failure to replicate human behavior renders LLMs ineffective for social simulations. Here, we address this gap by developing a digital twin of game-theoretic experiments and introducing a systematic prompting and probing framework for machine-behavioral evaluation. Testing three open-source models (Llama, Mistral and Qwen), we find that Llama reproduces human cooperation patterns with high fidelity, capturing human deviations from rational choice theory, while Qwen aligns closely with Nash equilibrium predictions. Notably, we achieved population-level behavioral replication without persona-based prompting, simplifying the simulation process. Extending beyond the original human-tested games, we generate and preregister testable hypotheses for novel game configurations outside the original parameter grid. Our findings demonstrate that appropriately calibrated LLMs can replicate aggregate human behavioral patterns and enable systematic exploration of unexplored experimental spaces, offering a complementary approach to traditional research in the social and behavioral sciences that generates new empirical predictions about human social decision-making.",
    "fetched_at": "2025-11-09T02:21:28.181619Z"
  },
  {
    "id": "2511.04505v1",
    "title": "Alternative Fairness and Accuracy Optimization in Criminal Justice",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Shaolong Wu",
      "James Blume",
      "Geshi Yeung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04505v1",
    "abstract": "Algorithmic fairness has grown rapidly as a research area, yet key concepts remain unsettled, especially in criminal justice. We review group, individual, and process fairness and map the conditions under which they conflict. We then develop a simple modification to standard group fairness. Rather than exact parity across protected groups, we minimize a weighted error loss while keeping differences in false negative rates within a small tolerance. This makes solutions easier to find, can raise predictive accuracy, and surfaces the ethical choice of error costs. We situate this proposal within three classes of critique: biased and incomplete data, latent affirmative action, and the explosion of subgroup constraints. Finally, we offer a practical framework for deployment in public decision systems built on three pillars: need-based decisions, Transparency and accountability, and narrowly tailored definitions and solutions. Together, these elements link technical design to legitimacy and provide actionable guidance for agencies that use risk assessment and related tools.",
    "fetched_at": "2025-11-09T02:21:28.181511Z"
  },
  {
    "id": "2511.04506v1",
    "title": "Modeling Clinical Uncertainty in Radiology Reports: from Explicit   Uncertainty Markers to Implicit Reasoning Pathways",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Paloma Rabaey",
      "Jong Hak Moon",
      "Jung-Oh Lee",
      "Min Gwan Kim",
      "Hangyul Yoon",
      "Thomas Demeester",
      "Edward Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04506v1",
    "abstract": "Radiology reports are invaluable for clinical decision-making and hold great potential for automated analysis when structured into machine-readable formats. These reports often contain uncertainty, which we categorize into two distinct types: (i) Explicit uncertainty reflects doubt about the presence or absence of findings, conveyed through hedging phrases. These vary in meaning depending on the context, making rule-based systems insufficient to quantify the level of uncertainty for specific findings; (ii) Implicit uncertainty arises when radiologists omit parts of their reasoning, recording only key findings or diagnoses. Here, it is often unclear whether omitted findings are truly absent or simply unmentioned for brevity. We address these challenges with a two-part framework. We quantify explicit uncertainty by creating an expert-validated, LLM-based reference ranking of common hedging phrases, and mapping each finding to a probability value based on this reference. In addition, we model implicit uncertainty through an expansion framework that systematically adds characteristic sub-findings derived from expert-defined diagnostic pathways for 14 common diagnoses. Using these methods, we release Lunguage++, an expanded, uncertainty-aware version of the Lunguage benchmark of fine-grained structured radiology reports. This enriched resource enables uncertainty-aware image classification, faithful diagnostic reasoning, and new investigations into the clinical impact of diagnostic uncertainty.",
    "fetched_at": "2025-11-09T02:21:28.181467Z"
  },
  {
    "id": "2511.04514v1",
    "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image   Classifiers",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "C. Hepburn",
      "T. Zielke",
      "A. P. Raulf"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04514v1",
    "abstract": "The phenomenon of linear mode connectivity (LMC) links several aspects of deep learning, including training stability under noisy stochastic gradients, the smoothness and generalization of local minima (basins), the similarity and functional diversity of sampled models, and architectural effects on data processing. In this work, we experimentally study LMC under data shifts and identify conditions that mitigate their impact. We interpret data shifts as an additional source of stochastic gradient noise, which can be reduced through small learning rates and large batch sizes. These parameters influence whether models converge to the same local minimum or to regions of the loss landscape with varying smoothness and generalization. Although models sampled via LMC tend to make similar errors more frequently than those converging to different basins, the benefit of LMC lies in balancing training efficiency against the gains achieved from larger, more diverse ensembles. Code and supplementary materials will be made publicly available at https://github.com/DLR-KI/LMC in due course.",
    "fetched_at": "2025-11-09T02:21:28.181410Z"
  },
  {
    "id": "2511.04518v1",
    "title": "Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom   Parity",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA",
      "stat.ML",
      "ML",
      "68T05, 62J07, 65M20, 65M60",
      "I.2.6; G.1.2; G.1.8",
      "8"
    ],
    "authors": [
      "Obed Amo",
      "Samit Ghosh",
      "Markus Lange-Hegermann",
      "Bogdan Raiţă",
      "Michael Pokojovy"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04518v1",
    "abstract": "We present a new benchmarking study comparing a boundary-constrained Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical finite element method combined with Crank--Nicolson time stepping (CN-FEM) for solving the two-dimensional wave equation with homogeneous Dirichlet boundary conditions. The B-EPGP construction leverages exponential-polynomial bases derived from the characteristic variety to enforce the PDE and boundary conditions exactly and employs penalized least squares to estimate the coefficients. To ensure fairness across paradigms, we introduce a degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP consistently attains lower space-time $L^2$-error and maximum-in-time $L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of magnitude.",
    "fetched_at": "2025-11-09T02:21:28.181366Z"
  },
  {
    "id": "2511.04522v1",
    "title": "End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air   Separation Unit",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Daniel Mayfrank",
      "Kayra Dernek",
      "Laura Lang",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04522v1",
    "abstract": "With our recently proposed method based on reinforcement learning (Mayfrank et al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained for optimal performance in specific (economic) nonlinear model predictive control ((e)NMPC) applications. So far, our method has exclusively been demonstrated on a small-scale case study. Herein, we show that our method scales well to a more challenging demand response case study built on a large-scale model of a single-product (nitrogen) air separation unit. Across all numerical experiments, we assume observability of only a few realistically measurable plant variables. Compared to a purely system identification-based Koopman eNMPC, which generates small economic savings but frequently violates constraints, our method delivers similar economic performance while avoiding constraint violations.",
    "fetched_at": "2025-11-09T02:21:28.181316Z"
  },
  {
    "id": "2511.04527v1",
    "title": "Are language models aware of the road not taken? Token-level uncertainty   and hidden state dynamics",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amir Zur",
      "Atticus Geiger",
      "Ekdeep Singh Lubana",
      "Eric Bigelow"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04527v1",
    "abstract": "When a language model generates text, the selection of individual tokens might lead it down very different reasoning paths, making uncertainty difficult to quantify. In this work, we consider whether reasoning language models represent the alternate paths that they could take during generation. To test this hypothesis, we use hidden activations to control and predict a language model's uncertainty during chain-of-thought reasoning. In our experiments, we find a clear correlation between how uncertain a model is at different tokens, and how easily the model can be steered by controlling its activations. This suggests that activation interventions are most effective when there are alternate paths available to the model -- in other words, when it has not yet committed to a particular final answer. We also find that hidden activations can predict a model's future outcome distribution, demonstrating that models implicitly represent the space of possible paths.",
    "fetched_at": "2025-11-09T02:21:28.181268Z"
  },
  {
    "id": "2511.04528v1",
    "title": "IntelliProof: An Argumentation Network-based Conversational Helper for   Organized Reflection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kaveh Eskandari Miandoab",
      "Katharine Kowalyshyn",
      "Kabir Pamnani",
      "Anesu Gavhera",
      "Vasanth Sarathy",
      "Matthias Scheutz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04528v1",
    "abstract": "We present IntelliProof, an interactive system for analyzing argumentative essays through LLMs. IntelliProof structures an essay as an argumentation graph, where claims are represented as nodes, supporting evidence is attached as node properties, and edges encode supporting or attacking relations. Unlike existing automated essay scoring systems, IntelliProof emphasizes the user experience: each relation is initially classified and scored by an LLM, then visualized for enhanced understanding. The system provides justifications for classifications and produces quantitative measures for essay coherence. It enables rapid exploration of argumentative quality while retaining human oversight. In addition, IntelliProof provides a set of tools for a better understanding of an argumentative essay and its corresponding graph in natural language, bridging the gap between the structural semantics of argumentative essays and the user's understanding of a given text. A live demo and the system are available here to try: \\textbf{https://intelliproof.vercel.app}",
    "fetched_at": "2025-11-09T02:21:28.181222Z"
  },
  {
    "id": "2511.04534v1",
    "title": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to   Cloud Microphysics",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "physics.ao-ph",
      "ao-ph",
      "physics.comp-ph",
      "comp-ph",
      "I.6.5; I.2.6; G.3; J.2",
      "2"
    ],
    "authors": [
      "Jonas E. Katona",
      "Emily K. de Jong",
      "Nipun Gunawardena"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04534v1",
    "abstract": "Reduced-order models (ROMs) can efficiently simulate high-dimensional physical systems, but lack robust uncertainty quantification methods. Existing approaches are frequently architecture- or training-specific, which limits flexibility and generalization. We introduce a post hoc, model-agnostic framework for predictive uncertainty quantification in latent space ROMs that requires no modification to the underlying architecture or training procedure. Using conformal prediction, our approach estimates statistical prediction intervals for multiple components of the ROM pipeline: latent dynamics, reconstruction, and end-to-end predictions. We demonstrate the method on a latent space dynamical model for cloud microphysics, where it accurately predicts the evolution of droplet-size distributions and quantifies uncertainty across the ROM pipeline.",
    "fetched_at": "2025-11-09T02:21:28.181172Z"
  },
  {
    "id": "2511.04538v1",
    "title": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities   Reporting",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Cyril Vallez",
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04538v1",
    "abstract": "As the role of Large Language Models (LLM)-based coding assistants in software development becomes more critical, so does the role of the bugs they generate in the overall cybersecurity landscape. While a number of LLM code security benchmarks have been proposed alongside approaches to improve the security of generated code, it remains unclear to what extent they have impacted widely used coding LLMs. Here, we show that even the latest open-weight models are vulnerable in the earliest reported vulnerability scenarios in a realistic use setting, suggesting that the safety-functionality trade-off has until now prevented effective patching of vulnerabilities. To help address this issue, we introduce a new severity metric that reflects the risk posed by an LLM-generated vulnerability, accounting for vulnerability severity, generation chance, and the formulation of the prompt that induces vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation of the most serious and prevalent vulnerabilities, we use PE to define the Model Exposure (ME) score, which indicates the severity and prevalence of vulnerabilities a model generates.",
    "fetched_at": "2025-11-09T02:21:28.181130Z"
  },
  {
    "id": "2511.04539v1",
    "title": "Unified Generative Latent Representation for Functional Brain Graphs",
    "date": "2025-11-06",
    "tags": [
      "q-bio.NC",
      "NC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Subati Abulikemu",
      "Tiago Azevedo",
      "Michail Mamalakis",
      "John Suckling"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04539v1",
    "abstract": "Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs.",
    "fetched_at": "2025-11-09T02:21:28.181079Z"
  },
  {
    "id": "2511.04541v1",
    "title": "LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Baptiste Bonin",
      "Maxime Heuillet",
      "Audrey Durand"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04541v1",
    "abstract": "Modeling user preferences across domains remains a key challenge in slate recommendation (i.e. recommending an ordered sequence of items) research. We investigate how Large Language Models (LLM) can effectively act as world models of user preferences through pairwise reasoning over slates. We conduct an empirical study involving several LLMs on three tasks spanning different datasets. Our results reveal relationships between task performance and properties of the preference function captured by LLMs, hinting towards areas for improvement and highlighting the potential of LLMs as world models in recommender systems.",
    "fetched_at": "2025-11-09T02:21:28.181035Z"
  },
  {
    "id": "2511.04550v1",
    "title": "Confidential Computing for Cloud Security: Exploring Hardware based   Encryption Using Trusted Execution Environments",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Dhruv Deepak Agarwal",
      "Aswani Kumar Cherukuri"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04550v1",
    "abstract": "The growth of cloud computing has revolutionized data processing and storage capacities to another levels of scalability and flexibility. But in the process, it has created a huge challenge of security, especially in terms of safeguarding sensitive data. Classical security practices, including encryption at rest and during transit, fail to protect data in use and expose it to various possible breaches. In response to this problem , Confidential Computing has been a tool ,seeking to secure data in processing by usage of hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts within the processor, where data is kept confidential ,intact and secure , even with malicious software or compromised operating systems. In this research, we have explored the architecture and security features of TEEs like Intel SGX and ARM TrustZone, and their effectiveness in improving cloud data security. From a thorough literature survey ,we have analyzed the deployment strategies, performance indicators, and practical uses of these TEEs for the same purpose. In addition, we have discussed the issues regarding deployment, possible weaknesses, scalability issues, and integration issues. Our results focuses on the central position of TEEs in strengthening and advancing cloud security infrastructures, pointing towards their ability to create a secure foundation for Confidential Computing.",
    "fetched_at": "2025-11-09T02:21:28.180997Z"
  },
  {
    "id": "2511.04556v1",
    "title": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse   Sensing Approach",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "Zihang Ding",
      "Kun Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04556v1",
    "abstract": "Urban surface water flooding, triggered by intense rainfall overwhelming drainage systems, is increasingly frequent and widespread. While flood prediction and monitoring in high spatial-temporal resolution are desired, practical constraints in time, budget, and technology hinder its full implementation. How to monitor urban drainage networks and predict flow conditions under constrained resource is a major challenge. This study presents a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to optimize sensor placement and reconstruct peak flowrates in a stormwater system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case study. We utilized a SWMM model to generate a training dataset of peak flowrate profiles across the stormwater network. Furthermore, we applied DSS - leveraging singular value decomposition for dimensionality reduction and QR factorization for sensor allocation - to identify the optimal monitoring nodes based on the simulated training dataset. We then validated the representativeness of these identified monitoring nodes by comparing the DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three optimally placed sensors among 77 nodes achieved satisfactory reconstruction performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to 75th percentiles). In addition, the model showed good robustness to uncertainty in measurements. Its robustness to sensor failures is location-dependent and improves with the number of sensors deployed. The framework balances computational efficiency and physical interpretability, enabling high-accuracy flow reconstruction with minimal sensors. This DSS framework can be further integrated with predictive models to realize flood early warning and real-time control under limited sensing and monitoring resource.",
    "fetched_at": "2025-11-09T02:21:28.180954Z"
  },
  {
    "id": "2511.04557v1",
    "title": "Integrating Temporal and Structural Context in Graph Transformers for   Relational Deep Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Divyansha Lachi",
      "Mahmoud Mohammadi",
      "Joe Meyer",
      "Vinam Arora",
      "Tom Palczewski",
      "Eva L. Dyer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04557v1",
    "abstract": "In domains such as healthcare, finance, and e-commerce, the temporal dynamics of relational data emerge from complex interactions-such as those between patients and providers, or users and products across diverse categories. To be broadly useful, models operating on these data must integrate long-range spatial and temporal dependencies across diverse types of entities, while also supporting multiple predictive tasks. However, existing graph models for relational data primarily focus on spatial structure, treating temporal information merely as a filtering constraint to exclude future events rather than a modeling signal, and are typically designed for single-task prediction. To address these gaps, we introduce a temporal subgraph sampler that enhances global context by retrieving nodes beyond the immediate neighborhood to capture temporally relevant relationships. In addition, we propose the Relational Graph Perceiver (RGP), a graph transformer architecture for relational deep learning that leverages a cross-attention-based latent bottleneck to efficiently integrate information from both structural and temporal contexts. This latent bottleneck integrates signals from different node and edge types into a common latent space, enabling the model to build global context across the entire relational system. RGP also incorporates a flexible cross-attention decoder that supports joint learning across tasks with disjoint label spaces within a single model. Experiments on RelBench, SALT, and CTU show that RGP delivers state-of-the-art performance, offering a general and scalable solution for relational deep learning with support for diverse predictive tasks.",
    "fetched_at": "2025-11-09T02:21:28.180902Z"
  },
  {
    "id": "2511.04560v1",
    "title": "BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented   Generation Strategies for Bangla Biomedical Question Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Sadia Sultana",
      "Saiyma Sittul Muna",
      "Mosammat Zannatul Samarukh",
      "Ajwad Abrar",
      "Tareque Mohmud Chowdhury"
    ],
    "institution": "OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2511.04560v1",
    "abstract": "Developing accurate biomedical Question Answering (QA) systems in low-resource languages remains a major challenge, limiting equitable access to reliable medical knowledge. This paper introduces BanglaMedQA and BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical artificial intelligence (AI). The study applies and benchmarks several Retrieval-Augmented Generation (RAG) strategies, including Traditional, Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining textbook-based and web retrieval with generative reasoning to improve factual accuracy. A key novelty lies in integrating a Bangla medical textbook corpus through Optical Character Recognition (OCR) and implementing an Agentic RAG pipeline that dynamically selects between retrieval and reasoning strategies. Experimental results show that the Agentic RAG achieved the highest accuracy 89.54% with openai/gpt-oss-120b, outperforming other configurations and demonstrating superior rationale quality. These findings highlight the potential of RAG-based methods to enhance the reliability and accessibility of Bangla medical QA, establishing a foundation for future research in multilingual medical artificial intelligence.",
    "fetched_at": "2025-11-09T02:21:28.180844Z"
  },
  {
    "id": "2511.04564v1",
    "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in   Scientific AI",
    "date": "2025-11-06",
    "tags": [
      "physics.comp-ph",
      "comp-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yoh-ichi Mototake",
      "Makoto Sasaki"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04564v1",
    "abstract": "Physics-informed machine learning (PIML) integrates partial differential equations (PDEs) into machine learning models to solve inverse problems, such as estimating coefficient functions (e.g., the Hamiltonian function) that characterize physical systems. This framework enables data-driven understanding and prediction of complex physical phenomena. While coefficient functions in PIML are typically estimated on the basis of predictive performance, physics as a discipline does not rely solely on prediction accuracy to evaluate models. For example, Kepler's heliocentric model was favored owing to small discrepancies in planetary motion, despite its similar predictive accuracy to the geocentric model. This highlights the inherent uncertainties in data-driven model inference and the scientific importance of selecting physically meaningful solutions. In this paper, we propose a framework to quantify and analyze such uncertainties in the estimation of coefficient functions in PIML. We apply our framework to reduced model of magnetohydrodynamics and our framework shows that there are uncertainties, and unique identification is possible with geometric constraints. Finally, we confirm that we can estimate the reduced model uniquely by incorporating these constraints.",
    "fetched_at": "2025-11-09T02:21:28.180792Z"
  },
  {
    "id": "2511.04567v1",
    "title": "Machine Learning for Electron-Scale Turbulence Modeling in W7-X",
    "date": "2025-11-06",
    "tags": [
      "physics.plasm-ph",
      "plasm-ph",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Ionut-Gabriel Farcas",
      "Don Lawrence Carl Agapito Fernando",
      "Alejandro Banon Navarro",
      "Gabriele Merlo",
      "Frank Jenko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04567v1",
    "abstract": "Constructing reduced models for turbulent transport is essential for accelerating profile predictions and enabling many-query tasks such as uncertainty quantification, parameter scans, and design optimization. This paper presents machine-learning-driven reduced models for Electron Temperature Gradient (ETG) turbulence in the Wendelstein 7-X (W7-X) stellarator. Each model predicts the ETG heat flux as a function of three plasma parameters: the normalized electron temperature radial gradient ($\\omega_{T_e}$), the ratio of normalized electron temperature and density radial gradients ($\\eta_e$), and the electron-to-ion temperature ratio ($\\tau$). We first construct models across seven radial locations using regression and an active machine-learning-based procedure. This process initializes models using low-cardinality sparse-grid training data and then iteratively refines their training sets by selecting the most informative points from a pre-existing simulation database. We evaluate the prediction capabilities of our models using out-of-sample datasets with over $393$ points per location, and $95\\%$ prediction intervals are estimated via bootstrapping to assess prediction uncertainty. We then investigate the construction of generalized reduced models, including a generic, position-independent model, and assess their heat flux prediction capabilities at three additional locations. Our models demonstrate robust performance and predictive accuracy comparable to the original reference simulations, even when applied beyond the training domain.",
    "fetched_at": "2025-11-09T02:21:28.180749Z"
  },
  {
    "id": "2511.04568v1",
    "title": "Riesz Regression As Direct Density Ratio Estimation",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "econ.EM",
      "EM",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Masahiro Kato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04568v1",
    "abstract": "Riesz regression has garnered attention as a tool in debiased machine learning for causal and structural parameter estimation (Chernozhukov et al., 2021). This study shows that Riesz regression is closely related to direct density-ratio estimation (DRE) in important cases, including average treat- ment effect (ATE) estimation. Specifically, the idea and objective in Riesz regression coincide with the one in least-squares importance fitting (LSIF, Kanamori et al., 2009) in direct density-ratio estimation. While Riesz regression is general in the sense that it can be applied to Riesz representer estimation in a wide class of problems, the equivalence with DRE allows us to directly import exist- ing results in specific cases, including convergence-rate analyses, the selection of loss functions via Bregman-divergence minimization, and regularization techniques for flexible models, such as neural networks. Conversely, insights about the Riesz representer in debiased machine learning broaden the applications of direct density-ratio estimation methods. This paper consolidates our prior results in Kato (2025a) and Kato (2025b).",
    "fetched_at": "2025-11-09T02:21:28.180694Z"
  },
  {
    "id": "2511.04570v1",
    "title": "Thinking with Video: Video Generation as a Promising Multimodal   Reasoning Paradigm",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jingqi Tong",
      "Yurong Mou",
      "Hangcheng Li",
      "Mingzhe Li",
      "Yongzhuo Yang",
      "Ming Zhang",
      "Qiguang Chen",
      "Tianyi Liang",
      "Xiaomeng Hu",
      "Yining Zheng",
      "Xinchi Chen",
      "Jun Zhao",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04570v1",
    "abstract": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly improve the reasoning ability of large language models (LLMs) and Vision Language Models (VLMs). However, these paradigms have inherent limitations. (1) Images capture only single moments and fail to represent dynamic processes or continuous changes, and (2) The separation of text and vision as distinct modalities, hindering unified multimodal understanding and generation. To overcome these limitations, we introduce \"Thinking with Video\", a new paradigm that leverages video generation models, such as Sora-2, to bridge visual and textual reasoning in a unified temporal framework. To support this exploration, we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks, Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU. Furthermore, we systematically analyse the source of these abilities. We also find that self-consistency and in-context learning can improve Sora-2's performance. In summary, our findings demonstrate that the video generation model is the potential unified multimodal understanding and generation model, positions \"thinking with video\" as a unified multimodal reasoning paradigm.",
    "fetched_at": "2025-11-09T02:21:28.180655Z"
  },
  {
    "id": "2511.04573v1",
    "title": "ARETE: an R package for Automated REtrieval from TExt with large   language models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Vasco V. Branco",
      "Jandó Benedek",
      "Lidia Pivovarova",
      "Luís Correia",
      "Pedro Cardoso"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04573v1",
    "abstract": "1. A hard stop for the implementation of rigorous conservation initiatives is our lack of key species data, especially occurrence data. Furthermore, researchers have to contend with an accelerated speed at which new information must be collected and processed due to anthropogenic activity. Publications ranging from scientific papers to gray literature contain this crucial information but their data are often not machine-readable, requiring extensive human work to be retrieved. 2. We present the ARETE R package, an open-source software aiming to automate data extraction of species occurrences powered by large language models, namely using the chatGPT Application Programming Interface. This R package integrates all steps of the data extraction and validation process, from Optical Character Recognition to detection of outliers and output in tabular format. Furthermore, we validate ARETE through systematic comparison between what is modelled and the work of human annotators. 3. We demonstrate the usefulness of the approach by comparing range maps produced using GBIF data and with those automatically extracted for 100 species of spiders. Newly extracted data allowed to expand the known Extent of Occurrence by a mean three orders of magnitude, revealing new areas where the species were found in the past, which mayhave important implications for spatial conservation planning and extinction risk assessments. 4. ARETE allows faster access to hitherto untapped occurrence data, a potential game changer in projects requiring such data. Researchers will be able to better prioritize resources, manually verifying selected species while maintaining automated extraction for the majority. This workflow also allows predicting available bibliographic data during project planning.",
    "fetched_at": "2025-11-09T02:21:28.180574Z"
  },
  {
    "id": "2511.04576v1",
    "title": "Physics-Informed Neural Networks and Neural Operators for Parametric   PDEs: A Human-AI Collaborative Analysis",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "68T01"
    ],
    "authors": [
      "Zhuo Zhang",
      "Xiong Xiong",
      "Sen Zhang",
      "Yuan Zhao",
      "Xi Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04576v1",
    "abstract": "PDEs arise ubiquitously in science and engineering, where solutions depend on parameters (physical properties, boundary conditions, geometry). Traditional numerical methods require re-solving the PDE for each parameter, making parameter space exploration prohibitively expensive. Recent machine learning advances, particularly physics-informed neural networks (PINNs) and neural operators, have revolutionized parametric PDE solving by learning solution operators that generalize across parameter spaces. We critically analyze two main paradigms: (1) PINNs, which embed physical laws as soft constraints and excel at inverse problems with sparse data, and (2) neural operators (e.g., DeepONet, Fourier Neural Operator), which learn mappings between infinite-dimensional function spaces and achieve unprecedented generalization. Through comparisons across fluid dynamics, solid mechanics, heat transfer, and electromagnetics, we show neural operators can achieve computational speedups of $10^3$ to $10^5$ times faster than traditional solvers for multi-query scenarios, while maintaining comparable accuracy. We provide practical guidance for method selection, discuss theoretical foundations (universal approximation, convergence), and identify critical open challenges: high-dimensional parameters, complex geometries, and out-of-distribution generalization. This work establishes a unified framework for understanding parametric PDE solvers via operator learning, offering a comprehensive, incrementally updated resource for this rapidly evolving field",
    "fetched_at": "2025-11-09T02:21:28.180516Z"
  },
  {
    "id": "2511.04583v1",
    "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration   from a Baseline Paper",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Atsuyuki Miyai",
      "Mashiro Toyooka",
      "Takashi Otonari",
      "Zaiying Zhao",
      "Kiyoharu Aizawa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04583v1",
    "abstract": "Understanding the current capabilities and risks of AI Scientist systems is essential for ensuring trustworthy and sustainable AI-driven scientific progress while preserving the integrity of the academic ecosystem. To this end, we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system that mimics the core research workflow of a novice student researcher: Given the baseline paper from the human mentor, it analyzes its limitations, formulates novel hypotheses for improvement, validates them through rigorous experimentation, and writes a paper with the results. Unlike previous approaches that assume full automation or operate on small-scale code, Jr. AI Scientist follows a well-defined research workflow and leverages modern coding agents to handle complex, multi-file implementations, leading to scientifically valuable contributions. For evaluation, we conducted automated assessments using AI Reviewers, author-led evaluations, and submissions to Agents4Science, a venue dedicated to AI-driven scientific contributions. The findings demonstrate that Jr. AI Scientist generates papers receiving higher review scores than existing fully automated systems. Nevertheless, we identify important limitations from both the author evaluation and the Agents4Science reviews, indicating the potential risks of directly applying current AI Scientist systems and key challenges for future research. Finally, we comprehensively report various risks identified during development. We hope these insights will deepen understanding of current progress and risks in AI Scientist development.",
    "fetched_at": "2025-11-09T02:21:28.180460Z"
  },
  {
    "id": "2511.04584v1",
    "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language   Queries for Tabular Data Analysis",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.DB",
      "DB",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Daniel Gomm",
      "Cornelius Wolff",
      "Madelon Hulsebos"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04584v1",
    "abstract": "Natural language interfaces to tabular data must handle ambiguities inherent to queries. Instead of treating ambiguity as a deficiency, we reframe it as a feature of cooperative interaction, where the responsibility of query specification is shared among the user and the system. We develop a principled framework distinguishing cooperative queries, i.e., queries that yield a resolvable interpretation, from uncooperative queries that cannot be resolved. Applying the framework to evaluations for tabular question answering and analysis, we analyze the queries in 15 popular datasets, and observe an uncontrolled mixing of query types neither adequate for evaluating a system's execution accuracy nor for evaluating interpretation capabilities. Our framework and analysis of queries shifts the perspective from fixing ambiguity to embracing cooperation in resolving queries. This reflection enables more informed design and evaluation for natural language interfaces for tabular data, for which we outline implications and directions for future research.",
    "fetched_at": "2025-11-09T02:21:28.180406Z"
  },
  {
    "id": "2511.04588v1",
    "title": "Question the Questions: Auditing Representation in Online Deliberative   Processes",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Soham De",
      "Lodewijk Gelauff",
      "Ashish Goel",
      "Smitha Milli",
      "Ariel Procaccia",
      "Alice Siu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04588v1",
    "abstract": "A central feature of many deliberative processes, such as citizens' assemblies and deliberative polls, is the opportunity for participants to engage directly with experts. While participants are typically invited to propose questions for expert panels, only a limited number can be selected due to time constraints. This raises the challenge of how to choose a small set of questions that best represent the interests of all participants. We introduce an auditing framework for measuring the level of representation provided by a slate of questions, based on the social choice concept known as justified representation (JR). We present the first algorithms for auditing JR in the general utility setting, with our most efficient algorithm achieving a runtime of $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number of proposed questions. We apply our auditing methods to historical deliberations, comparing the representativeness of (a) the actual questions posed to the expert panel (chosen by a moderator), (b) participants' questions chosen via integer linear programming, (c) summary questions generated by large language models (LLMs). Our results highlight both the promise and current limitations of LLMs in supporting deliberative processes. By integrating our methods into an online deliberation platform that has been used for over hundreds of deliberations across more than 50 countries, we make it easy for practitioners to audit and improve representation in future deliberations.",
    "fetched_at": "2025-11-09T02:21:28.180362Z"
  },
  {
    "id": "2511.04594v1",
    "title": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest   Path Problems",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Utkarsh U. Chavan",
      "Prashant Trivedi",
      "Nandyala Hemachandra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04594v1",
    "abstract": "Multi-agent systems (MAS) are central to applications such as swarm robotics and traffic routing, where agents must coordinate in a decentralized manner to achieve a common objective. Stochastic Shortest Path (SSP) problems provide a natural framework for modeling decentralized control in such settings. While the problem of learning in SSP has been extensively studied in single-agent settings, the decentralized multi-agent variant remains largely unexplored. In this work, we take a step towards addressing that gap. We study decentralized multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the transition dynamics and costs are represented using linear models. Applying novel symmetry-based arguments, we identify the structure of optimal policies. Our main contribution is the first regret lower bound for this setting based on the construction of hard-to-learn instances for any number of agents, $n$. Our regret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the inherent learning difficulty in Dec-MASSPs. These insights clarify the learning complexity of decentralized control and can further guide the design of efficient learning algorithms in multi-agent systems.",
    "fetched_at": "2025-11-09T02:21:28.180271Z"
  },
  {
    "id": "2511.04611v1",
    "title": "evomap: A Toolbox for Dynamic Mapping in Python",
    "date": "2025-11-06",
    "tags": [
      "cs.MS",
      "MS",
      "cs.LG",
      "LG",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Maximilian Matthe"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04611v1",
    "abstract": "This paper presents evomap, a Python package for dynamic mapping. Mapping methods are widely used across disciplines to visualize relationships among objects as spatial representations, or maps. However, most existing statistical software supports only static mapping, which captures objects' relationships at a single point in time and lacks tools to analyze how these relationships evolve. evomap fills this gap by implementing the dynamic mapping framework EvoMap, originally proposed by Matthe, Ringel, and Skiera (2023), which adapts traditional static mapping methods for dynamic analyses. The package supports multiple mapping techniques, including variants of Multidimensional Scaling (MDS), Sammon Mapping, and t-distributed Stochastic Neighbor Embedding (t-SNE). It also includes utilities for data preprocessing, exploration, and result evaluation, offering a comprehensive toolkit for dynamic mapping applications. This paper outlines the foundations of static and dynamic mapping, describes the architecture and functionality of evomap, and illustrates its application through an extensive usage example.",
    "fetched_at": "2025-11-09T02:21:28.180189Z"
  },
  {
    "id": "2511.04619v1",
    "title": "Dynamic causal discovery in Alzheimer's disease through latent   pseudotime modelling",
    "date": "2025-11-06",
    "tags": [
      "stat.AP",
      "AP",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Natalia Glazman",
      "Jyoti Mangal",
      "Pedro Borges",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04619v1",
    "abstract": "The application of causal discovery to diseases like Alzheimer's (AD) is limited by the static graph assumptions of most methods; such models cannot account for an evolving pathophysiology, modulated by a latent disease pseudotime. We propose to apply an existing latent variable model to real-world AD data, inferring a pseudotime that orders patients along a data-driven disease trajectory independent of chronological age, then learning how causal relationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC 0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge substantially improved graph accuracy and orientation. Our framework reveals dynamic interactions between novel (NfL, GFAP) and established AD markers, enabling practical causal discovery despite violated assumptions.",
    "fetched_at": "2025-11-09T02:21:28.180151Z"
  },
  {
    "id": "2511.04622v1",
    "title": "ODE approximation for the Adam algorithm: General and overparametrized   setting",
    "date": "2025-11-06",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG",
      "math.PR",
      "PR"
    ],
    "authors": [
      "Steffen Dereich",
      "Arnulf Jentzen",
      "Sebastian Kassing"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04622v1",
    "abstract": "The Adam optimizer is currently presumably the most popular optimization method in deep learning. In this article we develop an ODE based method to study the Adam optimizer in a fast-slow scaling regime. For fixed momentum parameters and vanishing step-sizes, we show that the Adam algorithm is an asymptotic pseudo-trajectory of the flow of a particular vector field, which is referred to as the Adam vector field. Leveraging properties of asymptotic pseudo-trajectories, we establish convergence results for the Adam algorithm. In particular, in a very general setting we show that if the Adam algorithm converges, then the limit must be a zero of the Adam vector field, rather than a local minimizer or critical point of the objective function.   In contrast, in the overparametrized empirical risk minimization setting, the Adam algorithm is able to locally find the set of minima. Specifically, we show that in a neighborhood of the global minima, the objective function serves as a Lyapunov function for the flow induced by the Adam vector field. As a consequence, if the Adam algorithm enters a neighborhood of the global minima infinitely often, it converges to the set of global minima.",
    "fetched_at": "2025-11-09T02:21:28.180090Z"
  },
  {
    "id": "2511.04638v1",
    "title": "Addressing divergent representations from causal interventions on neural   networks",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Satchel Grant",
      "Simon Jerome Han",
      "Alexa Tartaglini",
      "Christopher Potts"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04638v1",
    "abstract": "A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raises concerns about how faithful their resulting explanations are to the target model in its natural state. First, we demonstrate empirically that common causal intervention techniques often do shift internal representations away from the natural distribution of the target model. Then, we provide a theoretical analysis of two classes of such divergences: `harmless' divergences that occur in the null-space of the weights and from covariance within behavioral decision boundaries, and `pernicious' divergences that activate hidden network pathways and cause dormant behavioral changes. Finally, in an effort to mitigate the pernicious cases, we modify the Counterfactual Latent (CL) loss from Grant (2025) that regularizes interventions to remain closer to the natural distributions, reducing the likelihood of harmful divergences while preserving the interpretive power of interventions. Together, these results highlight a path towards more reliable interpretability methods.",
    "fetched_at": "2025-11-09T02:21:28.180046Z"
  },
  {
    "id": "2511.04641v1",
    "title": "Efficient probabilistic surrogate modeling techniques for   partially-observed large-scale dynamical systems",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hans Harder",
      "Abhijeet Vishwasrao",
      "Luca Guastoni",
      "Ricardo Vinuesa",
      "Sebastian Peitz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04641v1",
    "abstract": "This paper is concerned with probabilistic techniques for forecasting dynamical systems described by partial differential equations (such as, for example, the Navier-Stokes equations). In particular, it is investigating and comparing various extensions to the flow matching paradigm that reduce the number of sampling steps. In this regard, it compares direct distillation, progressive distillation, adversarial diffusion distillation, Wasserstein GANs and rectified flows. Moreover, experiments are conducted on a set of challenging systems. In particular, we also address the challenge of directly predicting 2D slices of large-scale 3D simulations, paving the way for efficient inflow generation for solvers.",
    "fetched_at": "2025-11-09T02:21:28.179996Z"
  },
  {
    "id": "2511.04643v1",
    "title": "When retrieval outperforms generation: Dense evidence retrieval for   scalable fake news detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alamgir Munir Qazi",
      "John P. McCrae",
      "Jamal Abdul Nasir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04643v1",
    "abstract": "The proliferation of misinformation necessitates robust yet computationally efficient fact verification systems. While current state-of-the-art approaches leverage Large Language Models (LLMs) for generating explanatory rationales, these methods face significant computational barriers and hallucination risks in real-world deployments. We present DeReC (Dense Retrieval Classification), a lightweight framework that demonstrates how general-purpose text embeddings can effectively replace autoregressive LLM-based approaches in fact verification tasks. By combining dense retrieval with specialized classification, our system achieves better accuracy while being significantly more efficient. DeReC outperforms explanation-generating LLMs in efficiency, reducing runtime by 95% on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92% on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds), showcasing its effectiveness across varying dataset sizes. On the RAWFC dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art method L-Defense (61.20%). Our results demonstrate that carefully engineered retrieval-based systems can match or exceed LLM performance in specialized tasks while being significantly more practical for real-world deployment.",
    "fetched_at": "2025-11-09T02:21:28.179951Z"
  },
  {
    "id": "2511.04647v1",
    "title": "Optimal Inference Schedules for Masked Diffusion Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sitan Chen",
      "Kevin Cong",
      "Jerry Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04647v1",
    "abstract": "A major bottleneck of standard auto-regressive large language models is that their inference process is inherently sequential, resulting in very long and costly inference times. To circumvent this, practitioners proposed a class of language models called diffusion language models, of which the masked diffusion model (MDM) is the most successful. The MDM is able to sample tokens out-of-order and, ostensibly, many tokens at once and in parallel. However, there is very limited rigorous understanding of how much parallel sampling these models can perform without noticeable degradation in their sampling performance. Prior work of Li and Cai obtained some preliminary bounds, but these are not tight for many natural classes of distributions. In this work, we give a new, exact characterization of the expected divergence between the true distribution and the sampled distribution, for any distribution and any unmasking schedule for the sampler, showing an elegant connection to the theory of univariate function approximation.   By leveraging this connection, we then attain a number of novel lower and upper bounds for this problem. While the connection to function approximation in principle gives the optimal unmasking schedule for any distribution, we show that it is in general impossible to compete with it without strong a priori knowledge of the distribution, even in seemingly benign settings. However, we also demonstrate new upper bounds and new sampling schedules in terms of well-studied information-theoretic properties of the base distribution, namely, its total correlation and dual total correlation, which show that in some natural settings, one can sample in $O(log n)$ steps without any visible loss in performance, where $n$ is the total sequence length.",
    "fetched_at": "2025-11-09T02:21:28.179850Z"
  },
  {
    "id": "2511.04653v1",
    "title": "TT-Prune: Joint Model Pruning and Resource Allocation for   Communication-efficient Time-triggered Federated Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinlu Zhang",
      "Yansha Deng",
      "Toktam Mahmoodi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04653v1",
    "abstract": "Federated learning (FL) offers new opportunities in machine learning, particularly in addressing data privacy concerns. In contrast to conventional event-based federated learning, time-triggered federated learning (TT-Fed), as a general form of both asynchronous and synchronous FL, clusters users into different tiers based on fixed time intervals. However, the FL network consists of a growing number of user devices with limited wireless bandwidth, consequently magnifying issues such as stragglers and communication overhead. In this paper, we introduce adaptive model pruning to wireless TT-Fed systems and study the problem of jointly optimizing the pruning ratio and bandwidth allocation to minimize the training loss while ensuring minimal learning latency. To answer this question, we perform convergence analysis on the gradient l_2 norm of the TT-Fed model based on model pruning. Based on the obtained convergence upper bound, a joint optimization problem of pruning ratio and wireless bandwidth is formulated to minimize the model training loss under a given delay threshold. Then, we derive closed-form solutions for wireless bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The simulation results show that model pruning could reduce the communication cost by 40% while maintaining the model performance at the same level.",
    "fetched_at": "2025-11-09T02:21:28.179802Z"
  },
  {
    "id": "2511.04654v1",
    "title": "Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought   Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mohammad Atif Quamar",
      "Mohammad Areeb"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04654v1",
    "abstract": "Chain-of-Thought (CoT) prompting is a key technique for enabling complex reasoning in large language models. However, generating full, fixed-length rationales is computationally wasteful, inflating both token usage and latency. We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free decoding algorithm that adaptively halts rationale generation. LEASH monitors two intrinsic signals: the slope of token-level entropy and the improvement in the top-logit margin. It terminates the generation once both signals plateau, indicating the model has reached a stable reasoning state. Across four instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces average token generation by 30--35% and latency by 27%, while incurring a 10 p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no additional training or supervision, offering a simple and efficient alternative to CoT decoding.",
    "fetched_at": "2025-11-09T02:21:28.179755Z"
  },
  {
    "id": "2511.04659v1",
    "title": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "physics.ao-ph",
      "ao-ph"
    ],
    "authors": [
      "Huaguan Chen",
      "Wei Han",
      "Haofei Sun",
      "Ning Lin",
      "Xingtao Song",
      "Yunfan Yang",
      "Jie Tian",
      "Yang Liu",
      "Ji-Rong Wen",
      "Xiaoye Zhang",
      "Xueshun Shen",
      "Hao Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04659v1",
    "abstract": "Extreme precipitation nowcasting demands high spatiotemporal fidelity and extended lead times, yet existing approaches remain limited. Numerical Weather Prediction (NWP) and its deep-learning emulations are too slow and coarse for rapidly evolving convection, while extrapolation and purely data-driven models suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce a gray-box, fully three-dimensional nowcasting framework that directly processes volumetric radar reflectivity and couples physically constrained neural operators with datadriven learning. The model learns vertically varying 3D advection fields under a conservative advection operator, parameterizes spatially varying diffusion, and introduces a Brownian-motion--inspired stochastic term to represent unresolved motions. A residual branch captures small-scale convective initiation and microphysical variability, while a diffusion-based stochastic module estimates uncertainty. The framework achieves more accurate forecasts up to three-hour lead time across precipitation regimes and ranked first in 57\\% of cases in a blind evaluation by 160 meteorologists. By restoring full 3D dynamics with physical consistency, it offers a scalable and robust pathway for skillful and reliable nowcasting of extreme precipitation.",
    "fetched_at": "2025-11-09T02:21:28.179715Z"
  },
  {
    "id": "2511.04662v1",
    "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical   Consistency Checks",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yu Feng",
      "Nathaniel Weir",
      "Kaj Bostrom",
      "Sam Bayless",
      "Darion Cassel",
      "Sapana Chaudhary",
      "Benjamin Kiesl-Reiter",
      "Huzefa Rangwala"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04662v1",
    "abstract": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but they cannot reliably verify their own logic. Even when they reach correct answers, the underlying reasoning may be flawed, undermining trust in high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a neuro-symbolic method that extracts and verifies formal logical arguments from CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order logic and identifies premises that ground the argument in source context, commonsense knowledge, or prior reasoning steps. The symbolic representation enables automated solvers to verify logical validity while the NL premises allow humans and systems to identify ungrounded or fallacious reasoning steps. Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT effectively identifies flawed reasoning, and serves as a strong predictor of final answer correctness. We also leverage VeriCoT's verification signal for (1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct preference optimization (DPO) using verification-based pairwise rewards, further improving reasoning validity and accuracy.",
    "fetched_at": "2025-11-09T02:21:28.179636Z"
  },
  {
    "id": "2511.04665v1",
    "title": "Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation   of Soft-Body Interactions",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kaifeng Zhang",
      "Shuo Sha",
      "Hanxiao Jiang",
      "Matthew Loper",
      "Hyunjong Song",
      "Guangyan Cai",
      "Zhuo Xu",
      "Xiaochen Hu",
      "Changxi Zheng",
      "Yunzhu Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04665v1",
    "abstract": "Robotic manipulation policies are advancing rapidly, but their direct evaluation in the real world remains costly, time-consuming, and difficult to reproduce, particularly for tasks involving deformable objects. Simulation provides a scalable and systematic alternative, yet existing simulators often fail to capture the coupled visual and physical complexity of soft-body interactions. We present a real-to-sim policy evaluation framework that constructs soft-body digital twins from real-world videos and renders robots, objects, and environments with photorealistic fidelity using 3D Gaussian Splatting. We validate our approach on representative deformable manipulation tasks, including plush toy packing, rope routing, and T-block pushing, demonstrating that simulated rollouts correlate strongly with real-world execution performance and reveal key behavioral patterns of learned policies. Our results suggest that combining physics-informed reconstruction with high-quality rendering enables reproducible, scalable, and accurate evaluation of robotic manipulation policies. Website: https://real2sim-eval.github.io/",
    "fetched_at": "2025-11-09T02:21:28.179576Z"
  },
  {
    "id": "2511.04666v1",
    "title": "Forgetting is Everywhere",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Ben Sanati",
      "Thomas L. Lee",
      "Trevor McInroe",
      "Aidan Scannell",
      "Nikolay Malkin",
      "David Abel",
      "Amos Storkey"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04666v1",
    "abstract": "A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.",
    "fetched_at": "2025-11-09T02:21:28.179506Z"
  },
  {
    "id": "2511.04667v1",
    "title": "Multi-Method Analysis of Mathematics Placement Assessments: Classical,   Machine Learning, and Clustering Approaches",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "97C70, 62P25, 62H30, 68T05"
    ],
    "authors": [
      "Julian D. Allagan",
      "Dasia A. Singleton",
      "Shanae N. Perry",
      "Gabrielle C. Morgan",
      "Essence A. Morgan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04667v1",
    "abstract": "This study evaluates a 40-item mathematics placement examination administered to 198 students using a multi-method framework combining Classical Test Theory, machine learning, and unsupervised clustering. Classical Test Theory analysis reveals that 55\\% of items achieve excellent discrimination ($D \\geq 0.40$) while 30\\% demonstrate poor discrimination ($D < 0.20$) requiring replacement. Question 6 (Graph Interpretation) emerges as the examination's most powerful discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA F-statistic ($F = 4609.1$), and maximum Random Forest feature importance (0.206), accounting for 20.6\\% of predictive power. Machine learning algorithms demonstrate exceptional performance, with Random Forest and Gradient Boosting achieving 97.5\\% and 96.0\\% cross-validation accuracy. K-means clustering identifies a natural binary competency structure with a boundary at 42.5\\%, diverging from the institutional threshold of 55\\% and suggesting potential overclassification into remedial categories. The two-cluster solution exhibits exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster purity. Convergent evidence across methods supports specific refinements: replace poorly discriminating items, implement a two-stage assessment, and integrate Random Forest predictions with transparency mechanisms. These findings demonstrate that multi-method integration provides a robust empirical foundation for evidence-based mathematics placement optimization.",
    "fetched_at": "2025-11-09T02:21:28.179448Z"
  },
  {
    "id": "2511.04671v1",
    "title": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human   Demonstrations",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Maximus A. Pace",
      "Prithwish Dan",
      "Chuanruo Ning",
      "Atiksh Bhardwaj",
      "Audrey Du",
      "Edward W. Duan",
      "Wei-Chiu Ma",
      "Kushal Kedia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04671v1",
    "abstract": "Human videos can be recorded quickly and at scale, making them an appealing source of training data for robot learning. However, humans and robots differ fundamentally in embodiment, resulting in mismatched action execution. Direct kinematic retargeting of human hand motion can therefore produce actions that are physically infeasible for robots. Despite these low-level differences, human demonstrations provide valuable motion cues about how to manipulate and interact with objects. Our key idea is to exploit the forward diffusion process: as noise is added to actions, low-level execution differences fade while high-level task guidance is preserved. We present X-Diffusion, a principled framework for training diffusion policies that maximally leverages human data without learning dynamically infeasible motions. X-Diffusion first trains a classifier to predict whether a noisy action is executed by a human or robot. Then, a human action is incorporated into policy training only after adding sufficient noise such that the classifier cannot discern its embodiment. Actions consistent with robot execution supervise fine-grained denoising at low noise levels, while mismatched human actions provide only coarse guidance at higher noise levels. Our experiments show that naive co-training under execution mismatches degrades policy performance, while X-Diffusion consistently improves it. Across five manipulation tasks, X-Diffusion achieves a 16% higher average success rate than the best baseline. The project website is available at https://portal-cornell.github.io/X-Diffusion/.",
    "fetched_at": "2025-11-09T02:21:28.179388Z"
  },
  {
    "id": "2511.04681v1",
    "title": "Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference   from weak lensing and galaxy clustering maps with deep learning. I. Analysis   design",
    "date": "2025-11-06",
    "tags": [
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "A. Thomsen",
      "J. Bucko",
      "T. Kacprzak",
      "V. Ajani",
      "J. Fluri",
      "A. Refregier",
      "D. Anbajagane",
      "F. J. Castander",
      "A. Ferté",
      "M. Gatti",
      "N. Jeffrey",
      "A. Alarcon",
      "A. Amon",
      "K. Bechtol",
      "M. R. Becker",
      "G. M. Bernstein",
      "A. Campos",
      "A. Carnero Rosell",
      "C. Chang",
      "R. Chen",
      "A. Choi",
      "M. Crocce",
      "C. Davis",
      "J. DeRose",
      "S. Dodelson",
      "C. Doux",
      "K. Eckert",
      "J. Elvin-Poole",
      "S. Everett",
      "P. Fosalba",
      "D. Gruen",
      "I. Harrison",
      "K. Herner",
      "E. M. Huff",
      "M. Jarvis",
      "N. Kuropatkin",
      "P. -F. Leget",
      "N. MacCrann",
      "J. McCullough",
      "J. Myles",
      "A. Navarro-Alsina",
      "S. Pandey",
      "A. Porredon",
      "J. Prat",
      "M. Raveri",
      "M. Rodriguez-Monroy",
      "R. P. Rollins",
      "A. Roodman",
      "E. S. Rykoff",
      "C. Sánchez",
      "L. F. Secco",
      "E. Sheldon",
      "T. Shin",
      "M. A. Troxel",
      "I. Tutusaus",
      "T. N. Varga",
      "N. Weaverdyck",
      "R. H. Wechsler",
      "B. Yanny",
      "B. Yin",
      "Y. Zhang",
      "J. Zuntz",
      "S. Allam",
      "F. Andrade-Oliveira",
      "D. Bacon",
      "J. Blazek",
      "D. Brooks",
      "R. Camilleri",
      "J. Carretero",
      "R. Cawthon",
      "L. N. da Costa",
      "M. E. da Silva Pereira",
      "T. M. Davis",
      "J. De Vicente",
      "S. Desai",
      "P. Doel",
      "J. García-Bellido",
      "G. Gutierrez",
      "S. R. Hinton",
      "D. L. Hollowood",
      "K. Honscheid",
      "D. J. James",
      "K. Kuehn",
      "O. Lahav",
      "S. Lee",
      "J. L. Marshall",
      "J. Mena-Fernández",
      "F. Menanteau",
      "R. Miquel",
      "J. Muir",
      "R. L. C. Ogando",
      "A. A. Plazas Malagón",
      "E. Sanchez",
      "D. Sanchez Cid",
      "I. Sevilla-Noarbe",
      "M. Smith",
      "E. Suchyta",
      "M. E. C. Swanson",
      "D. Thomas",
      "C. To",
      "D. L. Tucker"
    ],
    "institution": "DES Collaboration",
    "link": "http://arxiv.org/pdf/2511.04681v1",
    "abstract": "Data-driven approaches using deep learning are emerging as powerful techniques to extract non-Gaussian information from cosmological large-scale structure. This work presents the first simulation-based inference (SBI) pipeline that combines weak lensing and galaxy clustering maps in a realistic Dark Energy Survey Year 3 (DES Y3) configuration and serves as preparation for a forthcoming analysis of the survey data. We develop a scalable forward model based on the CosmoGridV1 suite of N-body simulations to generate over one million self-consistent mock realizations of DES Y3 at the map level. Leveraging this large dataset, we train deep graph convolutional neural networks on the full survey footprint in spherical geometry to learn low-dimensional features that approximately maximize mutual information with target parameters. These learned compressions enable neural density estimation of the implicit likelihood via normalizing flows in a ten-dimensional parameter space spanning cosmological $w$CDM, intrinsic alignment, and linear galaxy bias parameters, while marginalizing over baryonic, photometric redshift, and shear bias nuisances. To ensure robustness, we extensively validate our inference pipeline using synthetic observations derived from both systematic contaminations in our forward model and independent Buzzard galaxy catalogs. Our forecasts yield significant improvements in cosmological parameter constraints, achieving $2-3\\times$ higher figures of merit in the $\\Omega_m - S_8$ plane relative to our implementation of baseline two-point statistics and effectively breaking parameter degeneracies through probe combination. These results demonstrate the potential of SBI analyses powered by deep learning for upcoming Stage-IV wide-field imaging surveys.",
    "fetched_at": "2025-11-09T02:21:28.179303Z"
  },
  {
    "id": "2511.04133v1",
    "title": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing   Platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Miguel E. Andres",
      "Vadim Fedorov",
      "Rida Sadek",
      "Enric Spagnolo-Arrizabalaga",
      "Nadescha Trudel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04133v1",
    "abstract": "Voice AI agents are rapidly transitioning to production deployments, yet systematic methods for ensuring testing reliability remain underdeveloped. Organizations cannot objectively assess whether their testing approaches (internal tools or external platforms) actually work, creating a critical measurement gap as voice AI scales to billions of daily interactions.   We present the first systematic framework for evaluating voice AI testing quality through human-centered benchmarking. Our methodology addresses the fundamental dual challenge of testing platforms: generating realistic test conversations (simulation quality) and accurately evaluating agent responses (evaluation quality). The framework combines established psychometric techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence intervals, and permutation tests) with rigorous statistical validation to provide reproducible metrics applicable to any testing approach.   To validate the framework and demonstrate its utility, we conducted comprehensive empirical evaluation of three leading commercial platforms focused on Voice AI Testing using 21,600 human judgments across 45 simulations and ground truth validation on 60 conversations. Results reveal statistically significant performance differences with the proposed framework, with the top-performing platform, Evalion, achieving 0.92 evaluation quality measured as f1-score versus 0.73 for others, and 0.61 simulation quality using a league based scoring system (including ties) vs 0.43 for other platforms.   This framework enables researchers and organizations to empirically validate the testing capabilities of any platform, providing essential measurement foundations for confident voice AI deployment at scale. Supporting materials are made available to facilitate reproducibility and adoption.",
    "fetched_at": "2025-11-09T02:21:24.635252Z"
  },
  {
    "id": "2511.04156v1",
    "title": "Deep reinforcement learning based navigation of a jellyfish-like swimmer   in flows with obstacles",
    "date": "2025-11-06",
    "tags": [
      "physics.flu-dyn",
      "flu-dyn"
    ],
    "authors": [
      "Yihao Chen",
      "Yue Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04156v1",
    "abstract": "We develop a deep reinforcement learning framework for controlling a bio-inspired jellyfish swimmer to navigate complex fluid environments with obstacles. While existing methods often rely on kinematic and geometric states, a key challenge remains in achieving efficient obstacle avoidance under strong fluid-structure interactions and near-wall effects. We augment the agent's state representation within a soft actor-critic algorithm to include the real-time forces and torque experienced by the swimmer, providing direct mechanical feedback from vortex-wall interactions. This augmented state space enables the swimmer to perceive and interpret wall proximity and orientation through distinct hydrodynamic force signatures. We analyze how these force and torque patterns, generated by walls at different positions influence the swimmer's decision-making policy. Comparative experiments with a baseline model without force feedback demonstrate that the present one with force feedback achieves higher navigation efficiency in two-dimensional obstacle-avoidance tasks. The results show that explicit force feedback facilitates earlier, smoother maneuvers and enables the exploitation of wall effects for efficient turning behaviors. With an application to autonomous cave mapping, this work underscores the critical role of direct mechanical feedback in fluid environments and presents a physics-aware machine learning framework for advancing robust underwater exploration systems.",
    "fetched_at": "2025-11-09T02:21:24.635115Z"
  },
  {
    "id": "2511.04235v1",
    "title": "Shared Spatial Memory Through Predictive Coding",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "Zhengru Fang",
      "Yu Guo",
      "Jingjing Wang",
      "Yuang Zhang",
      "Haonan An",
      "Yinhai Wang",
      "Yuguang Fang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04235v1",
    "abstract": "Sharing and reconstructing a consistent spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulate coordination as the minimization of mutual uncertainty among agents. Instantiated as an information bottleneck objective, it prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations: an artificial analogue of hippocampal social place cells (SPCs). These social representations are further enacted by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to social collective intelligence.",
    "fetched_at": "2025-11-09T02:21:24.635069Z"
  },
  {
    "id": "2511.04375v1",
    "title": "Studying the Effect of Explicit Interaction Representations on Learning   Scene-level Distributions of Human Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Anna Mészáros",
      "Javier Alonso-Mora",
      "Jens Kober"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04375v1",
    "abstract": "Effectively capturing the joint distribution of all agents in a scene is relevant for predicting the true evolution of the scene and in turn providing more accurate information to the decision processes of autonomous vehicles. While new models have been developed for this purpose in recent years, it remains unclear how to best represent the joint distributions particularly from the perspective of the interactions between agents. Thus far there is no clear consensus on how best to represent interactions between agents; whether they should be learned implicitly from data by neural networks, or explicitly modeled using the spatial and temporal relations that are more grounded in human decision-making. This paper aims to study various means of describing interactions within the same network structure and their effect on the final learned joint distributions. Our findings show that more often than not, simply allowing a network to establish interactive connections between agents based on data has a detrimental effect on performance. Instead, having well defined interactions (such as which agent of an agent pair passes first at an intersection) can often bring about a clear boost in performance.",
    "fetched_at": "2025-11-09T02:21:24.634919Z"
  },
  {
    "id": "2511.04515v1",
    "title": "Robust mean-field control under common noise uncertainty",
    "date": "2025-11-06",
    "tags": [
      "math.OC",
      "OC",
      "math.PR",
      "PR",
      "q-fin.MF",
      "MF"
    ],
    "authors": [
      "Mathieu Laurière",
      "Ariel Neufeld",
      "Kyunghyun Park"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04515v1",
    "abstract": "We propose and analyze a framework for discrete-time robust mean-field control problems under common noise uncertainty. In this framework, the mean-field interaction describes the collective behavior of infinitely many cooperative agents' state and action, while the common noise -- a random disturbance affecting all agents' state dynamics -- is uncertain. A social planner optimizes over open-loop controls on an infinite horizon to maximize the representative agent's worst-case expected reward, where worst-case corresponds to the most adverse probability measure among all candidates inducing the unknown true law of the common noise process. We refer to this optimization as a robust mean-field control problem under common noise uncertainty. We first show that this problem arises as the asymptotic limit of a cooperative $N$-agent robust optimization problem, commonly known as propagation of chaos. We then prove the existence of an optimal open-loop control by linking the robust mean field control problem to a lifted robust Markov decision problem on the space of probability measures and by establishing the dynamic programming principle and Bellman--Isaac fixed point theorem for the lifted robust Markov decision problem. Finally, we complement our theoretical results with numerical experiments motivated by distribution planning and systemic risk in finance, highlighting the advantages of accounting for common noise uncertainty.",
    "fetched_at": "2025-11-09T02:21:24.634803Z"
  },
  {
    "id": "2511.04590v1",
    "title": "Complexity as Advantage: A Regret-Based Perspective on Emergent   Structure",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Oshri Naparstek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04590v1",
    "abstract": "We introduce Complexity as Advantage (CAA), a framework that defines the complexity of a system relative to a family of observers. Instead of measuring complexity as an intrinsic property, we evaluate how much predictive regret a system induces for different observers attempting to model it. A system is complex when it is easy for some observers and hard for others, creating an information advantage. We show that this formulation unifies several notions of emergent behavior, including multiscale entropy, predictive information, and observer-dependent structure. The framework suggests that \"interesting\" systems are those positioned to create differentiated regret across observers, providing a quantitative grounding for why complexity can be functionally valuable. We demonstrate the idea through simple dynamical models and discuss implications for learning, evolution, and artificial agents.",
    "fetched_at": "2025-11-09T02:21:24.634746Z"
  },
  {
    "id": "2511.04598v1",
    "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free   Autonomous Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hampus Åström",
      "Elin Anna Topp",
      "Jacek Malec"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04598v1",
    "abstract": "In this paper we study how transforming regular reinforcement learning environments into goal-conditioned environments can let agents learn to solve tasks autonomously and reward-free. We show that an agent can learn to solve tasks by selecting its own goals in an environment-agnostic way, at training times comparable to externally guided reinforcement learning. Our method is independent of the underlying off-policy learning algorithm. Since our method is environment-agnostic, the agent does not value any goals higher than others, leading to instability in performance for individual goals. However, in our experiments, we show that the average goal success rate improves and stabilizes. An agent trained with this method can be instructed to seek any observations made in the environment, enabling generic training of agents prior to specific use cases.",
    "fetched_at": "2025-11-09T02:21:24.634702Z"
  },
  {
    "id": "2511.03925v1",
    "title": "Collaborative Agents for Automated Program Repair in Ruby",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nikta Akbarpour",
      "Mahdieh Sadat Benis",
      "Fatemeh Hendijani Fard",
      "Ali Ouni",
      "Mohamed Aymen Saied"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03925v1",
    "abstract": "Automated Program Repair (APR) has advanced rapidly with Large Language Models (LLMs), but most existing methods remain computationally expensive, and focused on a small set of languages. Ruby, despite its widespread use in web development and the persistent challenges faced by its developers, has received little attention in APR research. In this paper, we introduce RAMP, a novel lightweight framework that formulates program repair as a feedback-driven, iterative process for Ruby. RAMP employs a team of collaborative agents that generate targeted tests, reflect on errors, and refine candidate fixes until a correct solution is found. Unlike prior approaches, RAMP is designed to avoid reliance on large multilingual repair databases or costly fine-tuning, instead operating directly on Ruby through lightweight prompting and test-driven feedback. Evaluation on the XCodeEval benchmark shows that RAMP achieves a pass@1 of 67% on Ruby, outper-forming prior approaches. RAMP converges quickly within five iterations, and ablation studies confirm that test generation and self-reflection are key drivers of its performance. Further analysis shows that RAMP is particularly effective at repairing wrong answers, compilation errors, and runtime errors. Our approach provides new insights into multi-agent repair strategies, and establishes a foundation for extending LLM-based debugging tools to under-studied languages.",
    "fetched_at": "2025-11-09T02:21:22.884853Z"
  },
  {
    "id": "2511.03934v1",
    "title": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive   Error Feedback Agentic-AI",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Athma Narayanan",
      "Mahesh Subedar",
      "Omesh Tickoo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03934v1",
    "abstract": "We present an agentic flow consisting of multiple agents that combine specialized LLMs and hardware simulation tools to collaboratively complete the complex task of Register Transfer Level (RTL) generation without human intervention. A key feature of the proposed flow is the progressive error feedback system of agents (PEFA), a self-correcting mechanism that leverages iterative error feedback to progressively increase the complexity of the approach. The generated RTL includes checks for compilation, functional correctness, and synthesizable constructs. To validate this adaptive approach to code generation, benchmarking is performed using two opensource natural language-to-RTL datasets. We demonstrate the benefits of the proposed approach implemented on an open source agentic framework, using both open- and closed-source LLMs, effectively bridging the performance gap between them. Compared to previously published methods, our approach sets a new benchmark, providing state-of-the-art pass rates while being efficient in token counts.",
    "fetched_at": "2025-11-09T02:21:22.884804Z"
  },
  {
    "id": "2511.03945v1",
    "title": "Direct Semantic Communication Between Large Language Models via Vector   Translation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Fu-Chun Yang",
      "Jason Eshraghian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03945v1",
    "abstract": "In multi-agent settings, such as debate, reflection, or tool-calling, large language models (LLMs) pass messages as plain tokens, discarding most latent semantics. This constrains information transfer and adds unnecessary computational overhead. We form a latent bridge via vector translations, which use learned mappings that enable direct semantic exchange between representation spaces. A dual-encoder translator trained between Llama-2-7B and Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the translated vectors at 30 percent blending strength steers the target model's generation without destabilizing logits. Bidirectional evaluation shows a 2.01:1 transfer asymmetry, indicating that general-purpose models yield more transferable representations than instruction-tuned variants. This conservative injection preserves computational stability while demonstrating that cross-model latent communication is feasible, enabling collaborative AI systems that share meaning rather than tokens.",
    "fetched_at": "2025-11-09T02:21:22.884763Z"
  },
  {
    "id": "2511.03958v1",
    "title": "Multi-Agent Collaborative Framework For Math Problem Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.MA",
      "MA",
      "cs.CL",
      "CL",
      "cs.HC",
      "HC",
      "I.2.11; I.2.6; K.3.1",
      "1"
    ],
    "authors": [
      "Kia Karbasi",
      "Kevin Hong",
      "Mohammad Amin Samadi",
      "Gregory Pottie"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.03958v1",
    "abstract": "Automatic question generation (AQG) for mathematics education remains an elusive goal for Intelligent Tutoring Systems and educators. While pre-trained transformer-based language models have significantly advanced natural language generation, they often struggle to precisely control problem complexity and cognitive demands. In this paper, we introduce a collaborative multi-agent framework as a novel method of incorporating inference-time computation into AQG. This approach leverages multiple agents that iteratively refine generated question-answer pairs to better balance complexity and cognitive demand. We evaluate the generated questions on five meta-evaluation criteria: relevance, importance, clarity, difficulty matching, answerability, to assess the system's ability to control the required complexity and quality of the questions. Preliminary evaluations show that this collaborative multi-agent framework elevates the quality of generated educational content by fostering a more nuanced balance between cognitive challenge and clarity. These promising outcomes suggest that integrating collaborative multi-agent workflows can yield more controlled, pedagogically valuable content that can help advance automated educational content generation and adaptive learning environments.",
    "fetched_at": "2025-11-09T02:21:22.884720Z"
  },
  {
    "id": "2511.03985v1",
    "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning   Engineering",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhuowen Yuan",
      "Tao Liu",
      "Yang Yang",
      "Yang Wang",
      "Feng Qi",
      "Kaushik Rangadurai",
      "Bo Li",
      "Shuang Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03985v1",
    "abstract": "Recent LLM-based agents have demonstrated strong capabilities in automated ML engineering. However, they heavily rely on repeated full training runs to evaluate candidate solutions, resulting in significant computational overhead, limited scalability to large search spaces, and slow iteration cycles. To address these challenges, we introduce ArchPilot, a multi-agent system that integrates architecture generation, proxy-based evaluation, and adaptive search into a unified framework. ArchPilot consists of three specialized agents: an orchestration agent that coordinates the search process using a Monte Carlo Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and manages memory of previous candidates; a generation agent that iteratively generates, improves, and debugs candidate architectures; and an evaluation agent that executes proxy training runs, generates and optimizes proxy functions, and aggregates the proxy scores into a fidelity-aware performance metric. This multi-agent collaboration allows ArchPilot to prioritize high-potential candidates with minimal reliance on expensive full training runs, facilitating efficient ML engineering under limited budgets. Experiments on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE and ML-Master, validating the effectiveness of our multi-agent system.",
    "fetched_at": "2025-11-09T02:21:22.884672Z"
  },
  {
    "id": "2511.04032v1",
    "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Divya Pathak",
      "Harshit Kumar",
      "Anuska Roy",
      "Felix George",
      "Mudit Verma",
      "Pratibha Moogi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04032v1",
    "abstract": "Multi-Agentic AI systems, powered by large language models (LLMs), are inherently non-deterministic and prone to silent failures such as drift, cycles, and missing details in outputs, which are difficult to detect. We introduce the task of anomaly detection in agentic trajectories to identify these failures and present a dataset curation pipeline that captures user behavior, agent non-determinism, and LLM variation. Using this pipeline, we curate and label two benchmark datasets comprising \\textbf{4,275 and 894} trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection methods on these datasets, we show that supervised (XGBoost) and semi-supervised (SVDD) approaches perform comparably, achieving accuracies up to 98% and 96%, respectively. This work provides the first systematic study of anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks, and insights to guide future research.",
    "fetched_at": "2025-11-09T02:21:22.884615Z"
  },
  {
    "id": "2511.04064v1",
    "title": "Benchmarking and Studying the LLM-based Agent System in End-to-End   Software Development",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Zhengran Zeng",
      "Yixin Li",
      "Rui Xie",
      "Wei Ye",
      "Shikun Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04064v1",
    "abstract": "The development of LLM-based autonomous agents for end-to-end software development represents a significant paradigm shift in software engineering. However, the scientific evaluation of these systems is hampered by significant challenges, including overly simplistic benchmarks and the difficulty of conducting fair comparisons between different agent architectures due to confounding implementation variables. To address these limitations, we first construct a challenging and dynamically curated E2EDevBench to simulate realistic development scenarios. Second, we propose a hybrid evaluation framework that combines test-case-based functional assessment with fine-grained, LLM-based requirement verification. Using this framework, we conduct a controlled empirical study on three representative agent architectures implemented upon a unified foundation to isolate the impact of workflow design. Our findings reveal that state-of-the-art agents can fulfill approximately 50\\% of requirements on \\bench{}, but their success is critically dependent on the architectural strategy for task decomposition and collaboration. Furthermore, our analysis indicates that the primary bottleneck is the omission of requirements and inadequate self-verification. This work provides the community with a more realistic benchmark, a comprehensive evaluation framework, and crucial insights into the current capabilities and core challenges of software development agents, guiding future research toward enhancing requirement comprehension and planning.",
    "fetched_at": "2025-11-09T02:21:22.884566Z"
  },
  {
    "id": "2511.04076v1",
    "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via   Large Language Model Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hao Li",
      "Haotian Chen",
      "Ruoyuan Gong",
      "Juanjuan Wang",
      "Hao Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04076v1",
    "abstract": "Redistricting plays a central role in shaping how votes are translated into political power. While existing computational methods primarily aim to generate large ensembles of legally valid districting plans, they often neglect the strategic dynamics involved in the selection process. This oversight creates opportunities for partisan actors to cherry-pick maps that, while technically compliant, are politically advantageous. Simply satisfying formal constraints does not ensure fairness when the selection process itself can be manipulated. We propose \\textbf{Agentmandering}, a framework that reimagines redistricting as a turn-based negotiation between two agents representing opposing political interests. Drawing inspiration from game-theoretic ideas, particularly the \\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction into the redistricting process via large language model (LLM) agents. Agents alternate between selecting and freezing districts from a small set of candidate maps, gradually partitioning the state through constrained and interpretable choices. Evaluation on post-2020 U.S. Census data across all states shows that Agentmandering significantly reduces partisan bias and unfairness, while achieving 2 to 3 orders of magnitude lower variance than standard baselines. These results demonstrate both fairness and stability, especially in swing-state scenarios. Our code is available at https://github.com/Lihaogx/AgentMandering.",
    "fetched_at": "2025-11-09T02:21:22.884515Z"
  },
  {
    "id": "2511.04153v1",
    "title": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated   Text-to-SQL Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Fahim Ahmed",
      "Md Mubtasim Ahasan",
      "Jahir Sadik Monon",
      "Muntasir Wahed",
      "M Ashraful Amin",
      "A K M Mahbubur Rahman",
      "Amin Ahsan Ali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04153v1",
    "abstract": "Text-to-SQL systems provide a natural language interface that can enable even laymen to access information stored in databases. However, existing Large Language Models (LLM) struggle with SQL generation from natural instructions due to large schema sizes and complex reasoning. Prior work often focuses on complex, somewhat impractical pipelines using flagship models, while smaller, efficient models remain overlooked. In this work, we explore three multi-agent LLM pipelines, with systematic performance benchmarking across a range of small to large open-source models: (1) Multi-agent discussion pipeline, where agents iteratively critique and refine SQL queries, and a judge synthesizes the final answer; (2) Planner-Coder pipeline, where a thinking model planner generates stepwise SQL generation plans and a coder synthesizes queries; and (3) Coder-Aggregator pipeline, where multiple coders independently generate SQL queries, and a reasoning agent selects the best query. Experiments on the Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small model performance, with up to 10.6% increase in Execution Accuracy for Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines, the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest score of 56.4%. Codes are available at https://github.com/treeDweller98/bappa-sql.",
    "fetched_at": "2025-11-09T02:21:22.884464Z"
  },
  {
    "id": "2511.04184v1",
    "title": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity   in LLM as a Communicator (LAAC) Framework in Multiple Application Domains",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mohammed Musthafa Rafi",
      "Adarsh Krishnamurthy",
      "Aditya Balu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04184v1",
    "abstract": "The proliferation of AI-generated content has created an absurd communication theater where senders use LLMs to inflate simple ideas into verbose content, recipients use LLMs to compress them back into summaries, and as a consequence neither party engage with authentic content. LAAC (LLM as a Communicator) proposes a paradigm shift - positioning LLMs as intelligent communication intermediaries that capture the sender's intent through structured dialogue and facilitate genuine knowledge exchange with recipients. Rather than perpetuating cycles of AI-generated inflation and compression, LAAC enables authentic communication across diverse contexts including academic papers, proposals, professional emails, and cross-platform content generation. However, deploying LLMs as trusted communication intermediaries raises critical questions about information fidelity, consistency, and reliability. This position paper systematically evaluates the trustworthiness requirements for LAAC's deployment across multiple communication domains. We investigate three fundamental dimensions: (1) Information Capture Fidelity - accuracy of intent extraction during sender interviews across different communication types, (2) Reproducibility - consistency of structured knowledge across multiple interaction instances, and (3) Query Response Integrity - reliability of recipient-facing responses without hallucination, source conflation, or fabrication. Through controlled experiments spanning multiple LAAC use cases, we assess these trust dimensions using LAAC's multi-agent architecture. Preliminary findings reveal measurable trust gaps that must be addressed before LAAC can be reliably deployed in high-stakes communication scenarios.",
    "fetched_at": "2025-11-09T02:21:22.884406Z"
  },
  {
    "id": "2511.04307v1",
    "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jian Mu",
      "Chaoyun Zhang",
      "Chiming Ni",
      "Lu Wang",
      "Bo Qiao",
      "Kartik Mathur",
      "Qianhui Wu",
      "Yuhang Xie",
      "Xiaojun Ma",
      "Mengyu Zhou",
      "Si Qin",
      "Liqun Li",
      "Yu Kang",
      "Minghua Ma",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04307v1",
    "abstract": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and benchmark suite designed to advance computer-using agents (CUAs). CUAs present unique challenges and is constrained by three persistent gaps: a scarcity of real-world CUA tasks, the lack of automated collection-and-annotation pipelines for multi-modal trajectories, and the absence of a unified benchmark that jointly evaluates GUI grounding, screen parsing, and action prediction.   GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated pipeline for query sourcing, environment-template construction, task instantiation, batched execution, and LLM-driven quality filtering. The released corpus contains over 1.2M executed action steps across thousands of trajectories in popular Windows office applications, and includes full-resolution screenshots, accessibility metadata when available, instantiated goals, intermediate reasoning traces, and both successful and failed action trajectories. The dataset supports three canonical tasks, GUI grounding, screen parsing, and action prediction, and a hybrid GUI+API action space that reflects modern agent designs. Benchmarking state-of-the-art vision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box shortcomings in grounding and action prediction; supervised fine-tuning and reinforcement learning yield significant gains but do not close the gap to human-level reliability. We release GUI-360$^\\circ$ and accompanying code to facilitate reproducible research and accelerate progress on robust desktop CUAs.   The full dataset has been made public on https://huggingface.co/datasets/vyokky/GUI-360.",
    "fetched_at": "2025-11-09T02:21:22.884355Z"
  },
  {
    "id": "2511.04393v1",
    "title": "Post-Training LLMs as Better Decision-Making Agents: A   Regret-Minimization Approach",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chanwoo Park",
      "Ziyang Chen",
      "Asuman Ozdaglar",
      "Kaiqing Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04393v1",
    "abstract": "Large language models (LLMs) are increasingly deployed as \"agents\" for decision-making (DM) in interactive and dynamic environments. Yet, since they were not originally designed for DM, recent studies show that LLMs can struggle even in basic online DM problems, failing to achieve low regret or an effective exploration-exploitation tradeoff. To address this, we introduce Iterative Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure that repeatedly distills low-regret decision trajectories back into the base model. At each iteration, the model rolls out multiple decision trajectories, selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior methods that (a) distill action sequences from known DM algorithms or (b) rely on manually crafted chain-of-thought templates, our approach leverages the regret metric to elicit the model's own DM ability and reasoning rationales. This reliance on model-generated reasoning avoids rigid output engineering and provides more flexible, natural-language training signals. Empirical results show that Iterative RMFT improves LLMs' DM performance across diverse models - from Transformers with numerical input/output, to open-weight LLMs, and advanced closed-weight models like GPT-4o mini. Its flexibility in output and reasoning formats enables generalization across tasks with varying horizons, action spaces, reward processes, and natural-language contexts. Finally, we provide theoretical insight showing that a single-layer Transformer under this paradigm can act as a no-regret learner in a simplified setting. Overall, Iterative RMFT offers a principled and general post-training framework for enhancing LLMs' decision-making capabilities.",
    "fetched_at": "2025-11-09T02:21:22.884265Z"
  },
  {
    "id": "2511.04427v1",
    "title": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on   Software Development",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hao He",
      "Courtney Miller",
      "Shyam Agarwal",
      "Christian Kästner",
      "Bogdan Vasilescu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04427v1",
    "abstract": "Large language models (LLMs) have demonstrated the promise to revolutionize the field of software engineering. Among other things, LLM agents are rapidly gaining momentum in their application to software development, with practitioners claiming a multifold productivity increase after adoption. Yet, empirical evidence is lacking around these claims. In this paper, we estimate the causal effect of adopting a widely popular LLM agent assistant, namely Cursor, on development velocity and software quality. The estimation is enabled by a state-of-the-art difference-in-differences design comparing Cursor-adopting GitHub projects with a matched control group of similar GitHub projects that do not use Cursor. We find that the adoption of Cursor leads to a significant, large, but transient increase in project-level development velocity, along with a significant and persistent increase in static analysis warnings and code complexity. Further panel generalized method of moments estimation reveals that the increase in static analysis warnings and code complexity acts as a major factor causing long-term velocity slowdown. Our study carries implications for software engineering practitioners, LLM agent assistant designers, and researchers.",
    "fetched_at": "2025-11-09T02:21:22.884212Z"
  },
  {
    "id": "2511.04464v1",
    "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Carnot Braun",
      "Rafael O. Jarczewski",
      "Gabriel U. Talasso",
      "Leandro A. Villas",
      "Allan M. de Souza"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04464v1",
    "abstract": "Traditional vehicle routing systems efficiently optimize singular metrics like time or distance, and when considering multiple metrics, they need more processes to optimize . However, they lack the capability to interpret and integrate the complex, semantic, and dynamic contexts of human drivers, such as multi-step tasks, situational constraints, or urgent needs. This paper introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a hybrid agentic assistant designed to augment classical pathfinding algorithms with contextual reasoning. Our approach employs a Large Language Model (LLM) agent that operates on a candidate set of routes generated by a multi-objective (time, CO2) Dijkstra algorithm. The agent evaluates these options against user-provided tasks, preferences, and avoidance rules by leveraging a pre-processed geospatial cache of urban Points of Interest (POIs). In a benchmark of realistic urban scenarios, PAVe successfully used complex user intent into appropriate route modifications, achieving over 88% accuracy in its initial route selections with a local model. We conclude that combining classical routing algorithms with an LLM-based semantic reasoning layer is a robust and effective approach for creating personalized, adaptive, and scalable solutions for urban mobility optimization.",
    "fetched_at": "2025-11-09T02:21:22.884152Z"
  },
  {
    "id": "2511.04481v1",
    "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy   Consumption through Empirical and Theoretical Analysis",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lars Krupp",
      "Daniel Geißler",
      "Vishal Banwari",
      "Paul Lukowicz",
      "Jakob Karolus"
    ],
    "institution": "Google, OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2511.04481v1",
    "abstract": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful agentic systems pushing the boundaries of Large Language Models (LLM). They can autonomously interact with the internet at the user's behest, such as navigating websites, filling search masks, and comparing price lists. Though web agent research is thriving, induced sustainability issues remain largely unexplored. To highlight the urgency of this issue, we provide an initial exploration of the energy and $CO_2$ cost associated with web agents from both a theoretical -via estimation- and an empirical perspective -by benchmarking. Our results show how different philosophies in web agent creation can severely impact the associated expended energy, and that more energy consumed does not necessarily equate to better results. We highlight a lack of transparency regarding disclosing model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. Our work contributes towards a change in thinking of how we evaluate web agents, advocating for dedicated metrics measuring energy consumption in benchmarks.",
    "fetched_at": "2025-11-09T02:21:22.884078Z"
  },
  {
    "id": "2511.04502v1",
    "title": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific   RAG",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Joshua Gao",
      "Quoc Huy Pham",
      "Subin Varghese",
      "Silwal Saurav",
      "Vedhus Hoskere"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04502v1",
    "abstract": "Retrieval-Augmented Generation (RAG) is a critical technique for grounding Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in specialized, safety-critical domains remains a significant challenge. Existing evaluation frameworks often rely on heuristic-based metrics that fail to capture domain-specific nuances and other works utilize LLM-as-a-Judge approaches that lack validated alignment with human judgment. This paper introduces RAGalyst, an automated, human-aligned agentic framework designed for the rigorous evaluation of domain-specific RAG systems. RAGalyst features an agentic pipeline that generates high-quality, synthetic question-answering (QA) datasets from source documents, incorporating an agentic filtering step to ensure data fidelity. The framework refines two key LLM-as-a-Judge metrics-Answer Correctness and Answerability-using prompt optimization to achieve a strong correlation with human annotations. Applying this framework to evaluate various RAG components across three distinct domains (military operations, cybersecurity, and bridge engineering), we find that performance is highly context-dependent. No single embedding model, LLM, or hyperparameter configuration proves universally optimal. Additionally, we provide an analysis on the most common low Answer Correctness reasons in RAG. These findings highlight the necessity of a systematic evaluation framework like RAGalyst, which empowers practitioners to uncover domain-specific trade-offs and make informed design choices for building reliable and effective RAG systems. RAGalyst is available on our Github.",
    "fetched_at": "2025-11-09T02:21:22.884022Z"
  },
  {
    "id": "2511.04646v1",
    "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for   Embodied LLM-Based Multi-Agent Collaboration",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Narjes Nourzad",
      "Hanqing Yang",
      "Shiyu Chen",
      "Carlee Joe-Wong"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04646v1",
    "abstract": "Cooperative multi-agent planning requires agents to make joint decisions with partial information and limited communication. Coordination at the trajectory level often fails, as small deviations in timing or movement cascade into conflicts. Symbolic planning mitigates this challenge by raising the level of abstraction and providing a minimal vocabulary of actions that enable synchronization and collective progress. We present DR. WELL, a decentralized neurosymbolic framework for cooperative multi-agent planning. Cooperation unfolds through a two-phase negotiation protocol: agents first propose candidate roles with reasoning and then commit to a joint allocation under consensus and environment constraints. After commitment, each agent independently generates and executes a symbolic plan for its role without revealing detailed trajectories. Plans are grounded in execution outcomes via a shared world model that encodes the current state and is updated as agents act. By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids brittle step-level alignment and enables higher-level operations that are reusable, synchronizable, and interpretable. Experiments on cooperative block-push tasks show that agents adapt across episodes, with the dynamic world model capturing reusable patterns and improving task completion rates and efficiency. Experiments on cooperative block-push tasks show that our dynamic world model improves task completion and efficiency through negotiation and self-refinement, trading a time overhead for evolving, more efficient collaboration strategies.",
    "fetched_at": "2025-11-09T02:21:22.883921Z"
  },
  {
    "id": "2511.03891v1",
    "title": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using   Class-Based Input Image Composition",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB"
    ],
    "authors": [
      "Hlali Azzeddine",
      "Majid Ben Yakhlef",
      "Soulaiman El Hazzat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03891v1",
    "abstract": "Small, imbalanced datasets and poor input image quality can lead to high false predictions rates with deep learning models. This paper introduces Class-Based Image Composition, an approach that allows us to reformulate training inputs through a fusion of multiple images of the same class into combined visual composites, named Composite Input Images (CoImg). That enhances the intra-class variance and improves the valuable information density per training sample and increases the ability of the model to distinguish between subtle disease patterns. Our method was evaluated on the Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et al., 2024), which contains 2,064 high-resolution optical coherence tomography (OCT) scans of the human retina, representing seven distinct diseases with a significant class imbalance. We constructed a perfectly class-balanced version of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout composite image. To assess the effectiveness of this new representation, we conducted a comparative analysis between the original dataset and its variant using a VGG16 model. A fair comparison was ensured by utilizing the identical model architecture and hyperparameters for all experiments. The proposed approach markedly improved diagnostic results.The enhanced Dataset achieved near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared to a baseline model trained on raw dataset. The false prediction rate was also significantly lower, this demonstrates that the method can producehigh-quality predictions even for weak datasets affected by class imbalance or small sample size.",
    "fetched_at": "2025-11-09T02:21:28.189749Z"
  },
  {
    "id": "2511.03892v1",
    "title": "A general technique for approximating high-dimensional empirical kernel   matrices",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chiraag Kaushik",
      "Justin Romberg",
      "Vidya Muthukumar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03892v1",
    "abstract": "We present simple, user-friendly bounds for the expected operator norm of a random kernel matrix under general conditions on the kernel function $k(\\cdot,\\cdot)$. Our approach uses decoupling results for U-statistics and the non-commutative Khintchine inequality to obtain upper and lower bounds depending only on scalar statistics of the kernel function and a ``correlation kernel'' matrix corresponding to $k(\\cdot,\\cdot)$. We then apply our method to provide new, tighter approximations for inner-product kernel matrices on general high-dimensional data, where the sample size and data dimension are polynomially related. Our method obtains simplified proofs of existing results that rely on the moment method and combinatorial arguments while also providing novel approximation results for the case of anisotropic Gaussian data. Finally, using similar techniques to our approximation result, we show a tighter lower bound on the bias of kernel regression with anisotropic Gaussian data.",
    "fetched_at": "2025-11-09T02:21:28.189699Z"
  },
  {
    "id": "2511.03898v1",
    "title": "Secure Code Generation at Scale with Reflexion",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Arup Datta",
      "Ahmed Aljohani",
      "Hyunsook Do"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03898v1",
    "abstract": "Large language models (LLMs) are now widely used to draft and refactor code, but code that works is not necessarily secure. We evaluate secure code generation using the Instruct Prime, which eliminated compliance-required prompts and cue contamination, and evaluate five instruction-tuned code LLMs using a zero-shot baseline and a three-round reflexion prompting approach. Security is measured using the Insecure Code Detector (ICD), and results are reported by measuring Repair, Regression, and NetGain metrics, considering the programming language and CWE family. Our findings show that insecurity remains common at the first round: roughly 25-33% of programs are insecure at a zero-shot baseline (t0 ). Weak cryptography/config-dependent bugs are the hardest to avoid while templated ones like XSS, code injection, and hard-coded secrets are handled more reliably. Python yields the highest secure rates; C and C# are the lowest, with Java, JS, PHP, and C++ in the middle. Reflexion prompting improves security for all models, improving average accuracy from 70.74% at t0 to 79.43% at t3 , with the largest gains in the first round followed by diminishing returns. The trends with Repair, Regression, and NetGain metrics show that applying one to two rounds produces most of the benefits. A replication package is available at https://doi.org/10.5281/zenodo.17065846.",
    "fetched_at": "2025-11-09T02:21:28.189659Z"
  },
  {
    "id": "2511.03900v1",
    "title": "GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Manh Nguyen",
      "Sunil Gupta",
      "Dai Do",
      "Hung Le"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03900v1",
    "abstract": "Hallucination mitigation remains a persistent challenge for large language models (LLMs), even as model scales grow. Existing approaches often rely on external knowledge sources, such as structured databases or knowledge graphs, accessed through prompting or retrieval. However, prompt-based grounding is fragile and domain-sensitive, while symbolic knowledge integration incurs heavy retrieval and formatting costs. Motivated by knowledge graphs, we introduce Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds generation in corpus-derived evidence without retraining. GRAD constructs a sparse token transition graph by accumulating next-token logits across a small retrieved corpus in a single forward pass. During decoding, graph-retrieved logits are max-normalized and adaptively fused with model logits to favor high-evidence continuations while preserving fluency. Across three models and a range of question-answering benchmarks spanning intrinsic, extrinsic hallucination, and factuality tasks, GRAD consistently surpasses baselines, achieving up to 9.7$\\%$ higher intrinsic accuracy, 8.6$\\%$ lower hallucination rates, and 6.9$\\%$ greater correctness compared to greedy decoding, while attaining the highest truth--informativeness product score among all methods. GRAD offers a lightweight, plug-and-play alternative to contrastive decoding and knowledge graph augmentation, demonstrating that statistical evidence from corpus-level token transitions can effectively steer generation toward more truthful and verifiable outputs.",
    "fetched_at": "2025-11-09T02:21:28.189613Z"
  },
  {
    "id": "2511.03907v1",
    "title": "SnappyMeal: Design and Longitudinal Evaluation of a Multimodal AI Food   Logging Application",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "I.2.1; J.3",
      "3"
    ],
    "authors": [
      "Liam Bakar",
      "Zachary Englhardt",
      "Vidya Srinivas",
      "Girish Narayanswamy",
      "Dilini Nissanka",
      "Shwetak Patel",
      "Vikram Iyer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03907v1",
    "abstract": "Food logging, both self-directed and prescribed, plays a critical role in uncovering correlations between diet, medical, fitness, and health outcomes. Through conversations with nutritional experts and individuals who practice dietary tracking, we find current logging methods, such as handwritten and app-based journaling, are inflexible and result in low adherence and potentially inaccurate nutritional summaries. These findings, corroborated by prior literature, emphasize the urgent need for improved food logging methods. In response, we propose SnappyMeal, an AI-powered dietary tracking system that leverages multimodal inputs to enable users to more flexibly log their food intake. SnappyMeal introduces goal-dependent follow-up questions to intelligently seek missing context from the user and information retrieval from user grocery receipts and nutritional databases to improve accuracy. We evaluate SnappyMeal through publicly available nutrition benchmarks and a multi-user, 3-week, in-the-wild deployment capturing over 500 logged food instances. Users strongly praised the multiple available input methods and reported a strong perceived accuracy. These insights suggest that multimodal AI systems can be leveraged to significantly improve dietary tracking flexibility and context-awareness, laying the groundwork for a new class of intelligent self-tracking applications.",
    "fetched_at": "2025-11-09T02:21:28.189565Z"
  },
  {
    "id": "2511.03909v1",
    "title": "Vectorized Computation of Euler Characteristic Functions and Transforms",
    "date": "2025-11-05",
    "tags": [
      "cs.CG",
      "CG",
      "cs.LG",
      "LG",
      "math.AT",
      "AT",
      "55N31, 55-08"
    ],
    "authors": [
      "Jessi Cisewski-Kehe",
      "Brittany Terese Fasy",
      "Alexander McCleary",
      "Eli Quist",
      "Jack Ruder"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03909v1",
    "abstract": "The weighted Euler characteristic transform (WECT) and Euler characteristic function (ECF) have proven to be useful tools in a variety of applications. However, current methods for computing these functions are neither optimized for speed nor do they scale to higher-dimensional settings. In this work, we present a vectorized framework for computing such topological transforms using tensor operations, which is highly optimized for GPU architectures and works in full generality across geometric simplicial complexes (or cubical complexes) of arbitrary dimension. Experimentally, the framework demonstrates significant speedups (up to $180 \\times$) over existing methods when computing the WECT and ECF across a variety of image datasets. Computation of these transforms is implemented in a publicly available Python package called pyECT.",
    "fetched_at": "2025-11-09T02:21:28.189468Z"
  },
  {
    "id": "2511.03911v1",
    "title": "DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory   Budgets",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sanggeon Yun",
      "Hyunwoo Oh",
      "Ryozo Masukawa",
      "Mohsen Imani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03911v1",
    "abstract": "Decomposition is a proven way to shrink deep networks without changing I/O. We bring this idea to hyperdimensional computing (HDC), where footprint cuts usually shrink the feature axis and erode concentration and robustness. Prior HDC decompositions decode via fixed atomic hypervectors, which are ill-suited for compressing learned class prototypes. We introduce DecoHD, which learns directly in a decomposed HDC parameterization: a small, shared set of per-layer channels with multiplicative binding across layers and bundling at the end, yielding a large representational space from compact factors. DecoHD compresses along the class axis via a lightweight bundling head while preserving native bind-bundle-score; training is end-to-end, and inference remains pure HDC, aligning with in/near-memory accelerators. In evaluation, DecoHD attains extreme memory savings with only minor accuracy degradation under tight deployment budgets. On average it stays within about 0.1-0.15% of a strong non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters, and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU (AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x over a baseline HDC ASIC.",
    "fetched_at": "2025-11-09T02:21:28.189417Z"
  },
  {
    "id": "2511.03912v1",
    "title": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic   Weight Averaging-Gaussian for Oracle-Free Medical Imaging",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nand Kumar Yadav",
      "Rodrigue Rizk",
      "William CW Chen",
      "KC Santosh"
    ],
    "institution": "AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA",
    "link": "http://arxiv.org/pdf/2511.03912v1",
    "abstract": "Unknown anomaly detection in medical imaging remains a fundamental challenge due to the scarcity of labeled anomalies and the high cost of expert supervision. We introduce an unsupervised, oracle-free framework that incrementally expands a trusted set of normal samples without any anomaly labels. Starting from a small, verified seed of normal images, our method alternates between lightweight adapter updates and uncertainty-gated sample admission. A frozen pretrained vision backbone is augmented with tiny convolutional adapters, ensuring rapid domain adaptation with negligible computational overhead. Extracted embeddings are stored in a compact coreset enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during incremental expansion is enforced by dual probabilistic gates, a sample is admitted into the normal memory only if its distance to the existing coreset lies within a calibrated z-score threshold, and its SWAG-based epistemic uncertainty remains below a seed-calibrated bound. This mechanism prevents drift and false inclusions without relying on generative reconstruction or replay buffers. Empirically, our system steadily refines the notion of normality as unlabeled data arrive, producing substantial gains over baselines. On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5, ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These results highlight the effectiveness and efficiency of the proposed framework for real-world, label-scarce medical imaging applications.",
    "fetched_at": "2025-11-09T02:21:28.189369Z"
  },
  {
    "id": "2511.03913v1",
    "title": "Evolutionary Optimization Trumps Adam Optimization on Embedding Space   Exploration",
    "date": "2025-11-05",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Domício Pereira Neto",
      "João Correia",
      "Penousal Machado"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03913v1",
    "abstract": "Deep generative models, especially diffusion architectures, have transformed image generation; however, they are challenging to control and optimize for specific goals without expensive retraining. Embedding Space Exploration, especially with Evolutionary Algorithms (EAs), has been shown to be a promising method for optimizing image generation, particularly within Diffusion Models. Therefore, in this work, we study the performance of an evolutionary optimization method, namely Separable Covariance Matrix Adaptation Evolution Strategy (sep-CMA-ES), against the widely adopted Adaptive Moment Estimation (Adam), applied to Stable Diffusion XL Turbo's prompt embedding vector. The evaluation of images combines the LAION Aesthetic Predictor V2 with CLIPScore into a weighted fitness function, allowing flexible trade-offs between visual appeal and adherence to prompts. Experiments on a subset of the Parti Prompts (P2) dataset showcase that sep-CMA-ES consistently yields superior improvements in aesthetic and alignment metrics in comparison to Adam. Results indicate that the evolutionary method provides efficient, gradient-free optimization for diffusion models, enhancing controllability without the need for fine-tuning. This study emphasizes the potential of evolutionary methods for embedding space exploration of deep generative models and outlines future research directions.",
    "fetched_at": "2025-11-09T02:21:28.189331Z"
  },
  {
    "id": "2511.03915v1",
    "title": "The Human Flourishing Geographic Index: A County-Level Dataset for the   United States, 2013--2023",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Stefano M. Iacus",
      "Devika Jain",
      "Andrea Nasuto",
      "Giuseppe Porro",
      "Marcello Carammia",
      "Andrea Vezzulli"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03915v1",
    "abstract": "Quantifying human flourishing, a multidimensional construct including happiness, health, purpose, virtue, relationships, and financial stability, is critical for understanding societal well-being beyond economic indicators. Existing measures often lack fine spatial and temporal resolution. Here we introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned large language models to classify expressions across 48 indicators aligned with Harvard's Global Flourishing Study framework plus attitudes towards migration and perception of corruption. The dataset offers monthly and yearly county- and state-level indicators of flourishing-related discourse, validated to confirm that the measures accurately represent the underlying constructs and show expected correlations with established indicators. This resource enables multidisciplinary analyses of well-being, inequality, and social change at unprecedented resolution, offering insights into the dynamics of human flourishing as reflected in social media discourse across the United States over the past decade.",
    "fetched_at": "2025-11-09T02:21:28.189282Z"
  },
  {
    "id": "2511.03100v1",
    "title": "Scaling Multi-Agent Environment Co-Design with Diffusion Models",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Hao Xiang Li",
      "Michael Amir",
      "Amanda Prorok"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03100v1",
    "abstract": "The agent-environment co-design paradigm jointly optimises agent policies and environment configurations in search of improved system performance. With application domains ranging from warehouse logistics to windfarm management, co-design promises to fundamentally change how we deploy multi-agent systems. However, current co-design methods struggle to scale. They collapse under high-dimensional environment design spaces and suffer from sample inefficiency when addressing moving targets inherent to joint optimisation. We address these challenges by developing Diffusion Co-Design (DiCoDe), a scalable and sample-efficient co-design framework pushing co-design towards practically relevant settings. DiCoDe incorporates two core innovations. First, we introduce Projected Universal Guidance (PUG), a sampling technique that enables DiCoDe to explore a distribution of reward-maximising environments while satisfying hard constraints such as spatial separation between obstacles. Second, we devise a critic distillation mechanism to share knowledge from the reinforcement learning critic, ensuring that the guided diffusion model adapts to evolving agent policies using a dense and up-to-date learning signal. Together, these improvements lead to superior environment-policy pairs when validated on challenging multi-agent environment co-design benchmarks including warehouse automation, multi-agent pathfinding and wind farm optimisation. Our method consistently exceeds the state-of-the-art, achieving, for example, 39% higher rewards in the warehouse setting with 66% fewer simulation samples. This sets a new standard in agent-environment co-design, and is a stepping stone towards reaping the rewards of co-design in real world domains.",
    "fetched_at": "2025-11-09T02:21:24.636359Z"
  },
  {
    "id": "2511.03187v1",
    "title": "Periodic Skill Discovery",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Jonghae Park",
      "Daesol Cho",
      "Jusuk Lee",
      "Dongseok Shim",
      "Inkyu Jang",
      "H. Jin Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03187v1",
    "abstract": "Unsupervised skill discovery in reinforcement learning (RL) aims to learn diverse behaviors without relying on external rewards. However, current methods often overlook the periodic nature of learned skills, focusing instead on increasing the mutual dependence between states and skills or maximizing the distance traveled in latent space. Considering that many robotic tasks -- particularly those involving locomotion -- require periodic behaviors across varying timescales, the ability to discover diverse periodic skills is essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a framework that discovers periodic behaviors in an unsupervised manner. The key idea of PSD is to train an encoder that maps states to a circular latent space, thereby naturally encoding periodicity in the latent representation. By capturing temporal distance, PSD can effectively learn skills with diverse periods in complex robotic tasks, even with pixel-based observations. We further show that these learned skills achieve high performance on downstream tasks such as hurdling. Moreover, integrating PSD with an existing skill discovery method offers more diverse behaviors, thus broadening the agent's repertoire. Our code and demos are available at https://jonghaepark.github.io/psd/",
    "fetched_at": "2025-11-09T02:21:24.636194Z"
  },
  {
    "id": "2511.03305v1",
    "title": "DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State   Uncertainty",
    "date": "2025-11-05",
    "tags": [
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Haoqin Zhao",
      "Zan Li",
      "Jiangbo Si",
      "Rui Huang",
      "Hang Hu",
      "Tony Q. S. Quek",
      "Naofal Al-Dhahir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03305v1",
    "abstract": "Owing to the openness of wireless channels, wireless communication systems are highly susceptible to malicious jamming. Most existing anti-jamming methods rely on the assumption of accurate sensing and optimize parameters on a single timescale. However, such methods overlook two practical issues: mismatched execution latencies across heterogeneous actions and measurement errors caused by sensor imperfections. Especially for deep reinforcement learning (DRL)-based methods, the inherent sensitivity of neural networks implies that even minor perturbations in the input can mislead the agent into choosing suboptimal actions, with potentially severe consequences. To ensure reliable wireless transmission, we establish a multi-timescale decision model that incorporates state uncertainty. Subsequently, we propose two robust schemes that sustain performance under bounded sensing errors. First, a Projected Gradient Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which derives worst-case perturbations under a norm-bounded error model and applies PGD during training for robust optimization. Second, a Nonlinear Q-Compression DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that adaptively contracts Q-value ranges to eliminate action aliasing. Simulation results indicate that, compared with the perfect-sensing baseline, the proposed algorithms show only minor degradation in anti-jamming performance while maintaining robustness under various perturbations, thereby validating their practicality in imperfect sensing conditions.",
    "fetched_at": "2025-11-09T02:21:24.636075Z"
  },
  {
    "id": "2511.03348v2",
    "title": "Learning Communication Skills in Multi-task Multi-agent Deep   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA",
      "68T05"
    ],
    "authors": [
      "Changxi Zhu",
      "Mehdi Dastani",
      "Shihan Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03348v2",
    "abstract": "In multi-agent deep reinforcement learning (MADRL), agents can communicate with one another to perform a task in a coordinated manner. When multiple tasks are involved, agents can also leverage knowledge from one task to improve learning in other tasks. In this paper, we propose Multi-task Communication Skills (MCS), a MADRL with communication method that learns and performs multiple tasks simultaneously, with agents interacting through learnable communication protocols. MCS employs a Transformer encoder to encode task-specific observations into a shared message space, capturing shared communication skills among agents. To enhance coordination among agents, we introduce a prediction network that correlates messages with the actions of sender agents in each task. We adapt three multi-agent benchmark environments to multi-task settings, where the number of agents as well as the observation and action spaces vary across tasks. Experimental results demonstrate that MCS achieves better performance than multi-task MADRL baselines without communication, as well as single-task MADRL baselines with and without communication.",
    "fetched_at": "2025-11-09T02:21:24.636015Z"
  },
  {
    "id": "2511.03591v1",
    "title": "Manifold-constrained Hamilton-Jacobi Reachability Learning for   Decentralized Multi-Agent Motion Planning",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Qingyi Chen",
      "Ruiqi Ni",
      "Jun Kim",
      "Ahmed H. Qureshi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03591v1",
    "abstract": "Safe multi-agent motion planning (MAMP) under task-induced constraints is a critical challenge in robotics. Many real-world scenarios require robots to navigate dynamic environments while adhering to manifold constraints imposed by tasks. For example, service robots must carry cups upright while avoiding collisions with humans or other robots. Despite recent advances in decentralized MAMP for high-dimensional systems, incorporating manifold constraints remains difficult. To address this, we propose a manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for decentralized MAMP. Our method solves HJR problems under manifold constraints to capture task-aware safety conditions, which are then integrated into a decentralized trajectory optimization planner. This enables robots to generate motion plans that are both safe and task-feasible without requiring assumptions about other agents' policies. Our approach generalizes across diverse manifold-constrained tasks and scales effectively to high-dimensional multi-agent manipulation problems. Experiments show that our method outperforms existing constrained motion planners and operates at speeds suitable for real-world applications. Video demonstrations are available at https://youtu.be/RYcEHMnPTH8 .",
    "fetched_at": "2025-11-09T02:21:24.635772Z"
  },
  {
    "id": "2511.03616v1",
    "title": "Going Beyond Expert Performance via Deep Implicit Imitation   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03616v1",
    "abstract": "Imitation learning traditionally requires complete state-action demonstrations from optimal or near-optimal experts. These requirements severely limit practical applicability, as many real-world scenarios provide only state observations without corresponding actions and expert performance is often suboptimal. In this paper we introduce a deep implicit imitation reinforcement learning framework that addresses both limitations by combining deep reinforcement learning with implicit imitation learning from observation-only datasets. Our main algorithm, Deep Implicit Imitation Q-Network (DIIQN), employs an action inference mechanism that reconstructs expert actions through online exploration and integrates a dynamic confidence mechanism that adaptively balances expert-guided and self-directed learning. This enables the agent to leverage expert guidance for accelerated training while maintaining capacity to surpass suboptimal expert performance. We further extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to tackle scenarios where expert and agent possess different action sets, a challenge previously unaddressed in the implicit imitation learning literature. HA-DIIQN introduces an infeasibility detection mechanism and a bridging procedure identifying alternative pathways connecting agent capabilities to expert guidance when direct action replication is impossible. Our experimental results demonstrate that DIIQN achieves up to 130% higher episodic returns compared to standard DQN, while consistently outperforming existing implicit imitation methods that cannot exceed expert performance. In heterogeneous action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging expert datasets unusable by conventional approaches. Extensive parameter sensitivity analysis reveals the framework's robustness across varying dataset sizes and hyperparameter configurations.",
    "fetched_at": "2025-11-09T02:21:24.635721Z"
  },
  {
    "id": "2511.03094v1",
    "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Longling Geng",
      "Edward Y. Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03094v1",
    "abstract": "Large language models enable flexible multi-agent planning but remain fragile in practice: verification is often circular, state changes are not tracked for repair, and small faults trigger costly global recomputation. We present ALAS, a stateful, disruption-aware framework that separates planning from non-circular validation, records a versioned execution log for grounded checks and restore points, and performs localized repair that preserves work in progress. The validator operates independently of the planning LLM with fresh, bounded context, avoiding self-check loops and mid-context attrition. The repair protocol edits only the minimal affected region under explicit policies (retry, catch, timeout, backoff, idempotency keys, compensation, loop guards) defined in a canonical workflow IR that maps to Amazon States Language and Argo Workflows. On job-shop scheduling suites (DMU, TA) across five classical benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent baselines, achieving 83.7% success, reducing token usage by 60%, and running 1.82times faster under comparable settings. A minimal reliability study shows that the validator detects injected structural faults with low overhead, and that localized repair contains runtime perturbations with a bounded edit radius and less makespan degradation than global recompute. Results indicate that the combination of validator isolation, versioned execution logs, and localized repair provides measurable efficiency, feasibility, and scalability for multi-agent LLM planning. Code and seeds will be released.",
    "fetched_at": "2025-11-09T02:21:22.886466Z"
  },
  {
    "id": "2511.03138v1",
    "title": "A Proprietary Model-Based Safety Response Framework for AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qi Li",
      "Jianjun Xu",
      "Pingtao Wei",
      "Jiu Li",
      "Peiqiang Zhao",
      "Jiwei Shi",
      "Xuan Zhang",
      "Yanhui Yang",
      "Xiaodong Hui",
      "Peng Xu",
      "Wenqin Shao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03138v1",
    "abstract": "With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response framework designed to systematically safeguard LLMs at both the input and output levels. At the input level, the framework employs a supervised fine-tuning-based safety classification model. Through a fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused Attention), it performs precise risk identification and differentiated handling of user queries, significantly enhancing risk coverage and business scenario adaptability, and achieving a risk recall rate of 99.3%. At the output level, the framework integrates Retrieval-Augmented Generation (RAG) with a specifically fine-tuned interpretation model, ensuring all responses are grounded in a real-time, trustworthy knowledge base. This approach eliminates information fabrication and enables result traceability. Experimental results demonstrate that our proposed safety control model achieves a significantly higher safety score on public safety evaluation benchmarks compared to the baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk test set, the framework's components attained a perfect 100% safety score, validating their exceptional protective capabilities in complex risk scenarios. This research provides an effective engineering pathway for building high-security, high-trust LLM applications.",
    "fetched_at": "2025-11-09T02:21:22.886424Z"
  },
  {
    "id": "2511.03143v1",
    "title": "From Measurement to Expertise: Empathetic Expert Adapters for   Context-Based Empathy in Conversational AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Erfan Shayegani",
      "Jina Suh",
      "Andy Wilson",
      "Nagu Rangan",
      "Javier Hernandez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03143v1",
    "abstract": "Empathy is a critical factor in fostering positive user experiences in conversational AI. While models can display empathy, it is often generic rather than tailored to specific tasks and contexts. In this work, we introduce a novel framework for developing and evaluating context-specific empathetic large language models (LLMs). We first analyze a real-world conversational dataset consisting of 672 multi-turn conversations across 8 tasks, revealing significant differences in terms of expected and experienced empathy before and after the conversations, respectively. To help minimize this gap, we develop a synthetic multi-turn conversational generation pipeline and steer responses toward our defined empathy patterns based on the context that more closely matches users' expectations. We then train empathetic expert adapters for context-specific empathy that specialize in varying empathy levels based on the recognized task. Our empirical results demonstrate a significant gap reduction of 72.66% between perceived and desired empathy with scores increasing by an average factor of 2.43 as measured by our metrics and reward models. Additionally, our trained empathetic expert adapters demonstrate superior effectiveness in preserving empathy patterns throughout conversation turns, outperforming system prompts, which tend to dramatically diminish in impact as conversations lengthen.",
    "fetched_at": "2025-11-09T02:21:22.886356Z"
  },
  {
    "id": "2511.03153v1",
    "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software   Refactoring",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Khouloud Oueslati",
      "Maxime Lamothe",
      "Foutse Khomh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03153v1",
    "abstract": "Large Language Models (LLMs) have substantially influenced various software engineering tasks. Indeed, in the case of software refactoring, traditional LLMs have shown the ability to reduce development time and enhance code quality. However, these LLMs often rely on static, detailed instructions for specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving contexts and autonomously make decisions by interacting with software tools and executing workflows. In this paper, we explore the potential of LLM-based agents in supporting refactoring activities. Specifically, we introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring. RefAgent consists of specialized agents responsible for planning, executing, testing, and iteratively refining refactorings using self-reflection and tool-calling capabilities. We evaluate RefAgent on eight open-source Java projects, comparing its effectiveness against a single-agent approach, a search-based refactoring tool, and historical developer refactorings. Our assessment focuses on: (1) the impact of generated refactorings on software quality, (2) the ability to identify refactoring opportunities, and (3) the contribution of each LLM agent through an ablation study. Our results show that RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a median of 52.5%, and improves key quality attributes (e.g., reusability) by a median of 8.6%. Additionally, it closely aligns with developer refactorings and the search-based tool in identifying refactoring opportunities, attaining a median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent approaches, RefAgent improves the median unit test pass rate by 64.7% and the median compilation success rate by 40.1%. These findings highlight the promise of multi-agent architectures in advancing automated software refactoring.",
    "fetched_at": "2025-11-09T02:21:22.886304Z"
  },
  {
    "id": "2511.03179v2",
    "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent   Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Varun Kumar",
      "George Em Karniadakis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03179v2",
    "abstract": "The engineering design process often demands expertise from multiple domains, leading to complex collaborations and iterative refinements. Traditional methods can be resource-intensive and prone to inefficiencies. To address this, we formalize the engineering design process through a multi-agent AI framework that integrates structured design and review loops. The framework introduces specialized knowledge-driven agents that collaborate to generate and refine design candidates. As an exemplar, we demonstrate its application to the aerodynamic optimization of 4-digit NACA airfoils. The framework consists of three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems Engineer. The Graph Ontologist employs a Large Language Model (LLM) to construct two domain-specific knowledge graphs from airfoil design literature. The Systems Engineer, informed by a human manager, formulates technical requirements that guide design generation and evaluation. The Design Engineer leverages the design knowledge graph and computational tools to propose candidate airfoils meeting these requirements. The Systems Engineer reviews and provides feedback both qualitative and quantitative using its own knowledge graph, forming an iterative feedback loop until a design is validated by the manager. The final design is then optimized to maximize performance metrics such as the lift-to-drag ratio. Overall, this work demonstrates how collaborative AI agents equipped with structured knowledge representations can enhance efficiency, consistency, and quality in the engineering design process.",
    "fetched_at": "2025-11-09T02:21:22.886256Z"
  },
  {
    "id": "2511.03217v1",
    "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language   Models, and Search-Based Retrieval Agents Improves Interpretable Claim   Verification",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "cs.IR",
      "IR",
      "68T50",
      "I.2.7; H.3.3",
      "3"
    ],
    "authors": [
      "Shaghayegh Kolli",
      "Richard Rosenbaum",
      "Timo Cavelius",
      "Lasse Strothe",
      "Andrii Lata",
      "Jana Diesner"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03217v1",
    "abstract": "Large language models (LLMs) excel in generating fluent utterances but can lack reliable grounding in verified information. At the same time, knowledge-graph-based fact-checkers deliver precise and interpretable evidence, yet suffer from limited coverage or latency. By integrating LLMs with knowledge graphs and real-time search agents, we introduce a hybrid fact-checking approach that leverages the individual strengths of each component. Our system comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid one-hop lookups in DBpedia, 2) an LM-based classification guided by a task-specific labeling prompt, producing outputs with internal rule-based logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient. Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the Supported/Refuted split without task-specific fine-tuning. To address Not enough information cases, we conduct a targeted reannotation study showing that our approach frequently uncovers valid evidence for claims originally labeled as Not Enough Information (NEI), as confirmed by both expert annotators and LLM reviewers. With this paper, we present a modular, opensource fact-checking pipeline with fallback strategies and generalization across datasets.",
    "fetched_at": "2025-11-09T02:21:22.886211Z"
  },
  {
    "id": "2511.03757v1",
    "title": "Laugh, Relate, Engage: Stylized Comment Generation for Short Videos",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xuan Ouyang",
      "Senan Wang",
      "Bouzhou Wang",
      "Siyuan Xiahou",
      "Jinrong Zhou",
      "Yuekang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03757v1",
    "abstract": "Short-video platforms have become a central medium in the modern Internet landscape, where efficient information delivery and strong interactivity are reshaping user engagement and cultural dissemination. Among the various forms of user interaction, comments play a vital role in fostering community participation and enabling content re-creation. However, generating comments that are both compliant with platform guidelines and capable of exhibiting stylistic diversity and contextual awareness remains a significant challenge. We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for controllable short-video comment generation. The system integrates video segmentation, contextual and affective analysis, and style-aware prompt construction. It supports six distinct comment styles: puns (homophones), rhyming, meme application, sarcasm (irony), plain humor, and content extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM directly processes video inputs and achieves fine-grained style control through explicit prompt markers and few-shot examples. To support development and evaluation, we construct a bilingual dataset using official APIs from Douyin (Chinese) and YouTube (English), covering five popular video genres: comedy skits, daily life jokes, funny animal clips, humorous commentary, and talk shows. Evaluation combines automated metrics originality, relevance, and style conformity with a large-scale human preference study involving 40 videos and 105 participants. Results show that LOLGORITHM significantly outperforms baseline models, achieving preference rates of over 90% on Douyin and 87.55% on YouTube. This work presents a scalable and culturally adaptive framework for stylized comment generation on short-video platforms, offering a promising path to enhance user engagement and creative interaction.",
    "fetched_at": "2025-11-09T02:21:22.886154Z"
  },
  {
    "id": "2511.03248v1",
    "title": "Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation   Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Junhao Li",
      "Jiahao Chen",
      "Zhou Feng",
      "Chunyi Zhou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03248v1",
    "abstract": "Recent advances in multi-modal Large Language Models (M-LLMs) have demonstrated a powerful ability to synthesize implicit information from disparate sources, including images and text. These resourceful data from social media also introduce a significant and underexplored privacy risk: the inference of sensitive personal attributes from seemingly daily media content. However, the lack of benchmarks and comprehensive evaluations of state-of-the-art M-LLM capabilities hinders the research of private attribute profiling on social media. Accordingly, we propose (1) PRISM, the first multi-modal, multi-dimensional and fine-grained synthesized dataset incorporating a comprehensive privacy landscape and dynamic user history; (2) an Efficient evaluation framework that measures the cross-modal privacy inference capabilities of advanced M-LLM. Specifically, PRISM is a large-scale synthetic benchmark designed to evaluate cross-modal privacy risks. Its key feature is 12 sensitive attribute labels across a diverse set of multi-modal profiles, which enables targeted privacy analysis. These profiles are generated via a sophisticated LLM agentic workflow, governed by a prior distribution to ensure they realistically mimic social media users. Additionally, we propose a Multi-Agent Inference Framework that leverages a pipeline of specialized LLMs to enhance evaluation capabilities. We evaluate the inference capabilities of six leading M-LLMs (Qwen, Gemini, GPT-4o, GLM, Doubao, and Grok) on PRISM. The comparison with human performance reveals that these MLLMs significantly outperform in accuracy and efficiency, highlighting the threat of potential privacy risks and the urgent need for robust defenses.",
    "fetched_at": "2025-11-09T02:21:22.886091Z"
  },
  {
    "id": "2511.03758v1",
    "title": "Leveraging LLM-based agents for social science research: insights from   citation network simulations",
    "date": "2025-11-05",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "cs.MA",
      "MA",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Jiarui Ji",
      "Runlin Lei",
      "Xuchen Pan",
      "Zhewei Wei",
      "Hao Sun",
      "Yankai Lin",
      "Xu Chen",
      "Yongzheng Yang",
      "Yaliang Li",
      "Bolin Ding",
      "Ji-Rong Wen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03758v1",
    "abstract": "The emergence of Large Language Models (LLMs) demonstrates their potential to encapsulate the logic and patterns inherent in human behavior simulation by leveraging extensive web data pre-training. However, the boundaries of LLM capabilities in social simulation remain unclear. To further explore the social attributes of LLMs, we introduce the CiteAgent framework, designed to generate citation networks based on human-behavior simulation with LLM-based agents. CiteAgent successfully captures predominant phenomena in real-world citation networks, including power-law distribution, citational distortion, and shrinking diameter. Building on this realistic simulation, we establish two LLM-based research paradigms in social science: LLM-SE (LLM-based Survey Experiment) and LLM-LE (LLM-based Laboratory Experiment). These paradigms facilitate rigorous analyses of citation network phenomena, allowing us to validate and challenge existing theories. Additionally, we extend the research scope of traditional science of science studies through idealized social experiments, with the simulation experiment results providing valuable insights for real-world academic environments. Our work demonstrates the potential of LLMs for advancing science of science research in social science.",
    "fetched_at": "2025-11-09T02:21:22.886039Z"
  },
  {
    "id": "2511.03363v1",
    "title": "A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in   Transportation Agentic AI Applications",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiaocai Zhang",
      "Hur Lim",
      "Ke Wang",
      "Zhe Xiao",
      "Jing Wang",
      "Kelvin Lee",
      "Xiuju Fu",
      "Zheng Qin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03363v1",
    "abstract": "In this study, a modular, data-free pipeline for multi-label intention recognition is proposed for agentic AI applications in transportation. Unlike traditional intent recognition systems that depend on large, annotated corpora and often struggle with fine-grained, multi-label discrimination, our approach eliminates the need for costly data collection while enhancing the accuracy of multi-label intention understanding. Specifically, the overall pipeline, named DMTC, consists of three steps: 1) using prompt engineering to guide large language models (LLMs) to generate diverse synthetic queries in different transport scenarios; 2) encoding each textual query with a Sentence-T5 model to obtain compact semantic embeddings; 3) training a lightweight classifier using a novel online focal-contrastive (OFC) loss that emphasizes hard samples and maximizes inter-class separability. The applicability of the proposed pipeline is demonstrated in an agentic AI application in the maritime transportation context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35% and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that Sentence-T5 embeddings improve subset accuracy by at least 3.29% over alternative encoders, and integrating the OFC loss yields an additional 0.98% gain compared to standard contrastive objectives. In conclusion, our system seamlessly routes user queries to task-specific modules (e.g., ETA information, traffic risk evaluation, and other typical scenarios in the transportation domain), laying the groundwork for fully autonomous, intention-aware agents without costly manual labelling.",
    "fetched_at": "2025-11-09T02:21:22.885968Z"
  },
  {
    "id": "2511.03370v1",
    "title": "EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models   for Edge-Deployable Credit Negotiation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yunbo Long",
      "Yuhan Liu",
      "Alexandra Brintrup"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03370v1",
    "abstract": "The deployment of large language models (LLMs) in automated negotiation has set a high performance benchmark, but their computational cost and data privacy requirements render them unsuitable for many privacy-sensitive, on-device applications such as mobile assistants, embodied AI agents or private client interactions. While small language models (SLMs) offer a practical alternative, they suffer from a significant performance gap compared to LLMs in playing emotionally charged complex personas, especially for credit negotiation. This paper introduces EQ-Negotiator, a novel framework that bridges this capability gap using emotional personas. Its core is a reasoning system that integrates game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional states online, without pre-training. This allows EQ-Negotiator to equip SLMs with the strategic intelligence to counter manipulation while de-escalating conflict and upholding ethical standards. Through extensive agent-to-agent simulations across diverse credit negotiation scenarios, including adversarial debtor strategies like cheating, threatening, and playing the victim, we show that a 7B parameter language model with EQ-Negotiator achieves better debt recovery and negotiation efficiency than baseline LLMs more than 10 times its size. This work advances persona modeling from descriptive character profiles to dynamic emotional architectures that operate within privacy constraints. Besides, this paper establishes that strategic emotional intelligence, not raw model scale, is the critical factor for success in automated negotiation, paving the way for effective, ethical, and privacy-preserving AI negotiators that can operate on the edge.",
    "fetched_at": "2025-11-09T02:21:22.885905Z"
  },
  {
    "id": "2511.03404v1",
    "title": "Towards Realistic Project-Level Code Generation via Multi-Agent   Collaboration and Semantic Architecture Modeling",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Qianhui Zhao",
      "Li Zhang",
      "Fang Liu",
      "Junhang Cheng",
      "Chengru Wu",
      "Junchen Ai",
      "Qiaoyuanhe Meng",
      "Lichen Zhang",
      "Xiaoli Lian",
      "Shubin Song",
      "Yuanping Guo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03404v1",
    "abstract": "In recent years, Large Language Models (LLMs) have achieved remarkable progress in automated code generation. In real-world software engineering, the growing demand for rapid iteration and continuous delivery underscores the importance of project-level code generation, where LLMs are expected to generate complete software projects directly from complex user requirements. Although existing studies have made initial explorations, they still face key limitations, including unrealistic datasets and unreliable evaluation metrics that fail to reflect real-world complexity, the semantic gap between human-written requirements and machine-interpretable structures, and difficulties in managing hierarchical dependencies and maintaining quality throughout the generation process. To address these limitations, we first introduce CodeProjectEval, a project-level code generation dataset built from 18 real-world repositories with 12.7 files and 2,388.6 lines of code per task on average, supplemented with documentation and executable test cases for automatic evaluation. We further propose ProjectGen, a multi-agent framework that decomposes projects into architecture design, skeleton generation, and code filling stages with iterative refinement and memory-based context management. Within this framework, we introduce the Semantic Software Architecture Tree (SSAT), a structured and semantically rich representation that effectively bridges user requirements and source code implementation. Experiments show that ProjectGen achieves state-of-the-art performance, passing 52/124 test cases on the small-scale project-level code generation dataset DevBench, a 57% improvement over the baseline approaches, and 310 test cases on CodeProjectEval, representing an improvement of roughly tenfold compared to the baselines.",
    "fetched_at": "2025-11-09T02:21:22.885857Z"
  },
  {
    "id": "2511.03434v1",
    "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof,   Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2,   ERC-8004, and Beyond",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA",
      "cs.NI",
      "NI",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Botao 'Amber' Hu",
      "Helena Rong"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2511.03434v1",
    "abstract": "As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered) autonomously transacting and collaborating-trust shifts from human oversight to protocol design. In 2025, several inter-agent protocols crystallized this shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2), and Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust assumptions remain under-examined. This paper presents a comparative study of trust models in inter-agent protocol design: Brief (self- or third-party verifiable claims), Claim (self-proclaimed capabilities and identity, e.g. AgentCard), Proof (cryptographic verification, including zero-knowledge proofs and trusted execution environment attestations), Stake (bonded collateral with slashing and insurance), Reputation (crowd feedback and graph-based trust signals), and Constraint (sandboxing and capability bounding). For each, we analyze assumptions, attack surfaces, and design trade-offs, with particular emphasis on LLM-specific fragilities-prompt injection, sycophancy/nudge-susceptibility, hallucination, deception, and misalignment-that render purely reputational or claim-only approaches brittle. Our findings indicate no single mechanism suffices. We argue for trustless-by-default architectures anchored in Proof and Stake to gate high-impact actions, augmented by Brief for identity and discovery and Reputation overlays for flexibility and social signals. We comparatively evaluate A2A, AP2, ERC-8004 and related historical variations in academic research under metrics spanning security, privacy, latency/cost, and social robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid trust model recommendations that mitigate reputation gaming and misinformed LLM behavior, and we distill actionable design guidelines for safer, interoperable, and scalable agent economies.",
    "fetched_at": "2025-11-09T02:21:22.885785Z"
  },
  {
    "id": "2511.03475v1",
    "title": "RAGBoost: Efficient Retrieval-Augmented Generation with   Accuracy-Preserving Context Reuse",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yinsicheng Jiang",
      "Yeqi Huang",
      "Liang Cheng",
      "Cheng Deng",
      "Xuan Sun",
      "Luo Mai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03475v1",
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with retrieved context but often suffers from downgraded prefill performance as modern applications demand longer and more complex inputs. Existing caching techniques either preserve accuracy with low cache reuse or improve reuse at the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG system that achieves high cache reuse without sacrificing accuracy through accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items across concurrent sessions and multi-turn interactions, using efficient context indexing, ordering, and de-duplication to maximize reuse, while lightweight contextual hints maintain reasoning fidelity. It integrates seamlessly with existing LLM inference engines and improves their prefill performance by 1.5-3X over state-of-the-art methods, while preserving or even enhancing reasoning accuracy across diverse RAG and agentic AI workloads. Our code is released at: https://github.com/Edinburgh-AgenticAI/RAGBoost.",
    "fetched_at": "2025-11-09T02:21:22.885737Z"
  },
  {
    "id": "2511.03497v1",
    "title": "ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied   AI Applications",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Lei Fu",
      "Sahar Salimpour",
      "Leonardo Militano",
      "Harry Edelman",
      "Jorge Peña Queralta",
      "Giovanni Toffetti"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.03497v1",
    "abstract": "Agentic AI systems and Physical or Embodied AI systems have been two key research verticals at the forefront of Artificial Intelligence and Robotics, with Model Context Protocol (MCP) increasingly becoming a key component and enabler of agentic applications. However, the literature at the intersection of these verticals, i.e., Agentic Embodied AI, remains scarce. This paper introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for analyzing, visualizing and processing robot data with natural language through LLMs and VLMs. We describe specific tooling built with robotics domain knowledge, with our initial release focused on mobile robotics and supporting natively the analysis of trajectories, laser scan data, transforms, or time series data. This is in addition to providing an interface to standard ROS 2 CLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to filter bags with a subset of topics or trimmed in time. Coupled with the MCP server, we provide a lightweight UI that allows the benchmarking of the tooling with different LLMs, both proprietary (Anthropic, OpenAI) and open-source (through Groq). Our experimental results include the analysis of tool calling capabilities of eight different state-of-the-art LLM/VLM models, both proprietary and open-source, large and small. Our experiments indicate that there is a large divide in tool calling capabilities, with Kimi K2 and Claude Sonnet 4 demonstrating clearly superior performance. We also conclude that there are multiple factors affecting the success rates, from the tool description schema to the number of arguments, as well as the number of tools available to the models. The code is available with a permissive license at https://github.com/binabik-ai/mcp-rosbags.",
    "fetched_at": "2025-11-09T02:21:22.885688Z"
  },
  {
    "id": "2511.03506v1",
    "title": "HaluMem: Evaluating Hallucinations in Memory Systems of Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ding Chen",
      "Simin Niu",
      "Kehang Li",
      "Peng Liu",
      "Xiangping Zheng",
      "Bo Tang",
      "Xinchi Li",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03506v1",
    "abstract": "Memory systems are key components that enable AI systems such as LLMs and AI agents to achieve long-term learning and sustained interaction. However, during memory storage and retrieval, these systems frequently exhibit memory hallucinations, including fabrication, errors, conflicts, and omissions. Existing evaluations of memory hallucinations are primarily end-to-end question answering, which makes it difficult to localize the operational stage within the memory system where hallucinations arise. To address this, we introduce the Hallucination in Memory Benchmark (HaluMem), the first operation level hallucination evaluation benchmark tailored to memory systems. HaluMem defines three evaluation tasks (memory extraction, memory updating, and memory question answering) to comprehensively reveal hallucination behaviors across different operational stages of interaction. To support evaluation, we construct user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and HaluMem-Long. Both include about 15k memory points and 3.5k multi-type questions. The average dialogue length per user reaches 1.5k and 2.6k turns, with context lengths exceeding 1M tokens, enabling evaluation of hallucinations across different context scales and task complexities. Empirical studies based on HaluMem show that existing memory systems tend to generate and accumulate hallucinations during the extraction and updating stages, which subsequently propagate errors to the question answering stage. Future research should focus on developing interpretable and constrained memory operation mechanisms that systematically suppress hallucinations and improve memory reliability.",
    "fetched_at": "2025-11-09T02:21:22.885630Z"
  },
  {
    "id": "2511.03517v1",
    "title": "U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Wencheng Ye",
      "Yan Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03517v1",
    "abstract": "Large language models (LLMs) have shown strong capabilities in software engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle well-defined problems using conventional methods, often overlooking alternative or innovative solutions beyond their predefined frameworks. This limitation is evident in open-world software environments, where emerging challenges transcend established paradigms.   We propose U2F (Unknown Unknowns to Functional solutions), a cognitive-inspired, uncertainty-embracing multi-agent framework that systematically surfaces \"Unknown Unknowns\" - novel solution pathways absent from initial formulations but holding innovative potential. U2F consists of two key components: (1) a Discovery-Exploration-Integration agent system for uncovering and synthesizing potential solutions, and (2) cognitive enhancement mechanisms across three dimensions: cross-domain analogical reasoning, reverse thinking, and external validation, which strategically reframe and extend conventional solution boundaries.   Applied to 218 real-world software enabler stories curated from authentic engineering tasks, U2F achieved notable improvements: human experts reported a 14 percent increase in overall novelty, 51 percent improvement in semantic novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based evaluator. These results highlight the potential of embracing uncertainty as a catalyst for innovation in software engineering.",
    "fetched_at": "2025-11-09T02:21:22.885566Z"
  },
  {
    "id": "2511.03542v1",
    "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across   Medical Specialties",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Roberta Di Marino",
      "Giovanni Dioguardi",
      "Antonio Romano",
      "Giuseppe Riccio",
      "Mariano Barone",
      "Marco Postiglione",
      "Flora Amato",
      "Vincenzo Moscato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03542v1",
    "abstract": "Medical question answering systems face deployment challenges including hallucinations, bias, computational demands, privacy concerns, and the need for specialized expertise across diverse domains. Here, we present SOLVE-Med, a multi-agent architecture combining domain-specialized small language models for complex medical queries. The system employs a Router Agent for dynamic specialist selection, ten specialized models (1B parameters each) fine-tuned on specific medical domains, and an Orchestrator Agent that synthesizes responses. Evaluated on Italian medical forum data across ten specialties, SOLVE-Med achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697, outperforming standalone models up to 14B parameters while enabling local deployment. Our code is publicly available on GitHub: https://github.com/PRAISELab-PicusLab/SOLVE-Med.",
    "fetched_at": "2025-11-09T02:21:22.885522Z"
  },
  {
    "id": "2511.03586v1",
    "title": "PerfDojo: Automated ML Library Generation for Heterogeneous   Architectures",
    "date": "2025-11-05",
    "tags": [
      "cs.PF",
      "PF",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Andrei Ivanov",
      "Siyuan Shen",
      "Gioele Gottardo",
      "Marcin Chrapek",
      "Afif Boudaoud",
      "Timo Schneider",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03586v1",
    "abstract": "The increasing complexity of machine learning models and the proliferation of diverse hardware architectures (CPUs, GPUs, accelerators) make achieving optimal performance a significant challenge. Heterogeneity in instruction sets, specialized kernel requirements for different data types and model features (e.g., sparsity, quantization), and architecture-specific optimizations complicate performance tuning. Manual optimization is resource-intensive, while existing automatic approaches often rely on complex hardware-specific heuristics and uninterpretable intermediate representations, hindering performance portability. We introduce PerfLLM, a novel automatic optimization methodology leveraging Large Language Models (LLMs) and Reinforcement Learning (RL). Central to this is PerfDojo, an environment framing optimization as an RL game using a human-readable, mathematically-inspired code representation that guarantees semantic validity through transformations. This allows effective optimization without prior hardware knowledge, facilitating both human analysis and RL agent training. We demonstrate PerfLLM's ability to achieve significant performance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.",
    "fetched_at": "2025-11-09T02:21:22.885468Z"
  },
  {
    "id": "2511.03628v1",
    "title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Haofei Yu",
      "Fenghai Li",
      "Jiaxuan You"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03628v1",
    "abstract": "Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty.",
    "fetched_at": "2025-11-09T02:21:22.885409Z"
  },
  {
    "id": "2511.03690v1",
    "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation   for Production Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xingyao Wang",
      "Simon Rosenberg",
      "Juan Michelini",
      "Calvin Smith",
      "Hoang Tran",
      "Engel Nyst",
      "Rohit Malhotra",
      "Xuhui Zhou",
      "Valerie Chen",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "institution": "Google, OpenAI",
    "link": "http://arxiv.org/pdf/2511.03690v1",
    "abstract": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensible to more complex, full-featured agents with features such as custom tools, memory management, and more. For security and reliability, it delivers seamless local-to-remote execution portability, integrated REST/WebSocket services. For interaction with human users, it can connect directly to a variety of interfaces, such as visual workspaces (VS Code, VNC, browser), command-line interfaces, and APIs. Compared with existing SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and built-in security analysis. Empirical results on SWE-Bench Verified and GAIA benchmarks demonstrate strong performance. Put together, these elements allow the OpenHands Software Agent SDK to provide a practical foundation for prototyping, unlocking new classes of custom applications, and reliably deploying agents at scale.",
    "fetched_at": "2025-11-09T02:21:22.885359Z"
  },
  {
    "id": "2511.03697v1",
    "title": "AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and   Sample-Efficient Analog Circuit Sizing",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.AR",
      "AR"
    ],
    "authors": [
      "Mohsen Ahmadzadeh",
      "Kaichang Chen",
      "Georges Gielen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03697v1",
    "abstract": "Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.",
    "fetched_at": "2025-11-09T02:21:22.885288Z"
  },
  {
    "id": "2511.03724v1",
    "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via   Self-Play and Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Richard Dewey",
      "Janos Botyanszki",
      "Ciamac C. Moallemi",
      "Andrew T. Zheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03724v1",
    "abstract": "AI researchers have long focused on poker-like games as a testbed for environments characterized by multi-player dynamics, imperfect information, and reasoning under uncertainty. While recent breakthroughs have matched elite human play at no-limit Texas hold'em, the multi-player dynamics are subdued: most hands converge quickly with only two players engaged through multiple rounds of bidding. In this paper, we present Solly, the first AI agent to achieve elite human play in reduced-format Liar's Poker, a game characterized by extensive multi-player engagement. We trained Solly using self-play with a model-free, actor-critic, deep reinforcement learning algorithm. Solly played at an elite human level as measured by win rate (won over 50% of hands) and equity (money won) in heads-up and multi-player Liar's Poker. Solly also outperformed large language models (LLMs), including those with reasoning abilities, on the same metrics. Solly developed novel bidding strategies, randomized play effectively, and was not easily exploitable by world-class human players.",
    "fetched_at": "2025-11-09T02:21:22.885241Z"
  },
  {
    "id": "2511.03773v1",
    "title": "Scaling Agent Learning via Experience Synthesis",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Kai Zhang",
      "Bo Liu",
      "Qi Qi",
      "Yifan Wu",
      "Tarun Kalluri",
      "Sara Cao",
      "Yuanhao Xiong",
      "Haibo Tong",
      "Huaxiu Yao",
      "Hengduo Li",
      "Jiacheng Zhu",
      "Xian Li",
      "Dawn Song",
      "Bo Li",
      "Jason Weston",
      "Dat Huynh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03773v1",
    "abstract": "While reinforcement learning (RL) can empower large language model (LLM) agents by enabling self-improvement through interaction, its practical adoption remains challenging due to costly rollouts, limited task diversity, unreliable reward signals, and infrastructure complexity, all of which obstruct the collection of scalable experience data. To address these challenges, we introduce DreamGym, the first unified framework designed to synthesize diverse experiences with scalability in mind to enable effective online RL training for autonomous agents. Rather than relying on expensive real-environment rollouts, DreamGym distills environment dynamics into a reasoning-based experience model that derives consistent state transitions and feedback signals through step-by-step reasoning, enabling scalable agent rollout collection for RL. To improve the stability and quality of transitions, DreamGym leverages an experience replay buffer initialized with offline real-world data and continuously enriched with fresh interactions to actively support agent training. To improve knowledge acquisition, DreamGym adaptively generates new tasks that challenge the current agent policy, enabling more effective online curriculum learning. Experiments across diverse environments and agent backbones demonstrate that DreamGym substantially improves RL training, both in fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in RL-ready but costly settings, it matches GRPO and PPO performance using only synthetic interactions. When transferring a policy trained purely on synthetic experiences to real-environment RL, DreamGym yields significant additional performance gains while requiring far fewer real-world interactions, providing a scalable warm-start strategy for general-purpose RL.",
    "fetched_at": "2025-11-09T02:21:22.885196Z"
  },
  {
    "id": "2511.03844v1",
    "title": "ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale   LLM Training",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Yuran Ding",
      "Xinwei Chen",
      "Xiaofan Zhang",
      "Zongwei Zhou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03844v1",
    "abstract": "Optimizing large-language model (LLM) training on distributed domain-specific accelerator systems presents significant challenges due to its complex optimization space. Existing optimization methods, however, rely on time-consuming manual tuning or resource-intensive black-box searches, which struggle to keep pace with the rapidly evolving LLM domain, leading to slow development and underutilized resources. To address this, we introduce ASAP, an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents, which integrates LLM reasoning with insights from performance profiling tools, roofline analysis, and a knowledge base of best practices and successful past optimizations from human experts. Our proposed design can automate the diagnosis of performance bottlenecks and recommend optimized sharding configurations with reasoning, thus effectively improving the efficiency of distributed LLM training. Experiments have shown that the ASAP-generated sharding configurations can contribute up to 28% training step time reduction and 1.43 times throughput improvement. When combined with additional optimization from human experts, throughput can be further increased to 2.58 times. The proposed ASAP promises to provide a scalable and explainable methodology for AI-assisted performance engineering in large-scale LLM training.",
    "fetched_at": "2025-11-09T02:21:22.885080Z"
  },
  {
    "id": "2511.03845v1",
    "title": "To See or To Read: User Behavior Reasoning in Multimodal LLMs",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianning Dong",
      "Luyi Ma",
      "Varun Vasudevan",
      "Jason Cho",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03845v1",
    "abstract": "Multimodal Large Language Models (MLLMs) are reshaping how modern agentic systems reason over sequential user-behavior data. However, whether textual or image representations of user behavior data are more effective for maximizing MLLM performance remains underexplored. We present \\texttt{BehaviorLens}, a systematic benchmarking framework for assessing modality trade-offs in user-behavior reasoning across six MLLMs by representing transaction data as (1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a real-world purchase-sequence dataset, we find that when data is represented as images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared with an equivalent textual representation without any additional computational cost.",
    "fetched_at": "2025-11-09T02:21:22.885028Z"
  },
  {
    "id": "2511.03852v1",
    "title": "GAIA: Geothermal Analytics and Intelligent Agent",
    "date": "2025-11-05",
    "tags": [
      "physics.geo-ph",
      "geo-ph"
    ],
    "authors": [
      "Randy Harsuko",
      "Zhengfa Bi",
      "Nori Nakata"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03852v1",
    "abstract": "Geothermal field development typically involves complex processes that require multi-disciplinary expertise in each process. Thus, decision-making often demands the integration of geological, geophysical, reservoir engineering, and operational data under tight time constraints. We present Geothermal Analytics and Intelligent Agent, or GAIA, an AI-based system for automation and assistance in geothermal field development. GAIA consists of three core components: GAIA Agent, GAIA Chat, and GAIA Digital Twin, or DT, which together constitute an agentic retrieval-augmented generation (RAG) workflow. Specifically, GAIA Agent, powered by a pre-trained large language model (LLM), designs and manages task pipelines by autonomously querying knowledge bases and orchestrating multi-step analyses. GAIA DT encapsulates classical and surrogate physics models, which, combined with built-in domain-specific subroutines and visualization tools, enable predictive modeling of geothermal systems. Lastly, GAIA Chat serves as a web-based interface for users, featuring a ChatGPT-like layout with additional functionalities such as interactive visualizations, parameter controls, and in-context document retrieval. To ensure GAIA's specialized capability for handling complex geothermal-related tasks, we curate a benchmark test set comprising various geothermal-related use cases, and we rigorously and continuously evaluate the system's performance. We envision GAIA as a pioneering step toward intelligent geothermal field development, capable of assisting human experts in decision-making, accelerating project workflows, and ultimately enabling automation of the development process.",
    "fetched_at": "2025-11-09T02:21:22.884981Z"
  },
  {
    "id": "2511.03878v1",
    "title": "KnowThyself: An Agentic Assistant for LLM Interpretability",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA",
      "I.2.7; I.2.0",
      "0"
    ],
    "authors": [
      "Suraj Prasai",
      "Mengnan Du",
      "Ying Zhang",
      "Fan Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03878v1",
    "abstract": "We develop KnowThyself, an agentic assistant that advances large language model (LLM) interpretability. Existing tools provide useful insights but remain fragmented and code-intensive. KnowThyself consolidates these capabilities into a chat-based interface, where users can upload models, pose natural language questions, and obtain interactive visualizations with guided explanations. At its core, an orchestrator LLM first reformulates user queries, an agent router further directs them to specialized modules, and the outputs are finally contextualized into coherent explanations. This design lowers technical barriers and provides an extensible platform for LLM inspection. By embedding the whole process into a conversational workflow, KnowThyself offers a robust foundation for accessible LLM interpretability.",
    "fetched_at": "2025-11-09T02:21:22.884935Z"
  },
  {
    "id": "2511.03908v1",
    "title": "Context informs pragmatic interpretation in vision-language models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alvin Wei Ming Tan",
      "Ben Prystawski",
      "Veronica Boyce",
      "Michael C. Frank"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03908v1",
    "abstract": "Iterated reference games - in which players repeatedly pick out novel referents using language - present a test case for agents' ability to perform context-sensitive pragmatic reasoning in multi-turn linguistic environments. We tested humans and vision-language models on trials from iterated reference games, varying the given context in terms of amount, order, and relevance. Without relevant context, models were above chance but substantially worse than humans. However, with relevant context, model performance increased dramatically over trials. Few-shot reference games with abstract referents remain a difficult task for machine learning models.",
    "fetched_at": "2025-11-09T02:21:22.884892Z"
  },
  {
    "id": "2511.03247v1",
    "title": "Death by a Thousand Prompts: Open Model Vulnerability Analysis",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Amy Chang",
      "Nicholas Conley",
      "Harish Santhanalakshmi Ganesan",
      "Adam Swanda"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2511.03247v1",
    "abstract": "Open-weight models provide researchers and developers with accessible foundations for diverse downstream applications. We tested the safety and security postures of eight open-weight large language models (LLMs) to identify vulnerabilities that may impact subsequent fine-tuning and deployment. Using automated adversarial testing, we measured each model's resilience against single-turn and multi-turn prompt injection and jailbreak attacks. Our findings reveal pervasive vulnerabilities across all tested models, with multi-turn attacks achieving success rates between 25.86\\% and 92.78\\% -- representing a $2\\times$ to $10\\times$ increase over single-turn baselines. These results underscore a systemic inability of current open-weight models to maintain safety guardrails across extended interactions. We assess that alignment strategies and lab priorities significantly influence resilience: capability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher multi-turn susceptibility, whereas safety-oriented designs such as Google Gemma 3 exhibit more balanced performance.   The analysis concludes that open-weight models, while crucial for innovation, pose tangible operational and ethical risks when deployed without layered security controls. These findings are intended to inform practitioners and developers of the potential risks and the value of professional AI security solutions to mitigate exposure. Addressing multi-turn vulnerabilities is essential to ensure the safe, reliable, and responsible deployment of open-weight LLMs in enterprise and public domains. We recommend adopting a security-first design philosophy and layered protections to ensure resilient deployments of open-weight models.",
    "fetched_at": "2025-11-07T02:16:47.497777Z"
  },
  {
    "id": "2511.03251v1",
    "title": "GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Zhibin Wang",
      "Zhixing Zhang",
      "Shuqi Wang",
      "Xuanting Xie",
      "Zhao Kang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03251v1",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated impressive performance on task-specific benchmarks, yet their ability to generalize across diverse domains and tasks remains limited. Existing approaches often struggle with negative transfer, scalability issues, and high adaptation costs. To address these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture with prompt-based learning for graphs. GMoPE leverages expert-specific prompt vectors and structure-aware MoE routing to enable each expert to specialize in distinct subdomains and dynamically contribute to predictions. To promote diversity and prevent expert collapse, we introduce a soft orthogonality constraint across prompt vectors, encouraging expert specialization and facilitating a more balanced expert utilization. Additionally, we adopt a prompt-only fine-tuning strategy that significantly reduces spatiotemporal complexity during transfer. We validate GMoPE through extensive experiments under various pretraining strategies and multiple downstream tasks. Results show that GMoPE consistently outperforms state-of-the-art baselines and achieves performance comparable to full parameter fine-tuning-while requiring only a fraction of the adaptation overhead. Our work provides a principled and scalable framework for advancing generalizable and efficient graph foundation models.",
    "fetched_at": "2025-11-07T02:16:47.497724Z"
  },
  {
    "id": "2511.03255v1",
    "title": "Generative deep learning for foundational video translation in   ultrasound",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nikolina Tomic Roshni Bhatnagar",
      "Sarthak Jain",
      "Connor Lau",
      "Tien-Yu Liu",
      "Laura Gambini",
      "Rima Arnaout"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03255v1",
    "abstract": "Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.",
    "fetched_at": "2025-11-07T02:16:47.497672Z"
  },
  {
    "id": "2511.03256v1",
    "title": "Decoupled Entropy Minimization",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV",
      "cs.IT",
      "IT",
      "math.IT",
      "math.ST",
      "ST",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Jing Ma",
      "Hanlin Li",
      "Xiang Xiang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03256v1",
    "abstract": "Entropy Minimization (EM) is beneficial to reducing class overlap, bridging domain gap, and restricting uncertainty for various tasks in machine learning, yet its potential is limited. To study the internal mechanism of EM, we reformulate and decouple the classical EM into two parts with opposite effects: cluster aggregation driving factor (CADF) rewards dominant classes and prompts a peaked output distribution, while gradient mitigation calibrator (GMC) penalizes high-confidence classes based on predicted probabilities. Furthermore, we reveal the limitations of classical EM caused by its coupled formulation: 1) reward collapse impedes the contribution of high-certainty samples in the learning process, and 2) easy-class bias induces misalignment between output distribution and label distribution. To address these issues, we propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the reward brought from CADF and employs a marginal entropy calibrator (MEC) to replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM, and achieves superior performance across various imperfectly supervised learning tasks in noisy and dynamic environments.",
    "fetched_at": "2025-11-07T02:16:47.497612Z"
  },
  {
    "id": "2511.03261v1",
    "title": "Comparing the Performance of LLMs in RAG-based Question-Answering: A   Case Study in Computer Science Literature",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "I.2.1; I.2.7",
      "7"
    ],
    "authors": [
      "Ranul Dayarathne",
      "Uvini Ranaweera",
      "Upeksha Ganegoda"
    ],
    "institution": "Google, Meta, OpenAI",
    "link": "http://arxiv.org/pdf/2511.03261v1",
    "abstract": "Retrieval Augmented Generation (RAG) is emerging as a powerful technique to enhance the capabilities of Generative AI models by reducing hallucination. Thus, the increasing prominence of RAG alongside Large Language Models (LLMs) has sparked interest in comparing the performance of different LLMs in question-answering (QA) in diverse domains. This study compares the performance of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA tasks within the computer science literature leveraging RAG support. Evaluation metrics employed in the study include accuracy and precision for binary questions and ranking by a human expert, ranking by Google's AI model Gemini, alongside cosine similarity for long-answer questions. GPT-3.5, when paired with RAG, effectively answers binary and long-answer questions, reaffirming its status as an advanced LLM. Regarding open-source LLMs, Mistral AI's Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b reports the shortest average latency in generating responses, whereas LLaMa2-7b-chat by Meta reports the highest average latency. This research underscores the fact that open-source LLMs, too, can go hand in hand with proprietary models like GPT-3.5 with better infrastructure.",
    "fetched_at": "2025-11-07T02:16:47.497562Z"
  },
  {
    "id": "2511.03270v1",
    "title": "SCALE: Upscaled Continual Learning of Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jin-woo Lee",
      "Junhwa Choi",
      "Bongkyu Hwang",
      "Jinho Choo",
      "Bogun Kim",
      "JeongSeon Yi",
      "Joonseok Lee",
      "DongYoung Jung",
      "Jaeseon Park",
      "Kyoungwon Park",
      "Suk-hoon Jung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03270v1",
    "abstract": "We revisit continual pre-training for large language models and argue that progress now depends more on scaling the right structure than on scaling parameters alone. We introduce SCALE, a width upscaling architecture that inserts lightweight expansion into linear modules while freezing all pre-trained parameters. This preserves the residual and attention topologies and increases capacity without perturbing the base model's original functionality. SCALE is guided by two principles: Persistent Preservation, which maintains the base model's behavior via preservation-oriented initialization and freezing of the pre-trained weights, and Collaborative Adaptation, which selectively trains a subset of expansion components to acquire new knowledge with minimal interference. We instantiate these ideas as SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and SCALE-Route, an optional routing extension that performs token-level routing between preservation and adaptation heads. On a controlled synthetic biography benchmark, SCALE mitigates the severe forgetting observed with depth expansion while still acquiring new knowledge. In continual pre-training on a Korean corpus, SCALE variants achieve less forgetting on English evaluations and competitive gains on Korean benchmarks, with these variants offering the best overall stability-plasticity trade-off. Accompanying analysis clarifies when preservation provably holds and why the interplay between preservation and adaptation stabilizes optimization compared to standard continual learning setups.",
    "fetched_at": "2025-11-07T02:16:47.497514Z"
  },
  {
    "id": "2511.03271v1",
    "title": "Let the Bees Find the Weak Spots: A Path Planning Perspective on   Multi-Turn Jailbreak Attacks against LLMs",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yize Liu",
      "Yunyun Hou",
      "Aina Sui"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03271v1",
    "abstract": "Large Language Models (LLMs) have been widely deployed across various applications, yet their potential security and ethical risks have raised increasing concerns. Existing research employs red teaming evaluations, utilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs. However, these approaches often lack exploration of successful dialogue trajectories within the attack space, and they tend to overlook the considerable overhead associated with the attack process. To address these limitations, this paper first introduces a theoretical model based on dynamically weighted graph topology, abstracting the multi-turn attack process as a path planning problem. Based on this framework, we propose ABC, an enhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a collaborative search mechanism with employed, onlooker, and scout bees. This algorithm significantly improves the efficiency of optimal attack path search while substantially reducing the average number of queries required. Empirical evaluations on three open-source and two proprietary language models demonstrate the effectiveness of our approach, achieving attack success rates above 90\\% across the board, with a peak of 98\\% on GPT-3.5-Turbo, and outperforming existing baselines. Furthermore, it achieves comparable success with only 26 queries on average, significantly reducing red teaming overhead and highlighting its superior efficiency.",
    "fetched_at": "2025-11-07T02:16:47.497440Z"
  },
  {
    "id": "2511.03276v1",
    "title": "Diffusion Language Models are Super Data Learners",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jinjie Ni",
      "Qian Liu",
      "Longxu Dou",
      "Chao Du",
      "Zili Wang",
      "Hang Yan",
      "Tianyu Pang",
      "Michael Qizhe Shieh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03276v1",
    "abstract": "Under strictly controlled pre-training settings, we observe a Crossover: when unique data is limited, diffusion language models (DLMs) consistently surpass autoregressive (AR) models by training for more epochs. The crossover shifts later with more or higher-quality data, earlier with larger models, and persists across dense and sparse architectures. We attribute the gains to three compounding factors: (1) any-order modeling, (2) super-dense compute from iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation; input or parameter noise improves AR under data constraint but cannot close the gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B unique Python tokens overtakes an AR coder trained with strictly matched settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag and > 33% on MMLU using only 1B tokens, without any special tricks, just by repeating standard pre-training data. We also show that rising validation cross-entropy does not imply degraded downstream performance in this regime.",
    "fetched_at": "2025-11-07T02:16:47.497393Z"
  },
  {
    "id": "2511.03279v1",
    "title": "Multi-Objective Adaptive Rate Limiting in Microservices Using Deep   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ning Lyu",
      "Yuxi Wang",
      "Ziyu Cheng",
      "Qingyuan Zhang",
      "Feng Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03279v1",
    "abstract": "As cloud computing and microservice architectures become increasingly prevalent, API rate limiting has emerged as a critical mechanism for ensuring system stability and service quality. Traditional rate limiting algorithms, such as token bucket and sliding window, while widely adopted, struggle to adapt to dynamic traffic patterns and varying system loads. This paper proposes an adaptive rate limiting strategy based on deep reinforcement learning that dynamically balances system throughput and service latency. We design a hybrid architecture combining Deep Q-Network (DQN) and Asynchronous Advantage Actor-Critic (A3C) algorithms, modeling the rate limiting decision process as a Markov Decision Process. The system continuously monitors microservice states and learns optimal rate limiting policies through environmental interaction. Extensive experiments conducted in a Kubernetes cluster environment demonstrate that our approach achieves 23.7% throughput improvement and 31.4% P99 latency reduction compared to traditional fixed-threshold strategies under high-load scenarios. Results from a 90-day production deployment handling 500 million daily requests validate the practical effectiveness of the proposed method, with 82% reduction in service degradation incidents and 68% decrease in manual interventions.",
    "fetched_at": "2025-11-07T02:16:47.497334Z"
  },
  {
    "id": "2511.03280v1",
    "title": "A Probabilistic Approach to Pose Synchronization for Multi-Reference   Alignment with Applications to MIMO Wireless Communication Systems",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Rob Romijnders",
      "Gabriele Cesa",
      "Christos Louizos",
      "Kumar Pratik",
      "Arash Behboodi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03280v1",
    "abstract": "From molecular imaging to wireless communications, the ability to align and reconstruct signals from multiple misaligned observations is crucial for system performance. We study the problem of multi-reference alignment (MRA), which arises in many real-world problems, such as cryo-EM, computer vision, and, in particular, wireless communication systems. Using a probabilistic approach to model MRA, we find a new algorithm that uses relative poses as nuisance variables to marginalize out -- thereby removing the global symmetries of the problem and allowing for more direct solutions and improved convergence. The decentralization of this approach enables significant computational savings by avoiding the cubic scaling of centralized methods through cycle consistency. Both proposed algorithms achieve lower reconstruction error across experimental settings.",
    "fetched_at": "2025-11-07T02:16:47.497282Z"
  },
  {
    "id": "2511.03282v1",
    "title": "When Generative Artificial Intelligence meets Extended Reality: A   Systematic Review",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinyu Ning",
      "Yan Zhuo",
      "Xian Wang",
      "Chan-In Devin Sio",
      "Lik-Hang Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03282v1",
    "abstract": "With the continuous advancement of technology, the application of generative artificial intelligence (AI) in various fields is gradually demonstrating great potential, particularly when combined with Extended Reality (XR), creating unprecedented possibilities. This survey article systematically reviews the applications of generative AI in XR, covering as much relevant literature as possible from 2023 to 2025. The application areas of generative AI in XR and its key technology implementations are summarised through PRISMA screening and analysis of the final 26 articles. The survey highlights existing articles from the last three years related to how XR utilises generative AI, providing insights into current trends and research gaps. We also explore potential opportunities for future research to further empower XR through generative AI, providing guidance and information for future generative XR research.",
    "fetched_at": "2025-11-07T02:16:47.497231Z"
  },
  {
    "id": "2511.03285v1",
    "title": "Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly   Detection in Microservices",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Qingyuan Zhang",
      "Ning Lyu",
      "Le Liu",
      "Yuxi Wang",
      "Ziyu Cheng",
      "Cancan Hua"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03285v1",
    "abstract": "This study addresses the problem of anomaly detection and root cause tracing in microservice architectures and proposes a unified framework that combines graph neural networks with temporal modeling. The microservice call chain is abstracted as a directed graph, where multidimensional features of nodes and edges are used to construct a service topology representation, and graph convolution is applied to aggregate features across nodes and model dependencies, capturing complex structural relationships among services. On this basis, gated recurrent units are introduced to model the temporal evolution of call chains, and multi-layer stacking and concatenation operations are used to jointly obtain structural and temporal representations, improving the ability to identify anomaly patterns. Furthermore, anomaly scoring functions at both the node and path levels are defined to achieve unified modeling from local anomaly detection to global call chain tracing, which enables the identification of abnormal service nodes and the reconstruction of potential anomaly propagation paths. Sensitivity experiments are then designed from multiple dimensions, including hyperparameters, environmental disturbances, and data distribution, to evaluate the framework, and results show that it outperforms baseline methods in key metrics such as AUC, ACC, Recall, and F1-Score, maintaining high accuracy and stability under dynamic topologies and complex environments. This research not only provides a new technical path for anomaly detection in microservices but also lays a methodological foundation for intelligent operations in distributed systems.",
    "fetched_at": "2025-11-07T02:16:47.497177Z"
  },
  {
    "id": "2511.03295v1",
    "title": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mauro Cettolo",
      "Marco Gaido",
      "Matteo Negri",
      "Sara Papi",
      "Luisa Bentivogli"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03295v1",
    "abstract": "Automatic evaluation of speech-to-text translation (ST) systems is typically performed by comparing translation hypotheses with one or more reference translations. While effective to some extent, this approach inherits the limitation of reference-based evaluation that ignores valuable information from the source input. In machine translation (MT), recent progress has shown that neural metrics incorporating the source text achieve stronger correlation with human judgments. Extending this idea to ST, however, is not trivial because the source is audio rather than text, and reliable transcripts or alignments between source and references are often unavailable. In this work, we conduct the first systematic study of source-aware metrics for ST, with a particular focus on real-world operating conditions where source transcripts are not available. We explore two complementary strategies for generating textual proxies of the input audio, automatic speech recognition (ASR) transcripts, and back-translations of the reference translation, and introduce a novel two-step cross-lingual re-segmentation algorithm to address the alignment mismatch between synthetic sources and reference translations. Our experiments, carried out on two ST benchmarks covering 79 language pairs and six ST systems with diverse architectures and performance levels, show that ASR transcripts constitute a more reliable synthetic source than back-translations when word error rate is below 20%, while back-translations always represent a computationally cheaper but still effective alternative. Furthermore, our cross-lingual re-segmentation algorithm enables robust use of source-aware MT metrics in ST evaluation, paving the way toward more accurate and principled evaluation methodologies for speech translation.",
    "fetched_at": "2025-11-07T02:16:47.497081Z"
  },
  {
    "id": "2511.03304v1",
    "title": "Extending Fair Null-Space Projections for Continuous Attributes to   Kernel Methods",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Felix Störck",
      "Fabian Hinder",
      "Barbara Hammer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03304v1",
    "abstract": "With the on-going integration of machine learning systems into the everyday social life of millions the notion of fairness becomes an ever increasing priority in their development. Fairness notions commonly rely on protected attributes to assess potential biases. Here, the majority of literature focuses on discrete setups regarding both target and protected attributes. The literature on continuous attributes especially in conjunction with regression -- we refer to this as \\emph{continuous fairness} -- is scarce. A common strategy is iterative null-space projection which as of now has only been explored for linear models or embeddings such as obtained by a non-linear encoder. We improve on this by generalizing to kernel methods, significantly extending the scope. This yields a model and fairness-score agnostic method for kernel embeddings applicable to continuous protected attributes. We demonstrate that our novel approach in conjunction with Support Vector Regression (SVR) provides competitive or improved performance across multiple datasets in comparisons to other contemporary methods.",
    "fetched_at": "2025-11-07T02:16:47.497026Z"
  },
  {
    "id": "2511.03320v1",
    "title": "Influence of Data Dimensionality Reduction Methods on the Effectiveness   of Quantum Machine Learning Models",
    "date": "2025-11-05",
    "tags": [
      "quant-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aakash Ravindra Shinde",
      "Jukka K. Nurminen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03320v1",
    "abstract": "Data dimensionality reduction techniques are often utilized in the implementation of Quantum Machine Learning models to address two significant issues: the constraints of NISQ quantum devices, which are characterized by noise and a limited number of qubits, and the challenge of simulating a large number of qubits on classical devices. It also raises concerns over the scalability of these approaches, as dimensionality reduction methods are slow to adapt to large datasets. In this article, we analyze how data reduction methods affect different QML models. We conduct this experiment over several generated datasets, quantum machine algorithms, quantum data encoding methods, and data reduction methods. All these models were evaluated on the performance metrics like accuracy, precision, recall, and F1 score. Our findings have led us to conclude that the usage of data dimensionality reduction methods results in skewed performance metric values, which results in wrongly estimating the actual performance of quantum machine learning models. There are several factors, along with data dimensionality reduction methods, that worsen this problem, such as characteristics of the datasets, classical to quantum information embedding methods, percentage of feature reduction, classical components associated with quantum models, and structure of quantum machine learning models. We consistently observed the difference in the accuracy range of 14% to 48% amongst these models, using data reduction and not using it. Apart from this, our observations have shown that some data reduction methods tend to perform better for some specific data embedding methodologies and ansatz constructions.",
    "fetched_at": "2025-11-07T02:16:47.496982Z"
  },
  {
    "id": "2511.03328v1",
    "title": "Benchmarking the Thinking Mode of Multimodal Large Language Models in   Clinical Tasks",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jindong Hong",
      "Tianjie Chen",
      "Lingjie Luo",
      "Chuanyang Zheng",
      "Ting Xu",
      "Haibao Yu",
      "Jianing Qiu",
      "Qianzhong Chen",
      "Suning Huang",
      "Yan Xu",
      "Yong Gui",
      "Yijun He",
      "Jiankai Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03328v1",
    "abstract": "A recent advancement in Multimodal Large Language Models (MLLMs) research is the emergence of \"reasoning MLLMs\" that offer explicit control over their internal thinking processes (normally referred as the \"thinking mode\") alongside the standard \"non-thinking mode\". This capability allows these models to engage in a step-by-step process of internal deliberation before generating a final response. With the rapid transition to and adoption of these \"dual-state\" MLLMs, this work rigorously evaluated how the enhanced reasoning processes of these MLLMs impact model performance and reliability in clinical tasks. This paper evaluates the active \"thinking mode\" capabilities of two leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We assessed their performance on four visual medical tasks using VQA-RAD and ROCOv2 datasets. Our findings reveal that the improvement from activating the thinking mode remains marginal compared to the standard non-thinking mode for the majority of the tasks. Their performance on complex medical tasks such as open-ended VQA and medical image interpretation remains suboptimal, highlighting the need for domain-specific medical data and more advanced methods for medical knowledge integration.",
    "fetched_at": "2025-11-07T02:16:47.496937Z"
  },
  {
    "id": "2511.03330v1",
    "title": "Discourse-Aware Scientific Paper Recommendation via QA-Style   Summarization and Multi-Level Contrastive Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shenghua Wang",
      "Zhen Yin"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03330v1",
    "abstract": "The rapid growth of open-access (OA) publications has intensified the challenge of identifying relevant scientific papers. Due to privacy constraints and limited access to user interaction data, recent efforts have shifted toward content-based recommendation, which relies solely on textual information. However, existing models typically treat papers as unstructured text, neglecting their discourse organization and thereby limiting semantic completeness and interpretability. To address these limitations, we propose OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective, Method, Result, Conclusion) summarization, multi-level contrastive learning, and structure-aware re-ranking for scholarly recommendation. The QA-style summarization module converts raw papers into structured and discourse-consistent representations, while multi-level contrastive objectives align semantic representations across metadata, section, and document levels. The final re-ranking stage further refines retrieval precision through contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in Precision@10 and Recall@10, respectively. Additional evaluations confirm that QA-style summarization produces more coherent and factually complete representations. Overall, OMRC-MR provides a unified and interpretable content-based paradigm for scientific paper recommendation, advancing trustworthy and privacy-aware scholarly information retrieval.",
    "fetched_at": "2025-11-07T02:16:47.496857Z"
  },
  {
    "id": "2511.03344v1",
    "title": "SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Elif Arslan",
      "Jacobus G. M. van der Linden",
      "Serge Hoogendoorn",
      "Marco Rinaldi",
      "Emir Demirović"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03344v1",
    "abstract": "Sparse decision tree learning provides accurate and interpretable predictive models that are ideal for high-stakes applications by finding the single most accurate tree within a (soft) size limit. Rather than relying on a single \"best\" tree, Rashomon sets-trees with similar performance but varying structures-can be used to enhance variable importance analysis, enrich explanations, and enable users to choose simpler trees or those that satisfy stakeholder preferences (e.g., fairness) without hard-coding such criteria into the objective function. However, because finding the optimal tree is NP-hard, enumerating the Rashomon set is inherently challenging. Therefore, we introduce SORTD, a novel framework that improves scalability and enumerates trees in the Rashomon set in order of the objective value, thus offering anytime behavior. Our experiments show that SORTD reduces runtime by up to two orders of magnitude compared with the state of the art. Moreover, SORTD can compute Rashomon sets for any separable and totally ordered objective and supports post-evaluating the set using other separable (and partially ordered) objectives. Together, these advances make exploring Rashomon sets more practical in real-world applications.",
    "fetched_at": "2025-11-07T02:16:47.496813Z"
  },
  {
    "id": "2511.03354v1",
    "title": "Generative Artificial Intelligence in Bioinformatics: A Systematic   Review of Models, Applications, and Methodological Advances",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Riasad Alvi",
      "Sayeem Been Zaman",
      "Wasimul Karim",
      "Arefin Ittesafun Abian",
      "Mohaimenul Azam Khan Raiaan",
      "Saddam Mukta",
      "Md Rafi Ur Rashid",
      "Md Rafiqul Islam",
      "Yakub Sebastian",
      "Sami Azam"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.03354v1",
    "abstract": "Generative artificial intelligence (GenAI) has become a transformative approach in bioinformatics that often enables advancements in genomics, proteomics, transcriptomics, structural biology, and drug discovery. To systematically identify and evaluate these growing developments, this review proposed six research questions (RQs), according to the preferred reporting items for systematic reviews and meta-analysis methods. The objective is to evaluate impactful GenAI strategies in methodological advancement, predictive performance, and specialization, and to identify promising approaches for advanced modeling, data-intensive discovery, and integrative biological analysis. RQ1 highlights diverse applications across multiple bioinformatics subfields (sequence analysis, molecular design, and integrative data modeling), which demonstrate superior performance over traditional methods through pattern recognition and output generation. RQ2 reveals that adapted specialized model architectures outperformed general-purpose models, an advantage attributed to targeted pretraining and context-aware strategies. RQ3 identifies significant benefits in the bioinformatics domains, focusing on molecular analysis and data integration, which improves accuracy and reduces errors in complex analysis. RQ4 indicates improvements in structural modeling, functional prediction, and synthetic data generation, validated by established benchmarks. RQ5 suggests the main constraints, such as the lack of scalability and biases in data that impact generalizability, and proposes future directions focused on robust evaluation and biologically grounded modeling. RQ6 examines that molecular datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly support the training and generalization of GenAI models.",
    "fetched_at": "2025-11-07T02:16:47.496764Z"
  },
  {
    "id": "2511.03361v1",
    "title": "Open Source State-Of-the-Art Solution for Romanian Speech Recognition",
    "date": "2025-11-05",
    "tags": [
      "eess.AS",
      "AS",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gabriel Pirlogeanu",
      "Alexandru-Lucian Georgescu",
      "Horia Cucu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03361v1",
    "abstract": "In this work, we present a new state-of-the-art Romanian Automatic Speech Recognition (ASR) system based on NVIDIA's FastConformer architecture--explored here for the first time in the context of Romanian. We train our model on a large corpus of, mostly, weakly supervised transcriptions, totaling over 2,600 hours of speech. Leveraging a hybrid decoder with both Connectionist Temporal Classification (CTC) and Token-Duration Transducer (TDT) branches, we evaluate a range of decoding strategies including greedy, ALSD, and CTC beam search with a 6-gram token-level language model. Our system achieves state-of-the-art performance across all Romanian evaluation benchmarks, including read, spontaneous, and domain-specific speech, with up to 27% relative WER reduction compared to previous best-performing systems. In addition to improved transcription accuracy, our approach demonstrates practical decoding efficiency, making it suitable for both research and deployment in low-latency ASR applications.",
    "fetched_at": "2025-11-07T02:16:47.496685Z"
  },
  {
    "id": "2511.03367v1",
    "title": "Decoupling Augmentation Bias in Prompt Learning for Vision-Language   Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gahyeon Kim",
      "Sohee Kim",
      "Seokju Lee"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03367v1",
    "abstract": "Recent advances in large-scale vision and language models have led to significant progress in zero-shot learning tasks. Methods such as CoOp and CoCoOp have shown that replacing handcrafted prompts with learnable vectors, known as prompt learning, can result in improved performance. However, these models often struggle to generalize to entirely unseen categories. While traditional zero-shot learning techniques benefit from various data augmentation strategies, prompt learning has primarily focused on text-based modifications, leaving the potential of image-based augmentation largely unexplored. In this work, we explore how image-level augmentations, particularly those that introduce attribute-specific variations, can support and enhance prompt learning. Our analysis examines the interaction between these augmentations and soft prompt frameworks, revealing their potential to improve generalization. We also identify a limitation in existing methods, such as CoCoOp, which do not provide explicit guidance for learning prompts that focus on semantically meaningful visual features. To address this, we propose Adding Attributes to Prompt Learning, AAPL, a novel method that introduces adversarial token embeddings to decouple superficial visual variations introduced by augmentation from class-relevant semantic representations. This decoupling enables the learned prompts to concentrate on visually discriminative features that align with the target categories. We conduct comprehensive experiments on eleven benchmark datasets, and AAPL consistently outperforms existing methods across few-shot, zero-shot, cross-dataset, and domain generalization settings. Our source code is publicly available at: https://github.com/Gahyeonkim09/AAPL",
    "fetched_at": "2025-11-07T02:16:47.496576Z"
  },
  {
    "id": "2511.03368v1",
    "title": "TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled   Markets",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hongrun Ren",
      "Yun Xiong",
      "Lei You",
      "Yingying Wang",
      "Haixu Xiong",
      "Yangyong Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03368v1",
    "abstract": "The rise of the machine learning (ML) model economy has intertwined markets for training datasets and pre-trained models. However, most pricing approaches still separate data and model transactions or rely on broker-centric pipelines that favor one side. Recent studies of data markets with externalities capture buyer interactions but do not yield a simultaneous and symmetric mechanism across data sellers, model producers, and model buyers. We propose a unified data-model coupled market that treats dataset and model trading as a single system. A supply-side mapping transforms dataset payments into buyer-visible model quotations, while a demand-side mapping propagates buyer prices back to datasets through Shapley-based allocation. Together, they form a closed loop that links four interactions: supply-demand propagation in both directions and mutual coupling among buyers and among sellers. We prove that the joint operator is a standard interference function (SIF), guaranteeing existence, uniqueness, and global convergence of equilibrium prices. Experiments demonstrate efficient convergence and improved fairness compared with broker-centric and one-sided baselines. The code is available on https://github.com/HongrunRen1109/Triple-Win-Pricing.",
    "fetched_at": "2025-11-07T02:16:47.496525Z"
  },
  {
    "id": "2511.03369v1",
    "title": "Silenced Biases: The Dark Side LLMs Learned to Refuse",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Rom Himelstein",
      "Amit LeVi",
      "Brit Youngmann",
      "Yaniv Nemcovsky",
      "Avi Mendelson"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03369v1",
    "abstract": "Safety-aligned large language models (LLMs) are becoming increasingly widespread, especially in sensitive applications where fairness is essential and biased outputs can cause significant harm. However, evaluating the fairness of models is a complex challenge, and approaches that do so typically utilize standard question-answer (QA) styled schemes. Such methods often overlook deeper issues by interpreting the model's refusal responses as positive fairness measurements, which creates a false sense of fairness. In this work, we introduce the concept of silenced biases, which are unfair preferences encoded within models' latent space and are effectively concealed by safety-alignment. Previous approaches that considered similar indirect biases often relied on prompt manipulation or handcrafted implicit queries, which present limited scalability and risk contaminating the evaluation process with additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to uncover these biases by employing activation steering to reduce model refusals during QA. SBB supports easy expansion to new demographic groups and subjects, presenting a fairness evaluation framework that encourages the future development of fair models and tools beyond the masking effects of alignment training. We demonstrate our approach over multiple LLMs, where our findings expose an alarming distinction between models' direct responses and their underlying fairness issues.",
    "fetched_at": "2025-11-07T02:16:47.496469Z"
  },
  {
    "id": "2511.03372v1",
    "title": "LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced   Logical Reasoning",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7; I.2.6; F.4.1",
      "1"
    ],
    "authors": [
      "Shenghao Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03372v1",
    "abstract": "For complex logical data augmentation, heavy reliance on human annotation is costly, whereas direct generation with large language models yields uninterpretable and logically homogeneous examples. To address this, we present LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to propositional expressions, a compact rule library is compiled, and a bounded state-space search systematically discovers valid formulas that are then verbalized back into natural-language questions, ensuring both diversity and logical rigor under propositional logic. Experiments on ReClor and LogiQA show significant improvements in the logical-reasoning accuracy of pretrained models, confirming the effectiveness of LFC-DA for LLM-guided logical data augmentation.",
    "fetched_at": "2025-11-07T02:16:47.496367Z"
  },
  {
    "id": "2511.03376v1",
    "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in   Brain Gliomas",
    "date": "2025-11-05",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Syed Muqeem Mahmood",
      "Hassan Mohy-ud-Din"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03376v1",
    "abstract": "We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM.",
    "fetched_at": "2025-11-07T02:16:47.496328Z"
  },
  {
    "id": "2511.03378v1",
    "title": "Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research   to Journalism and Policy-making",
    "date": "2025-11-05",
    "tags": [
      "cs.SI",
      "SI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yangliu Fan",
      "Kilian Buehling",
      "Volker Stocker"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03378v1",
    "abstract": "Despite the importance of social science knowledge for various stakeholders, measuring its diffusion into different domains remains a challenge. This study uses a novel text-based approach to measure the idea-level diffusion of social science knowledge from the research domain to the journalism and policy-making domains. By doing so, we expand the detection of knowledge diffusion beyond the measurements of direct references. Our study focuses on media effects theories as key research ideas in the field of communication science. Using 72,703 documents (2000-2019) from three domains (i.e., research, journalism, and policy-making) that mention these ideas, we count the mentions of these ideas in each domain, estimate their domain-specific contexts, and track and compare differences across domains and over time. Overall, we find that diffusion patterns and dynamics vary considerably between ideas, with some ideas diffusing between other domains, while others do not. Based on the embedding regression approach, we compare contextualized meanings across domains and find that the distances between research and policy are typically larger than between research and journalism. We also find that ideas largely shift roles across domains - from being the theories themselves in research to sense-making in news to applied, administrative use in policy. Over time, we observe semantic convergence mainly for ideas that are practically oriented. Our results characterize the cross-domain diffusion patterns and dynamics of social science knowledge at the idea level, and we discuss the implications for measuring knowledge diffusion beyond citations.",
    "fetched_at": "2025-11-07T02:16:47.496286Z"
  },
  {
    "id": "2511.03383v1",
    "title": "Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for   Optimal Machine Translation Performance",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Saumitra Yadav",
      "Manish Shrivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03383v1",
    "abstract": "Existing Machine Translation (MT) research often suggests a single, fixed set of hyperparameters for word segmentation models, symmetric Byte Pair Encoding (BPE), which applies the same number of merge operations (NMO) to train tokenizers for both source and target languages. However, we demonstrate that this uniform approach doesn't guarantee optimal MT performance across different language pairs and data sizes. This work investigates BPE segmentation recipes across various data volumes and language pairs to evaluate MT system performance. We find that utilizing asymmetric BPE, where the source and target languages have different NMOs, significantly improves results over the symmetric approach, especially in low-resource settings (50K, 100K, and 500K sentence pairs). Specifically, asymmetric BPE yield statistically significant ($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in low-resource setups. We validated this trend across six additional language pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut), observing statistically significant improvement in 10 out of 12 systems compared to symmetric BPE. Our findings indicate a high NMO for the source (4K to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results, particularly benefiting low-resource MT.",
    "fetched_at": "2025-11-07T02:16:47.496237Z"
  },
  {
    "id": "2511.03405v1",
    "title": "Adaptable Hindsight Experience Replay for Search-Based Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "I.2.8; I.2.6",
      "6"
    ],
    "authors": [
      "Alexandros Vazaios",
      "Jannis Brugger",
      "Cedric Derstroff",
      "Kristian Kersting",
      "Mira Mezini"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03405v1",
    "abstract": "AlphaZero-like Monte Carlo Tree Search systems, originally introduced for two-player games, dynamically balance exploration and exploitation using neural network guidance. This combination makes them also suitable for classical search problems. However, the original method of training the network with simulation results is limited in sparse reward settings, especially in the early stages, where the network cannot yet give guidance. Hindsight Experience Replay (HER) addresses this issue by relabeling unsuccessful trajectories from the search tree as supervised learning signals. We introduce Adaptable HER (\\ours{}), a flexible framework that integrates HER with AlphaZero, allowing easy adjustments to HER properties such as relabeled goals, policy targets, and trajectory selection. Our experiments, including equation discovery, show that the possibility of modifying HER is beneficial and surpasses the performance of pure supervised or reinforcement learning.",
    "fetched_at": "2025-11-07T02:16:47.496194Z"
  },
  {
    "id": "2511.03407v1",
    "title": "Overcoming the Generalization Limits of SLM Finetuning for Shape-Based   Extraction of Datatype and Object Properties",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7; I.2.4",
      "4"
    ],
    "authors": [
      "Célian Ringwald",
      "Fabien Gandon",
      "Catherine Faron",
      "Franck Michel",
      "Hanna Abi Akl"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03407v1",
    "abstract": "Small language models (SLMs) have shown promises for relation extraction (RE) when extracting RDF triples guided by SHACL shapes focused on common datatype properties. This paper investigates how SLMs handle both datatype and object properties for a complete RDF graph extraction. We show that the key bottleneck is related to long-tail distribution of rare properties. To solve this issue, we evaluate several strategies: stratified sampling, weighted loss, dataset scaling, and template-based synthetic data augmentation. We show that the best strategy to perform equally well over unbalanced target properties is to build a training set where the number of occurrences of each property exceeds a given threshold. To enable reproducibility, we publicly released our datasets, experimental results and code. Our findings offer practical guidance for training shape-aware SLMs and highlight promising directions for future work in semantic RE.",
    "fetched_at": "2025-11-07T02:16:47.496137Z"
  },
  {
    "id": "2511.03408v1",
    "title": "Efficient Reasoning via Thought-Training and Thought-Free Inference",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Canhui Wu",
      "Qiong Cao",
      "Chao Xue",
      "Wei Xi",
      "Xiaodong He"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03408v1",
    "abstract": "Recent advances in large language models (LLMs) have leveraged explicit Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most existing methods primarily compress verbose reasoning outputs. These Long-to-Short transformations aim to improve efficiency, but still rely on explicit reasoning during inference. In this work, we introduce \\textbf{3TF} (\\textbf{T}hought-\\textbf{T}raining and \\textbf{T}hought-\\textbf{F}ree inference), a framework for efficient reasoning that takes a Short-to-Long perspective. We first train a hybrid model that can operate in both reasoning and non-reasoning modes, and then further train it on CoT-annotated data to internalize structured reasoning, while enforcing concise, thought-free outputs at inference time using the no-reasoning mode. Unlike compression-based approaches, 3TF improves the reasoning quality of non-reasoning outputs, enabling models to perform rich internal reasoning implicitly while keeping external outputs short. Empirically, 3TF-trained models obtain large improvements on reasoning benchmarks under thought-free inference, demonstrating that high quality reasoning can be learned and executed implicitly without explicit step-by-step generation.",
    "fetched_at": "2025-11-07T02:16:47.496074Z"
  },
  {
    "id": "2511.03410v1",
    "title": "Knowledge-Augmented Question Error Correction for Chinese Question   Answer System with QuestionRAG",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Longpeng Qiu",
      "Ting Li",
      "Shuai Mao",
      "Nan Yang",
      "Xiaohui Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03410v1",
    "abstract": "Input errors in question-answering (QA) systems often lead to incorrect responses. Large language models (LLMs) struggle with this task, frequently failing to interpret user intent (misinterpretation) or unnecessarily altering the original question's structure (over-correction). We propose QuestionRAG, a framework that tackles these problems. To address misinterpretation, it enriches the input with external knowledge (e.g., search results, related entities). To prevent over-correction, it uses reinforcement learning (RL) to align the model's objective with precise correction, not just paraphrasing. Our results demonstrate that knowledge augmentation is critical for understanding faulty questions. Furthermore, RL-based alignment proves significantly more effective than traditional supervised fine-tuning (SFT), boosting the model's ability to follow instructions and generalize. By integrating these two strategies, QuestionRAG unlocks the full potential of LLMs for the question correction task.",
    "fetched_at": "2025-11-07T02:16:47.496021Z"
  },
  {
    "id": "2511.03421v1",
    "title": "Light over Heavy: Automated Performance Requirements Quantification with   Linguistic Inducement",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shihai Wang",
      "Tao Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03421v1",
    "abstract": "Elicited performance requirements need to be quantified for compliance in different engineering tasks, e.g., configuration tuning and performance testing. Much existing work has relied on manual quantification, which is expensive and error-prone due to the imprecision. In this paper, we present LQPR, a highly efficient automatic approach for performance requirements quantification.LQPR relies on a new theoretical framework that converts quantification as a classification problem. Despite the prevalent applications of Large Language Models (LLMs) for requirement analytics, LQPR takes a different perspective to address the classification: we observed that performance requirements can exhibit strong patterns and are often short/concise, therefore we design a lightweight linguistically induced matching mechanism. We compare LQPR against nine state-of-the-art learning-based approaches over diverse datasets, demonstrating that it is ranked as the sole best for 75% or more cases with two orders less cost. Our work proves that, at least for performance requirement quantification, specialized methods can be more suitable than the general LLM-driven approaches.",
    "fetched_at": "2025-11-07T02:16:47.495970Z"
  },
  {
    "id": "2511.03425v1",
    "title": "SyMuPe: Affective and Controllable Symbolic Music Performance",
    "date": "2025-11-05",
    "tags": [
      "cs.SD",
      "SD",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Ilya Borovik",
      "Dmitrii Gavrilev",
      "Vladimir Viro"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03425v1",
    "abstract": "Emotions are fundamental to the creation and perception of music performances. However, achieving human-like expression and emotion through machine learning models for performance rendering remains a challenging task. In this work, we present SyMuPe, a novel framework for developing and training affective and controllable symbolic piano performance models. Our flagship model, PianoFlow, uses conditional flow matching trained to solve diverse multi-mask performance inpainting tasks. By design, it supports both unconditional generation and infilling of music performance features. For training, we use a curated, cleaned dataset of 2,968 hours of aligned musical scores and expressive MIDI performances. For text and emotion control, we integrate a piano performance emotion classifier and tune PianoFlow with the emotion-weighted Flan-T5 text embeddings provided as conditional inputs. Objective and subjective evaluations against transformer-based baselines and existing models show that PianoFlow not only outperforms other approaches, but also achieves performance quality comparable to that of human-recorded and transcribed MIDI samples. For emotion control, we present and analyze samples generated under different text conditioning scenarios. The developed model can be integrated into interactive applications, contributing to the creation of more accessible and engaging music performance systems.",
    "fetched_at": "2025-11-07T02:16:47.495928Z"
  },
  {
    "id": "2511.03441v2",
    "title": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the   Biomedical Field",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Doria Bonzi",
      "Alexandre Guiggi",
      "Frédéric Béchet",
      "Carlos Ramisch",
      "Benoit Favre"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03441v2",
    "abstract": "Critical appraisal of scientific literature is an essential skill in the biomedical field. While large language models (LLMs) can offer promising support in this task, their reliability remains limited, particularly for critical reasoning in specialized domains. We introduce CareMedEval, an original dataset designed to evaluate LLMs on biomedical critical appraisal and reasoning tasks. Derived from authentic exams taken by French medical students, the dataset contains 534 questions based on 37 scientific articles. Unlike existing benchmarks, CareMedEval explicitly evaluates critical reading and reasoning grounded in scientific papers. Benchmarking state-of-the-art generalist and biomedical-specialized LLMs under various context conditions reveals the difficulty of the task: open and commercial models fail to exceed an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens considerably improves the results. Yet, models remain challenged especially on questions about study limitations and statistical analysis. CareMedEval provides a challenging benchmark for grounded reasoning, exposing current LLM limitations and paving the way for future development of automated support for critical appraisal.",
    "fetched_at": "2025-11-07T02:16:47.495830Z"
  },
  {
    "id": "2511.03443v1",
    "title": "A Support-Set Algorithm for Optimization Problems with Nonnegative and   Orthogonal Constraints",
    "date": "2025-11-05",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Lei Wang",
      "Xin Liu",
      "Xiaojun Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03443v1",
    "abstract": "In this paper, we investigate optimization problems with nonnegative and orthogonal constraints, where any feasible matrix of size $n \\times p$ exhibits a sparsity pattern such that each row accommodates at most one nonzero entry. Our analysis demonstrates that, by fixing the support set, the global solution of the minimization subproblem for the proximal linearization of the objective function can be computed in closed form with at most $n$ nonzero entries. Exploiting this structural property offers a powerful avenue for dramatically enhancing computational efficiency. Guided by this insight, we propose a support-set algorithm preserving strictly the feasibility of iterates. A central ingredient is a strategically devised update scheme for support sets that adjusts the placement of nonzero entries. We establish the global convergence of the support-set algorithm to a first-order stationary point, and show that its iteration complexity required to reach an $\\epsilon$-approximate first-order stationary point is $O (\\epsilon^{-2})$. Numerical results are strongly in favor of our algorithm in real-world applications, including nonnegative PCA, clustering, and community detection.",
    "fetched_at": "2025-11-07T02:16:47.495777Z"
  },
  {
    "id": "2511.03464v1",
    "title": "POEMS: Product of Experts for Interpretable Multi-omic Integration using   Sparse Decoding",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mihriban Kocak Balik",
      "Pekka Marttinen",
      "Negar Safinianaini"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03464v1",
    "abstract": "Integrating different molecular layers, i.e., multiomics data, is crucial for unraveling the complexity of diseases; yet, most deep generative models either prioritize predictive performance at the expense of interpretability or enforce interpretability by linearizing the decoder, thereby weakening the network's nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS: Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding, an unsupervised probabilistic framework that preserves predictive performance while providing interpretability. POEMS provides interpretability without linearizing any part of the network by 1) mapping features to latent factors using sparse connections, which directly translates to biomarker discovery, 2) allowing for cross-omic associations through a shared latent space using product of experts model, and 3) reporting contributions of each omic by a gating network that adaptively computes their influence in the representation learning. Additionally, we present an efficient sparse decoder. In a cancer subtyping case study, POEMS achieves competitive clustering and classification performance while offering our novel set of interpretations, demonstrating that biomarker based insight and predictive accuracy can coexist in multiomics representation learning.",
    "fetched_at": "2025-11-07T02:16:47.495731Z"
  },
  {
    "id": "2511.03466v1",
    "title": "Kastor: Fine-tuned Small Language Models for Shape-based Active Relation   Extraction",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.4; I.2.7",
      "7"
    ],
    "authors": [
      "Ringwald Celian",
      "Gandon Fabien",
      "Faron Catherine",
      "Michel Franck",
      "Abi Akl Hanna"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03466v1",
    "abstract": "RDF pattern-based extraction is a compelling approach for fine-tuning small language models (SLMs) by focusing a relation extraction task on a specified SHACL shape. This technique enables the development of efficient models trained on limited text and RDF data. In this article, we introduce Kastor, a framework that advances this approach to meet the demands for completing and refining knowledge bases in specialized domains. Kastor reformulates the traditional validation task, shifting from single SHACL shape validation to evaluating all possible combinations of properties derived from the shape. By selecting the optimal combination for each training example, the framework significantly enhances model generalization and performance. Additionally, Kastor employs an iterative learning process to refine noisy knowledge bases, enabling the creation of robust models capable of uncovering new, relevant facts",
    "fetched_at": "2025-11-07T02:16:47.495686Z"
  },
  {
    "id": "2511.03471v1",
    "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Ming Gu",
      "Ziwei Wang",
      "Sicen Lai",
      "Zirui Gao",
      "Sheng Zhou",
      "Jiajun Bu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03471v1",
    "abstract": "Ensuring web accessibility is crucial for advancing social welfare, justice, and equality in digital spaces, yet the vast majority of website user interfaces remain non-compliant, due in part to the resource-intensive and unscalable nature of current auditing practices. While WCAG-EM offers a structured methodology for site-wise conformance evaluation, it involves great human efforts and lacks practical support for execution at scale. In this work, we present an auditing framework, AAA, which operationalizes WCAG-EM through a human-AI partnership model. AAA is anchored by two key innovations: GRASP, a graph-based multimodal sampling method that ensures representative page coverage via learned embeddings of visual, textual, and relational cues; and MaC, a multimodal large language model-based copilot that supports auditors through cross-modal reasoning and intelligent assistance in high-effort tasks. Together, these components enable scalable, end-to-end web accessibility auditing, empowering human auditors with AI-enhanced assistance for real-world impact. We further contribute four novel datasets designed for benchmarking core stages of the audit pipeline. Extensive experiments demonstrate the effectiveness of our methods, providing insights that small-scale language models can serve as capable experts when fine-tuned.",
    "fetched_at": "2025-11-07T02:16:47.495638Z"
  },
  {
    "id": "2511.03473v1",
    "title": "Reinforcement Learning Using known Invariances",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alexandru Cioba",
      "Aya Kayal",
      "Laura Toni",
      "Sattar Vakili",
      "Alberto Bernacchia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03473v1",
    "abstract": "In many real-world reinforcement learning (RL) problems, the environment exhibits inherent symmetries that can be exploited to improve learning efficiency. This paper develops a theoretical and algorithmic framework for incorporating known group symmetries into kernel-based RL. We propose a symmetry-aware variant of optimistic least-squares value iteration (LSVI), which leverages invariant kernels to encode invariance in both rewards and transition dynamics. Our analysis establishes new bounds on the maximum information gain and covering numbers for invariant RKHSs, explicitly quantifying the sample efficiency gains from symmetry. Empirical results on a customized Frozen Lake environment and a 2D placement design problem confirm the theoretical improvements, demonstrating that symmetry-aware RL achieves significantly better performance than their standard kernel counterparts. These findings highlight the value of structural priors in designing more sample-efficient reinforcement learning algorithms.",
    "fetched_at": "2025-11-07T02:16:47.495583Z"
  },
  {
    "id": "2511.03481v1",
    "title": "Development of the Bioinspired Tendon-Driven DexHand 021 with   Proprioceptive Compliance Control",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jianbo Yuan",
      "Haohua Zhu",
      "Jing Dai",
      "Sheng Yi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03481v1",
    "abstract": "The human hand plays a vital role in daily life and industrial applications, yet replicating its multifunctional capabilities-including motion, sensing, and coordinated manipulation-with robotic systems remains a formidable challenge. Developing a dexterous robotic hand requires balancing human-like agility with engineering constraints such as complexity, size-to-weight ratio, durability, and force-sensing performance. This letter presents Dex-Hand 021, a high-performance, cable-driven five-finger robotic hand with 12 active and 7 passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight 1 kg design. We propose a proprioceptive force-sensing-based admittance control method to enhance manipulation. Experimental results demonstrate its superior performance: a single-finger load capacity exceeding 10 N, fingertip repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared to PID control, joint torques in multi-object grasping are reduced by 31.19%, significantly improves force-sensing capability while preventing overload during collisions. The hand excels in both power and precision grasps, successfully executing 33 GRASP taxonomy motions and complex manipulation tasks. This work advances the design of lightweight, industrial-grade dexterous hands and enhances proprioceptive control, contributing to robotic manipulation and intelligent manufacturing.",
    "fetched_at": "2025-11-07T02:16:47.495483Z"
  },
  {
    "id": "2511.03482v1",
    "title": "System Identification of a Moored ASV with Recessed Moon Pool via   Deterministic and Bayesian Hankel-DMDc",
    "date": "2025-11-05",
    "tags": [
      "eess.SY",
      "SY",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Giorgio Palma",
      "Ivan Santic",
      "Andrea Serani",
      "Lorenzo Minno",
      "Matteo Diez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03482v1",
    "abstract": "This study addresses the system identification of a small autonomous surface vehicle (ASV) under moored conditions using Hankel dynamic mode decomposition with control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were carried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under both irregular and regular head-sea wave conditions. The ASV under investigation features a recessed moon pool, which induces nonlinear responses due to sloshing, thereby increasing the modelling challenge. Data-driven reduced-order models were built from measurements of vessel motions and mooring loads. The HDMDc framework provided accurate deterministic predictions of vessel dynamics, while the Bayesian formulation enabled uncertainty-aware characterization of the model response by accounting for variability in hyperparameter selection. Validation against experimental data demonstrated that both HDMDc and BHDMDc can predict the vessel's response to unseen regular and irregular wave excitations. In conclusion, the study shows that HDMDc-based ROMs are a viable data-driven alternative for system identification, demonstrating for the first time their generalization capability for a sea condition different from the training set, achieving high accuracy in reproducing vessel dynamics.",
    "fetched_at": "2025-11-07T02:16:47.495434Z"
  },
  {
    "id": "2511.03488v1",
    "title": "NAP: Attention-Based Late Fusion for Automatic Sleep Staging",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alvise Dei Rossi",
      "Julia van der Meer",
      "Markus H. Schmidt",
      "Claudio L. A. Bassetti",
      "Luigi Fiorillo",
      "Francesca Faraci"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03488v1",
    "abstract": "Polysomnography signals are highly heterogeneous, varying in modality composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal, occipital EEG), and acquisition protocols across datasets and clinical sites. Most existing models that process polysomnography data rely on a fixed subset of modalities or channels and therefore neglect to fully exploit its inherently multimodal nature. We address this limitation by introducing NAP (Neural Aggregator of Predictions), an attention-based model which learns to combine multiple prediction streams using a tri-axial attention mechanism that captures temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to different input dimensions. By aggregating outputs from frozen, pretrained single-channel models, NAP consistently outperforms individual predictors and simple ensembles, achieving state-of-the-art zero-shot generalization across multiple datasets. While demonstrated in the context of automated sleep staging from polysomnography, the proposed approach could be extended to other multimodal physiological applications.",
    "fetched_at": "2025-11-07T02:16:47.495380Z"
  },
  {
    "id": "2511.03492v1",
    "title": "Why Less is More (Sometimes): A Theory of Data Curation",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Elvis Dohmatob",
      "Mohammad Pezeshki",
      "Reyhane Askari-Hemmat"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03492v1",
    "abstract": "This paper introduces a theoretical framework to resolve a central paradox in modern machine learning: When is it better to use less data? This question has become critical as classical scaling laws suggesting ``more is more'' (Sun et al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et al., 2025; Muenighoff et al., 2025), which achieve superior performance with small, aggressively curated datasets. Here, we study data curation strategies where an imperfect oracle selects the training examples according to their difficulty and correctness. Our results provide exact scaling law curves for test error under both label-agnostic and label-aware curation rules, revealing when and why keeping only a subset of data can improve generalization. In contrast to classical scaling laws, we show that under certain conditions, small curated datasets can outperform full datasets, and we provide analytical conditions for this by deriving precise phase transition curves tied to data size and quality. We validate these theoretical claims with empirical results on ImageNet, confirming our predictions about when curation improves accuracy and can even mitigate model collapse. Furthermore, our framework provides a principled explanation for the contradictory curation strategies recently observed in LLM mathematical reasoning.",
    "fetched_at": "2025-11-07T02:16:47.495329Z"
  },
  {
    "id": "2511.03498v1",
    "title": "BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English   Translation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kazi Reyazul Hasan",
      "Mubasshira Musarrat",
      "A. B. M. Alim Al Islam",
      "Muhammad Abdullah Adnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03498v1",
    "abstract": "Large language models work well for technical problem solving in English but perform poorly when the same questions are asked in Bangla. A simple solution would be to translate Bangla questions into English first and then use these models. However, existing Bangla-English translation systems struggle with technical terms. They often mistranslate specialized vocabulary, which changes the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM fields including computer science, mathematics, physics, chemistry, and biology. We generated over 12,000 translations using language models and then used human evaluators to select the highest quality pairs that preserve technical terminology correctly. We train a T5-based translation model on BanglaSTEM and test it on two tasks: generating code and solving math problems. Our results show significant improvements in translation accuracy for technical content, making it easier for Bangla speakers to use English-focused language models effectively. Both the BanglaSTEM dataset and the trained translation model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.",
    "fetched_at": "2025-11-07T02:16:47.495224Z"
  },
  {
    "id": "2511.03499v2",
    "title": "A Theoretical Framework for Environmental Similarity and Vessel Mobility   as Coupled Predictors of Marine Invasive Species Pathways",
    "date": "2025-11-05",
    "tags": [
      "cs.CE",
      "CE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gabriel Spadon",
      "Vaishnav Vaidheeswaran",
      "Claudio DiBacco"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03499v2",
    "abstract": "Marine invasive species spread through global shipping and generate substantial ecological and economic impacts. Traditional risk assessments require detailed records of ballast water and traffic patterns, which are often incomplete, limiting global coverage. This work advances a theoretical framework that quantifies invasion risk by combining environmental similarity across ports with observed and forecasted maritime mobility. Climate-based feature representations characterize each port's marine conditions, while mobility networks derived from Automatic Identification System data capture vessel flows and potential transfer pathways. Clustering and metric learning reveal climate analogues and enable the estimation of species survival likelihood along shipping routes. A temporal link prediction model captures how traffic patterns may change under shifting environmental conditions. The resulting fusion of environmental similarity and predicted mobility provides exposure estimates at the port and voyage levels, supporting targeted monitoring, routing adjustments, and management interventions.",
    "fetched_at": "2025-11-07T02:16:47.495176Z"
  },
  {
    "id": "2511.03508v1",
    "title": "One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction   Following with a Benchmark Evolving Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Qi Jia",
      "Kaiwei Zhang",
      "Xiujie Song",
      "Ye Shen",
      "Xiangyang Zhu",
      "Guangtao Zhai"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03508v1",
    "abstract": "Understanding how well large language models can follow users' instructions throughout a dialogue spanning multiple topics is of great importance for data-intensive conversational applications. Existing benchmarks are often limited to a fixed number of turns, making them susceptible to saturation and failing to account for the user's interactive experience. In this work, we propose an extensible framework for assessing multi-turn instruction-following ability. At its core, our framework decouples linguistic surface forms from user intent simulation through a three-layer mechanism that tracks constraints, instructions, and topics. This framework mimics User-LLM interaction by enabling the dynamic construction of benchmarks with state changes and tracebacks, terminating a conversation only when the model exhausts a simulated user's patience. We define a suite of metrics capturing the quality of the interaction process. Using this framework, we construct EvolIF, an evolving instruction-following benchmark incorporating nine distinct constraint types. Our results indicate that GPT-5 exhibits superior instruction-following performance. It sustains an average of 18.54 conversational turns and demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant margin of 11.41%, while other models lag far behind. All of the data and code will be made publicly available online.",
    "fetched_at": "2025-11-07T02:16:47.495041Z"
  },
  {
    "id": "2511.03527v1",
    "title": "Learning Without Critics? Revisiting GRPO in Classical Reinforcement   Learning Environments",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bryan L. M. de Oliveira",
      "Felipe V. Frujeri",
      "Marcos P. C. M. Queiroz",
      "Luana G. B. Martins",
      "Telma W. de L. Soares",
      "Luckeciano C. Melo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03527v1",
    "abstract": "Group Relative Policy Optimization (GRPO) has emerged as a scalable alternative to Proximal Policy Optimization (PPO) by eliminating the learned critic and instead estimating advantages through group-relative comparisons of trajectories. This simplification raises fundamental questions about the necessity of learned baselines in policy-gradient methods. We present the first systematic study of GRPO in classical single-task reinforcement learning environments, spanning discrete and continuous control tasks. Through controlled ablations isolating baselines, discounting, and group sampling, we reveal three key findings: (1) learned critics remain essential for long-horizon tasks: all critic-free baselines underperform PPO except in short-horizon environments like CartPole where episodic returns can be effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except in HalfCheetah, where lack of early termination favors moderate discounting (gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting limitations in batch-based grouping strategies that mix unrelated episodes. These results reveal both the limitations of critic-free methods in classical control and the specific conditions where they remain viable alternatives to learned value functions.",
    "fetched_at": "2025-11-07T02:16:47.494986Z"
  },
  {
    "id": "2511.03529v1",
    "title": "Byzantine-Robust Federated Learning with Learnable Aggregation Weights",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Javad Parsa",
      "Amir Hossein Daghestani",
      "André M. H. Teixeira",
      "Mikael Johansson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03529v1",
    "abstract": "Federated Learning (FL) enables clients to collaboratively train a global model without sharing their private data. However, the presence of malicious (Byzantine) clients poses significant challenges to the robustness of FL, particularly when data distributions across clients are heterogeneous. In this paper, we propose a novel Byzantine-robust FL optimization problem that incorporates adaptive weighting into the aggregation process. Unlike conventional approaches, our formulation treats aggregation weights as learnable parameters, jointly optimizing them alongside the global model parameters. To solve this optimization problem, we develop an alternating minimization algorithm with strong convergence guarantees under adversarial attack. We analyze the Byzantine resilience of the proposed objective. We evaluate the performance of our algorithm against state-of-the-art Byzantine-robust FL approaches across various datasets and attack scenarios. Experimental results demonstrate that our method consistently outperforms existing approaches, particularly in settings with highly heterogeneous data and a large proportion of malicious clients.",
    "fetched_at": "2025-11-07T02:16:47.494931Z"
  },
  {
    "id": "2511.03531v1",
    "title": "Efficient Neural Networks with Discrete Cosine Transform Activations",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Marc Martinez-Gost",
      "Sara Pepe",
      "Ana Pérez-Neira",
      "Miguel Ángel Lagunas"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03531v1",
    "abstract": "In this paper, we extend our previous work on the Expressive Neural Network (ENN), a multilayer perceptron with adaptive activation functions parametrized using the Discrete Cosine Transform (DCT). Building upon previous work that demonstrated the strong expressiveness of ENNs with compact architectures, we now emphasize their efficiency, interpretability and pruning capabilities. The DCT-based parameterization provides a structured and decorrelated representation that reveals the functional role of each neuron and allows direct identification of redundant components. Leveraging this property, we propose an efficient pruning strategy that removes unnecessary DCT coefficients with negligible or no loss in performance. Experimental results across classification and implicit neural representation tasks confirm that ENNs achieve state-of-the-art accuracy while maintaining a low number of parameters. Furthermore, up to 40% of the activation coefficients can be safely pruned, thanks to the orthogonality and bounded nature of the DCT basis. Overall, these findings demonstrate that the ENN framework offers a principled integration of signal processing concepts into neural network design, achieving a balanced trade-off between expressiveness, compactness, and interpretability.",
    "fetched_at": "2025-11-07T02:16:47.494885Z"
  },
  {
    "id": "2511.03545v1",
    "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis   (Part I)",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sebastian Ordyniak",
      "Giacomo Paesani",
      "Mateusz Rychlicki",
      "Stefan Szeider"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03545v1",
    "abstract": "This paper presents a comprehensive theoretical investigation into the parameterized complexity of explanation problems in various machine learning (ML) models. Contrary to the prevalent black-box perception, our study focuses on models with transparent internal mechanisms. We address two principal types of explanation problems: abductive and contrastive, both in their local and global variants. Our analysis encompasses diverse ML models, including Decision Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof, each offering unique explanatory challenges. This research fills a significant gap in explainable AI (XAI) by providing a foundational understanding of the complexities of generating explanations for these models. This work provides insights vital for further research in the domain of XAI, contributing to the broader discourse on the necessity of transparency and accountability in AI systems.",
    "fetched_at": "2025-11-07T02:16:47.494778Z"
  },
  {
    "id": "2511.03547v1",
    "title": "Bearing Syntactic Fruit with Stack-Augmented Neural Networks",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Brian DuSell",
      "Ryan Cotterell"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03547v1",
    "abstract": "Any finite set of training data is consistent with an infinite number of hypothetical algorithms that could have generated it. Studies have shown that when human children learn language, they consistently favor hypotheses based on hierarchical syntactic rules without ever encountering disambiguating examples. A recent line of work has inquired as to whether common neural network architectures share this bias, finding that they do so only under special conditions: when syntactically supervised, when pre-trained on massive corpora, or when trained long past convergence. In this paper, we demonstrate, for the first time, neural network architectures that are able to generalize in human-like fashion without any of the aforementioned requirements: stack-augmented neural networks. We test three base architectures (transformer, simple RNN, LSTM) augmented with two styles of stack: the superposition stack of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed by DuSell & Chiang (2023). We find that transformers with nondeterministic stacks generalize best out of these architectures on a classical question formation task. We also propose a modification to the stack RNN architecture that improves hierarchical generalization. These results suggest that stack-augmented neural networks may be more accurate models of human language acquisition than standard architectures, serving as useful objects of psycholinguistic study. Our code is publicly available.",
    "fetched_at": "2025-11-07T02:16:47.494734Z"
  },
  {
    "id": "2511.03549v1",
    "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code   Understanding",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ziv Nevo",
      "Orna Raz",
      "Karen Yorav"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03549v1",
    "abstract": "Understanding the purpose of source code is a critical task in software maintenance, onboarding, and modernization. While large language models (LLMs) have shown promise in generating code explanations, they often lack grounding in the broader software engineering context. We propose a novel approach that leverages natural language artifacts from GitHub -- such as pull request descriptions, issue descriptions and discussions, and commit messages -- to enhance LLM-based code understanding. Our system consists of three components: one that extracts and structures relevant GitHub context, another that uses this context to generate high-level explanations of the code's purpose, and a third that validates the explanation. We implemented this as a standalone tool, as well as a server within the Model Context Protocol (MCP), enabling integration with other AI-assisted development tools. Our main use case is that of enhancing a standard LLM-based code explanation with code insights that our system generates. To evaluate explanations' quality, we conducted a small scale user study, with developers of several open projects, as well as developers of proprietary projects. Our user study indicates that when insights are generated they often are helpful and non trivial, and are free from hallucinations.",
    "fetched_at": "2025-11-07T02:16:47.494691Z"
  },
  {
    "id": "2511.03548v1",
    "title": "Flat Minima and Generalization: Insights from Stochastic Convex   Optimization",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matan Schliserman",
      "Shira Vansover-Hager",
      "Tomer Koren"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03548v1",
    "abstract": "Understanding the generalization behavior of learning algorithms is a central goal of learning theory. A recently emerging explanation is that learning algorithms are successful in practice because they converge to flat minima, which have been consistently associated with improved generalization performance. In this work, we study the link between flat minima and generalization in the canonical setting of stochastic convex optimization with a non-negative, $\\beta$-smooth objective. Our first finding is that, even in this fundamental and well-studied setting, flat empirical minima may incur trivial $\\Omega(1)$ population risk while sharp minima generalizes optimally. Then, we show that this poor generalization behavior extends to two natural ''sharpness-aware'' algorithms originally proposed by Foret et al. (2021), designed to bias optimization toward flat solutions: Sharpness-Aware Gradient Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which performs gradient steps on the maximal loss in a predefined neighborhood, we prove that while it successfully converges to a flat minimum at a fast rate, the population risk of the solution can still be as large as $\\Omega(1)$, indicating that even flat minima found algorithmically using a sharpness-aware gradient method might generalize poorly. For SAM, a computationally efficient approximation of SA-GD based on normalized ascent steps, we show that although it minimizes the empirical loss, it may converge to a sharp minimum and also incur population risk $\\Omega(1)$. Finally, we establish population risk upper bounds for both SA-GD and SAM using algorithmic stability techniques.",
    "fetched_at": "2025-11-07T02:16:47.494646Z"
  },
  {
    "id": "2511.03553v1",
    "title": "MultiZebraLogic: A Multilingual Logical Reasoning Benchmark",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sofie Helene Bruun",
      "Dan Saattrup Smart"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03553v1",
    "abstract": "Measuring the full abilities of large language models (LLMs) requires benchmarks representing multiple tasks. We aim to create large, high-quality datasets for comparison of logical reasoning skills across several languages and of suitable difficulty for LLMs of various reasoning ability. We explore multiple ways of increasing difficulty. We generate zebra puzzles in multiple languages, themes, sizes and including 14 different clue types and 8 red herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a reasoning model), respectively. Including 5 red herrings decreases o3-mini puzzle-level accuracy on 4x5 puzzles by 15$\\pm$7 %. Scores of o3-mini on 4x5 puzzles are not significantly affected by use of English vs. Danish or the common houses theme vs. the country-specific smoerrebroed theme. We find no correlation between difficulty and the selected clue types. Datasets of 128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic languages for sizes 2x3 and 4x5. We publish code for puzzle generation, designed for adaptablity into more languages and themes.",
    "fetched_at": "2025-11-07T02:16:47.494597Z"
  },
  {
    "id": "2511.03554v1",
    "title": "The Structure of Cross-Validation Error: Stability, Covariance, and   Minimax Limits",
    "date": "2025-11-05",
    "tags": [
      "math.ST",
      "ST",
      "cs.LG",
      "LG",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Ido Nachum",
      "Rüdiger Urbanke",
      "Thomas Weinberger"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03554v1",
    "abstract": "Despite ongoing theoretical research on cross-validation (CV), many theoretical questions about CV remain widely open. This motivates our investigation into how properties of algorithm-distribution pairs can affect the choice for the number of folds in $k$-fold cross-validation.   Our results consist of a novel decomposition of the mean-squared error of cross-validation for risk estimation, which explicitly captures the correlations of error estimates across overlapping folds and includes a novel algorithmic stability notion, squared loss stability, that is considerably weaker than the typically required hypothesis stability in other comparable works.   Furthermore, we prove:   1. For every learning algorithm that minimizes empirical error, a minimax lower bound on the mean-squared error of $k$-fold CV estimating the population risk $L_\\mathcal{D}$: \\[ \\min_{k \\mid n}\\; \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega\\!\\big(\\sqrt{k}/n\\big), \\] where $n$ is the sample size and $k$ the number of folds. This shows that even under idealized conditions, for large values of $k$, CV cannot attain the optimum of order $1/n$ achievable by a validation set of size $n$, reflecting an inherent penalty caused by dependence between folds.   2. Complementing this, we exhibit learning rules for which \\[   \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega(k/n), \\] matching (up to constants) the accuracy of a hold-out estimator of a single fold of size $n/k$.   Together these results delineate the fundamental trade-off in resampling-based risk estimation: CV cannot fully exploit all $n$ samples for unbiased risk evaluation, and its minimax performance is pinned between the $k/n$ and $\\sqrt{k}/n$ regimes.",
    "fetched_at": "2025-11-07T02:16:47.494557Z"
  },
  {
    "id": "2511.03559v1",
    "title": "AILA--First Experiments with Localist Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Joachim Diederich"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03559v1",
    "abstract": "This paper presents the first empirical demonstration of controllable locality in transformer language models, a novel architectural framework that enables continuous control over the degree of representation localization through a tunable locality dial parameter. Unlike traditional language models that rely exclusively on distributed representations, our approach allows dynamic interpolation between highly interpretable localist encodings and efficient distributed representations without requiring model retraining. We conducted experiments on the WikiText corpus using a two-layer transformer architecture, systematically varying the locality parameter {\\lambda} across the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our results demonstrate that localist configurations achieve dramatically lower attention entropy, with {\\lambda} = 1.0 yielding 5.36 bits compared to 7.18 bits at {\\lambda} = 0.0, while maintaining substantially higher pointer fidelity scores reflecting stronger alignment with rule-specified targets. Prediction experiments reveal that intermediate locality values optimize the tradeoff between interpretability and performance, with {\\lambda} = 0.6 achieving test perplexity of 4.65 and accuracy of 84.7%. These findings establish that localist language models provide a practical framework for applications in regulated domains requiring both transparency and capability, offering precise mathematical control over the interpretability-performance spectrum through explicit penalty thresholds and information-theoretic design principles.",
    "fetched_at": "2025-11-07T02:16:47.494508Z"
  },
  {
    "id": "2511.03563v1",
    "title": "ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for   Enhanced Legal Regulation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "One Octadion",
      "Bondan Sapta Prakoso",
      "Nanang Yudi Setiawan",
      "Novanto Yudistira"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03563v1",
    "abstract": "In this study, we explore the fine-tuning of Large Language Models (LLMs) to better support policymakers in their crucial work of understanding, analyzing, and crafting legal regulations. To equip the model with a deep understanding of legal texts, we curated a supervised dataset tailored to the specific needs of the legal domain. Additionally, we integrated the Retrieval-Augmented Generation (RAG) method, enabling the LLM to access and incorporate up-to-date legal knowledge from external sources. This combination of fine-tuning and RAG-based augmentation results in a tool that not only processes legal information but actively assists policymakers in interpreting regulations and drafting new ones that align with current needs. The results demonstrate that this approach can significantly enhance the effectiveness of legal research and regulation development, offering a valuable resource in the ever-evolving field of law.",
    "fetched_at": "2025-11-07T02:16:47.494466Z"
  },
  {
    "id": "2511.03565v1",
    "title": "Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent   Advances",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03565v1",
    "abstract": "Imitation learning (IL) enables agents to acquire skills by observing and replicating the behavior of one or multiple experts. In recent years, advances in deep learning have significantly expanded the capabilities and scalability of imitation learning across a range of domains, where expert data can range from full state-action trajectories to partial observations or unlabeled sequences. Alongside this growth, novel approaches have emerged, with new methodologies being developed to address longstanding challenges such as generalization, covariate shift, and demonstration quality. In this survey, we review the latest advances in imitation learning research, highlighting recent trends, methodological innovations, and practical applications. We propose a novel taxonomy that is distinct from existing categorizations to better reflect the current state of the IL research stratum and its trends. Throughout the survey, we critically examine the strengths, limitations, and evaluation practices of representative works, and we outline key challenges and open directions for future research.",
    "fetched_at": "2025-11-07T02:16:47.494421Z"
  },
  {
    "id": "2511.03570v1",
    "title": "TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and   Retrieval",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Günther Schindler",
      "Maximilian Schambach",
      "Michael Medek",
      "Sam Thelin"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03570v1",
    "abstract": "We study LLMs for tabular prediction with mixed text, numeric, and categorical fields. We introduce TabGemma, a schema-agnostic in-context learner that treats rows as sequences and tackles two practical hurdles when adapting pretrained LLMs for tabular predictions: unstable numeric tokenization and limited context size. We propose to canonicalize numbers via signed scientific notation and continue pretraining of a 12B Gemma 3 model with a target imputation objective using a large-scale real world dataset. For inference, we use a compact n-gram-based retrieval to select informative exemplars that fit within a 128k-token window.   On semantically rich benchmarks, TabGemma establishes a new state of the art on classification across low- and high-data regimes and improves monotonically with more context rows. For regression, it is competitive at small sample sizes but trails conventional approaches as data grows. Our results show that LLMs can be effective tabular in-context learners on highly semantic tasks when paired with dedicated numeric handling and context retrieval, while motivating further advances in numeric modeling and long-context scaling.",
    "fetched_at": "2025-11-07T02:16:47.494379Z"
  },
  {
    "id": "2511.03576v1",
    "title": "Multi-User Personalisation in Human-Robot Interaction: Using   Quantitative Bipolar Argumentation Frameworks for Preferences Conflict   Resolution",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "68T40",
      "I.2.9; I.2.4",
      "4"
    ],
    "authors": [
      "Aniol Civit",
      "Antonio Andriella",
      "Carles Sierra",
      "Guillem Alenyà"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03576v1",
    "abstract": "While personalisation in Human-Robot Interaction (HRI) has advanced significantly, most existing approaches focus on single-user adaptation, overlooking scenarios involving multiple stakeholders with potentially conflicting preferences. To address this, we propose the Multi-User Preferences Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user personalisation framework based on Quantitative Bipolar Argumentation Frameworks (QBAFs) that explicitly models and resolves multi-user preference conflicts. Unlike prior work in Argumentation Frameworks, which typically assumes static inputs, our approach is tailored to robotics: it incorporates both users' arguments and the robot's dynamic observations of the environment, allowing the system to adapt over time and respond to changing contexts. Preferences, both positive and negative, are represented as arguments whose strength is recalculated iteratively based on new information. The framework's properties and capabilities are presented and validated through a realistic case study, where an assistive robot mediates between the conflicting preferences of a caregiver and a care recipient during a frailty assessment task. This evaluation further includes a sensitivity analysis of argument base scores, demonstrating how preference outcomes can be shaped by user input and contextual observations. By offering a transparent, structured, and context-sensitive approach to resolving competing user preferences, this work advances the field of multi-user HRI. It provides a principled alternative to data-driven methods, enabling robots to navigate conflicts in real-world environments.",
    "fetched_at": "2025-11-07T02:16:47.494332Z"
  },
  {
    "id": "2511.03578v1",
    "title": "Learning Under Laws: A Constraint-Projected Neural PDE Solver that   Eliminates Hallucinations",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mainak Singha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03578v1",
    "abstract": "Neural networks can approximate solutions to partial differential equations, but they often break the very laws they are meant to model-creating mass from nowhere, drifting shocks, or violating conservation and entropy. We address this by training within the laws of physics rather than beside them. Our framework, called Constraint-Projected Learning (CPL), keeps every update physically admissible by projecting network outputs onto the intersection of constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and positivity. The projection is differentiable and adds only about 10% computational overhead, making it fully compatible with back-propagation. We further stabilize training with total-variation damping (TVD) to suppress small oscillations and a rollout curriculum that enforces consistency over long prediction horizons. Together, these mechanisms eliminate both hard and soft violations: conservation holds at machine precision, total-variation growth vanishes, and entropy and error remain bounded. On Burgers and Euler systems, CPL produces stable, physically lawful solutions without loss of accuracy. Instead of hoping neural solvers will respect physics, CPL makes that behavior an intrinsic property of the learning process.",
    "fetched_at": "2025-11-07T02:16:47.494278Z"
  },
  {
    "id": "2511.03595v1",
    "title": "Tensor-Efficient High-Dimensional Q-learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Junyi Wu",
      "Dan Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03595v1",
    "abstract": "High-dimensional reinforcement learning faces challenges with complex calculations and low sample efficiency in large state-action spaces. Q-learning algorithms struggle particularly with the curse of dimensionality, where the number of state-action pairs grows exponentially with problem size. While neural network-based approaches like Deep Q-Networks have shown success, recent tensor-based methods using low-rank decomposition offer more parameter-efficient alternatives. Building upon existing tensor-based methods, we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor decomposition via improved block coordinate descent on discretized state-action spaces, incorporating novel exploration and regularization mechanisms. The key innovation is an exploration strategy that combines approximation error with visit count-based upper confidence bound to prioritize actions with high uncertainty, avoiding wasteful random exploration. Additionally, we incorporate a frequency-based penalty term in the objective function to encourage exploration of less-visited state-action pairs and reduce overfitting to frequently visited regions. Empirical results on classic control tasks demonstrate that TEQL outperforms conventional matrix-based methods and deep RL approaches in both sample efficiency and total rewards, making it suitable for resource-constrained applications, such as space and healthcare where sampling costs are high.",
    "fetched_at": "2025-11-07T02:16:47.494178Z"
  },
  {
    "id": "2511.03601v1",
    "title": "Step-Audio-EditX Technical Report",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.SD",
      "SD",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Chao Yan",
      "Boyong Wu",
      "Peng Yang",
      "Pengfei Tan",
      "Guoqiang Hu",
      "Yuxin Zhang",
      "Xiangyu",
      "Zhang",
      "Fei Tian",
      "Xuerui Yang",
      "Xiangyu Zhang",
      "Daxin Jiang",
      "Gang Yu"
    ],
    "institution": "Tony",
    "link": "http://arxiv.org/pdf/2511.03601v1",
    "abstract": "We present Step-Audio-EditX, the first open-source LLM-based audio model excelling at expressive and iterative audio editing encompassing emotion, speaking style, and paralinguistics alongside robust zero-shot text-to-speech (TTS) capabilities.Our core innovation lies in leveraging only large-margin synthetic data, which circumvents the need for embedding-based priors or auxiliary modules. This large-margin learning approach enables both iterative control and high expressivity across voices, and represents a fundamental pivot from the conventional focus on representation-level disentanglement. Evaluation results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.",
    "fetched_at": "2025-11-07T02:16:47.494133Z"
  },
  {
    "id": "2511.03606v1",
    "title": "Vector-valued self-normalized concentration inequalities beyond   sub-Gaussianity",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Diego Martinez-Taboada",
      "Tomas Gonzalez",
      "Aaditya Ramdas"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03606v1",
    "abstract": "The study of self-normalized processes plays a crucial role in a wide range of applications, from sequential decision-making to econometrics. While the behavior of self-normalized concentration has been widely investigated for scalar-valued processes, vector-valued processes remain comparatively underexplored, especially outside of the sub-Gaussian framework. In this contribution, we provide concentration bounds for self-normalized processes with light tails beyond sub-Gaussianity (such as Bennett or Bernstein bounds). We illustrate the relevance of our results in the context of online linear regression, with applications in (kernelized) linear bandits.",
    "fetched_at": "2025-11-07T02:16:47.494044Z"
  },
  {
    "id": "2511.03610v1",
    "title": "A systematic review of relation extraction task since the emergence of   Transformers",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "A.1; I.2.4; I.2.7",
      "7"
    ],
    "authors": [
      "Ringwald Celian",
      "Gandon",
      "Fabien",
      "Faron Catherine",
      "Michel Franck",
      "Abi Akl Hanna"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03610v1",
    "abstract": "This article presents a systematic review of relation extraction (RE) research since the advent of Transformer-based models. Using an automated framework to collect and annotate publications, we analyze 34 surveys, 64 datasets, and 104 models published between 2019 and 2024. The review highlights methodological advances, benchmark resources, and the integration of semantic web technologies. By consolidating results across multiple dimensions, the study identifies current trends, limitations, and open challenges, offering researchers and practitioners a comprehensive reference for understanding the evolution and future directions of RE.",
    "fetched_at": "2025-11-07T02:16:47.494003Z"
  },
  {
    "id": "2511.03617v1",
    "title": "Visualization Biases MLLM's Decision Making in Network Data Tasks",
    "date": "2025-11-05",
    "tags": [
      "cs.GR",
      "GR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Timo Brand",
      "Henry Förster",
      "Stephen G. Kobourov",
      "Jacob Miller"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03617v1",
    "abstract": "We evaluate how visualizations can influence the judgment of MLLMs about the presence or absence of bridges in a network. We show that the inclusion of visualization improves confidence over a structured text-based input that could theoretically be helpful for answering the question. On the other hand, we observe that standard visualization techniques create a strong bias towards accepting or refuting the presence of a bridge -- independently of whether or not a bridge actually exists in the network. While our results indicate that the inclusion of visualization techniques can effectively influence the MLLM's judgment without compromising its self-reported confidence, they also imply that practitioners must be careful of allowing users to include visualizations in generative AI applications so as to avoid undesired hallucinations.",
    "fetched_at": "2025-11-07T02:16:47.493908Z"
  },
  {
    "id": "2511.03618v1",
    "title": "Towards Formalizing Reinforcement Learning Theory",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Shangtong Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03618v1",
    "abstract": "In this paper, we formalize the almost sure convergence of $Q$-learning and linear temporal difference (TD) learning with Markovian samples using the Lean 4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are among the earliest and most influential reinforcement learning (RL) algorithms. The investigation of their convergence properties is not only a major research topic during the early development of the RL field but also receives increasing attention nowadays. This paper formally verifies their almost sure convergence in a unified framework based on the Robbins-Siegmund theorem. The framework developed in this work can be easily extended to convergence rates and other modes of convergence. This work thus makes an important step towards fully formalizing convergent RL results. The code is available at https://github.com/ShangtongZhang/rl-theory-in-lean.",
    "fetched_at": "2025-11-07T02:16:47.493865Z"
  },
  {
    "id": "2511.03620v1",
    "title": "CLAX: Fast and Flexible Neural Click Models in JAX",
    "date": "2025-11-05",
    "tags": [
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Philipp Hager",
      "Onno Zoeter",
      "Maarten de Rijke"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03620v1",
    "abstract": "CLAX is a JAX-based library that implements classic click models using modern gradient-based optimization. While neural click models have emerged over the past decade, complex click models based on probabilistic graphical models (PGMs) have not systematically adopted gradient-based optimization, preventing practitioners from leveraging modern deep learning frameworks while preserving the interpretability of classic models. CLAX addresses this gap by replacing EM-based optimization with direct gradient-based optimization in a numerically stable manner. The framework's modular design enables the integration of any component, from embeddings and deep networks to custom modules, into classic click models for end-to-end optimization. We demonstrate CLAX's efficiency by running experiments on the full Baidu-ULTR dataset comprising over a billion user sessions in $\\approx$ 2 hours on a single GPU, orders of magnitude faster than traditional EM approaches. CLAX implements ten classic click models, serving both industry practitioners seeking to understand user behavior and improve ranking performance at scale and researchers developing new click models. CLAX is available at: https://github.com/philipphager/clax",
    "fetched_at": "2025-11-07T02:16:47.493831Z"
  },
  {
    "id": "2511.03631v1",
    "title": "Financial Management System for SMEs: Real-World Deployment of Accounts   Receivable and Cash Flow Prediction",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bartłomiej Małkus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03631v1",
    "abstract": "Small and Medium Enterprises (SMEs), particularly freelancers and early-stage businesses, face unique financial management challenges due to limited resources, small customer bases, and constrained data availability. This paper presents the development and deployment of an integrated financial prediction system that combines accounts receivable prediction and cash flow forecasting specifically designed for SME operational constraints. Our system addresses the gap between enterprise-focused financial tools and the practical needs of freelancers and small businesses. The solution integrates two key components: a binary classification model for predicting invoice payment delays, and a multi-module cash flow forecasting model that handles incomplete and limited historical data. A prototype system has been implemented and deployed as a web application with integration into Cluee's platform, a startup providing financial management tools for freelancers, demonstrating practical feasibility for real-world SME financial management.",
    "fetched_at": "2025-11-07T02:16:47.493737Z"
  },
  {
    "id": "2511.03632v1",
    "title": "Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility   Environments",
    "date": "2025-11-05",
    "tags": [
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "math.IT"
    ],
    "authors": [
      "Cemil Vahapoglu",
      "Timothy J. O'Shea",
      "Wan Liu",
      "Sennur Ulukus"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03632v1",
    "abstract": "Beamforming has significance for enhancing spectral efficiency and mitigating interference in multi-antenna wireless systems, facilitating spatial multiplexing and diversity in dense and high mobility scenarios. Traditional beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming experience performance deterioration under adverse channel conditions. Deep learning-based beamforming offers an alternative with nonlinear mappings from channel state information (CSI) to beamforming weights by improving robustness against dynamic channel environments. Transformer-based models are particularly effective due to their ability to model long-range dependencies across time and frequency. However, their quadratic attention complexity limits scalability in large OFDM grids. Recent studies address this issue through sparse attention mechanisms that reduce complexity while maintaining expressiveness, yet often employ patterns that disregard channel dynamics, as they are not specifically designed for wireless communication scenarios. In this work, we propose a Doppler-aware Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that incorporates a channel-adaptive sparse attention mechanism in a multi-user single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure is configurable along 2D time-frequency axes based on channel dynamics and is theoretically proven to ensure full connectivity within p hops, where p is the number of attention heads. Simulation results under urban macro (UMa) channel conditions show that Doppler-aware Sparse NNBF significantly outperforms both a fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios, while maintaining structured sparsity with a controlled number of attended keys per query.",
    "fetched_at": "2025-11-07T02:16:47.493696Z"
  },
  {
    "id": "2511.03634v1",
    "title": "nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alexander Pfefferle",
      "Johannes Hog",
      "Lennart Purucker",
      "Frank Hutter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03634v1",
    "abstract": "Tabular foundation models such as TabPFN have revolutionized predictive machine learning for tabular data. At the same time, the driving factors of this revolution are hard to understand. Existing open-source tabular foundation models are implemented in complicated pipelines boasting over 10,000 lines of code, lack architecture documentation or code quality. In short, the implementations are hard to understand, not beginner-friendly, and complicated to adapt for new experiments. We introduce nanoTabPFN, a simplified and lightweight implementation of the TabPFN v2 architecture and a corresponding training loop that uses pre-generated training data. nanoTabPFN makes tabular foundation models more accessible to students and researchers alike. For example, restricted to a small data setting it achieves a performance comparable to traditional machine learning baselines within one minute of pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This eliminated requirement of large computational resources makes pre-training tabular foundation models accessible for educational purposes. Our code is available at https://github.com/automl/nanoTabPFN.",
    "fetched_at": "2025-11-07T02:16:47.493641Z"
  },
  {
    "id": "2511.03635v1",
    "title": "Towards Transparent Stance Detection: A Zero-Shot Approach Using   Implicit and Explicit Interpretability",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Apoorva Upadhyaya",
      "Wolfgang Nejdl",
      "Marco Fisichella"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03635v1",
    "abstract": "Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward unseen targets. Existing research using contrastive, meta-learning, or data augmentation suffers from generalizability issues or lack of coherence between text and target. Recent works leveraging large language models (LLMs) for ZSSD focus either on improving unseen target-specific knowledge or generating explanations for stance analysis. However, most of these works are limited by their over-reliance on explicit reasoning, provide coarse explanations that lack nuance, and do not explicitly model the reasoning process, making it difficult to interpret the model's predictions. To address these issues, in our study, we develop a novel interpretable ZSSD framework, IRIS. We provide an interpretable understanding of the attitude of the input towards the target implicitly based on sequences within the text (implicit rationales) and explicitly based on linguistic measures (explicit rationales). IRIS considers stance detection as an information retrieval ranking task, understanding the relevance of implicit rationales for different stances to guide the model towards correct predictions without requiring the ground-truth of rationales, thus providing inherent interpretability. In addition, explicit rationales based on communicative features help decode the emotional and cognitive dimensions of stance, offering an interpretable understanding of the author's attitude towards the given target. Extensive experiments on the benchmark datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10% training data prove the generalizability of our model, benefiting from the proposed architecture and interpretable design.",
    "fetched_at": "2025-11-07T02:16:47.493595Z"
  },
  {
    "id": "2511.03636v1",
    "title": "Quantifying Weighted Morphological Content of Large-Scale Structures via   Simulation-Based Inference",
    "date": "2025-11-05",
    "tags": [
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "M. H. Jalali Kanafi",
      "S. M. S. Movahed"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03636v1",
    "abstract": "In this work, we perform a simulation-based forecasting analysis to compare the constraining power of two higher-order summary statistics of the large-scale structure (LSS), the Minkowski Functionals (MFs) and the Conditional Moments of Derivative (CMD), with a particular focus on their sensitivity to nonlinear and anisotropic features in redshift-space. Our analysis relies on halo catalogs from the Big Sobol Sequence(BSQ) simulations at redshift $z=0.5$, employing a likelihood-free inference framework implemented via neural posterior estimation. At the fiducial cosmology of the Quijote simulations $(\\Omega_{m}=0.3175,\\,\\sigma_{8}=0.834)$, and for the smoothing scale $R=15\\,h^{-1}$Mpc, we find that the CMD yields tighter forecasts for $(\\Omega_{m}},\\,\\sigma_{8})$ than the zeroth- to third-order MFs components, improving the constraint precision by ${\\sim}(44\\%,\\,52\\%)$, ${\\sim}(30\\%,\\,45\\%)$, ${\\sim}(27\\%,\\,17\\%)$, and ${\\sim}(26\\%,\\,17\\%)$, respectively. A joint configuration combining the MFs and CMD further enhances the precision by approximately ${\\sim}27\\%$ compared to the standard MFs alone, highlighting the complementary anisotropy-sensitive information captured by the CMD in contrast to the scalar morphological content encapsulated by the MFs. We further extend the forecasting analysis to a continuous range of cosmological parameter values and multiple smoothing scales. Our results show that, although the absolute forecast uncertainty for each component of summary statistics depends on the underlying parameter values and the adopted smoothing scale, the relative constraining power among the summary statistics remains nearly constant throughout.",
    "fetched_at": "2025-11-07T02:16:47.493547Z"
  },
  {
    "id": "2511.03641v1",
    "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in   Light of Technology",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "68T01, 68727, 68T30, 68T35, 68T37, 68T50"
    ],
    "authors": [
      "Thomas Souverain"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03641v1",
    "abstract": "To foster trustworthy Artificial Intelligence (AI) within the European Union, the AI Act requires providers to mark and detect the outputs of their general-purpose models. The Article 50 and Recital 133 call for marking methods that are ''sufficiently reliable, interoperable, effective and robust''. Yet, the rapidly evolving and heterogeneous landscape of watermarks for Large Language Models (LLMs) makes it difficult to determine how these four standards can be translated into concrete and measurable evaluations. Our paper addresses this challenge, anchoring the normativity of European requirements in the multiplicity of watermarking techniques. Introducing clear and distinct concepts on LLM watermarking, our contribution is threefold. (1) Watermarking Categorisation: We propose an accessible taxonomy of watermarking methods according to the stage of the LLM lifecycle at which they are applied - before, during, or after training, and during next-token distribution or sampling. (2) Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping each criterion with state-of-the-art evaluations on robustness and detectability of the watermark, and of quality of the LLM. Since interoperability remains largely untheorised in LLM watermarking research, we propose three normative dimensions to frame its assessment. (3) Watermarking Comparison: We compare current watermarking methods for LLMs against the operationalised European criteria and show that no approach yet satisfies all four standards. Encouraged by emerging empirical tests, we recommend further research into watermarking directly embedded within the low-level architecture of LLMs.",
    "fetched_at": "2025-11-07T02:16:47.493501Z"
  },
  {
    "id": "2511.03643v1",
    "title": "Explaining Human Choice Probabilities with Simple Vector Representations",
    "date": "2025-11-05",
    "tags": [
      "q-bio.NC",
      "NC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Peter DiBerardino",
      "Britt Anderson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03643v1",
    "abstract": "When people pursue rewards in stochastic environments, they often match their choice frequencies to the observed target frequencies, even when this policy is demonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this behavior under conditions where pursuit (seeking) could be toggled to avoidance (hiding), while leaving the probability distribution fixed, or varying complexity by changing the number of possible choices. We developed a model for participant choice built from choice frequency histograms treated as vectors. We posited the existence of a probability antimatching strategy for avoidance (hiding) rounds, and formalized this as a vector reflection of probability matching. We found that only two basis policies: matching/antimatching and maximizing/minimizing were sufficient to account for participant choices across a range of room numbers and opponent probability distributions. This schema requires only that people have the ability to remember the relative frequency of the different outcomes. With this knowledge simple operations can construct the maximizing and minimizing policies as well as matching and antimatching strategies. A mixture of these two policies captures human choice patterns in a stochastic environment.",
    "fetched_at": "2025-11-07T02:16:47.493457Z"
  },
  {
    "id": "2511.03653v1",
    "title": "Efficient Testing Implies Structured Symmetry",
    "date": "2025-11-05",
    "tags": [
      "cs.CC",
      "CC",
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Cynthia Dwork",
      "Pranay Tankala"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03653v1",
    "abstract": "Given a small random sample of $n$-bit strings labeled by an unknown Boolean function, which properties of this function can be tested computationally efficiently? We show an equivalence between properties that are efficiently testable from few samples and properties with structured symmetry, which depend only on the function's average values on parts of a low-complexity partition of the domain. Without the efficiency constraint, a similar characterization in terms of unstructured symmetry was obtained by Blais and Yoshida (2019). Our main technical tool is supersimulation, which builds on methods from the algorithmic fairness literature to approximate arbitrarily complex functions by small-circuit simulators that fool significantly larger distinguishers.   We extend the characterization along other axes as well. We show that allowing parts to overlap exponentially reduces their required number, broadening the scope of the construction from properties testable with $O(\\log n)$ samples to properties testable with $O(n)$ samples. For larger sample sizes, we show that any efficient tester is essentially checking for indistinguishability from a bounded collection of small circuits, in the spirit of a characterization of testable graph properties. Finally, we show that our results for Boolean function testing generalize to high-entropy distribution testing on arbitrary domains.",
    "fetched_at": "2025-11-07T02:16:47.493416Z"
  },
  {
    "id": "2511.03656v1",
    "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained   Evaluation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jing Gao",
      "Shutiao Luo",
      "Yumeng Liu",
      "Yuanming Li",
      "Hongji Zeng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03656v1",
    "abstract": "With the rapid advancement of natural language processing (NLP) technologies, the demand for high-quality Chinese document question-answering datasets is steadily growing. To address this issue, we present the Chinese Multi-Document Question Answering Dataset(ChiMDQA), specifically designed for downstream business scenarios across prevalent domains including academic, education, finance, law, medical treatment, and news. ChiMDQA encompasses long-form documents from six distinct fields, consisting of 6,068 rigorously curated, high-quality question-answer (QA) pairs further classified into ten fine-grained categories. Through meticulous document screening and a systematic question-design methodology, the dataset guarantees both diversity and high quality, rendering it applicable to various NLP tasks such as document comprehension, knowledge extraction, and intelligent QA systems. Additionally, this paper offers a comprehensive overview of the dataset's design objectives, construction methodologies, and fine-grained evaluation system, supplying a substantial foundation for future research and practical applications in Chinese QA. The code and data are available at: https://anonymous.4open.science/r/Foxit-CHiMDQA/.",
    "fetched_at": "2025-11-07T02:16:47.493372Z"
  },
  {
    "id": "2511.03661v1",
    "title": "SHIELD: Securing Healthcare IoT with Efficient Machine Learning   Techniques for Anomaly Detection",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mahek Desai",
      "Apoorva Rumale",
      "Marjan Asadinia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03661v1",
    "abstract": "The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.",
    "fetched_at": "2025-11-07T02:16:47.493320Z"
  },
  {
    "id": "2511.03670v1",
    "title": "DQN Performance with Epsilon Greedy Policies and Prioritized Experience   Replay",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T05"
    ],
    "authors": [
      "Daniel Perkins",
      "Oscar J. Escobar",
      "Luke Green"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03670v1",
    "abstract": "We present a detailed study of Deep Q-Networks in finite environments, emphasizing the impact of epsilon-greedy exploration schedules and prioritized experience replay. Through systematic experimentation, we evaluate how variations in epsilon decay schedules affect learning efficiency, convergence behavior, and reward optimization. We investigate how prioritized experience replay leads to faster convergence and higher returns and show empirical results comparing uniform, no replay, and prioritized strategies across multiple simulations. Our findings illuminate the trade-offs and interactions between exploration strategies and memory management in DQN training, offering practical recommendations for robust reinforcement learning in resource-constrained settings.",
    "fetched_at": "2025-11-07T02:16:47.493269Z"
  },
  {
    "id": "2511.03675v1",
    "title": "Whisper Leak: a side-channel attack on Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "K.4.1; C.2.0; K.6.5; I.2.7",
      "7"
    ],
    "authors": [
      "Geoff McDonald",
      "Jonathan Bar Or"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03675v1",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in sensitive domains including healthcare, legal services, and confidential communications, where privacy is paramount. This paper introduces Whisper Leak, a side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. Despite TLS encryption protecting content, these metadata patterns leak sufficient information to enable topic classification. We demonstrate the attack across 28 popular LLMs from major providers, achieving near-perfect classification (often >98% AUPRC) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, we achieve 100% precision in identifying sensitive topics like \"money laundering\" while recovering 5-20% of target conversations. This industry-wide vulnerability poses significant risks for users under network surveillance by ISPs, governments, or local adversaries. We evaluate three mitigation strategies - random padding, token batching, and packet injection - finding that while each reduces attack effectiveness, none provides complete protection. Through responsible disclosure, we have collaborated with providers to implement initial countermeasures. Our findings underscore the need for LLM providers to address metadata leakage as AI systems handle increasingly sensitive information.",
    "fetched_at": "2025-11-07T02:16:47.493226Z"
  },
  {
    "id": "2511.03685v1",
    "title": "Structured Matrix Scaling for Multi-Class Calibration",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Eugène Berta",
      "David Holzmüller",
      "Michael I. Jordan",
      "Francis Bach"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03685v1",
    "abstract": "Post-hoc recalibration methods are widely used to ensure that classifiers provide faithful probability estimates. We argue that parametric recalibration functions based on logistic regression can be motivated from a simple theoretical setting for both binary and multiclass classification. This insight motivates the use of more expressive calibration methods beyond standard temperature scaling. For multi-class calibration however, a key challenge lies in the increasing number of parameters introduced by more complex models, often coupled with limited calibration data, which can lead to overfitting. Through extensive experiments, we demonstrate that the resulting bias-variance tradeoff can be effectively managed by structured regularization, robust preprocessing and efficient optimization. The resulting methods lead to substantial gains over existing logistic-based calibration techniques. We provide efficient and easy-to-use open-source implementations of our methods, making them an attractive alternative to common temperature, vector, and matrix scaling implementations.",
    "fetched_at": "2025-11-07T02:16:47.493181Z"
  },
  {
    "id": "2511.03693v1",
    "title": "Colorectal Cancer Histopathological Grading using Multi-Scale Federated   Learning",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Md Ahasanul Arafath",
      "Abhijit Kumar Ghosh",
      "Md Rony Ahmed",
      "Sabrin Afroz",
      "Minhazul Hosen",
      "Md Hasan Moon",
      "Md Tanzim Reza",
      "Md Ashad Alam"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03693v1",
    "abstract": "Colorectal cancer (CRC) grading is a critical prognostic factor but remains hampered by inter-observer variability and the privacy constraints of multi-institutional data sharing. While deep learning offers a path to automation, centralized training models conflict with data governance regulations and neglect the diagnostic importance of multi-scale analysis. In this work, we propose a scalable, privacy-preserving federated learning (FL) framework for CRC histopathological grading that integrates multi-scale feature learning within a distributed training paradigm. Our approach employs a dual-stream ResNetRS50 backbone to concurrently capture fine-grained nuclear detail and broader tissue-level context. This architecture is integrated into a robust FL system stabilized using FedProx to mitigate client drift across heterogeneous data distributions from multiple hospitals. Extensive evaluation on the CRC-HGD dataset demonstrates that our framework achieves an overall accuracy of 83.5%, outperforming a comparable centralized model (81.6%). Crucially, the system excels in identifying the most aggressive Grade III tumors with a high recall of 87.5%, a key clinical priority to prevent dangerous false negatives. Performance further improves with higher magnification, reaching 88.0% accuracy at 40x. These results validate that our federated multi-scale approach not only preserves patient privacy but also enhances model performance and generalization. The proposed modular pipeline, with built-in preprocessing, checkpointing, and error handling, establishes a foundational step toward deployable, privacy-aware clinical AI for digital pathology.",
    "fetched_at": "2025-11-07T02:16:47.493018Z"
  },
  {
    "id": "2511.03695v1",
    "title": "Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online   RL",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lipeng Zu",
      "Hansong Zhou",
      "Xiaonan Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03695v1",
    "abstract": "Offline reinforcement learning (RL) enables training from fixed data without online interaction, but policies learned offline often struggle when deployed in dynamic environments due to distributional shift and unreliable value estimates on unseen state-action pairs. We introduce Behavior-Adaptive Q-Learning (BAQ), a framework designed to enable a smooth and reliable transition from offline to online RL. The key idea is to leverage an implicit behavioral model derived from offline data to provide a behavior-consistency signal during online fine-tuning. BAQ incorporates a dual-objective loss that (i) aligns the online policy toward the offline behavior when uncertainty is high, and (ii) gradually relaxes this constraint as more confident online experience is accumulated. This adaptive mechanism reduces error propagation from out-of-distribution estimates, stabilizes early online updates, and accelerates adaptation to new scenarios. Across standard benchmarks, BAQ consistently outperforms prior offline-to-online RL approaches, achieving faster recovery, improved robustness, and higher overall performance. Our results demonstrate that implicit behavior adaptation is a principled and practical solution for reliable real-world policy deployment.",
    "fetched_at": "2025-11-07T02:16:47.492954Z"
  },
  {
    "id": "2511.03699v1",
    "title": "Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset   in Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Francesco Corso",
      "Francesco Pierri",
      "Gianmarco De Francisci Morales"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03699v1",
    "abstract": "In this paper, we investigate whether Large Language Models (LLMs) exhibit conspiratorial tendencies, whether they display sociodemographic biases in this domain, and how easily they can be conditioned into adopting conspiratorial perspectives. Conspiracy beliefs play a central role in the spread of misinformation and in shaping distrust toward institutions, making them a critical testbed for evaluating the social fidelity of LLMs. LLMs are increasingly used as proxies for studying human behavior, yet little is known about whether they reproduce higher-order psychological constructs such as a conspiratorial mindset. To bridge this research gap, we administer validated psychometric surveys measuring conspiracy mindset to multiple models under different prompting and conditioning strategies. Our findings reveal that LLMs show partial agreement with elements of conspiracy belief, and conditioning with socio-demographic attributes produces uneven effects, exposing latent demographic biases. Moreover, targeted prompts can easily shift model responses toward conspiratorial directions, underscoring both the susceptibility of LLMs to manipulation and the potential risks of their deployment in sensitive contexts. These results highlight the importance of critically evaluating the psychological dimensions embedded in LLMs, both to advance computational social science and to inform possible mitigation strategies against harmful uses.",
    "fetched_at": "2025-11-07T02:16:47.492859Z"
  },
  {
    "id": "2511.03708v1",
    "title": "The Adaptivity Barrier in Batched Nonparametric Bandits: Sharp   Characterization of the Price of Unknown Margin",
    "date": "2025-11-05",
    "tags": [
      "math.ST",
      "ST",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Rong Jiang",
      "Cong Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03708v1",
    "abstract": "We study batched nonparametric contextual bandits under a margin condition when the margin parameter $\\alpha$ is unknown. To capture the statistical price of this ignorance, we introduce the regret inflation criterion, defined as the ratio between the regret of an adaptive algorithm and that of an oracle knowing $\\alpha$. We show that the optimal regret inflation grows polynomial with the horizon $T$, with exponent precisely given by the value of a convex optimization problem involving the dimension, smoothness, and batch budget. Moreover, the minimizers of this optimization problem directly prescribe the batch allocation and exploration strategy of a rate-optimal algorithm. Building on this principle, we develop RoBIN (RObust batched algorithm with adaptive BINning), which achieves the optimal regret inflation up to logarithmic factors. These results reveal a new adaptivity barrier: under batching, adaptation to an unknown margin parameter inevitably incurs a polynomial penalty, sharply characterized by a variational problem. Remarkably, this barrier vanishes when the number of batches exceeds $\\log \\log T$; with only a doubly logarithmic number of updates, one can recover the oracle regret rate up to polylogarithmic factors.",
    "fetched_at": "2025-11-07T02:16:47.492810Z"
  },
  {
    "id": "2511.03710v1",
    "title": "Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning   with Verifiable Rewards",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Guanning Zeng",
      "Zhaoyi Zhou",
      "Daman Arora",
      "Andrea Zanette"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03710v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for post-training large reasoning models (LRMs) using policy-gradient methods such as GRPO. To stabilize training, these methods typically center trajectory rewards by subtracting the empirical mean for each prompt. Statistically, this centering acts as a control variate (or baseline), reducing the variance of the policy-gradient estimator.   Typically, the mean reward is estimated using per-prompt empirical averages for each prompt in a batch. Drawing inspiration from Stein's paradox, we propose using shrinkage estimators that combine per-prompt and across-prompt means to improve the overall per-prompt mean estimation accuracy -- particularly in the low-generation regime typical of RLVR. Theoretically, we construct a shrinkage-based baseline that provably yields lower-variance policy-gradient estimators across algorithms. Our proposed baseline serves as a drop-in replacement for existing per-prompt mean baselines, requiring no additional hyper-parameters or computation. Empirically, shrinkage baselines consistently outperform standard empirical-mean baselines, leading to lower-variance gradient updates and improved training stability.",
    "fetched_at": "2025-11-07T02:16:47.492764Z"
  },
  {
    "id": "2511.03718v1",
    "title": "Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist   Annotation Scheme for MapTask",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nan Li",
      "Albert Gatt",
      "Massimo Poesio"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03718v1",
    "abstract": "Collaborative dialogue relies on participants incrementally establishing common ground, yet in asymmetric settings they may believe they agree while referring to different entities. We introduce a perspectivist annotation scheme for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures speaker and addressee grounded interpretations for each reference expression, enabling us to trace how understanding emerges, diverges, and repairs over time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k annotated reference expressions with reliability estimates and analyze the resulting understanding states. The results show that full misunderstandings are rare once lexical variants are unified, but multiplicity discrepancies systematically induce divergences, revealing how apparent grounding can mask referential misalignment. Our framework provides both a resource and an analytic lens for studying grounded misunderstanding and for evaluating (V)LLMs' capacity to model perspective-dependent grounding in collaborative dialogue.",
    "fetched_at": "2025-11-07T02:16:47.492711Z"
  },
  {
    "id": "2511.02192v1",
    "title": "A Quantitative Comparison of Centralised and Distributed Reinforcement   Learning-Based Control for Soft Robotic Arms",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Linxin Hou",
      "Qirui Wu",
      "Zhihang Qin",
      "Neil Banerjee",
      "Yongxin Guo",
      "Cecilia Laschi"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.02192v1",
    "abstract": "This paper presents a quantitative comparison between centralised and distributed multi-agent reinforcement learning (MARL) architectures for controlling a soft robotic arm modelled as a Cosserat rod in simulation. Using PyElastica and the OpenAI Gym interface, we train both a global Proximal Policy Optimisation (PPO) controller and a Multi-Agent PPO (MAPPO) under identical budgets. Both approaches are based on the arm having $n$ number of controlled sections. The study systematically varies $n$ and evaluates the performance of the arm to reach a fixed target in three scenarios: default baseline condition, recovery from external disturbance, and adaptation to actuator failure. Quantitative metrics used for the evaluation are mean action magnitude, mean final distance, mean episode length, and success rate. The results show that there are no significant benefits of the distributed policy when the number of controlled sections $n\\le4$. In very simple systems, when $n\\le2$, the centralised policy outperforms the distributed one. When $n$ increases to $4< n\\le 12$, the distributed policy shows a high sample efficiency. In these systems, distributed policy promotes a stronger success rate, resilience, and robustness under local observability and yields faster convergence given the same sample size. However, centralised policies achieve much higher time efficiency during training as it takes much less time to train the same size of samples. These findings highlight the trade-offs between centralised and distributed policy in reinforcement learning-based control for soft robotic systems and provide actionable design guidance for future sim-to-real transfer in soft rod-like manipulators.",
    "fetched_at": "2025-11-09T02:21:24.638277Z"
  },
  {
    "id": "2511.02216v1",
    "title": "Adaptive Cooperative Transmission Design for Ultra-Reliable Low-Latency   Communications via Deep Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.IT",
      "IT",
      "cs.AI",
      "AI",
      "math.IT"
    ],
    "authors": [
      "Hyemin Yu",
      "Hong-Chuan Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02216v1",
    "abstract": "Next-generation wireless communication systems must support ultra-reliable low-latency communication (URLLC) service for mission-critical applications. Meeting stringent URLLC requirements is challenging, especially for two-hop cooperative communication. In this paper, we develop an adaptive transmission design for a two-hop relaying communication system. Each hop transmission adaptively configures its transmission parameters separately, including numerology, mini-slot size, and modulation and coding scheme, for reliable packet transmission within a strict latency constraint. We formulate the hop-specific transceiver configuration as a Markov decision process (MDP) and propose a dual-agent reinforcement learning-based cooperative latency-aware transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies in a distributed manner. Simulation results verify that the proposed algorithm achieves the near-optimal reliability while satisfying strict latency requirements.",
    "fetched_at": "2025-11-09T02:21:24.638164Z"
  },
  {
    "id": "2511.02225v1",
    "title": "Learning Interactive World Model for Object-Centric Reinforcement   Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fan Feng",
      "Phillip Lippe",
      "Sara Magliacane"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02225v1",
    "abstract": "Agents that understand objects and their interactions can learn policies that are more robust and transferable. However, most object-centric RL methods factor state by individual objects while leaving interactions implicit. We introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a unified framework that learns structured representations of both objects and their interactions within a world model. FIOC-WM captures environment dynamics with disentangled and modular representations of object interactions, improving sample efficiency and generalization for policy learning. Concretely, FIOC-WM first learns object-centric latents and an interaction structure directly from pixels, leveraging pre-trained vision encoders. The learned world model then decomposes tasks into composable interaction primitives, and a hierarchical policy is trained on top: a high level selects the type and order of interactions, while a low level executes them. On simulated robotic and embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and generalization over world-model baselines, indicating that explicit, modular interaction learning is crucial for robust control.",
    "fetched_at": "2025-11-09T02:21:24.638061Z"
  },
  {
    "id": "2511.02241v1",
    "title": "Structural Plasticity as Active Inference: A Biologically-Inspired   Architecture for Homeostatic Control",
    "date": "2025-11-04",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC",
      "68T07, 92B20",
      "I.2.6; I.2.0; I.2.11",
      "11"
    ],
    "authors": [
      "Brennen A. Hill"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02241v1",
    "abstract": "Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",
    "fetched_at": "2025-11-09T02:21:24.637844Z"
  },
  {
    "id": "2511.02304v1",
    "title": "Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.FL",
      "FL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Beyazit Yalcinkaya",
      "Marcell Vazquez-Chanlatte",
      "Ameesh Shah",
      "Hanna Krasowski",
      "Sanjit A. Seshia"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02304v1",
    "abstract": "We study the problem of learning multi-task, multi-agent policies for cooperative, temporal objectives, under centralized training, decentralized execution. In this setting, using automata to represent tasks enables the decomposition of complex tasks into simpler sub-tasks that can be assigned to agents. However, existing approaches remain sample-inefficient and are limited to the single-task case. In this work, we present Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for learning task-conditioned, decentralized team policies. We identify the main challenges to ACC-MARL's feasibility in practice, propose solutions, and prove the correctness of our approach. We further show that the value functions of learned policies can be used to assign tasks optimally at test time. Experiments show emergent task-aware, multi-step coordination among agents, e.g., pressing a button to unlock a door, holding the door, and short-circuiting tasks.",
    "fetched_at": "2025-11-09T02:21:24.637674Z"
  },
  {
    "id": "2511.02314v1",
    "title": "Large-scale automatic carbon ion treatment planning for head and neck   cancers via parallel multi-agent reinforcement learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Jueye Zhang",
      "Chao Yang",
      "Youfang Lai",
      "Kai-Wen Li",
      "Wenting Yan",
      "Yunzhou Xia",
      "Haimei Zhang",
      "Jingjing Zhou",
      "Gen Yang",
      "Chen Lin",
      "Tian Li",
      "Yibao Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02314v1",
    "abstract": "Head-and-neck cancer (HNC) planning is difficult because multiple critical organs-at-risk (OARs) are close to complex targets. Intensity-modulated carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but remains slow due to relative biological effectiveness (RBE) modeling, leading to laborious, experience-based, and often suboptimal tuning of many treatment-planning parameters (TPPs). Recent deep learning (DL) methods are limited by data bias and plan feasibility, while reinforcement learning (RL) struggles to efficiently explore the exponentially large TPP search space. We propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45 TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE) QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for stable learning in a high-dimensional, non-stationary environment. To enhance efficiency, we (1) use compact historical DVH vectors as state inputs, (2) apply a linear action-to-value transform mapping small discrete actions to uniform parameter adjustments, and (3) design an absolute, clinically informed piecewise reward aligned with plan scores. A synchronous multi-process worker system interfaces with the PHOENIX TPS for parallel optimization and accelerated data collection. On a head-and-neck dataset (10 training, 10 testing), the method tuned 45 parameters simultaneously and produced plans comparable to or better than expert manual ones (relative plan score: RL $85.93\\pm7.85%$ vs Manual $85.02\\pm6.92%$), with significant (p-value $<$ 0.05) improvements for five OARs. The framework efficiently explores high-dimensional TPP spaces and generates clinically competitive IMCT plans through direct TPS interaction, notably improving OAR sparing.",
    "fetched_at": "2025-11-09T02:21:24.637626Z"
  },
  {
    "id": "2511.02317v2",
    "title": "Fiedler-Based Characterization and Identification of Leaders in   Semi-Autonomous Networks",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC"
    ],
    "authors": [
      "Evyatar Matmon",
      "Daniel Zelazo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02317v2",
    "abstract": "This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.",
    "fetched_at": "2025-11-09T02:21:24.637552Z"
  },
  {
    "id": "2511.02504v1",
    "title": "Dexterous Robotic Piano Playing at Scale",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Le Chen",
      "Yi Zhao",
      "Jan Schneider",
      "Quankai Gao",
      "Simon Guist",
      "Cheng Qian",
      "Juho Kannala",
      "Bernhard Schölkopf",
      "Joni Pajarinen",
      "Dieter Büchler"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02504v1",
    "abstract": "Endowing robot hands with human-level dexterity has been a long-standing goal in robotics. Bimanual robotic piano playing represents a particularly challenging task: it is high-dimensional, contact-rich, and requires fast, precise control. We present OmniPianist, the first agent capable of performing nearly one thousand music pieces via scalable, human-demonstration-free learning. Our approach is built on three core components. First, we introduce an automatic fingering strategy based on Optimal Transport (OT), allowing the agent to autonomously discover efficient piano-playing strategies from scratch without demonstrations. Second, we conduct large-scale Reinforcement Learning (RL) by training more than 2,000 agents, each specialized in distinct music pieces, and aggregate their experience into a dataset named RP1M++, consisting of over one million trajectories for robotic piano playing. Finally, we employ a Flow Matching Transformer to leverage RP1M++ through large-scale imitation learning, resulting in the OmniPianist agent capable of performing a wide range of musical pieces. Extensive experiments and ablation studies highlight the effectiveness and scalability of our approach, advancing dexterous robotic piano playing at scale.",
    "fetched_at": "2025-11-09T02:21:24.637333Z"
  },
  {
    "id": "2511.02532v1",
    "title": "Agentic AI for Mobile Network RAN Management and Optimization",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jorge Pellejero",
      "Luis A. Hernández Gómez",
      "Luis Mendo Tomás",
      "Zoraida Frias Barroso"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02532v1",
    "abstract": "Agentic AI represents a new paradigm for automating complex systems by using Large AI Models (LAMs) to provide human-level cognitive abilities with multimodal perception, planning, memory, and reasoning capabilities. This will lead to a new generation of AI systems that autonomously decompose goals, retain context over time, learn continuously, operate across tools and environments, and adapt dynamically. The complexity of 5G and upcoming 6G networks renders manual optimization ineffective, pointing to Agentic AI as a method for automating decisions in dynamic RAN environments. However, despite its rapid advances, there is no established framework outlining the foundational components and operational principles of Agentic AI systems nor a universally accepted definition.   This paper contributes to ongoing research on Agentic AI in 5G and 6G networks by outlining its core concepts and then proposing a practical use case that applies Agentic principles to RAN optimization. We first introduce Agentic AI, tracing its evolution from classical agents and discussing the progress from workflows and simple AI agents to Agentic AI. Core design patterns-reflection, planning, tool use, and multi-agent collaboration-are then described to illustrate how intelligent behaviors are orchestrated. These theorical concepts are grounded in the context of mobile networks, with a focus on RAN management and optimization. A practical 5G RAN case study shows how time-series analytics and LAM-driven agents collaborate for KPI-based autonomous decision-making.",
    "fetched_at": "2025-11-09T02:21:24.637270Z"
  },
  {
    "id": "2511.02560v1",
    "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated   Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Dan Bohus",
      "Sean Andrist",
      "Ann Paradiso",
      "Nick Saw",
      "Tim Schoonbeek",
      "Maia Stiber"
    ],
    "institution": "Microsoft",
    "link": "http://arxiv.org/pdf/2511.02560v1",
    "abstract": "We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operating in this space. In future work, we plan to use the dataset to construct a set of benchmarks for physically situated collaboration in mixed-reality task assistive scenarios. SigmaCollab is available at https://github.com/microsoft/SigmaCollab.",
    "fetched_at": "2025-11-09T02:21:24.637219Z"
  },
  {
    "id": "2511.02605v1",
    "title": "Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in   Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Tiberiu-Andrei Georgescu",
      "Alexander W. Goodall",
      "Dalal Alrajeh",
      "Francesco Belardinelli",
      "Sebastian Uchitel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02605v1",
    "abstract": "Shielding is widely used to enforce safety in reinforcement learning (RL), ensuring that an agent's actions remain compliant with formal specifications. Classical shielding approaches, however, are often static, in the sense that they assume fixed logical specifications and hand-crafted abstractions. While these static shields provide safety under nominal assumptions, they fail to adapt when environment assumptions are violated. In this paper, we develop the first adaptive shielding framework - to the best of our knowledge - based on Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and expressive fragment of Linear Temporal Logic (LTL) that captures both safety and liveness properties. Our method detects environment assumption violations at runtime and employs Inductive Logic Programming (ILP) to automatically repair GR(1) specifications online, in a systematic and interpretable way. This ensures that the shield evolves gracefully, ensuring liveness is achievable and weakening goals only when necessary. We consider two case studies: Minepump and Atari Seaquest; showing that (i) static symbolic controllers are often severely suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped with our adaptive shield maintain near-optimal reward and perfect logical compliance compared with static shields.",
    "fetched_at": "2025-11-09T02:21:24.637167Z"
  },
  {
    "id": "2511.02606v1",
    "title": "A Multi-Agent Psychological Simulation System for Human Behavior   Modeling",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Xiangen Hu",
      "Jiarui Tong",
      "Sheng Xu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02606v1",
    "abstract": "Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher training and research, and discuss how it embodies principles of social learning, cognitive apprenticeship, deliberate practice, and meta-cognition.",
    "fetched_at": "2025-11-09T02:21:24.637110Z"
  },
  {
    "id": "2511.02762v1",
    "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with   Single-Agent Demos",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Xun Wang",
      "Zhuoran Li",
      "Yanshan Lin",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02762v1",
    "abstract": "Training a team of agents from scratch in multi-agent reinforcement learning (MARL) is highly inefficient, much like asking beginners to play a symphony together without first practicing solo. Existing methods, such as offline or transferable MARL, can ease this burden, but they still rely on costly multi-agent data, which often becomes the bottleneck. In contrast, solo experiences are far easier to obtain in many important scenarios, e.g., collaborative coding, household cooperation, and search-and-rescue. To unlock their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that transfers solo knowledge into cooperative learning. SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism that combines an MoE-like gating selector and an action editor. Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms. These results demonstrate that solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable.",
    "fetched_at": "2025-11-09T02:21:24.636819Z"
  },
  {
    "id": "2511.02823v1",
    "title": "Optimizing AI Agent Attacks With Synthetic Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chloe Loughridge",
      "Paul Colognese",
      "Avery Griffin",
      "Tyler Tracy",
      "Jon Kutasov",
      "Joe Benton"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02823v1",
    "abstract": "As AI deployments become more complex and high-stakes, it becomes increasingly important to be able to estimate their risk. AI control is one framework for doing so. However, good control evaluations require eliciting strong attack policies. This can be challenging in complex agentic environments where compute constraints leave us data-poor. In this work, we show how to optimize attack policies in SHADE-Arena, a dataset of diverse realistic control environments. We do this by decomposing attack capability into five constituent skills -- suspicion modeling, attack selection, plan synthesis, execution and subtlety -- and optimizing each component individually. To get around the constraint of limited data, we develop a probabilistic model of attack dynamics, optimize our attack hyperparameters using this simulation, and then show that the results transfer to SHADE-Arena. This results in a substantial improvement in attack strength, reducing safety score from a baseline of 0.87 to 0.41 using our scaffold.",
    "fetched_at": "2025-11-09T02:21:24.636704Z"
  },
  {
    "id": "2511.02957v1",
    "title": "Digital Twin-Driven Pavement Health Monitoring and Maintenance   Optimization Using Graph Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CE",
      "CE",
      "cs.ET",
      "ET",
      "cs.NE",
      "NE",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Mohsin Mahmud Topu",
      "Mahfuz Ahmed Anik",
      "Azmine Toushik Wasi",
      "Md Manjurul Ahsan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02957v1",
    "abstract": "Pavement infrastructure monitoring is challenged by complex spatial dependencies, changing environmental conditions, and non-linear deterioration across road networks. Traditional Pavement Management Systems (PMS) remain largely reactive, lacking real-time intelligence for failure prevention and optimal maintenance planning. To address this, we propose a unified Digital Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven pavement health monitoring and predictive maintenance. Pavement segments and spatial relations are modeled as graph nodes and edges, while real-time UAV, sensor, and LiDAR data stream into the DT. The inductive GNN learns deterioration patterns from graph-structured inputs to forecast distress and enable proactive interventions. Trained on a real-world-inspired dataset with segment attributes and dynamic connectivity, our model achieves an R2 of 0.3798, outperforming baseline regressors and effectively capturing non-linear degradation. We also develop an interactive dashboard and reinforcement learning module for simulation, visualization, and adaptive maintenance planning. This DT-GNN integration enhances forecasting precision and establishes a closed feedback loop for continuous improvement, positioning the approach as a foundation for proactive, intelligent, and sustainable pavement management, with future extensions toward real-world deployment, multi-agent coordination, and smart-city integration.",
    "fetched_at": "2025-11-09T02:21:24.636656Z"
  },
  {
    "id": "2511.02200v1",
    "title": "Optimal-Agent-Selection: State-Aware Routing Framework for Efficient   Multi-Agent Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingbo Wang",
      "Sendong Zhao",
      "Haochun Wang",
      "Yuzheng Fan",
      "Lizhe Zhang",
      "Yan Liu",
      "Ting Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02200v1",
    "abstract": "The emergence of multi-agent systems powered by large language models (LLMs) has unlocked new frontiers in complex task-solving, enabling diverse agents to integrate unique expertise, collaborate flexibly, and address challenges unattainable for individual models. However, the full potential of such systems is hindered by rigid agent scheduling and inefficient coordination strategies that fail to adapt to evolving task requirements. In this paper, we propose STRMAC, a state-aware routing framework designed for efficient collaboration in multi-agent systems. Our method separately encodes interaction history and agent knowledge to power the router, which adaptively selects the most suitable single agent at each step for efficient and effective collaboration. Furthermore, we introduce a self-evolving data generation approach that accelerates the collection of high-quality execution paths for efficient system training. Experiments on challenging collaborative reasoning benchmarks demonstrate that our method achieves state-of-the-art performance, achieving up to 23.8% improvement over baselines and reducing data collection overhead by up to 90.1% compared to exhaustive search.",
    "fetched_at": "2025-11-09T02:21:22.888774Z"
  },
  {
    "id": "2511.02208v1",
    "title": "Training Proactive and Personalized LLM Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Weiwei Sun",
      "Xuhui Zhou",
      "Weihua Du",
      "Xingyao Wang",
      "Sean Welleck",
      "Graham Neubig",
      "Maarten Sap",
      "Yiming Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02208v1",
    "abstract": "While existing work focuses primarily on task success, we argue that effective real-world agents require optimizing three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to diverse user preferences). We introduce UserVille, an interactive environment with LLM-based user simulators enabling diverse, configurable user preferences. Leveraging UserVille, we introduce PPP, a multi-objective reinforcement learning approach that jointly optimizes all three dimensions: Productivity, Proactivity, and Personalization. Experiments on software engineering and deep research tasks show that agents trained with PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6 on average), demonstrating the ability to ask strategic clarifying questions, adapt to unseen user preferences, and improve task success through better interaction. This work demonstrates that explicitly optimizing for user-centered interaction is critical for building practical and effective AI agents.",
    "fetched_at": "2025-11-09T02:21:22.888720Z"
  },
  {
    "id": "2511.02223v1",
    "title": "Quantitative Risk Assessment in Radiation Oncology via LLM-Powered Root   Cause Analysis of Incident Reports",
    "date": "2025-11-04",
    "tags": [
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Yuntao Wang",
      "Siamak P. Najad-Davarani",
      "Elizabeth Bossart",
      "Matthew T. Studenski",
      "Mariluz De Ornelas",
      "Yunze Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02223v1",
    "abstract": "Background: Modern large language models (LLMs) offer powerful reasoning that converts narratives into structured, taxonomy-aligned data, revealing patterns across planning, delivery, and verification. Embedded as agentic tools, LLMs can assist root-cause analysis and risk assessment (e.g., failure mode and effect analysis FMEA), produce auditable rationales, and draft targeted mitigation actions.   Methods: We developed a data-driven pipeline utilizing an LLM to perform automated root cause analysis on 254 institutional safety incidents. The LLM systematically classified each incident into structured taxonomies for radiotherapy pathway steps and contributory factors. Subsequent quantitative analyses included descriptive statistics, Analysis of Variance (ANOVA), multiple Ordinal Logistic Regression (OLR) analyses to identify predictors of event severity, and Association Rule Mining (ARM) to uncover systemic vulnerabilities.   Results: The high-level Ordinal Logistic Regression (OLR) models identified specific, significant drivers of severity. The Pathway model was statistically significant (Pseudo R2 = 0.033, LR p = 0.015), as was the Responsibility model (Pseudo R2 = 0.028, LR p < 0.001). Association Rule Mining (ARM) identified high-confidence systemic rules, such as \"CF5 Teamwork, management and organisational\" (n = 8, Conf = 1.0) and the high-frequency link between \"(11) Pre-treatment planning process\" and \"CF2 Procedural\" (n = 152, Conf = 0.916).   Conclusion: The LLM-powered, data-driven framework provides a more objective and powerful methodology for risk assessment than traditional approaches. Our findings empirically demonstrate that interventions focused on fortifying high-risk process steps and mitigating systemic failures are most effective for improving patient safety.",
    "fetched_at": "2025-11-09T02:21:22.888666Z"
  },
  {
    "id": "2511.02230v1",
    "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV   Cache Time-to-Live",
    "date": "2025-11-04",
    "tags": [
      "cs.OS",
      "OS",
      "cs.AI",
      "AI",
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Hanchen Li",
      "Qiuyang Mang",
      "Runyuan He",
      "Qizheng Zhang",
      "Huanzhi Mao",
      "Xiaokun Chen",
      "Alvin Cheung",
      "Joseph Gonzalez",
      "Ion Stoica"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02230v1",
    "abstract": "Agentic LLM applications interleave LLM generation requests with tool calls. These tool calls break the continuity of the workflow by creating pauses between LLM requests, bringing many challenges for the serving system, especially under multi-turn scenarios. Each pause potentially causes KV cache eviction and extra waiting time before entering the continuous batch for the following LLM request. Since these pauses happen for each call, this problem becomes increasingly severe as turn number grow for agentic programs. Previous works either fail to incorporate information from the tool call, evicting KV cache that leads to repetitive prefill or loading, or ignore the continuity of a multi-turn program, creating waiting time between turns that increases per-request latency.   We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by combining tool-aware KV cache timeout with program-level scheduling. By predicting tool call durations in agentic workflows, Continuum selectively pins the KV cache in GPU memory with a time-to-live value based on total turn number. When combined with program-level first-come-first-serve, Continuum prevents scheduling bubbles, preserves multi-turn continuity, and optimizes for throughput for complex agentic workflows. By modeling the variability of tool call and agent program continuity, Continuum outperforms state-of-the-art baselines. Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B models shows that Continuum significantly improves the average job completion times, and remains performant across different hardware setups and DRAM offloading schemes. Preview code is available at: https://github.com/Hanchenli/vllm-continuum",
    "fetched_at": "2025-11-09T02:21:22.888610Z"
  },
  {
    "id": "2511.02238v1",
    "title": "Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on   Scientific Concept Network",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Keyu Zhao",
      "Weiquan Lin",
      "Qirui Zheng",
      "Fengli Xu",
      "Yong Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02238v1",
    "abstract": "Novel research ideas play a critical role in advancing scientific inquiries. Recent advancements in Large Language Models (LLMs) have demonstrated their potential to generate novel research ideas by leveraging large-scale scientific literature. However, previous work in research ideation has primarily relied on simplistic methods, such as keyword co-occurrence or semantic similarity. These approaches focus on identifying statistical associations in the literature but overlook the complex, contextual relationships between scientific concepts, which are essential to effectively leverage knowledge embedded in human literature. For instance, papers that simultaneously mention \"keyword A\" and \"keyword B\" often present research ideas that integrate both concepts. Additionally, some LLM-driven methods propose and refine research ideas using the model's internal knowledge, but they fail to effectively utilize the scientific concept network, limiting the grounding of ideas in established research. To address these challenges, we propose the Deep Ideation framework to address these challenges, integrating a scientific network that captures keyword co-occurrence and contextual relationships, enriching LLM-driven ideation. The framework introduces an explore-expand-evolve workflow to iteratively refine research ideas, using an Idea Stack to track progress. A critic engine, trained on real-world reviewer feedback, guides the process by providing continuous feedback on the novelty and feasibility of ideas. Our experiments show that our approach improves the quality of generated ideas by 10.67% compared to other methods, with ideas surpassing top conference acceptance levels. Human evaluation highlights their practical value in scientific research, and ablation studies confirm the effectiveness of each component in the workflow. Code repo is available at https://github.com/kyZhao-1/Deep-Ideation.",
    "fetched_at": "2025-11-09T02:21:22.888544Z"
  },
  {
    "id": "2511.02239v1",
    "title": "LACY: A Vision-Language Model-based Language-Action Cycle for   Self-Improving Robotic Manipulation",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Youngjin Hong",
      "Houjian Yu",
      "Mingen Li",
      "Changhyun Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02239v1",
    "abstract": "Learning generalizable policies for robotic manipulation increasingly relies on large-scale models that map language instructions to actions (L2A). However, this one-way paradigm often produces policies that execute tasks without deeper contextual understanding, limiting their ability to generalize or explain their behavior. We argue that the complementary skill of mapping actions back to language (A2L) is essential for developing more holistic grounding. An agent capable of both acting and explaining its actions can form richer internal representations and unlock new paradigms for self-supervised learning. We introduce LACY (Language-Action Cycle), a unified framework that learns such bidirectional mappings within a single vision-language model. LACY is jointly trained on three synergistic tasks: generating parameterized actions from language (L2A), explaining observed actions in language (A2L), and verifying semantic consistency between two language descriptions (L2C). This enables a self-improving cycle that autonomously generates and filters new training data through an active augmentation strategy targeting low-confidence cases, thereby improving the model without additional human labels. Experiments on pick-and-place tasks in both simulation and the real world show that LACY improves task success rates by 56.46% on average and yields more robust language-action grounding for robotic manipulation. Project page: https://vla2026.github.io/LACY/",
    "fetched_at": "2025-11-09T02:21:22.888488Z"
  },
  {
    "id": "2511.02246v1",
    "title": "Demo: Statistically Significant Results On Biases and Errors of LLMs Do   Not Guarantee Generalizable Results",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jonathan Liu",
      "Haoling Qiu",
      "Jonathan Lasko",
      "Damianos Karakos",
      "Mahsa Yarmohammadi",
      "Mark Dredze"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02246v1",
    "abstract": "Recent research has shown that hallucinations, omissions, and biases are prevalent in everyday use-cases of LLMs. However, chatbots used in medical contexts must provide consistent advice in situations where non-medical factors are involved, such as when demographic information is present. In order to understand the conditions under which medical chatbots fail to perform as expected, we develop an infrastructure that 1) automatically generates queries to probe LLMs and 2) evaluates answers to these queries using multiple LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples the space of patient demographics, histories, disorders, and writing styles to create realistic questions that we subsequently use to prompt LLMs. In 2), our evaluation pipeline provides hallucination and omission detection using LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge treatment category detectors. As a baseline study, we perform two case studies on inter-LLM agreement and the impact of varying the answering and evaluation LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's Kappa $\\kappa=0.118$), and only specific (answering, evaluation) LLM pairs yield statistically significant differences across writing styles, genders, and races. We recommend that studies using LLM evaluation use multiple LLMs as evaluators in order to avoid arriving at statistically significant but non-generalizable results, particularly in the absence of ground-truth data. We also suggest publishing inter-LLM agreement metrics for transparency. Our code and dataset are available here: https://github.com/BBN-E/medic-neurips-2025-demo.",
    "fetched_at": "2025-11-09T02:21:22.888440Z"
  },
  {
    "id": "2511.02303v1",
    "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents   to Deliberation",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zhiwei Zhang",
      "Xiaomin Li",
      "Yudi Lin",
      "Hui Liu",
      "Ramraj Chandradevan",
      "Linlin Wu",
      "Minhua Lin",
      "Fali Wang",
      "Xianfeng Tang",
      "Qi He",
      "Suhang Wang"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02303v1",
    "abstract": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping mitigate this issue. Finally, as collaboration intensifies, the reasoning agent risks getting lost in multi-turn interactions and trapped by previous noisy responses. To counter this, we propose a verifiable reward mechanism that encourages deliberation by allowing the reasoning agent to discard noisy outputs, consolidate instructions, and restart its reasoning process when necessary. Extensive experiments demonstrate that our framework alleviates lazy agent behavior and unlocks the full potential of multi-agent framework for complex reasoning tasks.",
    "fetched_at": "2025-11-09T02:21:22.888383Z"
  },
  {
    "id": "2511.02366v1",
    "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for   LLMs in Chinese Context",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yudong Li",
      "Zhongliang Yang",
      "Kejiang Chen",
      "Wenxuan Wang",
      "Tianxin Zhang",
      "Sifang Wan",
      "Kecheng Wang",
      "Haitian Li",
      "Xu Wang",
      "Lefan Cheng",
      "Youdan Yang",
      "Baocheng Chen",
      "Ziyu Liu",
      "Yufei Sun",
      "Liyan Wu",
      "Wenya Wen",
      "Xingchi Gu",
      "Peiru Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02366v1",
    "abstract": "In this work, we propose LiveSecBench, a dynamic and continuously updated safety benchmark specifically for Chinese-language LLM application scenarios. LiveSecBench evaluates models across six critical dimensions (Legality, Ethics, Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in the Chinese legal and social frameworks. This benchmark maintains relevance through a dynamic update schedule that incorporates new threat vectors, such as the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs, providing a landscape of AI safety in the context of Chinese language. The leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.",
    "fetched_at": "2025-11-09T02:21:22.888315Z"
  },
  {
    "id": "2511.02371v1",
    "title": "LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming   Alignment",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rohan Wandre",
      "Yash Gajewar",
      "Namrata Patel",
      "Vivek Dhalkari"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02371v1",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for grounding large language model outputs in verifiable evidence. However, as modern AI agents transition from static knowledge bases to continuous multimodal streams encompassing text, images, video, and audio, two critical challenges arise: maintaining index freshness without prohibitive re-indexing costs, and preserving cross-modal semantic consistency across heterogeneous embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture featuring three key innovations: (i) a streaming, multi-tier memory system that dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that maintains cross-modal consistency through incremental orthogonal Procrustes updates; and (iii) stability-aware retrieval telemetry providing Safe@k guarantees by jointly bounding alignment drift and quantization error. Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94), graceful performance degradation under product quantization offloading, and provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG as a practical framework for production multimodal RAG systems.",
    "fetched_at": "2025-11-09T02:21:22.888232Z"
  },
  {
    "id": "2511.02378v1",
    "title": "Revisiting put-that-there, context aware window interactions via LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Riccardo Bovo",
      "Daniele Giunchi",
      "Pasquale Cascarano",
      "Eric J. Gonzalez",
      "Mar Gonzalez-Franco"
    ],
    "institution": "Google, Meta",
    "link": "http://arxiv.org/pdf/2511.02378v1",
    "abstract": "We revisit Bolt's classic \"Put-That-There\" concept for modern head-mounted displays by pairing Large Language Models (LLMs) with XR sensor and tech stack. The agent fuses (i) a semantically segmented 3-D environment, (ii) live application metadata, and (iii) users' verbal, pointing, and head-gaze cues to issue JSON window-placement actions. As a result, users can manage a panoramic workspace through: (1) explicit commands (\"Place Google Maps on the coffee table\"), (2) deictic speech plus gestures (\"Put that there\"), or (3) high-level goals (\"I need to send a message\"). Unlike traditional explicit interfaces, our system supports one-to-many action mappings and goal-centric reasoning, allowing the LLM to dynamically infer relevant applications and layout decisions, including interrelationships across tools. This enables seamless, intent-driven interaction without manual window juggling in immersive XR environments.",
    "fetched_at": "2025-11-09T02:21:22.888186Z"
  },
  {
    "id": "2511.02399v1",
    "title": "EvoDev: An Iterative Feature-Driven Framework for End-to-End Software   Development with LLM-based Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junwei Liu",
      "Chen Xu",
      "Chong Wang",
      "Tong Bai",
      "Weitong Chen",
      "Kaseng Wong",
      "Yiling Lou",
      "Xin Peng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02399v1",
    "abstract": "Recent advances in large language model agents offer the promise of automating end-to-end software development from natural language requirements. However, existing approaches largely adopt linear, waterfall-style pipelines, which oversimplify the iterative nature of real-world development and struggle with complex, large-scale projects. To address these limitations, we propose EvoDev, an iterative software development framework inspired by feature-driven development. EvoDev decomposes user requirements into a set of user-valued features and constructs a Feature Map, a directed acyclic graph that explicitly models dependencies between features. Each node in the feature map maintains multi-level information, including business logic, design, and code, which is propagated along dependencies to provide context for subsequent development iterations. We evaluate EvoDev on challenging Android development tasks and show that it outperforms the best-performing baseline, Claude Code, by a substantial margin of 56.8%, while improving single-agent performance by 16.0%-76.6% across different base LLMs, highlighting the importance of dependency modeling, context propagation, and workflow-aware agent design for complex software projects. Our work summarizes practical insights for designing iterative, LLM-driven development frameworks and informs future training of base LLMs to better support iterative software development.",
    "fetched_at": "2025-11-09T02:21:22.888110Z"
  },
  {
    "id": "2511.02424v1",
    "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for   Long-Horizon Task Planning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jae-Woo Choi",
      "Hyungmin Kim",
      "Hyobin Ong",
      "Minsu Jang",
      "Dohyung Kim",
      "Jaehong Kim",
      "Youngwoo Yoon"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02424v1",
    "abstract": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents. However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process. To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree. Each subgoal is handled by an LLM agent node capable of reasoning, acting, and further expanding the tree, while control flow nodes coordinate the execution strategies of agent nodes. In addition, we integrate two complementary memory systems: each agent node retrieves goal-specific, subgoal-level examples from episodic memory and shares environment-specific observations through working memory. Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs. Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.",
    "fetched_at": "2025-11-09T02:21:22.888053Z"
  },
  {
    "id": "2511.02427v1",
    "title": "From the Laboratory to Real-World Application: Evaluating Zero-Shot   Scene Interpretation on Edge Devices for Mobile Robotics",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Nicolas Schuler",
      "Lea Dewald",
      "Nick Baldig",
      "Jürgen Graf"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02427v1",
    "abstract": "Video Understanding, Scene Interpretation and Commonsense Reasoning are highly challenging tasks enabling the interpretation of visual information, allowing agents to perceive, interact with and make rational decisions in its environment. Large Language Models (LLMs) and Visual Language Models (VLMs) have shown remarkable advancements in these areas in recent years, enabling domain-specific applications as well as zero-shot open vocabulary tasks, combining multiple domains. However, the required computational complexity poses challenges for their application on edge devices and in the context of Mobile Robotics, especially considering the trade-off between accuracy and inference time. In this paper, we investigate the capabilities of state-of-the-art VLMs for the task of Scene Interpretation and Action Recognition, with special regard to small VLMs capable of being deployed to edge devices in the context of Mobile Robotics. The proposed pipeline is evaluated on a diverse dataset consisting of various real-world cityscape, on-campus and indoor scenarios. The experimental evaluation discusses the potential of these small models on edge devices, with particular emphasis on challenges, weaknesses, inherent model biases and the application of the gained information. Supplementary material is provided via the following repository: https://datahub.rz.rptu.de/hstr-csrl-public/publications/scene-interpretation-on-edge-devices/",
    "fetched_at": "2025-11-09T02:21:22.888001Z"
  },
  {
    "id": "2511.02469v1",
    "title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs   for Monetary Policy Decision Classification",
    "date": "2025-11-04",
    "tags": [
      "q-fin.CP",
      "CP",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kaito Takano",
      "Masanori Hirano",
      "Kei Nakagawa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02469v1",
    "abstract": "Accurately forecasting central bank policy decisions, particularly those of the Federal Open Market Committee(FOMC) has become increasingly important amid heightened economic uncertainty. While prior studies have used monetary policy texts to predict rate changes, most rely on static classification models that overlook the deliberative nature of policymaking. This study proposes a novel framework that structurally imitates the FOMC's collective decision-making process by modeling multiple large language models(LLMs) as interacting agents. Each agent begins with a distinct initial belief and produces a prediction based on both qualitative policy texts and quantitative macroeconomic indicators. Through iterative rounds, agents revise their predictions by observing the outputs of others, simulating deliberation and consensus formation. To enhance interpretability, we introduce a latent variable representing each agent's underlying belief(e.g., hawkish or dovish), and we theoretically demonstrate how this belief mediates the perception of input information and interaction dynamics. Empirical results show that this debate-based approach significantly outperforms standard LLMs-based baselines in prediction accuracy. Furthermore, the explicit modeling of beliefs provides insights into how individual perspectives and social influence shape collective policy forecasts.",
    "fetched_at": "2025-11-09T02:21:22.887952Z"
  },
  {
    "id": "2511.02503v1",
    "title": "Adapting General-Purpose Foundation Models for X-ray Ptychography in   Low-Data Regimes",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Robinson Umeike",
      "Neil Getty",
      "Yin Xiangyu",
      "Yi Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02503v1",
    "abstract": "The automation of workflows in advanced microscopy is a key goal where foundation models like Language Models (LLMs) and Vision-Language Models (VLMs) show great potential. However, adapting these general-purpose models for specialized scientific tasks is critical, and the optimal domain adaptation strategy is often unclear. To address this, we introduce PtychoBench, a new multi-modal, multi-task benchmark for ptychographic analysis. Using this benchmark, we systematically compare two specialization strategies: Supervised Fine-Tuning (SFT) and In-Context Learning (ICL). We evaluate these strategies on a visual artifact detection task with VLMs and a textual parameter recommendation task with LLMs in a data-scarce regime. Our findings reveal that the optimal specialization pathway is task-dependent. For the visual task, SFT and ICL are highly complementary, with a fine-tuned model guided by context-aware examples achieving the highest mean performance (Micro-F1 of 0.728). Conversely, for the textual task, ICL on a large base model is the superior strategy, reaching a peak Micro-F1 of 0.847 and outperforming a powerful \"super-expert\" SFT model (0-shot Micro-F1 of 0.839). We also confirm the superiority of context-aware prompting and identify a consistent contextual interference phenomenon in fine-tuned models. These results, benchmarked against strong baselines including GPT-4o and a DINOv3-based classifier, offer key observations for AI in science: the optimal specialization path in our benchmark is dependent on the task modality, offering a clear framework for developing more effective science-based agentic systems.",
    "fetched_at": "2025-11-09T02:21:22.887907Z"
  },
  {
    "id": "2511.02885v1",
    "title": "AgentSLA : Towards a Service Level Agreement for AI Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gwendal Jouneaux",
      "Jordi Cabot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02885v1",
    "abstract": "AI components are increasingly becoming a key element of all types of software systems to enhance their functionality. These AI components are often implemented as AI Agents, offering more autonomy than a plain integration of Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an Agent-as-a-Service one, bringing new challenges to the development of smart software systems. Indeed, while support for the design, implementation, and deployment of those agents exist, the specification of Quality of Service (QoS) and definition of Service Level Agreements (SLAs) aspects for those agents, important to ensure the quality of the resulting systems, remains an open challenge. Part of this is due to the difficulty to clearly define quality in the context of AI components, resulting in a lack of consensus on how to best approach Quality Assurance (QA) for these types of systems. To address this challenge, this paper proposes both a quality model for AI agents based on the ISO/IEC 25010 standard, and a domain specific language to support the definition of SLAs for the services provided by these AI agents.",
    "fetched_at": "2025-11-09T02:21:22.887860Z"
  },
  {
    "id": "2511.02651v1",
    "title": "Apriel-H1: Towards Efficient Enterprise Reasoning Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oleksiy Ostapenko",
      "Luke Kumar",
      "Raymond Li",
      "Denis Kocetkov",
      "Joel Lamy-Poirier",
      "Shruthan Radhakrishna",
      "Soham Parikh",
      "Shambhavi Mishra",
      "Sebastien Paquet",
      "Srinivas Sunkara",
      "Valérie Bécaert",
      "Sathwik Tejaswi Madhusudhan",
      "Torsten Scholak"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02651v1",
    "abstract": "Large Language Models (LLMs) achieve remarkable reasoning capabilities through transformer architectures with attention mechanisms. However, transformers suffer from quadratic time and memory complexity in the attention module (MHA) and require caching key-value states during inference, which severely limits throughput and scalability. High inference throughput is critical for agentic tasks, long-context reasoning, efficient deployment under high request loads, and more efficient test-time compute scaling.   State Space Models (SSMs) such as Mamba offer a promising alternative with linear inference complexity and a constant memory footprint via recurrent computation with fixed-size hidden states. In this technical report we introduce the Apriel-H1 family of hybrid LLMs that combine transformer attention and SSM sequence mixers for efficient reasoning at 15B model size. These models are obtained through incremental distillation from a pretrained reasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing less critical attention layers with linear Mamba blocks.   We release multiple post-distillation variants of Apriel-H1-15B-Thinker with different SSM-to-MHA ratios and analyse how reasoning performance degrades as more Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant of Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces, achieving over 2x higher inference throughput when deployed in the production-ready vLLM environment, with minimal degradation in reasoning performance. This shows that distilled hybrid SSM-Transformer architectures can deliver substantial efficiency gains over the pretrained transformer equivalent without substantially compromising the reasoning quality.",
    "fetched_at": "2025-11-09T02:21:22.887820Z"
  },
  {
    "id": "2511.02690v1",
    "title": "Curriculum Design for Trajectory-Constrained Agent: Compressing   Chain-of-Thought Tokens in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Georgios Tzannetos",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02690v1",
    "abstract": "Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.",
    "fetched_at": "2025-11-09T02:21:22.887740Z"
  },
  {
    "id": "2511.02734v1",
    "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in   Dynamic Environments for LLM Tool-Use Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jiayu Liu",
      "Cheng Qian",
      "Zhaochen Su",
      "Qing Zong",
      "Shijue Huang",
      "Bingxiang He",
      "Yi R. Fung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02734v1",
    "abstract": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability. This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments. To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities. Situated in the travel-planning domain, CostBench comprises tasks solvable via multiple sequences of atomic and composite tools with diverse, customizable costs. It also supports four types of dynamic blocking events, such as tool failures and cost changes, to simulate real-world unpredictability and necessitate agents to adapt in real time. Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. By diagnosing these weaknesses, CostBench lays the groundwork for developing future agents that are both economically rational and robust.",
    "fetched_at": "2025-11-09T02:21:22.887690Z"
  },
  {
    "id": "2511.02748v1",
    "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.NI",
      "NI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Farhad Rezazadeh",
      "Hatim Chergui",
      "Merouane Debbah",
      "Houbing Song",
      "Dusit Niyato",
      "Lingjia Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02748v1",
    "abstract": "We argue that sixth-generation (6G) intelligence is not fluent token prediction but the capacity to imagine and choose -- to simulate future scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe open radio access network (O-RAN) near-real-time (Near-RT) control via counterfactual dynamics and a world modeling (WM) paradigm that learns an action-conditioned generative state space. This enables quantitative \"what-if\" forecasting beyond large language models (LLMs) as the primary modeling primitive. Actions such as physical resource blocks (PRBs) are treated as first-class control inputs in a causal world model, and both aleatoric and epistemic uncertainty are modeled for prediction and what-if analysis. An agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner operates over short horizons, using prior-mean rollouts within data-driven PRB bounds to maximize a deterministic reward. The model couples multi-scale structured state-space mixtures (MS3M) with a compact stochastic latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories and predicting next-step KPIs under hypothetical PRB sequences. On realistic O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with 32% fewer parameters and similar latency, and achieves 35-80% lower root mean squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster inference, enabling rare-event simulation and offline policy screening.",
    "fetched_at": "2025-11-09T02:21:22.887635Z"
  },
  {
    "id": "2511.02755v1",
    "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM   System with Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bowen Jin",
      "TJ Collins",
      "Donghan Yu",
      "Mert Cemri",
      "Shenao Zhang",
      "Mengyu Li",
      "Jay Tang",
      "Tian Qin",
      "Zhiyang Xu",
      "Jiarui Lu",
      "Guoli Yin",
      "Jiawei Han",
      "Zirui Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02755v1",
    "abstract": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
    "fetched_at": "2025-11-09T02:21:22.887581Z"
  },
  {
    "id": "2511.02794v1",
    "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Chenyu Zhang",
      "Minsol Kim",
      "Shohreh Ghorbani",
      "Jingyao Wu",
      "Rosalind Picard",
      "Patricia Maes",
      "Paul Pu Liang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02794v1",
    "abstract": "Despite rapid growth in multimodal large language models (MLLMs), their reasoning traces remain opaque: it is often unclear which modality drives a prediction, how conflicts are resolved, or when one stream dominates. In this paper, we introduce modality sabotage, a diagnostic failure mode in which a high-confidence unimodal error overrides other evidence and misleads the fused result. To analyze such dynamics, we propose a lightweight, model-agnostic evaluation layer that treats each modality as an agent, producing candidate labels and a brief self-assessment used for auditing. A simple fusion mechanism aggregates these outputs, exposing contributors (modalities supporting correct outcomes) and saboteurs (modalities that mislead). Applying our diagnostic layer in a case study on multimodal emotion recognition benchmarks with foundation models revealed systematic reliability profiles, providing insight into whether failures may arise from dataset artifacts or model limitations. More broadly, our framework offers a diagnostic scaffold for multimodal reasoning, supporting principled auditing of fusion dynamics and informing possible interventions.",
    "fetched_at": "2025-11-09T02:21:22.887507Z"
  },
  {
    "id": "2511.02805v1",
    "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via   End-to-End Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qianhao Yuan",
      "Jie Lou",
      "Zichao Li",
      "Jiawei Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Le Sun",
      "Debing Zhang",
      "Xianpei Han"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02805v1",
    "abstract": "Typical search agents concatenate the entire interaction history into the LLM context, preserving information integrity but producing long, noisy contexts, resulting in high computation and memory costs. In contrast, using only the current turn avoids this overhead but discards essential information. This trade-off limits the scalability of search agents. To address this challenge, we propose MemSearcher, an agent workflow that iteratively maintains a compact memory and combines the current turn with it. At each turn, MemSearcher fuses the user's question with the memory to generate reasoning traces, perform search actions, and update memory to retain only information essential for solving the task. This design stabilizes context length across multi-turn interactions, improving efficiency without sacrificing accuracy. To optimize this workflow, we introduce multi-context GRPO, an end-to-end RL framework that jointly optimize reasoning, search strategies, and memory management of MemSearcher Agents. Specifically, multi-context GRPO samples groups of trajectories under different contexts and propagates trajectory-level advantages across all conversations within them. Trained on the same dataset as Search-R1, MemSearcher achieves significant improvements over strong baselines on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher even outperforms 7B-based baselines, demonstrating that striking a balance between information integrity and efficiency yields both higher accuracy and lower computational overhead. The code and models will be publicly available at https://github.com/icip-cas/MemSearcher",
    "fetched_at": "2025-11-09T02:21:22.887450Z"
  },
  {
    "id": "2511.02834v2",
    "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for   Understanding Anything",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Huawei Lin",
      "Yunzhi Shi",
      "Tong Geng",
      "Weijie Zhao",
      "Wei Wang",
      "Ravender Pal Singh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02834v2",
    "abstract": "Multimodal large language models (MLLMs) have shown strong capabilities but remain limited to fixed modality pairs and require costly fine-tuning with large aligned datasets. Building fully omni-capable models that can integrate text, images, audio, and video remains impractical and lacks robust reasoning support. In this paper, we propose an Agent-Omni framework that coordinates existing foundation models through a master-agent system, enabling flexible multimodal reasoning without retraining. The master agent interprets user intent, delegates subtasks to modality-specific agents, and integrates their outputs into coherent responses. Extensive experiments across text, image, audio, video, and omni benchmarks show that Agent-Omni consistently achieves state-of-the-art performance, particularly on tasks requiring complex cross-modal reasoning. Its agent-based design enables seamless integration of specialized foundation models, ensuring adaptability to diverse inputs while maintaining transparency and interpretability. In addition, the framework is modular and easily extensible, allowing future improvements as stronger models become available.",
    "fetched_at": "2025-11-09T02:21:22.887380Z"
  },
  {
    "id": "2511.02919v1",
    "title": "Cache Mechanism for Agent RAG Systems",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shuhang Lin",
      "Zhencan Peng",
      "Lingyao Li",
      "Xiao Lin",
      "Xi Zhu",
      "Yongfeng Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02919v1",
    "abstract": "Recent advances in Large Language Model (LLM)-based agents have been propelled by Retrieval-Augmented Generation (RAG), which grants the models access to vast external knowledge bases. Despite RAG's success in improving agent performance, agent-level cache management, particularly constructing, maintaining, and updating a compact, relevant corpus dynamically tailored to each agent's need, remains underexplored. Therefore, we introduce ARC (Agent RAG Cache Mechanism), a novel, annotation-free caching framework that dynamically manages small, high-value corpora for each agent. By synthesizing historical query distribution patterns with the intrinsic geometry of cached items in the embedding space, ARC automatically maintains a high-relevance cache. With comprehensive experiments on three retrieval datasets, our experimental results demonstrate that ARC reduces storage requirements to 0.015% of the original corpus while offering up to 79.8% has-answer rate and reducing average retrieval latency by 80%. Our results demonstrate that ARC can drastically enhance efficiency and effectiveness in RAG-powered LLM agents.",
    "fetched_at": "2025-11-09T02:21:22.886766Z"
  },
  {
    "id": "2511.03001v1",
    "title": "LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied   Environments with Tool Augmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Gyeom Hwangbo",
      "Hyungjoo Chae",
      "Minseok Kang",
      "Hyeonjong Ju",
      "Soohyun Oh",
      "Jinyoung Yeo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03001v1",
    "abstract": "Despite recent progress in using Large Language Models (LLMs) for automatically generating 3D scenes, generated scenes often lack realistic spatial layouts and object attributes found in real-world environments. As this problem stems from insufficiently detailed, coarse-grained instructions, advancing 3D scene synthesis guided by more detailed, fine-grained instructions that reflect real-world environments becomes crucial. Without such realistic scenes, training embodied agents in unrealistic environments can lead them to learn priors that diverge significantly from real-world physics and semantics, degrading their performance when deployed. Thus, verifying the alignment between the fine-grained instruction and the generated scene is essential for effective learning. However, current evaluation methods, such as CLIPScore and vision-language models (VLMs), often fail to reliably assess such alignment. This shortcoming arises primarily from their shallow understanding of 3D scenes, which often leads to improperly grounded scene components. To address this, we introduce LEGO-Eval, an evaluation framework equipped with diverse tools designed to explicitly ground scene components, enabling more accurate alignment assessments. We also present LEGO-Bench, a benchmark of detailed instructions that specify complex layouts and attributes of real-world environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with LEGO-Bench reveals significant limitations in current generation methods. Across all evaluated approaches, success rates reached at most 10% in generating scenes that fully align with fine-grained instructions.",
    "fetched_at": "2025-11-09T02:21:22.886718Z"
  },
  {
    "id": "2511.03023v1",
    "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data   Analysis Framework",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sina Montazeri",
      "Yunhe Feng",
      "Kewei Sha"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03023v1",
    "abstract": "Open data repositories hold potential for evidence-based decision-making, yet are inaccessible to non-experts lacking expertise in dataset discovery, schema mapping, and statistical analysis. Large language models show promise for individual tasks, but end-to-end analytical workflows expose fundamental limitations: attention dilutes across growing contexts, specialized reasoning patterns interfere, and errors propagate undetected. We present PublicAgent, a multi-agent framework that addresses these limitations through decomposition into specialized agents for intent clarification, dataset discovery, analysis, and reporting. This architecture maintains focused attention within agent contexts and enables validation at each stage. Evaluation across five models and 50 queries derives five design principles for multi-agent LLM systems. First, specialization provides value independent of model strength--even the strongest model shows 97.5% agent win rates, with benefits orthogonal to model scale. Second, agents divide into universal (discovery, analysis) and conditional (report, intent) categories. Universal agents show consistent effectiveness (std dev 12.4%) while conditional agents vary by model (std dev 20.5%). Third, agents mitigate distinct failure modes--removing discovery or analysis causes catastrophic failures (243-280 instances), while removing report or intent causes quality degradation. Fourth, architectural benefits persist across task complexity with stable win rates (86-92% analysis, 84-94% discovery), indicating workflow management value rather than reasoning enhancement. Fifth, wide variance in agent effectiveness across models (42-96% for analysis) requires model-aware architecture design. These principles guide when and why specialization is necessary for complex analytical workflows while enabling broader access to public data through natural language interfaces.",
    "fetched_at": "2025-11-09T02:21:22.886661Z"
  },
  {
    "id": "2511.03047v1",
    "title": "Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Emi Soroka",
      "Tanmay Chopra",
      "Krish Desai",
      "Sanjay Lall"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03047v1",
    "abstract": "Large language models (LLMs) have seen increasing popularity in enterprise applications where AI agents and humans engage in objective-driven interactions. However, these systems are difficult to evaluate: data may be complex and unlabeled; human annotation is often impractical at scale; custom metrics can monitor for specific errors, but not previously-undetected ones; and LLM judges can produce unreliable results. We introduce the first set of unsupervised metrics for objective-driven interactions, leveraging statistical properties of unlabeled interaction data and using fine-tuned LLMs to adapt to distributional shifts. We develop metrics for labeling user goals, measuring goal completion, and quantifying LLM uncertainty without grounding evaluations in human-generated ideal responses. Our approach is validated on open-domain and task-specific interaction data.",
    "fetched_at": "2025-11-09T02:21:22.886611Z"
  },
  {
    "id": "2511.03051v1",
    "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Tao Zhang",
      "Kehui Yao",
      "Luyi Ma",
      "Jiao Chen",
      "Reza Yousefi Maragheh",
      "Kai Zhao",
      "Jianpeng Xu",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03051v1",
    "abstract": "Evaluating large language models (LLMs) as judges is increasingly critical for building scalable and trustworthy evaluation pipelines. We present ScalingEval, a large-scale benchmarking study that systematically compares 36 LLMs, including GPT, Gemini, Claude, and Llama, across multiple product categories using a consensus-driven evaluation protocol. Our multi-agent framework aggregates pattern audits and issue codes into ground-truth labels via scalable majority voting, enabling reproducible comparison of LLM evaluators without human annotation. Applied to large-scale complementary-item recommendation, the benchmark reports four key findings: (i) Anthropic Claude 3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers the best overall performance across categories; (iii) GPT-4o provides the most favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among open-source models. Category-level analysis shows strong consensus in structured domains (Electronics, Sports) but persistent disagreement in lifestyle categories (Clothing, Food). These results establish ScalingEval as a reproducible benchmark and evaluation protocol for LLMs as judges, with actionable guidance on scaling, reliability, and model family tradeoffs.",
    "fetched_at": "2025-11-09T02:21:22.886570Z"
  },
  {
    "id": "2511.03075v1",
    "title": "A Collaborative Reasoning Framework for Anomaly Diagnostics in   Underwater Robotics",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Markus Buchholz",
      "Ignacio Carlucho",
      "Yvan R. Petillot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03075v1",
    "abstract": "The safe deployment of autonomous systems in safety-critical settings requires a paradigm that combines human expertise with AI-driven analysis, especially when anomalies are unforeseen. We introduce AURA (Autonomous Resilience Agent), a collaborative framework for anomaly and fault diagnostics in robotics. AURA integrates large language models (LLMs), a high-fidelity digital twin (DT), and human-in-the-loop interaction to detect and respond to anomalous behavior in real time. The architecture uses two agents with clear roles: (i) a low-level State Anomaly Characterization Agent that monitors telemetry and converts signals into a structured natural-language problem description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a knowledge-grounded dialogue with an operator to identify root causes, drawing on external sources. Human-validated diagnoses are then converted into new training examples that refine the low-level perceptual model. This feedback loop progressively distills expert knowledge into the AI, transforming it from a static tool into an adaptive partner. We describe the framework's operating principles and provide a concrete implementation, establishing a pattern for trustworthy, continually improving human-robot teams.",
    "fetched_at": "2025-11-09T02:21:22.886508Z"
  },
  {
    "id": "2511.02137v1",
    "title": "DoFlow: Causal Generative Flows for Interventional and Counterfactual   Time-Series Prediction",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.ME",
      "ME"
    ],
    "authors": [
      "Dongze Wu",
      "Feng Qiu",
      "Yao Xie"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02137v1",
    "abstract": "Time-series forecasting increasingly demands not only accurate observational predictions but also causal forecasting under interventional and counterfactual queries in multivariate systems. We present DoFlow, a flow based generative model defined over a causal DAG that delivers coherent observational and interventional predictions, as well as counterfactuals through the natural encoding and decoding mechanism of continuous normalizing flows (CNFs). We also provide a supporting counterfactual recovery result under certain assumptions. Beyond forecasting, DoFlow provides explicit likelihoods of future trajectories, enabling principled anomaly detection. Experiments on synthetic datasets with various causal DAG and real world hydropower and cancer treatment time series show that DoFlow achieves accurate system-wide observational forecasting, enables causal forecasting over interventional and counterfactual queries, and effectively detects anomalies. This work contributes to the broader goal of unifying causal reasoning and generative modeling for complex dynamical systems.",
    "fetched_at": "2025-11-06T02:19:07.219664Z"
  },
  {
    "id": "2511.02140v1",
    "title": "QuPCG: Quantum Convolutional Neural Network for Detecting Abnormal   Patterns in PCG Signals",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Yasaman Torabi",
      "Shahram Shirani",
      "James P. Reilly"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02140v1",
    "abstract": "Early identification of abnormal physiological patterns is essential for the timely detection of cardiac disease. This work introduces a hybrid quantum-classical convolutional neural network (QCNN) designed to classify S3 and murmur abnormalities in heart sound signals. The approach transforms one-dimensional phonocardiogram (PCG) signals into compact two-dimensional images through a combination of wavelet feature extraction and adaptive threshold compression methods. We compress the cardiac-sound patterns into an 8-pixel image so that only 8 qubits are needed for the quantum stage. Preliminary results on the HLS-CMDS dataset demonstrate 93.33% classification accuracy on the test set and 97.14% on the train set, suggesting that quantum models can efficiently capture temporal-spectral correlations in biomedical signals. To our knowledge, this is the first application of a QCNN algorithm for bioacoustic signal processing. The proposed method represents an early step toward quantum-enhanced diagnostic systems for resource-constrained healthcare environments.",
    "fetched_at": "2025-11-06T02:19:07.219619Z"
  },
  {
    "id": "2511.02146v1",
    "title": "Disentangling Causal Substructures for Interpretable and Generalizable   Drug Synergy Prediction",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yi Luo",
      "Haochen Zhao",
      "Xiao Liang",
      "Yiwei Liu",
      "Yuye Zhang",
      "Xinyu Li",
      "Jianxin Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02146v1",
    "abstract": "Drug synergy prediction is a critical task in the development of effective combination therapies for complex diseases, including cancer. Although existing methods have shown promising results, they often operate as black-box predictors that rely predominantly on statistical correlations between drug characteristics and results. To address this limitation, we propose CausalDDS, a novel framework that disentangles drug molecules into causal and spurious substructures, utilizing the causal substructure representations for predicting drug synergy. By focusing on causal sub-structures, CausalDDS effectively mitigates the impact of redundant features introduced by spurious substructures, enhancing the accuracy and interpretability of the model. In addition, CausalDDS employs a conditional intervention mechanism, where interventions are conditioned on paired molecular structures, and introduces a novel optimization objective guided by the principles of sufficiency and independence. Extensive experiments demonstrate that our method outperforms baseline models, particularly in cold start and out-of-distribution settings. Besides, CausalDDS effectively identifies key substructures underlying drug synergy, providing clear insights into how drug combinations work at the molecular level. These results underscore the potential of CausalDDS as a practical tool for predicting drug synergy and facilitating drug discovery.",
    "fetched_at": "2025-11-06T02:19:07.219566Z"
  },
  {
    "id": "2511.02148v1",
    "title": "CFL: On the Use of Characteristic Function Loss for Domain Alignment in   Machine Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Abdullah Almansour",
      "Ozan Tonguz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02148v1",
    "abstract": "Machine Learning (ML) models are extensively used in various applications due to their significant advantages over traditional learning methods. However, the developed ML models often underperform when deployed in the real world due to the well-known distribution shift problem. This problem can lead to a catastrophic outcomes when these decision-making systems have to operate in high-risk applications. Many researchers have previously studied this problem in ML, known as distribution shift problem, using statistical techniques (such as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to quantify the distribution shift. In this letter, we show that using Characteristic Function (CF) as a frequency domain approach is a powerful alternative for measuring the distribution shift in high-dimensional space and for domain adaptation.",
    "fetched_at": "2025-11-06T02:19:07.219489Z"
  },
  {
    "id": "2511.02152v1",
    "title": "ProtoTSNet: Interpretable Multivariate Time Series Classification With   Prototypical Parts",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bartłomiej Małkus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02152v1",
    "abstract": "Time series data is one of the most popular data modalities in critical domains such as industry and medicine. The demand for algorithms that not only exhibit high accuracy but also offer interpretability is crucial in such fields, as decisions made there bear significant consequences. In this paper, we present ProtoTSNet, a novel approach to interpretable classification of multivariate time series data, through substantial enhancements to the ProtoPNet architecture. Our method is tailored to overcome the unique challenges of time series analysis, including capturing dynamic patterns and handling varying feature significance. Central to our innovation is a modified convolutional encoder utilizing group convolutions, pre-trainable as part of an autoencoder and designed to preserve and quantify feature importance. We evaluated our model on 30 multivariate time series datasets from the UEA archive, comparing our approach with existing explainable methods as well as non-explainable baselines. Through comprehensive evaluation and ablation studies, we demonstrate that our approach achieves the best performance among ante-hoc explainable methods while maintaining competitive performance with non-explainable and post-hoc explainable approaches, providing interpretable results accessible to domain experts.",
    "fetched_at": "2025-11-06T02:19:07.219452Z"
  },
  {
    "id": "2511.02157v1",
    "title": "Near Optimal Convergence to Coarse Correlated Equilibrium in General-Sum   Markov Games",
    "date": "2025-11-04",
    "tags": [
      "cs.GT",
      "GT",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Asrin Efe Yorulmaz",
      "Tamer Başar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02157v1",
    "abstract": "No-regret learning dynamics play a central role in game theory, enabling decentralized convergence to equilibrium for concepts such as Coarse Correlated Equilibrium (CCE) or Correlated Equilibrium (CE). In this work, we improve the convergence rate to CCE in general-sum Markov games, reducing it from the previously best-known rate of $\\mathcal{O}(\\log^5 T / T)$ to a sharper $\\mathcal{O}(\\log T / T)$. This matches the best known convergence rate for CE in terms of $T$, number of iterations, while also improving the dependence on the action set size from polynomial to polylogarithmic-yielding exponential gains in high-dimensional settings. Our approach builds on recent advances in adaptive step-size techniques for no-regret algorithms in normal-form games, and extends them to the Markovian setting via a stage-wise scheme that adjusts learning rates based on real-time feedback. We frame policy updates as an instance of Optimistic Follow-the-Regularized-Leader (OFTRL), customized for value-iteration-based learning. The resulting self-play algorithm achieves, to our knowledge, the fastest known convergence rate to CCE in Markov games.",
    "fetched_at": "2025-11-06T02:19:07.219408Z"
  },
  {
    "id": "2511.02162v1",
    "title": "Text to Robotic Assembly of Multi Component Objects using 3D Generative   AI and Vision Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Alexander Htet Kyaw",
      "Richa Gupta",
      "Dhruv Shah",
      "Anoop Sinha",
      "Kory Mathewson",
      "Stefanie Pender",
      "Sachin Chitta",
      "Yotto Koga",
      "Faez Ahmed",
      "Lawrence Sass",
      "Randall Davis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02162v1",
    "abstract": "Advances in 3D generative AI have enabled the creation of physical objects from text prompts, but challenges remain in creating objects involving multiple component types. We present a pipeline that integrates 3D generative AI with vision-language models (VLMs) to enable the robotic assembly of multi-component objects from natural language. Our method leverages VLMs for zero-shot, multi-modal reasoning about geometry and functionality to decompose AI-generated meshes into multi-component 3D models using predefined structural and panel components. We demonstrate that a VLM is capable of determining which mesh regions need panel components in addition to structural components, based on object functionality. Evaluation across test objects shows that users preferred the VLM-generated assignments 90.6% of the time, compared to 59.4% for rule-based and 2.5% for random assignment. Lastly, the system allows users to refine component assignments through conversational feedback, enabling greater human control and agency in making physical objects with generative AI and robotics.",
    "fetched_at": "2025-11-06T02:19:07.219362Z"
  },
  {
    "id": "2511.02164v1",
    "title": "ScenicProver: A Framework for Compositional Probabilistic Verification   of Learning-Enabled Systems",
    "date": "2025-11-04",
    "tags": [
      "cs.LO",
      "LO",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.PL",
      "PL"
    ],
    "authors": [
      "Eric Vin",
      "Kyle A. Miller",
      "Inigo Incer",
      "Sanjit A. Seshia",
      "Daniel J. Fremont"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02164v1",
    "abstract": "Full verification of learning-enabled cyber-physical systems (CPS) has long been intractable due to challenges including black-box components and complex real-world environments. Existing tools either provide formal guarantees for limited types of systems or test the system as a monolith, but no general framework exists for compositional analysis of learning-enabled CPS using varied verification techniques over complex real-world environments. This paper introduces ScenicProver, a verification framework that aims to fill this gap. Built upon the Scenic probabilistic programming language, the framework supports: (1) compositional system description with clear component interfaces, ranging from interpretable code to black boxes; (2) assume-guarantee contracts over those components using an extension of Linear Temporal Logic containing arbitrary Scenic expressions; (3) evidence generation through testing, formal proofs via Lean 4 integration, and importing external assumptions; (4) systematic combination of generated evidence using contract operators; and (5) automatic generation of assurance cases tracking the provenance of system-level guarantees. We demonstrate the framework's effectiveness through a case study on an autonomous vehicle's automatic emergency braking system with sensor fusion. By leveraging manufacturer guarantees for radar and laser sensors and focusing testing efforts on uncertain conditions, our approach enables stronger probabilistic guarantees than monolithic testing with the same computational budget.",
    "fetched_at": "2025-11-06T02:19:07.219291Z"
  },
  {
    "id": "2511.02168v1",
    "title": "Eliminating Multi-GPU Performance Taxes: A Systems Approach to Efficient   Distributed LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Octavian Alexandru Trifan",
      "Karthik Sangaiah",
      "Muhammad Awad",
      "Muhammad Osama",
      "Sumanth Gudaparthi",
      "Alexandru Nicolau",
      "Alexander Veidenbaum",
      "Ganesh Dasika"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02168v1",
    "abstract": "As large language models (LLMs) continue to scale, their workloads increasingly rely on distributed execution across multiple GPUs. However, the conventional bulk synchronous parallel~(BSP) model used in such settings introduces significant performance inefficiencies. To characterize these bottlenecks, we introduce the ''Three Taxes'' (Bulk Synchronous, Inter-Kernel Data Locality, and Kernel Launch Overhead) as an analytical framework. We propose moving beyond the rigid BSP model to address key inefficiencies in distributed GPU execution. By exploiting libraries like Iris for Triton, we gain access to in-kernel communication primitives that enable the design of novel fine-grained programming patterns, offering greater flexibility and performance than traditional BSP-based approaches. These patterns systematically eliminate the three taxes by creating direct, tile-level producer-consumer pipelines and replacing global barriers with fine-grained dataflow synchronization. Applying this methodology to critical kernels, from the foundational All-Gather + general matrix multiplication operation to the complex Flash Decode algorithm, we observe a 10-20% speedup in end-to-end latency over BSP-based approaches, establishing a more programmable and efficient paradigm for distributed LLM workloads.",
    "fetched_at": "2025-11-06T02:19:07.219236Z"
  },
  {
    "id": "2511.02175v1",
    "title": "Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep   Learning Framework for Uncertainty Quantification",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuzhuang Pian",
      "Taiyu Wang",
      "Shiqi Zhang",
      "Rui Xu",
      "Yonghong Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02175v1",
    "abstract": "Accurate air quality forecasts are vital for public health alerts, exposure assessment, and emissions control. In practice, observational data are often missing in varying proportions and patterns due to collection and transmission issues. These incomplete spatiotemporal records impede reliable inference and risk assessment and can lead to overconfident extrapolation. To address these challenges, we propose an end to end framework, the channel gated learning unit based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features with a graph attention encoder to capture multiscale spatial dependencies and seasonal temporal dynamics. A channel gated learning unit, equipped with learnable activations and gated residual connections, adaptively filters and amplifies informative features. Bayesian inference jointly optimizes predictive distributions and parameter uncertainty, producing point estimates and calibrated prediction intervals. We conduct a systematic evaluation on two real world datasets, covering four typical missing data patterns and comparing against five state of the art baselines. CGLUBNF achieves superior prediction accuracy and sharper confidence intervals. In addition, we further validate robustness across multiple prediction horizons and analysis the contribution of extraneous variables. This research lays a foundation for reliable deep learning based spatio-temporal forecasting with incomplete observations in emerging sensing paradigms, such as real world vehicle borne mobile monitoring.",
    "fetched_at": "2025-11-06T02:19:07.219175Z"
  },
  {
    "id": "2511.02185v1",
    "title": "PrivGNN: High-Performance Secure Inference for Cryptographic Graph   Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fuyi Wang",
      "Zekai Chen",
      "Mingyuan Fan",
      "Jianying Zhou",
      "Lei Pan",
      "Leo Yu Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02185v1",
    "abstract": "Graph neural networks (GNNs) are powerful tools for analyzing and learning from graph-structured (GS) data, facilitating a wide range of services. Deploying such services in privacy-critical cloud environments necessitates the development of secure inference (SI) protocols that safeguard sensitive GS data. However, existing SI solutions largely focus on convolutional models for image and text data, leaving the challenge of securing GNNs and GS data relatively underexplored. In this work, we design, implement, and evaluate $\\sysname$, a lightweight cryptographic scheme for graph-centric inference in the cloud. By hybridizing additive and function secret sharings within secure two-party computation (2PC), $\\sysname$ is carefully designed based on a series of novel 2PC interactive protocols that achieve $1.5\\times \\sim 1.7\\times$ speedups for linear layers and $2\\times \\sim 15\\times$ for non-linear layers over state-of-the-art (SotA) solutions. A thorough theoretical analysis is provided to prove $\\sysname$'s correctness, security, and lightweight nature. Extensive experiments across four datasets demonstrate $\\sysname$'s superior efficiency with $1.3\\times \\sim 4.7\\times$ faster secure predictions while maintaining accuracy comparable to plaintext graph property inference.",
    "fetched_at": "2025-11-06T02:19:07.219121Z"
  },
  {
    "id": "2511.02193v1",
    "title": "MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel   Segmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiawen Liu",
      "Yuanbo Zeng",
      "Jiaming Liang",
      "Yizhen Yang",
      "Yiheng Zhang",
      "Enhui Cai",
      "Xiaoqi Sheng",
      "Hongmin Cai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02193v1",
    "abstract": "Accurate detection of retinal vessels plays a critical role in reflecting a wide range of health status indicators in the clinical diagnosis of ocular diseases. Recently, advances in deep learning have led to a surge in retinal vessel segmentation methods, which have significantly contributed to the quantitative analysis of vascular morphology. However, retinal vasculature differs significantly from conventional segmentation targets in that it consists of extremely thin and branching structures, whose global morphology varies greatly across images. These characteristics continue to pose challenges to segmentation precision and robustness. To address these issues, we propose MM-UNet, a novel architecture tailored for efficient retinal vessel segmentation. The model incorporates Morph Mamba Convolution layers, which replace pointwise convolutions to enhance branching topological perception through morph, state-aware feature sampling. Additionally, Reverse Selective State Guidance modules integrate reverse guidance theory with state-space modeling to improve geometric boundary awareness and decoding efficiency. Extensive experiments conducted on two public retinal vessel segmentation datasets demonstrate the superior performance of the proposed method in segmentation accuracy. Compared to the existing approaches, MM-UNet achieves F1-score gains of 1.64 $\\%$ on DRIVE and 1.25 $\\%$ on STARE, demonstrating its effectiveness and advancement. The project code is public via https://github.com/liujiawen-jpg/MM-UNet.",
    "fetched_at": "2025-11-06T02:19:07.219066Z"
  },
  {
    "id": "2511.02194v1",
    "title": "Personalized Decision Modeling: Utility Optimization or   Textualized-Symbolic Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yibo Zhao",
      "Yang Zhao",
      "Hongru Du",
      "Hao Frank Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02194v1",
    "abstract": "Decision-making models for individuals, particularly in high-stakes scenarios like vaccine uptake, often diverge from population optimal predictions. This gap arises from the uniqueness of the individual decision-making process, shaped by numerical attributes (e.g., cost, time) and linguistic influences (e.g., personal preferences and constraints). Developing upon Utility Theory and leveraging the textual-reasoning capabilities of Large Language Models (LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric Reasoning framework (ATHENA) to address the optimal information integration. ATHENA uniquely integrates two stages: First, it discovers robust, group-level symbolic utility functions via LLM-augmented symbolic discovery; Second, it implements individual-level semantic adaptation, creating personalized semantic templates guided by the optimal utility to model personalized choices. Validated on real-world travel mode and vaccine choice tasks, ATHENA consistently outperforms utility-based, machine learning, and other LLM-based models, lifting F1 score by at least 6.5% over the strongest cutting-edge models. Further, ablation studies confirm that both stages of ATHENA are critical and complementary, as removing either clearly degrades overall predictive performance. By organically integrating symbolic utility modeling and semantic adaptation, ATHENA provides a new scheme for modeling human-centric decisions. The project page can be found at https://yibozh.github.io/Athena.",
    "fetched_at": "2025-11-06T02:19:07.219003Z"
  },
  {
    "id": "2511.02196v1",
    "title": "BoolSkeleton: Boolean Network Skeletonization via Homogeneous Pattern   Reduction",
    "date": "2025-11-04",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Liwei Ni",
      "Jiaxi Zhang",
      "Shenggen Zheng",
      "Junfeng Liu",
      "Xingyu Meng",
      "Biwei Xie",
      "Xingquan Li",
      "Huawei Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02196v1",
    "abstract": "Boolean equivalence allows Boolean networks with identical functionality to exhibit diverse graph structures. This gives more room for exploration in logic optimization, while also posing a challenge for tasks involving consistency between Boolean networks. To tackle this challenge, we introduce BoolSkeleton, a novel Boolean network skeletonization method that improves the consistency and reliability of design-specific evaluations. BoolSkeleton comprises two key steps: preprocessing and reduction. In preprocessing, the Boolean network is transformed into a defined Boolean dependency graph, where nodes are assigned the functionality-related status. Next, the homogeneous and heterogeneous patterns are defined for the node-level pattern reduction step. Heterogeneous patterns are preserved to maintain critical functionality-related dependencies, while homogeneous patterns can be reduced. Parameter K of the pattern further constrains the fanin size of these patterns, enabling fine-tuned control over the granularity of graph reduction. To validate BoolSkeleton's effectiveness, we conducted four analysis/downstream tasks around the Boolean network: compression analysis, classification, critical path analysis, and timing prediction, demonstrating its robustness across diverse scenarios. Furthermore, it improves above 55% in the average accuracy compared to the original Boolean network for the timing prediction task. These experiments underscore the potential of BoolSkeleton to enhance design consistency in logic synthesis.",
    "fetched_at": "2025-11-06T02:19:07.218947Z"
  },
  {
    "id": "2511.02197v1",
    "title": "Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning   Confidence in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shufan Wang",
      "Xing Hu",
      "Junkai Chen",
      "Zhiyuan Pan",
      "Xin Xia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02197v1",
    "abstract": "With the widespread application of large language models (LLMs) in the field of code intelligence, increasing attention has been paid to the reliability and controllability of their outputs in code reasoning tasks. Confidence estimation serves as an effective and convenient approach for evaluating these aspects. This paper proposes a confidence analysis and enhancement framework for LLMs tailored to code reasoning tasks. We conduct a comprehensive empirical study on the confidence reliability of mainstream LLMs across different tasks, and further evaluate the effectiveness of techniques such as prompt strategy optimisation and mathematical calibration (e.g., Platt Scaling) in improving confidence reliability. Our results show that DeepSeek-Reasoner achieves the best performance across various tasks, outperforming other models by up to $0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance Score, respectively. The hybrid strategy combining the reassess prompt strategy and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$ over the original performance in the aforementioned three metrics. These results indicate that models with reasoning capabilities demonstrate superior confidence reliability, and that the hybrid strategy is the most effective in enhancing the confidence reliability of various models. Meanwhile, we elucidate the impact of different task complexities, model scales, and strategies on confidence performance, and highlight that the confidence of current LLMs in complex reasoning tasks still has considerable room for improvement. This study not only provides a research foundation and technical reference for the application of confidence in LLM-assisted software engineering, but also points the way for future optimisation and engineering deployment of confidence mechanisms.",
    "fetched_at": "2025-11-06T02:19:07.218881Z"
  },
  {
    "id": "2511.02205v1",
    "title": "OmniField: Conditioned Neural Fields for Robust Multimodal   Spatiotemporal Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Kevin Valencia",
      "Thilina Balasooriya",
      "Xihaier Luo",
      "Shinjae Yoo",
      "David Keetae Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02205v1",
    "abstract": "Multimodal spatiotemporal learning on real-world experimental data is constrained by two challenges: within-modality measurements are sparse, irregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of available modalities varies across space and time, shrinking the usable record unless models can adapt to arbitrary subsets at train and test time. We propose OmniField, a continuity-aware framework that learns a continuous neural field conditioned on available modalities and iteratively fuses cross-modal context. A multimodal crosstalk block architecture paired with iterative cross-modal refinement aligns signals prior to the decoder, enabling unified reconstruction, interpolation, forecasting, and cross-modal prediction without gridding or surrogate preprocessing. Extensive evaluations show that OmniField consistently outperforms eight strong multimodal spatiotemporal baselines. Under heavy simulated sensor noise, performance remains close to clean-input levels, highlighting robustness to corrupted measurements.",
    "fetched_at": "2025-11-06T02:19:07.218768Z"
  },
  {
    "id": "2511.02207v1",
    "title": "Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction   and Phenotyping",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiajia Li",
      "Keyi Zhu",
      "Qianwen Zhang",
      "Dong Chen",
      "Qi Sun",
      "Zhaojian Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02207v1",
    "abstract": "Strawberries are among the most economically significant fruits in the United States, generating over $2 billion in annual farm-gate sales and accounting for approximately 13% of the total fruit production value. Plant phenotyping plays a vital role in selecting superior cultivars by characterizing plant traits such as morphology, canopy structure, and growth dynamics. However, traditional plant phenotyping methods are time-consuming, labor-intensive, and often destructive. Recently, neural rendering techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have emerged as powerful frameworks for high-fidelity 3D reconstruction. By capturing a sequence of multi-view images or videos around a target plant, these methods enable non-destructive reconstruction of complex plant architectures. Despite their promise, most current applications of 3DGS in agricultural domains reconstruct the entire scene, including background elements, which introduces noise, increases computational costs, and complicates downstream trait analysis. To address this limitation, we propose a novel object-centric 3D reconstruction framework incorporating a preprocessing pipeline that leverages the Segment Anything Model v2 (SAM-2) and alpha channel background masking to achieve clean strawberry plant reconstructions. This approach produces more accurate geometric representations while substantially reducing computational time. With a background-free reconstruction, our algorithm can automatically estimate important plant traits, such as plant height and canopy width, using DBSCAN clustering and Principal Component Analysis (PCA). Experimental results show that our method outperforms conventional pipelines in both accuracy and efficiency, offering a scalable and non-destructive solution for strawberry plant phenotyping.",
    "fetched_at": "2025-11-06T02:19:07.218717Z"
  },
  {
    "id": "2511.02210v1",
    "title": "Estimation of Segmental Longitudinal Strain in Transesophageal   Echocardiography by Deep Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Anders Austlid Taskén",
      "Thierry Judge",
      "Erik Andreas Rye Berg",
      "Jinyang Yu",
      "Bjørnar Grenne",
      "Frank Lindseth",
      "Svend Aakhus",
      "Pierre-Marc Jodoin",
      "Nicolas Duchateau",
      "Olivier Bernard",
      "Gabriel Kiss"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02210v1",
    "abstract": "Segmental longitudinal strain (SLS) of the left ventricle (LV) is an important prognostic indicator for evaluating regional LV dysfunction, in particular for diagnosing and managing myocardial ischemia. Current techniques for strain estimation require significant manual intervention and expertise, limiting their efficiency and making them too resource-intensive for monitoring purposes. This study introduces the first automated pipeline, autoStrain, for SLS estimation in transesophageal echocardiography (TEE) using deep learning (DL) methods for motion estimation. We present a comparative analysis of two DL approaches: TeeFlow, based on the RAFT optical flow model for dense frame-to-frame predictions, and TeeTracker, based on the CoTracker point trajectory model for sparse long-sequence predictions.   As ground truth motion data from real echocardiographic sequences are hardly accessible, we took advantage of a unique simulation pipeline (SIMUS) to generate a highly realistic synthetic TEE (synTEE) dataset of 80 patients with ground truth myocardial motion to train and evaluate both models. Our evaluation shows that TeeTracker outperforms TeeFlow in accuracy, achieving a mean distance error in motion estimation of 0.65 mm on a synTEE test dataset.   Clinical validation on 16 patients further demonstrated that SLS estimation with our autoStrain pipeline aligned with clinical references, achieving a mean difference (95\\% limits of agreement) of 1.09% (-8.90% to 11.09%). Incorporation of simulated ischemia in the synTEE data improved the accuracy of the models in quantifying abnormal deformation. Our findings indicate that integrating AI-driven motion estimation with TEE can significantly enhance the precision and efficiency of cardiac function assessment in clinical settings.",
    "fetched_at": "2025-11-06T02:19:07.218590Z"
  },
  {
    "id": "2511.02213v1",
    "title": "IG-Pruning: Input-Guided Block Pruning for Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kangyu Qiao",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02213v1",
    "abstract": "With the growing computational demands of large language models (LLMs), efficient inference has become increasingly critical for practical deployment. Depth pruning has emerged as a promising approach for reducing the computational costs of large language models by removing transformer layers. However, existing methods typically rely on fixed block masks, which can lead to suboptimal performance across different tasks and inputs. In this paper, we propose IG-Pruning, a novel input-aware block-wise pruning method that dynamically selects layer masks at inference time. Our approach consists of two stages: (1) Discovering diverse mask candidates through semantic clustering and L0 optimization, and (2) Implementing efficient dynamic pruning without the need for extensive training. Experimental results demonstrate that our method consistently outperforms state-of-the-art static depth pruning methods, making it particularly suitable for resource-constrained deployment scenarios.",
    "fetched_at": "2025-11-06T02:19:07.218494Z"
  },
  {
    "id": "2511.02217v1",
    "title": "Optimizing Multi-Lane Intersection Performance in Mixed Autonomy   Environments",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Manonmani Sekar",
      "Nasim Nezamoddini"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02217v1",
    "abstract": "One of the main challenges in managing traffic at multilane intersections is ensuring smooth coordination between human-driven vehicles (HDVs) and connected autonomous vehicles (CAVs). This paper presents a novel traffic signal control framework that combines Graph Attention Networks (GAT) with Soft Actor-Critic (SAC) reinforcement learning to address this challenge. GATs are used to model the dynamic graph- structured nature of traffic flow to capture spatial and temporal dependencies between lanes and signal phases. The proposed SAC is a robust off-policy reinforcement learning algorithm that enables adaptive signal control through entropy-optimized decision making. This design allows the system to coordinate the signal timing and vehicle movement simultaneously with objectives focused on minimizing travel time, enhancing performance, ensuring safety, and improving fairness between HDVs and CAVs. The model is evaluated using a SUMO-based simulation of a four-way intersection and incorporating different traffic densities and CAV penetration rates. The experimental results demonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1% reduction in average delay and up to 29.2% fewer traffic violations compared to traditional methods. Additionally, the fairness ratio between HDVs and CAVs improved to 1.59, indicating more equitable treatment across vehicle types. These findings suggest that the GAT-SAC framework holds significant promise for real-world deployment in mixed-autonomy traffic systems.",
    "fetched_at": "2025-11-06T02:19:07.218412Z"
  },
  {
    "id": "2511.02219v2",
    "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning   in Tabular Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Changjiang Jiang",
      "Fengchang Yu",
      "Haihua Chen",
      "Wei Lu",
      "Jin Zeng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02219v2",
    "abstract": "Complex reasoning over tabular data is crucial in real-world data analysis, yet large language models (LLMs) often underperform due to complex queries, noisy data, and limited numerical capabilities. To address these issues, we propose TabDSR, a framework consisting of: (1) a query decomposer that breaks down complex questions, (2) a table sanitizer that cleans and filters noisy tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates executable code to derive the final answer from the sanitized table. To ensure unbiased evaluation and mitigate data leakage, we introduce a new dataset, CalTab151, specifically designed for complex numerical reasoning over tables. Experimental results demonstrate that TabDSR consistently outperforms existing methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and 19.87% accuracy improvement on TAT-QA, TableBench, and TabDSR, respectively. Moreover, our framework integrates seamlessly with mainstream LLMs, providing a robust solution for complex tabular numerical reasoning. These findings highlight the effectiveness of our framework in enhancing LLM performance for complex tabular numerical reasoning. Data and code are available upon request.",
    "fetched_at": "2025-11-06T02:19:07.218368Z"
  },
  {
    "id": "2511.02228v1",
    "title": "Collaborative Attention and Consistent-Guided Fusion of MRI and PET for   Alzheimer's Disease Diagnosis",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Delin Ma",
      "Menghui Zhou",
      "Jun Qi",
      "Yun Yang",
      "Po Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02228v1",
    "abstract": "Alzheimer's disease (AD) is the most prevalent form of dementia, and its early diagnosis is essential for slowing disease progression. Recent studies on multimodal neuroimaging fusion using MRI and PET have achieved promising results by integrating multi-scale complementary features. However, most existing approaches primarily emphasize cross-modal complementarity while overlooking the diagnostic importance of modality-specific features. In addition, the inherent distributional differences between modalities often lead to biased and noisy representations, degrading classification performance. To address these challenges, we propose a Collaborative Attention and Consistent-Guided Fusion framework for MRI and PET based AD diagnosis. The proposed model introduces a learnable parameter representation (LPR) block to compensate for missing modality information, followed by a shared encoder and modality-independent encoders to preserve both shared and specific representations. Furthermore, a consistency-guided mechanism is employed to explicitly align the latent distributions across modalities. Experimental results on the ADNI dataset demonstrate that our method achieves superior diagnostic performance compared with existing fusion strategies.",
    "fetched_at": "2025-11-06T02:19:07.218274Z"
  },
  {
    "id": "2511.02234v1",
    "title": "An Evaluation of Interleaved Instruction Tuning on Semantic Reasoning   Performance in an Audio MLLM",
    "date": "2025-11-04",
    "tags": [
      "cs.MM",
      "MM",
      "cs.CL",
      "CL",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Jiawei Liu",
      "Enis Berk Çoban",
      "Zarina Schevchenko",
      "Hao Tang",
      "Zhigang Zhu",
      "Michael I Mandel",
      "Johanna Devaney"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02234v1",
    "abstract": "Standard training for Multi-modal Large Language Models (MLLMs) involves concatenating non-textual information, like vision or audio, with a text prompt. This approach may not encourage deep integration of modalities, limiting the model's ability to leverage the core language model's reasoning capabilities. This work examined the impact of interleaved instruction tuning in an audio MLLM, where audio tokens are interleaved within the prompt. Using the Listen, Think, and Understand (LTU) model as a testbed, we conduct an experiment using the Synonym and Hypernym Audio Reasoning Dataset (SHARD), our newly created reasoning benchmark for audio-based semantic reasoning focusing on synonym and hypernym recognition. Our findings show that while even zero-shot interleaved prompting improves performance on our reasoning tasks, a small amount of fine-tuning using interleaved training prompts improves the results further, however, at the expense of the MLLM's audio labeling ability.",
    "fetched_at": "2025-11-06T02:19:07.218152Z"
  },
  {
    "id": "2511.02237v1",
    "title": "Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster   Decode Without Retraining",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Costin-Andrei Oncescu",
      "Qingyang Wu",
      "Wai Tong Chung",
      "Robert Wu",
      "Bryan Gopal",
      "Junxiong Wang",
      "Tri Dao",
      "Ben Athiwaratkun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02237v1",
    "abstract": "An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures where the feed-forward layer is replaced by a pool of experts and each token only activates a small subset of them. During autoregressive generation, these models often enter a memory-bound regime even for moderate batch sizes because the average expert load grows more slowly than in an equivalent dense feedforward layer. Consequently, MoE latency is governed by the number of activated experts. We introduce a framework for dynamically re-routing token-to-expert mapping to lower this number (and thus, the decode latency) while preserving a comparable quality. Our best results use a batch-aware routing that works by having tokens piggyback experts that have already been loaded into memory due to being crucial to other tokens within the same batch. Empirically, we evaluate our method on the Qwen3-30B and Qwen3-235B models with a batch size of $16$. Without any statistically significant loss in accuracy, our approach achieves latency reductions of $39\\%$ and $15\\%$ in the MoE layer decode latency, respectively.",
    "fetched_at": "2025-11-06T02:19:07.218039Z"
  },
  {
    "id": "2511.02243v1",
    "title": "When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs   Preference Dynamics in MLLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhuoran Zhang",
      "Tengyue Wang",
      "Xilin Gong",
      "Yang Shi",
      "Haotian Wang",
      "Di Wang",
      "Lijie Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02243v1",
    "abstract": "Multimodal large language models (MLLMs) must resolve conflicts when different modalities provide contradictory information, a process we term modality following. Prior work measured this behavior only with coarse dataset-level statistics, overlooking the influence of model's confidence in unimodal reasoning. In this paper, we introduce a new framework that decomposes modality following into two fundamental factors: relative reasoning uncertainty (the case-specific confidence gap between unimodal predictions) and inherent modality preference( a model's stable bias when uncertainties are balanced). To validate this framework, we construct a controllable dataset that systematically varies the reasoning difficulty of visual and textual inputs. Using entropy as a fine-grained uncertainty metric, we uncover a universal law: the probability of following a modality decreases monotonically as its relative uncertainty increases. At the relative difficulty level where the model tends to follow both modalities with comparable probability what we call the balance point, a practical indicator of the model's inherent preference. Unlike traditional macro-level ratios, this measure offers a more principled and less confounded way to characterize modality bias, disentangling it from unimodal capabilities and dataset artifacts. Further, by probing layer-wise predictions, we reveal the internal mechanism of oscillation: in ambiguous regions near the balance point, models vacillate between modalities across layers, explaining externally observed indecision. Together, these findings establish relative uncertainty and inherent preference as the two governing principles of modality following, offering both a quantitative framework and mechanistic insight into how MLLMs resolve conflicting information.",
    "fetched_at": "2025-11-06T02:19:07.217881Z"
  },
  {
    "id": "2511.02244v1",
    "title": "Neural network initialization with nonlinear characteristics and   information on spectral bias",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hikaru Homma",
      "Jun Ohkubo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02244v1",
    "abstract": "Initialization of neural network parameters, such as weights and biases, has a crucial impact on learning performance; if chosen well, we can even avoid the need for additional training with backpropagation. For example, algorithms based on the ridgelet transform or the SWIM (sampling where it matters) concept have been proposed for initialization. On the other hand, it is well-known that neural networks tend to learn coarse information in the earlier layers. The feature is called spectral bias. In this work, we investigate the effects of utilizing information on the spectral bias in the initialization of neural networks. Hence, we propose a framework that adjusts the scale factors in the SWIM algorithm to capture low-frequency components in the early-stage hidden layers and to represent high-frequency components in the late-stage hidden layers. Numerical experiments on a one-dimensional regression task and the MNIST classification task demonstrate that the proposed method outperforms the conventional initialization algorithms. This work clarifies the importance of intrinsic spectral properties in learning neural networks, and the finding yields an effective parameter initialization strategy that enhances their training performance.",
    "fetched_at": "2025-11-06T02:19:07.217817Z"
  },
  {
    "id": "2511.02248v1",
    "title": "From Models to Operators: Rethinking Autoscaling Granularity for Large   Generative Models",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xingqi Cui",
      "Chieh-Jan Mike Liang",
      "Jiarong Xing",
      "Haoran Qiu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02248v1",
    "abstract": "Serving large generative models such as LLMs and multi- modal transformers requires balancing user-facing SLOs (e.g., time-to-first-token, time-between-tokens) with provider goals of efficiency and cost reduction. Existing solutions rely on static provisioning or model-level autoscaling, both of which treat the model as a monolith. This coarse-grained resource management leads to degraded performance or significant resource underutilization due to poor adaptability to dynamic inference traffic that is common online.   The root cause of this inefficiency lies in the internal structure of generative models: they are executed as graphs of interconnected operators. Through detailed characterization and systematic analysis, we find that operators are heterogeneous in their compute and memory footprints and exhibit diverse sensitivity to workload and resource factors such as batch size, sequence length, and traffic rate. This heterogeneity suggests that the operator, rather than the entire model, is the right granularity for scaling decisions.   We propose an operator-level autoscaling framework, which allocates resources at finer (operator)-granularity, optimizing the scaling, batching, and placement based on individual operator profiles. Evaluated on production-scale traces, our approach preserves SLOs with up to 40% fewer GPUs and 35% less energy, or under fixed resources achieves 1.6x higher throughput with 5% less energy. These results show that the operator, rather than the model, is fundamentally a more effective unit for scaling large generative workloads.",
    "fetched_at": "2025-11-06T02:19:07.217710Z"
  },
  {
    "id": "2511.02254v1",
    "title": "Fast Approximation Algorithm for Non-Monotone DR-submodular Maximization   under Size Constraint",
    "date": "2025-11-04",
    "tags": [
      "cs.DS",
      "DS",
      "cs.AI",
      "AI",
      "cs.CC",
      "CC"
    ],
    "authors": [
      "Tan D. Tran",
      "Canh V. Pham"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02254v1",
    "abstract": "This work studies the non-monotone DR-submodular Maximization over a ground set of $n$ subject to a size constraint $k$. We propose two approximation algorithms for solving this problem named FastDrSub and FastDrSub++. FastDrSub offers an approximation ratio of $0.044$ with query complexity of $O(n \\log(k))$. The second one, FastDrSub++, improves upon it with a ratio of $1/4-\\epsilon$ within query complexity of $(n \\log k)$ for an input parameter $\\epsilon >0$. Therefore, our proposed algorithms are the first constant-ratio approximation algorithms for the problem with the low complexity of $O(n \\log(k))$.   Additionally, both algorithms are experimentally evaluated and compared against existing state-of-the-art methods, demonstrating their effectiveness in solving the Revenue Maximization problem with DR-submodular objective function. The experimental results show that our proposed algorithms significantly outperform existing approaches in terms of both query complexity and solution quality.",
    "fetched_at": "2025-11-06T02:19:07.217658Z"
  },
  {
    "id": "2511.02258v1",
    "title": "Limit Theorems for Stochastic Gradient Descent in High-Dimensional   Single-Layer Networks",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.PR",
      "PR",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Parsa Rangriz"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02258v1",
    "abstract": "This paper studies the high-dimensional scaling limits of online stochastic gradient descent (SGD) for single-layer networks. Building on the seminal work of Saad and Solla, which analyzed the deterministic (ballistic) scaling limits of SGD corresponding to the gradient flow of the population loss, we focus on the critical scaling regime of the step size. Below this critical scale, the effective dynamics are governed by ballistic (ODE) limits, but at the critical scale, new correction term appears that changes the phase diagram. In this regime, near the fixed points, the corresponding diffusive (SDE) limits of the effective dynamics reduces to an Ornstein-Uhlenbeck process under certain conditions. These results highlight how the information exponent controls sample complexity and illustrates the limitations of deterministic scaling limit in capturing the stochastic fluctuations of high-dimensional learning dynamics.",
    "fetched_at": "2025-11-06T02:19:07.217615Z"
  },
  {
    "id": "2511.02263v2",
    "title": "LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for   AI-MARRVEL in Rare Disease Diagnosis",
    "date": "2025-11-04",
    "tags": [
      "q-bio.GN",
      "GN",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jaeyeon Lee",
      "Hyun-Hwan Jeong",
      "Zhandong Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02263v2",
    "abstract": "Diagnosing rare diseases often requires connecting variant-bearing genes to evidence that is written as unstructured clinical prose, which the current established pipelines still leave for clinicians to reconcile manually. To this end, we introduce LA-MARRVEL, a knowledge-grounded and language-aware reranking layer that operates on top of AI-MARRVEL: it supplies expert-engineered context, queries a large language model multiple times, and aggregates the resulting partial rankings with a ranked voting method to produce a stable, explainable gene ranking. Evaluated on three real-world cohorts (BG, DDD, UDN), LA-MARRVEL consistently improves Recall@K over AI-MARRVEL and established phenotype-driven tools such as Exomiser and LIRICAL, with especially large gains on cases where the first-stage ranker placed the causal gene lower. Each ranked gene is accompanied by LLM-generated reasoning that integrates phenotypic, inheritance, and variant-level evidence, thereby making the output more interpretable and facilitating clinical review.",
    "fetched_at": "2025-11-06T02:19:07.217570Z"
  },
  {
    "id": "2511.02272v2",
    "title": "Probabilistic Graph Cuts",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.DS",
      "DS",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Ayoub Ghriss"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02272v2",
    "abstract": "Probabilistic relaxations of graph cuts offer a differentiable alternative to spectral clustering, enabling end-to-end and online learning without eigendecompositions, yet prior work centered on RatioCut and lacked general guarantees and principled gradients. We present a unified probabilistic framework that covers a wide class of cuts, including Normalized Cut. Our framework provides tight analytic upper bounds on expected discrete cuts via integral representations and Gauss hypergeometric functions with closed-form forward and backward. Together, these results deliver a rigorous, numerically stable foundation for scalable, differentiable graph partitioning covering a wide range of clustering and contrastive learning objectives.",
    "fetched_at": "2025-11-06T02:19:07.217507Z"
  },
  {
    "id": "2511.02276v1",
    "title": "Gradient-Variation Online Adaptivity for Accelerated Optimization with   Hölder Smoothness",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Yuheng Zhao",
      "Yu-Hu Yan",
      "Kfir Yehuda Levy",
      "Peng Zhao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02276v1",
    "abstract": "Smoothness is known to be crucial for acceleration in offline optimization, and for gradient-variation regret minimization in online learning. Interestingly, these two problems are actually closely connected -- accelerated optimization can be understood through the lens of gradient-variation online learning. In this paper, we investigate online learning with H\\\"older smooth functions, a general class encompassing both smooth and non-smooth (Lipschitz) functions, and explore its implications for offline optimization. For (strongly) convex online functions, we design the corresponding gradient-variation online learning algorithm whose regret smoothly interpolates between the optimal guarantees in smooth and non-smooth regimes. Notably, our algorithms do not require prior knowledge of the H\\\"older smoothness parameter, exhibiting strong adaptivity over existing methods. Through online-to-batch conversion, this gradient-variation online adaptivity yields an optimal universal method for stochastic convex optimization under H\\\"older smoothness. However, achieving universality in offline strongly convex optimization is more challenging. We address this by integrating online adaptivity with a detection-based guess-and-check procedure, which, for the first time, yields a universal offline method that achieves accelerated convergence in the smooth regime while maintaining near-optimal convergence in the non-smooth one.",
    "fetched_at": "2025-11-06T02:19:07.217472Z"
  },
  {
    "id": "2511.02280v1",
    "title": "SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL   Tuning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Fangxun Shu",
      "Yongjie Ye",
      "Yue Liao",
      "Zijian Kang",
      "Weijie Yin",
      "Jiacong Wang",
      "Xiao Liang",
      "Shuicheng Yan",
      "Chao Feng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02280v1",
    "abstract": "We introduce SAIL-RL, a reinforcement learning (RL) post-training framework that enhances the reasoning capabilities of multimodal large language models (MLLMs) by teaching them when and how to think. Existing approaches are limited by outcome-only supervision, which rewards correct answers without ensuring sound reasoning, and by uniform thinking strategies, which often lead to overthinking on simple tasks and underthinking on complex ones. SAIL-RL addresses these challenges with a dual reward system: the Thinking Reward, which evaluates reasoning quality through factual grounding, logical coherence, and answer consistency, and the Judging Reward, which adaptively determines whether deep reasoning or direct answering is appropriate. Experiments on the state-of-the-art SAIL-VL2 show that SAIL-RL improves reasoning and multimodal understanding benchmarks at both 4B and 8B scales, achieving competitive performance against commercial closed-source models such as GPT-4o, and substantially reduces hallucinations, establishing it as a principled framework for building more reliable and adaptive MLLMs. The code will be available at https://github.com/BytedanceDouyinContent/SAIL-RL.",
    "fetched_at": "2025-11-06T02:19:07.217412Z"
  },
  {
    "id": "2511.02286v1",
    "title": "Reinforcement learning based data assimilation for unknown state model",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ziyi Wang",
      "Lijian Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02286v1",
    "abstract": "Data assimilation (DA) has increasingly emerged as a critical tool for state estimation   across a wide range of applications. It is signiffcantly challenging when the governing equations of the underlying dynamics are unknown. To this end, various machine learning approaches have been employed to construct a surrogate state transition   model in a supervised learning framework, which relies on pre-computed training   datasets. However, it is often infeasible to obtain noise-free ground-truth state sequences in practice. To address this challenge, we propose a novel method that integrates reinforcement learning with ensemble-based Bayesian ffltering methods, enabling   the learning of surrogate state transition model for unknown dynamics directly from noisy observations, without using true state trajectories. Speciffcally, we treat the process for computing maximum likelihood estimation of surrogate model parameters   as a sequential decision-making problem, which can be formulated as a discretetime   Markov decision process (MDP). Under this formulation, learning the surrogate transition model is equivalent to ffnding an optimal policy of the MDP, which can be effectively addressed using reinforcement learning techniques. Once the model is trained offfine, state estimation can be performed in the online stage using ffltering methods based on the learned dynamics. The proposed framework accommodates a wide range of observation scenarios, including nonlinear and partially observed measurement   models. A few numerical examples demonstrate that the proposed method achieves superior accuracy and robustness in high-dimensional settings.",
    "fetched_at": "2025-11-06T02:19:07.217349Z"
  },
  {
    "id": "2511.02288v1",
    "title": "Link prediction Graph Neural Networks for structure recognition of   Handwritten Mathematical Expressions",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Cuong Tuan Nguyen",
      "Ngoc Tuan Nguyen",
      "Triet Hoang Minh Dao",
      "Huy Minh Nhat",
      "Huy Truong Dinh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02288v1",
    "abstract": "We propose a Graph Neural Network (GNN)-based approach for Handwritten Mathematical Expression (HME) recognition by modeling HMEs as graphs, where nodes represent symbols and edges capture spatial dependencies. A deep BLSTM network is used for symbol segmentation, recognition, and spatial relation classification, forming an initial primitive graph. A 2D-CFG parser then generates all possible spatial relations, while the GNN-based link prediction model refines the structure by removing unnecessary connections, ultimately forming the Symbol Label Graph. Experimental results demonstrate the effectiveness of our approach, showing promising performance in HME structure recognition.",
    "fetched_at": "2025-11-06T02:19:07.217304Z"
  },
  {
    "id": "2511.02290v1",
    "title": "From data to design: Random forest regression model for predicting   mechanical properties of alloy steel",
    "date": "2025-11-04",
    "tags": [
      "cond-mat.mtrl-sci",
      "mtrl-sci",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Samjukta Sinha",
      "Prabhat Das"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02290v1",
    "abstract": "This study investigates the application of Random Forest Regression for predicting mechanical properties of alloy steel-Elongation, Tensile Strength, and Yield Strength-from material composition features including Iron (Fe), Chromium (Cr), Nickel (Ni), Manganese (Mn), Silicon (Si), Copper (Cu), Carbon (C), and deformation percentage during cold rolling. Utilizing a dataset comprising these features, we trained and evaluated the Random Forest model, achieving high predictive performance as evidenced by R2 scores and Mean Squared Errors (MSE). The results demonstrate the model's efficacy in providing accurate predictions, which is validated through various performance metrics including residual plots and learning curves. The findings underscore the potential of ensemble learning techniques in enhancing material property predictions, with implications for industrial applications in material science.",
    "fetched_at": "2025-11-06T02:19:07.217257Z"
  },
  {
    "id": "2511.02301v1",
    "title": "Federated Quantum Kernel Learning for Anomaly Detection in Multivariate   IoT Time-Series",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "quant-ph"
    ],
    "authors": [
      "Kuan-Cheng Chen",
      "Samuel Yen-Chi Chen",
      "Chen-Yu Liu",
      "Kin K. Leung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02301v1",
    "abstract": "The rapid growth of industrial Internet of Things (IIoT) systems has created new challenges for anomaly detection in high-dimensional, multivariate time-series, where privacy, scalability, and communication efficiency are critical. Classical federated learning approaches mitigate privacy concerns by enabling decentralized training, but they often struggle with highly non-linear decision boundaries and imbalanced anomaly distributions. To address this gap, we propose a Federated Quantum Kernel Learning (FQKL) framework that integrates quantum feature maps with federated aggregation to enable distributed, privacy-preserving anomaly detection across heterogeneous IoT networks. In our design, quantum edge nodes locally compute compressed kernel statistics using parameterized quantum circuits and share only these summaries with a central server, which constructs a global Gram matrix and trains a decision function (e.g., Fed-QSVM). Experimental results on synthetic IIoT benchmarks demonstrate that FQKL achieves superior generalization in capturing complex temporal correlations compared to classical federated baselines, while significantly reducing communication overhead. This work highlights the promise of quantum kernels in federated settings, advancing the path toward scalable, robust, and quantum-enhanced intelligence for next-generation IoT infrastructures.",
    "fetched_at": "2025-11-06T02:19:07.217218Z"
  },
  {
    "id": "2511.02302v1",
    "title": "FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization   Error",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fengjuan Wang",
      "Zhiyi Su",
      "Xingzhu Hu",
      "Cheng Wang",
      "Mou Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02302v1",
    "abstract": "Training large Mixture-of-Experts (MoE) models remains computationally prohibitive due to their extreme compute and memory demands. Although low-precision training promises to accelerate computation and reduce memory footprint, existing implementations still rely on BF16-dominated dataflows with frequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode much of FP8's theoretical efficiency. However, naively removing these casts by keeping dataflows entirely in FP8 introduces double quantization error: tensors quantized along different dimensions accumulate inconsistent scaling factors, degrading numerical stability.   We propose FP8-Flow-MoE, an FP8 training recipe featuring a quantization-consistent FP8-centric dataflow with a scaling-aware transpose and fused FP8 operators that streamline computation and eliminate explicit cast operations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate up to 21\\% higher throughput and 16.5 GB lower memory usage per GPU compared to BF16 and na\\\"ive FP8 baselines, while maintaining stable convergence. We provide a plug-and-play FP8 recipe compatible with TransformerEngine and Megatron-LM, which will be open-sourced soon.",
    "fetched_at": "2025-11-06T02:19:07.217169Z"
  },
  {
    "id": "2511.02309v1",
    "title": "The Sequential Edge: Inverse-Entropy Voting Beats Parallel   Self-Consistency at Matched Compute",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aman Sharma",
      "Paras Chopra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02309v1",
    "abstract": "We revisit test-time scaling for language model reasoning and ask a fundamental question: at equal token budget and compute, is it better to run multiple independent chains in parallel, or to run fewer chains that iteratively refine through sequential steps? Through comprehensive evaluation across 5 state-of-the-art open source models and 3 challenging reasoning benchmarks, we find that sequential scaling where chains explicitly build upon previous attempts consistently outperforms the dominant parallel self-consistency paradigm in 95.6% of configurations with gains in accuracy upto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel training-free method to further boost the accuracy of sequential scaling. By weighing answers in proportion to the inverse entropy of their reasoning chains, we increase our success rate over parallel majority and establish it as the optimal test-time scaling strategy. Our findings fundamentally challenge the parallel reasoning orthodoxy that has dominated test-time scaling since Wang et al.'s self-consistency decoding (Wang et al., 2022), positioning sequential refinement as the robust default for modern LLM reasoning and necessitating a paradigm shift in how we approach inference-time optimization.",
    "fetched_at": "2025-11-06T02:19:07.216992Z"
  },
  {
    "id": "2511.02331v1",
    "title": "RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction   across Domains",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianle Pu",
      "Zijie Geng",
      "Haoyang Liu",
      "Shixuan Liu",
      "Jie Wang",
      "Li Zeng",
      "Chao Chen",
      "Changjun Fan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02331v1",
    "abstract": "Mixed-Integer Linear Programming (MILP) is a fundamental and powerful framework for modeling complex optimization problems across diverse domains. Recently, learning-based methods have shown great promise in accelerating MILP solvers by predicting high-quality solutions. However, most existing approaches are developed and evaluated in single-domain settings, limiting their ability to generalize to unseen problem distributions. This limitation poses a major obstacle to building scalable and general-purpose learning-based solvers. To address this challenge, we introduce RoME, a domain-Robust Mixture-of-Experts framework for predicting MILP solutions across domains. RoME dynamically routes problem instances to specialized experts based on learned task embeddings. The model is trained using a two-level distributionally robust optimization strategy: inter-domain to mitigate global shifts across domains, and intra-domain to enhance local robustness by introducing perturbations on task embeddings. We reveal that cross-domain training not only enhances the model's generalization capability to unseen domains but also improves performance within each individual domain by encouraging the model to capture more general intrinsic combinatorial patterns. Specifically, a single RoME model trained on three domains achieves an average improvement of 67.7% then evaluated on five diverse domains. We further test the pretrained model on MIPLIB in a zero-shot setting, demonstrating its ability to deliver measurable performance gains on challenging real-world instances where existing learning-based approaches often struggle to generalize.",
    "fetched_at": "2025-11-06T02:19:07.216871Z"
  },
  {
    "id": "2511.02332v1",
    "title": "Biological Regulatory Network Inference through Circular Causal   Structure Learning",
    "date": "2025-11-04",
    "tags": [
      "q-bio.MN",
      "MN",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hongyang Jiang",
      "Yuezhu Wang",
      "Ke Feng",
      "Chaoyi Yin",
      "Yi Chang",
      "Huiyan Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02332v1",
    "abstract": "Biological networks are pivotal in deciphering the complexity and functionality of biological systems. Causal inference, which focuses on determining the directionality and strength of interactions between variables rather than merely relying on correlations, is considered a logical approach for inferring biological networks. Existing methods for causal structure inference typically assume that causal relationships between variables can be represented by directed acyclic graphs (DAGs). However, this assumption is at odds with the reality of widespread feedback loops in biological systems, making these methods unsuitable for direct use in biological network inference. In this study, we propose a new framework named SCALD (Structural CAusal model for Loop Diagram), which employs a nonlinear structure equation model and a stable feedback loop conditional constraint through continuous optimization to infer causal regulatory relationships under feedback loops. We observe that SCALD outperforms state-of-the-art methods in inferring both transcriptional regulatory networks and signaling transduction networks. SCALD has irreplaceable advantages in identifying feedback regulation. Through transcription factor (TF) perturbation data analysis, we further validate the accuracy and sensitivity of SCALD. Additionally, SCALD facilitates the discovery of previously unknown regulatory relationships, which we have subsequently confirmed through ChIP-seq data analysis. Furthermore, by utilizing SCALD, we infer the key driver genes that facilitate the transformation from colon inflammation to cancer by examining the dynamic changes within regulatory networks during the process.",
    "fetched_at": "2025-11-06T02:19:07.216807Z"
  },
  {
    "id": "2511.02336v1",
    "title": "Learning A Universal Crime Predictor with Knowledge-guided Hypernetworks",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fidan Karimova",
      "Tong Chen",
      "Yu Yang",
      "Shazia Sadiq"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02336v1",
    "abstract": "Predicting crimes in urban environments is crucial for public safety, yet existing prediction methods often struggle to align the knowledge across diverse cities that vary dramatically in data availability of specific crime types. We propose HYpernetwork-enhanced Spatial Temporal Learning (HYSTL), a framework that can effectively train a unified, stronger crime predictor without assuming identical crime types in different cities' records. In HYSTL, instead of parameterising a dedicated predictor per crime type, a hypernetwork is designed to dynamically generate parameters for the prediction function conditioned on the crime type of interest. To bridge the semantic gap between different crime types, a structured crime knowledge graph is built, where the learned representations of crimes are used as the input to the hypernetwork to facilitate parameter generation. As such, when making predictions for each crime type, the predictor is additionally guided by its intricate association with other relevant crime types. Extensive experiments are performed on two cities with non-overlapping crime types, and the results demonstrate HYSTL outperforms state-of-the-art baselines.",
    "fetched_at": "2025-11-06T02:19:07.216741Z"
  },
  {
    "id": "2511.02340v1",
    "title": "Chronic Kidney Disease Prognosis Prediction Using Transformer",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "q-bio.OT",
      "OT"
    ],
    "authors": [
      "Yohan Lee",
      "DongGyun Kang",
      "SeHoon Park",
      "Sa-Yoon Park",
      "Kwangsoo Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02340v1",
    "abstract": "Chronic Kidney Disease (CKD) affects nearly 10\\% of the global population and often progresses to end-stage renal failure. Accurate prognosis prediction is vital for timely interventions and resource optimization. We present a transformer-based framework for predicting CKD progression using multi-modal electronic health records (EHR) from the Seoul National University Hospital OMOP Common Data Model. Our approach (\\textbf{ProQ-BERT}) integrates demographic, clinical, and laboratory data, employing quantization-based tokenization for continuous lab values and attention mechanisms for interpretability. The model was pretrained with masked language modeling and fine-tuned for binary classification tasks predicting progression from stage 3a to stage 5 across varying follow-up and assessment periods. Evaluated on a cohort of 91,816 patients, our model consistently outperformed CEHR-BERT, achieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction. These results highlight the effectiveness of transformer architectures and temporal design choices in clinical prognosis modeling, offering a promising direction for personalized CKD care.",
    "fetched_at": "2025-11-06T02:19:07.216695Z"
  },
  {
    "id": "2511.02345v1",
    "title": "Reducing normalizing flow complexity for MCMC preconditioning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "stat.CO",
      "CO",
      "stat.ML",
      "ML",
      "62-08",
      "G.3; I.5.1",
      "1"
    ],
    "authors": [
      "David Nabergoj",
      "Erik Štrumbelj"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02345v1",
    "abstract": "Preconditioning is a key component of MCMC algorithms that improves sampling efficiency by facilitating exploration of geometrically complex target distributions through an invertible map. While linear preconditioners are often sufficient for moderately complex target distributions, recent work has explored nonlinear preconditioning with invertible neural networks as components of normalizing flows (NFs). However, empirical and theoretical studies show that overparameterized NF preconditioners can degrade sampling efficiency and fit quality. Moreover, existing NF-based approaches do not adapt their architectures to the target distribution. Related work outside of MCMC similarly finds that suitably parameterized NFs can achieve comparable or superior performance with substantially less training time or data. We propose a factorized preconditioning architecture that reduces NF complexity by combining a linear component with a conditional NF, improving adaptability to target geometry. The linear preconditioner is applied to dimensions that are approximately Gaussian, as estimated from warmup samples, while the conditional NF models more complex dimensions. Our method yields significantly better tail samples on two complex synthetic distributions and consistently better performance on a sparse logistic regression posterior across varying likelihood and prior strengths. It also achieves higher effective sample sizes on hierarchical Bayesian model posteriors with weak likelihoods and strong funnel geometries. This approach is particularly relevant for hierarchical Bayesian model analyses with limited data and could inform current theoretical and software strides in neural MCMC design.",
    "fetched_at": "2025-11-06T02:19:07.216645Z"
  },
  {
    "id": "2511.02347v1",
    "title": "LTD-Bench: Evaluating Large Language Models by Letting Them Draw",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Liuhao Lin",
      "Ke Li",
      "Zihan Xu",
      "Yuchen Shi",
      "Yulei Qin",
      "Yan Zhang",
      "Xing Sun",
      "Rongrong Ji"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02347v1",
    "abstract": "Current evaluation paradigms for large language models (LLMs) represent a critical blind spot in AI research--relying on opaque numerical metrics that conceal fundamental limitations in spatial reasoning while providing no intuitive understanding of model capabilities. This deficiency creates a dangerous disconnect between reported performance and practical abilities, particularly for applications requiring physical world understanding. We introduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation from abstract scores to directly observable visual outputs by requiring models to generate drawings through dot matrices or executable code. This approach makes spatial reasoning limitations immediately apparent even to non-experts, bridging the fundamental gap between statistical performance and intuitive assessment. LTD-Bench implements a comprehensive methodology with complementary generation tasks (testing spatial imagination) and recognition tasks (assessing spatial perception) across three progressively challenging difficulty levels, methodically evaluating both directions of the critical language-spatial mapping. Our extensive experiments with state-of-the-art models expose an alarming capability gap: even LLMs achieving impressive results on traditional benchmarks demonstrate profound deficiencies in establishing bidirectional mappings between language and spatial concept--a fundamental limitation that undermines their potential as genuine world models. Furthermore, LTD-Bench's visual outputs enable powerful diagnostic analysis, offering a potential approach to investigate model similarity.",
    "fetched_at": "2025-11-06T02:19:07.216597Z"
  },
  {
    "id": "2511.02351v1",
    "title": "Human-Machine Ritual: Synergic Performance through Real-Time Motion   Recognition",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Zhuodi Cai",
      "Ziyu Xu",
      "Juan Pampin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02351v1",
    "abstract": "We introduce a lightweight, real-time motion recognition system that enables synergic human-machine performance through wearable IMU sensor data, MiniRocket time-series classification, and responsive multimedia control. By mapping dancer-specific movement to sound through somatic memory and association, we propose an alternative approach to human-machine collaboration, one that preserves the expressive depth of the performing body while leveraging machine learning for attentive observation and responsiveness. We demonstrate that this human-centered design reliably supports high accuracy classification (<50 ms latency), offering a replicable framework to integrate dance-literate machines into creative, educational, and live performance contexts.",
    "fetched_at": "2025-11-06T02:19:07.216522Z"
  },
  {
    "id": "2511.02354v1",
    "title": "Evolving Graph Learning for Out-of-Distribution Generalization in   Non-stationary Environments",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Qingyun Sun",
      "Jiayi Luo",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Hao Peng",
      "Jianxin Li",
      "Philip S. Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02354v1",
    "abstract": "Graph neural networks have shown remarkable success in exploiting the spatial and temporal patterns on dynamic graphs. However, existing GNNs exhibit poor generalization ability under distribution shifts, which is inevitable in dynamic scenarios. As dynamic graph generation progresses amid evolving latent non-stationary environments, it is imperative to explore their effects on out-of-distribution (OOD) generalization. This paper proposes a novel Evolving Graph Learning framework for OOD generalization (EvoOOD) by environment-aware invariant pattern recognition. Specifically, we first design an environment sequential variational auto-encoder to model environment evolution and infer the underlying environment distribution. Then, we introduce a mechanism for environment-aware invariant pattern recognition, tailored to address environmental diversification through inferred distributions. Finally, we conduct fine-grained causal interventions on individual nodes using a mixture of instantiated environment samples. This approach helps to distinguish spatio-temporal invariant patterns for OOD prediction, especially in non-stationary environments. Experimental results demonstrate the superiority of EvoGOOD on both real-world and synthetic dynamic datasets under distribution shifts. To the best of our knowledge, it is the first attempt to study the dynamic graph OOD generalization problem from the environment evolution perspective.",
    "fetched_at": "2025-11-06T02:19:07.216480Z"
  },
  {
    "id": "2511.02356v1",
    "title": "An Automated Framework for Strategy Discovery, Retrieval, and Evolution   in LLM Jailbreak Attacks",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xu Liu",
      "Yan Chen",
      "Kan Ling",
      "Yichi Zhu",
      "Hengrun Zhang",
      "Guisheng Fan",
      "Huiqun Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02356v1",
    "abstract": "The widespread deployment of Large Language Models (LLMs) as public-facing web services and APIs has made their security a core concern for the web ecosystem. Jailbreak attacks, as one of the significant threats to LLMs, have recently attracted extensive research. In this paper, we reveal a jailbreak strategy which can effectively evade current defense strategies. It can extract valuable information from failed or partially successful attack attempts and contains self-evolution from attack interactions, resulting in sufficient strategy diversity and adaptability. Inspired by continuous learning and modular design principles, we propose ASTRA, a jailbreak framework that autonomously discovers, retrieves, and evolves attack strategies to achieve more efficient and adaptive attacks. To enable this autonomous evolution, we design a closed-loop \"attack-evaluate-distill-reuse\" core mechanism that not only generates attack prompts but also automatically distills and generalizes reusable attack strategies from every interaction. To systematically accumulate and apply this attack knowledge, we introduce a three-tier strategy library that categorizes strategies into Effective, Promising, and Ineffective based on their performance scores. The strategy library not only provides precise guidance for attack generation but also possesses exceptional extensibility and transferability. We conduct extensive experiments under a black-box setting, and the results show that ASTRA achieves an average Attack Success Rate (ASR) of 82.7%, significantly outperforming baselines.",
    "fetched_at": "2025-11-06T02:19:07.216421Z"
  },
  {
    "id": "2511.02358v1",
    "title": "Let Multimodal Embedders Learn When to Augment Query via Adaptive Query   Augmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Wongyu Kim",
      "Hochang Lee",
      "Sanghak Lee",
      "Yoonsung Kim",
      "Jaehyun Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02358v1",
    "abstract": "Query augmentation makes queries more meaningful by appending further information to the queries to find relevant documents. Current studies have proposed Large Language Model (LLM)-based embedders, which learn representation for embedding and generation for query augmentation in a multi-task manner by leveraging the generative capabilities of LLM. During inference, these jointly trained embedders have conducted query augmentation followed by embedding, showing effective results. However, augmenting every query leads to substantial embedding latency and query augmentation can be detrimental to performance for some queries. Also, previous methods have not been explored in multimodal environments. To tackle these problems, we propose M-Solomon, a universal multimodal embedder that can adaptively determine when to augment queries. Our approach first divides the queries of the training datasets into two groups at the dataset level. One includes queries that require augmentation and the other includes queries that do not. Then, we introduces a synthesis process that generates appropriate augmentations for queries that require them by leveraging a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation. Through this step, M-Solomon can conduct query augmentation only when necessary by learning to generate synthetic augmentations with the prefix /augment for queries that demand them and to generate the simple string /embed for others. Experimental results showed that M-Solomon not only surpassed the baseline without augmentation by a large margin but also outperformed the baseline that always used augmentation, providing much faster embedding latency.",
    "fetched_at": "2025-11-06T02:19:07.216361Z"
  },
  {
    "id": "2511.02360v1",
    "title": "CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jizheng Ma",
      "Xiaofei Zhou",
      "Yanlong Song",
      "Han Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02360v1",
    "abstract": "In human cognition, there exist numerous thought processes that are tacit and beyond verbal expression, enabling us to understand and interact with the world in multiple ways. However, contemporary Vision-Language Models (VLMs) remain constrained to reasoning within the discrete and rigid space of linguistic tokens, thereby bottlenecking the rich, high-dimensional nature of visual perception. To bridge this gap, we propose CoCoVa (Chain of Continuous Vision-Language Thought), a novel framework for vision-language model that leverages continuous cross-modal reasoning for diverse vision-language tasks. The core of CoCoVa is an iterative reasoning cycle, where a novel Latent Q-Former (LQ-Former) acts as a dynamic reasoning engine, iteratively refining a chain of latent thought vectors through cross-modal fusion. To focus this process, a token selection mechanism dynamically identifies salient visual regions, mimicking attentional focus. To ensure these latent thoughts remain grounded, we train the model with a multi-task objective that combines contrastive learning and diffusion-based reconstruction, enforcing alignment between latent representations and both visual and textual modalities. Evaluations show CoCoVa improves accuracy and token efficiency over strong baselines. With a 1.5B backbone, it competes with or surpasses larger 7B-9B models on almost all benchmarks. When scaled to 7B LLM backbones, it remains competitive with state-of-the-art models. Qualitative analysis validates that learned latent space captures interpretable and structured reasoning patterns, highlighting the potential of CoCoVa to bridge the representational gap between discrete language processing and the continuous nature of visual understanding.",
    "fetched_at": "2025-11-06T02:19:07.216303Z"
  },
  {
    "id": "2511.02370v1",
    "title": "AI Credibility Signals Outrank Institutions and Engagement in Shaping   News Perception on Social Media",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Adnan Hoq",
      "Matthew Facciani",
      "Tim Weninger"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02370v1",
    "abstract": "AI-generated content is rapidly becoming a salient component of online information ecosystems, yet its influence on public trust and epistemic judgments remains poorly understood. We present a large-scale mixed-design experiment (N = 1,000) investigating how AI-generated credibility scores affect user perception of political news. Our results reveal that AI feedback significantly moderates partisan bias and institutional distrust, surpassing traditional engagement signals such as likes and shares. These findings demonstrate the persuasive power of generative AI and suggest a need for design strategies that balance epistemic influence with user autonomy.",
    "fetched_at": "2025-11-06T02:19:07.216161Z"
  },
  {
    "id": "2511.02373v1",
    "title": "A new class of Markov random fields enabling lightweight sampling",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "stat.CO",
      "CO"
    ],
    "authors": [
      "Jean-Baptiste Courbot",
      "Hugo Gangloff",
      "Bruno Colicchio"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02373v1",
    "abstract": "This work addresses the problem of efficient sampling of Markov random fields (MRF). The sampling of Potts or Ising MRF is most often based on Gibbs sampling, and is thus computationally expensive. We consider in this work how to circumvent this bottleneck through a link with Gaussian Markov Random fields. The latter can be sampled in several cost-effective ways, and we introduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting new class of MRF benefits from a few theoretical properties that validate the new model. Numerical results show the drastic performance gain in terms of computational efficiency, as we sample at least 35x faster than Gibbs sampling using at least 37x less energy, all the while exhibiting empirical properties close to classical MRFs.",
    "fetched_at": "2025-11-06T02:19:07.216070Z"
  },
  {
    "id": "2511.02374v1",
    "title": "AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mohd Nauman",
      "Sravan Gvm",
      "Vijay Devane",
      "Shyam Pawar",
      "Viraj Thakur",
      "Kundeshwar Pundalik",
      "Piyush Sawarkar",
      "Rohit Saluja",
      "Maunendra Desarkar",
      "Ganesh Ramakrishnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02374v1",
    "abstract": "Current large language models excel at broad, general-purpose tasks, but consistently underperform when exposed to highly specialized domains that require deep cultural, linguistic, and subject-matter expertise. In particular, traditional medical systems such as Ayurveda embody centuries of nuanced textual and clinical knowledge that mainstream LLMs fail to accurately interpret or apply. We introduce AyurParam-2.9B, a domain-specialized, bilingual language model fine-tuned from Param-1-2.9B using an extensive, expertly curated Ayurveda dataset spanning classical texts and clinical guidance. AyurParam's dataset incorporates context-aware, reasoning, and objective-style Q&A in both English and Hindi, with rigorous annotation protocols for factual precision and instructional clarity. Benchmarked on BhashaBench-Ayur, AyurParam not only surpasses all open-source instruction-tuned models in its size class (1.5--3B parameters), but also demonstrates competitive or superior performance compared to much larger models. The results from AyurParam highlight the necessity for authentic domain adaptation and high-quality supervision in delivering reliable, culturally congruent AI for specialized medical knowledge.",
    "fetched_at": "2025-11-06T02:19:07.216030Z"
  },
  {
    "id": "2511.02376v1",
    "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of   Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aashray Reddy",
      "Andrew Zagula",
      "Nicholas Saban"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02376v1",
    "abstract": "Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where adversarial prompts elicit harmful outputs, yet most evaluations focus on single-turn interactions while real-world attacks unfold through adaptive multi-turn conversations. We present AutoAdv, a training-free framework for automated multi-turn jailbreaking that achieves up to 95% attack success rate on Llama-3.1-8B within six turns a 24 percent improvement over single turn baselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern manager that learns from successful attacks to enhance future prompts, a temperature manager that dynamically adjusts sampling parameters based on failure modes, and a two-phase rewriting strategy that disguises harmful requests then iteratively refines them. Extensive evaluation across commercial and open-source models (GPT-4o-mini, Qwen3-235B, Mistral-7B) reveals persistent vulnerabilities in current safety mechanisms, with multi-turn attacks consistently outperforming single-turn approaches. These findings demonstrate that alignment strategies optimized for single-turn interactions fail to maintain robustness across extended conversations, highlighting an urgent need for multi-turn-aware defenses.",
    "fetched_at": "2025-11-06T02:19:07.215962Z"
  },
  {
    "id": "2511.02379v1",
    "title": "H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart   Sound Recordings",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.SD",
      "SD",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Rohith Shinoj Kumar",
      "Rushdeep Dinda",
      "Aditya Tyagi",
      "Annappa B.",
      "Naveen Kumar M. R"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02379v1",
    "abstract": "Early detection of heart arrhythmia can prevent severe future complications in cardiac patients. While manual diagnosis still remains the clinical standard, it relies heavily on visual interpretation and is inherently subjective. In recent years, deep learning has emerged as a powerful tool to automate arrhythmia detection, offering improved accuracy, consistency, and efficiency. Several variants of convolutional and recurrent neural network architectures have been widely explored to capture spatial and temporal patterns in physiological signals. However, despite these advancements, current models often struggle to generalize well in real-world scenarios, especially when dealing with small or noisy datasets, which are common challenges in biomedical applications. In this paper, a novel CNN-H-Infinity-LSTM architecture is proposed to identify arrhythmic heart signals from heart sound recordings. This architecture introduces trainable parameters inspired by the H-Infinity filter from control theory, enhancing robustness and generalization. Extensive experimentation on the PhysioNet CinC Challenge 2016 dataset, a public benchmark of heart audio recordings, demonstrates that the proposed model achieves stable convergence and outperforms existing benchmarks, with a test accuracy of 99.42% and an F1 score of 98.85%.",
    "fetched_at": "2025-11-06T02:19:07.215915Z"
  },
  {
    "id": "2511.02392v1",
    "title": "Fuzzy Soft Set Theory based Expert System for the Risk Assessment in   Breast Cancer Patients",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Muhammad Sheharyar Liaqat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02392v1",
    "abstract": "Breast cancer remains one of the leading causes of mortality among women worldwide, with early diagnosis being critical for effective treatment and improved survival rates. However, timely detection continues to be a challenge due to the complex nature of the disease and variability in patient risk factors. This study presents a fuzzy soft set theory-based expert system designed to assess the risk of breast cancer in patients using measurable clinical and physiological parameters. The proposed system integrates Body Mass Index, Insulin Level, Leptin Level, Adiponectin Level, and age as input variables to estimate breast cancer risk through a set of fuzzy inference rules and soft set computations. These parameters can be obtained from routine blood analyses, enabling a non-invasive and accessible method for preliminary assessment. The dataset used for model development and validation was obtained from the UCI Machine Learning Repository. The proposed expert system aims to support healthcare professionals in identifying high-risk patients and determining the necessity of further diagnostic procedures such as biopsies.",
    "fetched_at": "2025-11-06T02:19:07.215860Z"
  },
  {
    "id": "2511.02395v1",
    "title": "Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar   Point Clouds",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Leon Schwarzer",
      "Matthias Zeller",
      "Daniel Casado Herraez",
      "Simon Dierl",
      "Michael Heidingsfeld",
      "Cyrill Stachniss"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02395v1",
    "abstract": "Moving object segmentation is a crucial task for safe and reliable autonomous mobile systems like self-driving cars, improving the reliability and robustness of subsequent tasks like SLAM or path planning. While the segmentation of camera or LiDAR data is widely researched and achieves great results, it often introduces an increased latency by requiring the accumulation of temporal sequences to gain the necessary temporal context. Radar sensors overcome this problem with their ability to provide a direct measurement of a point's Doppler velocity, which can be exploited for single-scan moving object segmentation. However, radar point clouds are often sparse and noisy, making data annotation for use in supervised learning very tedious, time-consuming, and cost-intensive. To overcome this problem, we address the task of self-supervised moving object segmentation of sparse and noisy radar point clouds. We follow a two-step approach of contrastive self-supervised representation learning with subsequent supervised fine-tuning using limited amounts of annotated data. We propose a novel clustering-based contrastive loss function with cluster refinement based on dynamic points removal to pretrain the network to produce motion-aware representations of the radar data. Our method improves label efficiency after fine-tuning, effectively boosting state-of-the-art performance by self-supervised pretraining.",
    "fetched_at": "2025-11-06T02:19:07.215824Z"
  },
  {
    "id": "2511.02398v1",
    "title": "A Spatially Informed Gaussian Process UCB Method for Decentralized   Coverage Control",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gennaro Guidone",
      "Luca Monegaglia",
      "Elia Raimondi",
      "Han Wang",
      "Mattia Bianchi",
      "Florian Dörfler"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02398v1",
    "abstract": "We present a novel decentralized algorithm for coverage control in unknown spatial environments modeled by Gaussian Processes (GPs). To trade-off between exploration and exploitation, each agent autonomously determines its trajectory by minimizing a local cost function. Inspired by the GP-UCB (Upper Confidence Bound for GPs) acquisition function, the proposed cost combines the expected locational cost with a variance-based exploration term, guiding agents toward regions that are both high in predicted density and model uncertainty. Compared to previous work, our algorithm operates in a fully decentralized fashion, relying only on local observations and communication with neighboring agents. In particular, agents periodically update their inducing points using a greedy selection strategy, enabling scalable online GP updates. We demonstrate the effectiveness of our algorithm in simulation.",
    "fetched_at": "2025-11-06T02:19:07.215767Z"
  },
  {
    "id": "2511.02400v1",
    "title": "MammoClean: Toward Reproducible and Bias-Aware AI in Mammography through   Dataset Harmonization",
    "date": "2025-11-04",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yalda Zafari",
      "Hongyi Pan",
      "Gorkem Durak",
      "Ulas Bagci",
      "Essam A. Rashed",
      "Mohamed Mabrok"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02400v1",
    "abstract": "The development of clinically reliable artificial intelligence (AI) systems for mammography is hindered by profound heterogeneity in data quality, metadata standards, and population distributions across public datasets. This heterogeneity introduces dataset-specific biases that severely compromise the generalizability of the model, a fundamental barrier to clinical deployment. We present MammoClean, a public framework for standardization and bias quantification in mammography datasets. MammoClean standardizes case selection, image processing (including laterality and intensity correction), and unifies metadata into a consistent multi-view structure. We provide a comprehensive review of breast anatomy, imaging characteristics, and public mammography datasets to systematically identify key sources of bias. Applying MammoClean to three heterogeneous datasets (CBIS-DDSM, TOMPEI-CMMD, VinDr-Mammo), we quantify substantial distributional shifts in breast density and abnormality prevalence. Critically, we demonstrate the direct impact of data corruption: AI models trained on corrupted datasets exhibit significant performance degradation compared to their curated counterparts. By using MammoClean to identify and mitigate bias sources, researchers can construct unified multi-dataset training corpora that enable development of robust models with superior cross-domain generalization. MammoClean provides an essential, reproducible pipeline for bias-aware AI development in mammography, facilitating fairer comparisons and advancing the creation of safe, effective systems that perform equitably across diverse patient populations and clinical settings. The open-source code is publicly available from: https://github.com/Minds-R-Lab/MammoClean.",
    "fetched_at": "2025-11-06T02:19:07.215650Z"
  },
  {
    "id": "2511.02404v1",
    "title": "Purrturbed but Stable: Human-Cat Invariant Representations Across CNNs,   ViTs and Self-Supervised ViTs",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Arya Shah",
      "Vaibhav Tripathi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02404v1",
    "abstract": "Cats and humans differ in ocular anatomy. Most notably, Felis Catus (domestic cats) have vertically elongated pupils linked to ambush predation; yet, how such specializations manifest in downstream visual representations remains incompletely understood. We present a unified, frozen-encoder benchmark that quantifies feline-human cross-species representational alignment in the wild, across convolutional networks, supervised Vision Transformers, windowed transformers, and self-supervised ViTs (DINO), using layer-wise Centered Kernel Alignment (linear and RBF) and Representational Similarity Analysis, with additional distributional and stability tests reported in the paper. Across models, DINO ViT-B/16 attains the most substantial alignment (mean CKA-RBF $\\approx0.814$, mean CKA-linear $\\approx0.745$, mean RSA $\\approx0.698$), peaking at early blocks, indicating that token-level self-supervision induces early-stage features that bridge species-specific statistics. Supervised ViTs are competitive on CKA yet show weaker geometric correspondence than DINO (e.g., ViT-B/16 RSA $\\approx0.53$ at block8; ViT-L/16 $\\approx0.47$ at block14), revealing depth-dependent divergences between similarity and representational geometry. CNNs remain strong baselines but below plain ViTs on alignment, and windowed transformers underperform plain ViTs, implicating architectural inductive biases in cross-species alignment. Results indicate that self-supervision coupled with ViT inductive biases yields representational geometries that more closely align feline and human visual systems than widely used CNNs and windowed Transformers, providing testable neuroscientific hypotheses about where and how cross-species visual computations converge. We release our code and dataset for reference and reproducibility.",
    "fetched_at": "2025-11-06T02:19:07.215590Z"
  },
  {
    "id": "2511.02406v1",
    "title": "Arithmetic Circuits and Neural Networks for Regular Matroids",
    "date": "2025-11-04",
    "tags": [
      "math.CO",
      "CO",
      "cs.CC",
      "CC",
      "cs.DM",
      "DM",
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Christoph Hertrich",
      "Stefan Kober",
      "Georg Loho"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02406v1",
    "abstract": "We prove that there exist uniform $(+,\\times,/)$-circuits of size $O(n^3)$ to compute the basis generating polynomial of regular matroids on $n$ elements. By tropicalization, this implies that there exist uniform $(\\max,+,-)$-circuits and ReLU neural networks of the same size for weighted basis maximization of regular matroids. As a consequence in linear programming theory, we obtain a first example where taking the difference of two extended formulations can be more efficient than the best known individual extended formulation of size $O(n^6)$ by Aprile and Fiorini. Such differences have recently been introduced as virtual extended formulations. The proof of our main result relies on a fine-tuned version of Seymour's decomposition of regular matroids which allows us to identify and maintain graphic substructures to which we can apply a local version of the star-mesh transformation.",
    "fetched_at": "2025-11-06T02:19:07.215531Z"
  },
  {
    "id": "2511.02414v1",
    "title": "A New Perspective on Precision and Recall for Generative Models",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Benjamin Sykes",
      "Loïc Simon",
      "Julien Rabin",
      "Jalal Fadili"
    ],
    "institution": "UNICAEN, ENSICAEN, GREYC",
    "link": "http://arxiv.org/pdf/2511.02414v1",
    "abstract": "With the recent success of generative models in image and text, the question of their evaluation has recently gained a lot of attention. While most methods from the state of the art rely on scalar metrics, the introduction of Precision and Recall (PR) for generative model has opened up a new avenue of research. The associated PR curve allows for a richer analysis, but their estimation poses several challenges. In this paper, we present a new framework for estimating entire PR curves based on a binary classification standpoint. We conduct a thorough statistical analysis of the proposed estimates. As a byproduct, we obtain a minimax upper bound on the PR estimation risk. We also show that our framework extends several landmark PR metrics of the literature which by design are restrained to the extreme values of the curve. Finally, we study the different behaviors of the curves obtained experimentally in various settings.",
    "fetched_at": "2025-11-06T02:19:07.215488Z"
  },
  {
    "id": "2511.02426v1",
    "title": "A Kullback-Leibler divergence method for input-system-state   identification",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.IT",
      "IT",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.IT",
      "68T05 (Learning and adaptive systems)",
      "I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Marios Impraimakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02426v1",
    "abstract": "The capability of a novel Kullback-Leibler divergence method is examined herein within the Kalman filter framework to select the input-parameter-state estimation execution with the most plausible results. This identification suffers from the uncertainty related to obtaining different results from different initial parameter set guesses, and the examined approach uses the information gained from the data in going from the prior to the posterior distribution to address the issue. Firstly, the Kalman filter is performed for a number of different initial parameter sets providing the system input-parameter-state estimation. Secondly, the resulting posterior distributions are compared simultaneously to the initial prior distributions using the Kullback-Leibler divergence. Finally, the identification with the least Kullback-Leibler divergence is selected as the one with the most plausible results. Importantly, the method is shown to select the better performed identification in linear, nonlinear, and limited information applications, providing a powerful tool for system monitoring.",
    "fetched_at": "2025-11-06T02:19:07.215394Z"
  },
  {
    "id": "2511.02435v1",
    "title": "Improving Unlearning with Model Updates Probably Aligned with Gradients",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Virgile Dine",
      "Teddy Furon",
      "Charly Faure"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02435v1",
    "abstract": "We formulate the machine unlearning problem as a general constrained optimization problem. It unifies the first-order methods from the approximate machine unlearning literature. This paper then introduces the concept of feasible updates as the model's parameter update directions that help with unlearning while not degrading the utility of the initial model. Our design of feasible updates is based on masking, \\ie\\ a careful selection of the model's parameters worth updating. It also takes into account the estimation noise of the gradients when processing each batch of data to offer a statistical guarantee to derive locally feasible updates. The technique can be plugged in, as an add-on, to any first-order approximate unlearning methods. Experiments with computer vision classifiers validate this approach.",
    "fetched_at": "2025-11-06T02:19:07.215352Z"
  },
  {
    "id": "2511.02451v1",
    "title": "Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case   Study in Finance",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kentaro Ueda",
      "François Portet",
      "Hirohiko Suwa",
      "Keiichi Yasumoto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02451v1",
    "abstract": "While LLMs excel at general tasks, they struggle in specialized domains like finance, requiring diverse skills in domain knowledge, mathematical reasoning, and multilingual processing. Merging domain-specific Continual Pre-training (CPT) \"experts\" offers a practical alternative to costly and unstable multi-skill training. However, unlike established Supervised Fine-Tuning (SFT) model-based merging, CPT model merging remains largely unexplored. We address this gap by creating financial LLMs from experts in finance, math, and Japanese. We propose a three-stage evaluation focusing on knowledge recovery, complementarity, and emergence, and assess three merging methods (Task Arithmetic, TIES, and DARE-TIES) on a comprehensive financial benchmark curated from 18 tasks across 8 established datasets. Results show that merging an expert with its base model recovers general knowledge lost during CPT, while merging experts improves performance and can yield emergent cross-domain skills. Among the methods, Task Arithmetic performs strongly but is hyperparameter-sensitive, whereas TIES is more robust. Our findings also suggest that while model similarity correlates with merging success, emergent skills depend on more complex factors. This work presents the first foundational analysis of CPT model merging, establishing a principled framework and providing clear guidance for building multi-skill LLMs from existing assets.",
    "fetched_at": "2025-11-06T02:19:07.215314Z"
  },
  {
    "id": "2511.02452v1",
    "title": "An Adaptive Sampling Framework for Detecting Localized Concept Drift   under Label Scarcity",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Junghee Pyeon",
      "Davide Cacciarelli",
      "Kamran Paynabar"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02452v1",
    "abstract": "Concept drift and label scarcity are two critical challenges limiting the robustness of predictive models in dynamic industrial environments. Existing drift detection methods often assume global shifts and rely on dense supervision, making them ill-suited for regression tasks with local drifts and limited labels. This paper proposes an adaptive sampling framework that combines residual-based exploration and exploitation with EWMA monitoring to efficiently detect local concept drift under labeling budget constraints. Empirical results on synthetic benchmarks and a case study on electricity market demonstrate superior performance in label efficiency and drift detection accuracy.",
    "fetched_at": "2025-11-06T02:19:07.215265Z"
  },
  {
    "id": "2511.02453v1",
    "title": "Accounting for Underspecification in Statistical Claims of Model   Superiority",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Thomas Sanchez",
      "Pedro M. Gordaliza",
      "Meritxell Bach Cuadra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02453v1",
    "abstract": "Machine learning methods are increasingly applied in medical imaging, yet many reported improvements lack statistical robustness: recent works have highlighted that small but significant performance gains are highly likely to be false positives. However, these analyses do not take \\emph{underspecification} into account -- the fact that models achieving similar validation scores may behave differently on unseen data due to random initialization or training dynamics. Here, we extend a recent statistical framework modeling false outperformance claims to include underspecification as an additional variance component. Our simulations demonstrate that even modest seed variability ($\\sim1\\%$) substantially increases the evidence required to support superiority claims. Our findings underscore the need for explicit modeling of training variance when validating medical imaging systems.",
    "fetched_at": "2025-11-06T02:19:07.215227Z"
  },
  {
    "id": "2511.02458v1",
    "title": "Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic   LLM Personas",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CE",
      "CE",
      "econ.GN",
      "GN",
      "q-fin.EC",
      "EC"
    ],
    "authors": [
      "Giulia Iadisernia",
      "Carolina Camassa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02458v1",
    "abstract": "We evaluate whether persona-based prompting improves Large Language Model (LLM) performance on macroeconomic forecasting tasks. Using 2,368 economics-related personas from the PersonaHub corpus, we prompt GPT-4o to replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds (2013-2025). We compare the persona-prompted forecasts against the human experts panel, across four target variables (HICP, core HICP, GDP growth, unemployment) and four forecast horizons. We also compare the results against 100 baseline forecasts without persona descriptions to isolate its effect. We report two main findings. Firstly, GPT-4o and human forecasters achieve remarkably similar accuracy levels, with differences that are statistically significant yet practically modest. Our out-of-sample evaluation on 2024-2025 data demonstrates that GPT-4o can maintain competitive forecasting performance on unseen events, though with notable differences compared to the in-sample period. Secondly, our ablation experiment reveals no measurable forecasting advantage from persona descriptions, suggesting these prompt components can be omitted to reduce computational costs without sacrificing accuracy. Our results provide evidence that GPT-4o can achieve competitive forecasting accuracy even on out-of-sample macroeconomic events, if provided with relevant context data, while revealing that diverse prompts produce remarkably homogeneous forecasts compared to human panels.",
    "fetched_at": "2025-11-06T02:19:07.215185Z"
  },
  {
    "id": "2511.02460v1",
    "title": "SKGE: Spherical Knowledge Graph Embedding with Geometric Regularization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xuan-Truong Quan",
      "Xuan-Son Quan",
      "Duc Do Minh",
      "Vinh Nguyen Van"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02460v1",
    "abstract": "Knowledge graph embedding (KGE) has become a fundamental technique for representation learning on multi-relational data. Many seminal models, such as TransE, operate in an unbounded Euclidean space, which presents inherent limitations in modeling complex relations and can lead to inefficient training. In this paper, we propose Spherical Knowledge Graph Embedding (SKGE), a model that challenges this paradigm by constraining entity representations to a compact manifold: a hypersphere. SKGE employs a learnable, non-linear Spherization Layer to map entities onto the sphere and interprets relations as a hybrid translate-then-project transformation. Through extensive experiments on three benchmark datasets, FB15k-237, CoDEx-S, and CoDEx-M, we demonstrate that SKGE consistently and significantly outperforms its strong Euclidean counterpart, TransE, particularly on large-scale benchmarks such as FB15k-237 and CoDEx-M, demonstrating the efficacy of the spherical geometric prior. We provide an in-depth analysis to reveal the sources of this advantage, showing that this geometric constraint acts as a powerful regularizer, leading to comprehensive performance gains across all relation types. More fundamentally, we prove that the spherical geometry creates an \"inherently hard negative sampling\" environment, naturally eliminating trivial negatives and forcing the model to learn more robust and semantically coherent representations. Our findings compellingly demonstrate that the choice of manifold is not merely an implementation detail but a fundamental design principle, advocating for geometric priors as a cornerstone for designing the next generation of powerful and stable KGE models.",
    "fetched_at": "2025-11-06T02:19:07.215141Z"
  },
  {
    "id": "2511.02463v1",
    "title": "Auditable-choice reframing unlocks RL-based verification for open-ended   tasks",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mengyu Zhang",
      "Xubo Liu",
      "Siyu Ding",
      "Weichong Yin",
      "Yu Sun",
      "Hua Wu",
      "Wenya Guo",
      "Ying Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02463v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great potential in enhancing the reasoning capabilities of large language models (LLMs), achieving remarkable progress in domains such as mathematics and programming where standard answers are available. However, for open-ended tasks lacking ground-truth solutions (e.g., creative writing and instruction following), existing studies typically regard them as non-reasoning scenarios, thereby overlooking the latent value of reasoning capabilities. This raises a key question: Can strengthening reasoning improve performance in open-ended tasks? To address this, we explore the transfer of the RLVR paradigm to the open domain. Yet, since RLVR fundamentally relies on verifiers that presuppose the existence of standard answers, it cannot be directly applied to open-ended tasks. To overcome this challenge, we introduce Verifiable Multiple-Choice Reformulation (VMR), a novel training strategy that restructures open-ended data into verifiable multiple-choice formats, enabling effective training even in the absence of explicit ground truth. Experimental results on multiple benchmarks validate the effectiveness of our method in improving LLM performance on open-ended tasks. Notably, across eight open-ended benchmarks, our VMR-based training delivers an average gain of 5.99 points over the baseline. Code will be released upon acceptance to facilitate reproducibility.",
    "fetched_at": "2025-11-06T02:19:07.215090Z"
  },
  {
    "id": "2511.02478v1",
    "title": "Wireless Video Semantic Communication with Decoupled Diffusion   Multi-frame Compensation",
    "date": "2025-11-04",
    "tags": [
      "cs.MM",
      "MM",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Bingyan Xie",
      "Yongpeng Wu",
      "Yuxuan Shi",
      "Biqian Feng",
      "Wenjun Zhang",
      "Jihong Park",
      "Tony Quek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02478v1",
    "abstract": "Existing wireless video transmission schemes directly conduct video coding in pixel level, while neglecting the inner semantics contained in videos. In this paper, we propose a wireless video semantic communication framework with decoupled diffusion multi-frame compensation (DDMFC), abbreviated as WVSC-D, which integrates the idea of semantic communication into wireless video transmission scenarios. WVSC-D first encodes original video frames as semantic frames and then conducts video coding based on such compact representations, enabling the video coding in semantic level rather than pixel level. Moreover, to further reduce the communication overhead, a reference semantic frame is introduced to substitute motion vectors of each frame in common video coding methods. At the receiver, DDMFC is proposed to generate compensated current semantic frame by a two-stage conditional diffusion process. With both the reference frame transmission and DDMFC frame compensation, the bandwidth efficiency improves with satisfying video transmission performance. Experimental results verify the performance gain of WVSC-D over other DL-based methods e.g. DVSC about 1.8 dB in terms of PSNR.",
    "fetched_at": "2025-11-06T02:19:07.214980Z"
  },
  {
    "id": "2511.02481v2",
    "title": "NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammad Sadegh Eshaghi",
      "Cosmin Anitescu",
      "Navid Valizadeh",
      "Yizheng Wang",
      "Xiaoying Zhuang",
      "Timon Rabczuk"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02481v2",
    "abstract": "Partial differential equations (PDEs) underpin quantitative descriptions across the physical sciences and engineering, yet high-fidelity simulation remains a major computational bottleneck for many-query, real-time, and design tasks. Data-driven surrogates can be strikingly fast but are often unreliable when applied outside their training distribution. Here we introduce Neural Operator Warm Starts (NOWS), a hybrid strategy that harnesses learned solution operators to accelerate classical iterative solvers by producing high-quality initial guesses for Krylov methods such as conjugate gradient and GMRES. NOWS leaves existing discretizations and solver infrastructures intact, integrating seamlessly with finite-difference, finite-element, isogeometric analysis, finite volume method, etc. Across our benchmarks, the learned initialization consistently reduces iteration counts and end-to-end runtime, resulting in a reduction of the computational time of up to 90 %, while preserving the stability and convergence guarantees of the underlying numerical algorithms. By combining the rapid inference of neural operators with the rigor of traditional solvers, NOWS provides a practical and trustworthy approach to accelerate high-fidelity PDE simulations.",
    "fetched_at": "2025-11-06T02:19:07.214922Z"
  },
  {
    "id": "2511.02487v1",
    "title": "Learning CNF formulas from uniform random solutions in the local lemma   regime",
    "date": "2025-11-04",
    "tags": [
      "cs.DS",
      "DS",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Weiming Feng",
      "Xiongxin Yang",
      "Yixiao Yu",
      "Yiyao Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02487v1",
    "abstract": "We study the problem of learning a $n$-variables $k$-CNF formula $\\Phi$ from its i.i.d. uniform random solutions, which is equivalent to learning a Boolean Markov random field (MRF) with $k$-wise hard constraints. Revisiting Valiant's algorithm (Commun. ACM'84), we show that it can exactly learn (1) $k$-CNFs with bounded clause intersection size under Lov\\'asz local lemma type conditions, from $O(\\log n)$ samples; and (2) random $k$-CNFs near the satisfiability threshold, from $\\widetilde{O}(n^{\\exp(-\\sqrt{k})})$ samples. These results significantly improve the previous $O(n^k)$ sample complexity. We further establish new information-theoretic lower bounds on sample complexity for both exact and approximate learning from i.i.d. uniform random solutions.",
    "fetched_at": "2025-11-06T02:19:07.214869Z"
  },
  {
    "id": "2511.02490v1",
    "title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and   Monitoring",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Rajan Das Gupta",
      "Md Kishor Morol",
      "Nafiz Fahad",
      "Md Tanzib Hosain",
      "Sumaya Binte Zilani Choya",
      "Md Jakir Hossen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02490v1",
    "abstract": "As the global burden of Alzheimer's disease (AD) continues to grow, early and accurate detection has become increasingly critical, especially in regions with limited access to advanced diagnostic tools. We propose BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address this challenge. This novel system harnesses the powerful reasoning capabilities of Large Language Models (LLMs) for Alzheimer's detection and monitoring. BRAINS features a dual-module architecture: a cognitive diagnostic module and a case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain volume metrics -- to perform structured assessments of Alzheimer's risk. Meanwhile, the Case Retrieval Module encodes patient profiles into latent representations and retrieves similar cases from a curated knowledge base. These auxiliary cases are fused with the input profile via a Case Fusion Layer to enhance contextual understanding. The combined representation is then processed with clinical prompts for inference. Evaluations on real-world datasets demonstrate BRAINS effectiveness in classifying disease severity and identifying early signs of cognitive decline. This system not only shows strong potential as an assistive tool for scalable, explainable, and early-stage Alzheimer's disease detection, but also offers hope for future applications in the field.",
    "fetched_at": "2025-11-06T02:19:07.214825Z"
  },
  {
    "id": "2511.02495v1",
    "title": "DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and   Language for Fire Understanding",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zixuan Liu",
      "Siavash H. Khajavi",
      "Guangkai Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02495v1",
    "abstract": "Recent advances in multi-modal models have demonstrated strong performance in tasks such as image generation and reasoning. However, applying these models to the fire domain remains challenging due to the lack of publicly available datasets with high-quality fire domain annotations. To address this gap, we introduce DetectiumFire, a large-scale, multi-modal dataset comprising of 22.5k high-resolution fire-related images and 2.5k real-world fire-related videos covering a wide range of fire types, environments, and risk levels. The data are annotated with both traditional computer vision labels (e.g., bounding boxes) and detailed textual prompts describing the scene, enabling applications such as synthetic data generation and fire risk reasoning. DetectiumFire offers clear advantages over existing benchmarks in scale, diversity, and data quality, significantly reducing redundancy and enhancing coverage of real-world scenarios. We validate the utility of DetectiumFire across multiple tasks, including object detection, diffusion-based image generation, and vision-language reasoning. Our results highlight the potential of this dataset to advance fire-related research and support the development of intelligent safety systems. We release DetectiumFire to promote broader exploration of fire understanding in the AI community. The dataset is available at https://kaggle.com/datasets/38b79c344bdfc55d1eed3d22fbaa9c31fad45e27edbbe9e3c529d6e5c4f93890",
    "fetched_at": "2025-11-06T02:19:07.214769Z"
  },
  {
    "id": "2511.02496v1",
    "title": "Variational Geometric Information Bottleneck: Learning the Shape of   Understanding",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ronald Katende"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02496v1",
    "abstract": "We propose a unified information-geometric framework that formalizes understanding in learning as a trade-off between informativeness and geometric simplicity. An encoder phi is evaluated by U(phi) = I(phi(X); Y) - beta * C(phi), where C(phi) penalizes curvature and intrinsic dimensionality, enforcing smooth, low-complexity manifolds. Under mild manifold and regularity assumptions, we derive non-asymptotic bounds showing that generalization error scales with intrinsic dimension while curvature controls approximation stability, directly linking geometry to sample efficiency. To operationalize this theory, we introduce the Variational Geometric Information Bottleneck (V-GIB), a variational estimator that unifies mutual-information compression and curvature regularization through tractable geometric proxies such as the Hutchinson trace, Jacobian norms, and local PCA. Experiments across synthetic manifolds, few-shot settings, and real-world datasets (Fashion-MNIST, CIFAR-10) reveal a robust information-geometry Pareto frontier, stable estimators, and substantial gains in interpretive efficiency. Fractional-data experiments on CIFAR-10 confirm that curvature-aware encoders maintain predictive power under data scarcity, validating the predicted efficiency-curvature law. Overall, V-GIB provides a principled and measurable route to representations that are geometrically coherent, data-efficient, and aligned with human-understandable structure.",
    "fetched_at": "2025-11-06T02:19:07.214718Z"
  },
  {
    "id": "2511.02525v1",
    "title": "An End-to-End Learning Approach for Solving Capacitated Location-Routing   Problems",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Changhao Miao",
      "Yuntian Zhang",
      "Tongyu Wu",
      "Fang Deng",
      "Chen Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02525v1",
    "abstract": "The capacitated location-routing problems (CLRPs) are classical problems in combinatorial optimization, which require simultaneously making location and routing decisions. In CLRPs, the complex constraints and the intricate relationships between various decisions make the problem challenging to solve. With the emergence of deep reinforcement learning (DRL), it has been extensively applied to address the vehicle routing problem and its variants, while the research related to CLRPs still needs to be explored. In this paper, we propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP (OCLRP), respectively. We are the first to propose an end-to-end learning approach for CLRPs, following the encoder-decoder structure. In particular, we reformulate the CLRPs as a markov decision process tailored to various decisions, a general modeling framework that can be adapted to other DRL-based methods. To better handle the interdependency across location and routing decisions, we also introduce a novel heterogeneous querying attention mechanism designed to adapt dynamically to various decision-making stages. Experimental results on both synthetic and benchmark datasets demonstrate superior solution quality and better generalization performance of our proposed approach over representative traditional and DRL-based baselines in solving both CLRP and OCLRP.",
    "fetched_at": "2025-11-06T02:19:07.214678Z"
  },
  {
    "id": "2511.02526v1",
    "title": "Many-vs-Many Missile Guidance via Virtual Targets",
    "date": "2025-11-04",
    "tags": [
      "eess.SY",
      "SY",
      "cs.LG",
      "LG",
      "cs.RO",
      "RO",
      "cs.SY"
    ],
    "authors": [
      "Marc Schneider",
      "Walter Fichter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02526v1",
    "abstract": "This paper presents a novel approach to many-vs-many missile guidance using virtual targets (VTs) generated by a Normalizing Flows-based trajectory predictor. Rather than assigning n interceptors directly to m physical targets through conventional weapon target assignment algorithms, we propose a centralized strategy that constructs n VT trajectories representing probabilistic predictions of maneuvering target behavior. Each interceptor is guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse flight, transitioning to Proportional Navigation guidance for terminal interception. This approach treats many-vs-many engagements as many-vs-distribution scenarios, exploiting numerical superiority (n > m) by distributing interceptors across diverse trajectory hypotheses rather than pursuing identical deterministic predictions. Monte Carlo simulations across various target-interceptor configurations (1-6 targets, 1-8 interceptors) demonstrate that the VT method matches or exceeds baseline straight-line prediction performance by 0-4.1% when n = m, with improvements increasing to 5.8-14.4% when n > m. The results confirm that probabilistic VTs enable effective exploitation of numerical superiority, significantly increasing interception probability in many-vs-many scenarios.",
    "fetched_at": "2025-11-06T02:19:07.214624Z"
  },
  {
    "id": "2511.02531v1",
    "title": "Causal Graph Neural Networks for Healthcare",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Munib Mesinovic",
      "Max Buhlan",
      "Tingting Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02531v1",
    "abstract": "Healthcare artificial intelligence systems routinely fail when deployed across institutions, with documented performance drops and perpetuation of discriminatory patterns embedded in historical data. This brittleness stems, in part, from learning statistical associations rather than causal mechanisms. Causal graph neural networks address this triple crisis of distribution shift, discrimination, and inscrutability by combining graph-based representations of biomedical data with causal inference principles to learn invariant mechanisms rather than spurious correlations. This Review examines methodological foundations spanning structural causal models, disentangled causal representation learning, and techniques for interventional prediction and counterfactual reasoning on graphs. We analyse applications demonstrating clinical value across psychiatric diagnosis through brain network analysis, cancer subtyping via multi-omics causal integration, continuous physiological monitoring with mechanistic interpretation, and drug recommendation correcting prescription bias. These advances establish foundations for patient-specific Causal Digital Twins, enabling in silico clinical experimentation, with integration of large language models for hypothesis generation and causal graph neural networks for mechanistic validation. Substantial barriers remain, including computational requirements precluding real-time deployment, validation challenges demanding multi-modal evidence triangulation beyond cross-validation, and risks of causal-washing where methods employ causal terminology without rigorous evidentiary support. We propose tiered frameworks distinguishing causally-inspired architectures from causally-validated discoveries and identify critical research priorities making causal rather than purely associational claims.",
    "fetched_at": "2025-11-06T02:19:07.214580Z"
  },
  {
    "id": "2511.02533v1",
    "title": "Rawlsian many-to-one matching with non-linear utility",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hortence Nana",
      "Andreas Athanasopoulos",
      "Christos Dimitrakakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02533v1",
    "abstract": "We study a many-to-one matching problem, such as the college admission problem, where each college can admit multiple students. Unlike classical models, colleges evaluate sets of students through non-linear utility functions that capture diversity between them. In this setting, we show that classical stable matchings may fail to exist. To address this, we propose alternative solution concepts based on Rawlsian fairness, aiming to maximize the minimum utility across colleges. We design both deterministic and stochastic algorithms that iteratively improve the outcome of the worst-off college, offering a practical approach to fair allocation when stability cannot be guaranteed.",
    "fetched_at": "2025-11-06T02:19:07.214468Z"
  },
  {
    "id": "2511.02534v1",
    "title": "Knowledge Graph-enhanced Large Language Model for Incremental Game   PlayTesting",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Enhong Mu",
      "Jinyu Cai",
      "Yijun Lu",
      "Mingyue Zhang",
      "Kenji Tei",
      "Jialong Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02534v1",
    "abstract": "The rapid iteration and frequent updates of modern video games pose significant challenges to the efficiency and specificity of testing. Although automated playtesting methods based on Large Language Models (LLMs) have shown promise, they often lack structured knowledge accumulation mechanisms, making it difficult to conduct precise and efficient testing tailored for incremental game updates. To address this challenge, this paper proposes a KLPEG framework. The framework constructs and maintains a Knowledge Graph (KG) to systematically model game elements, task dependencies, and causal relationships, enabling knowledge accumulation and reuse across versions. Building on this foundation, the framework utilizes LLMs to parse natural language update logs, identify the scope of impact through multi-hop reasoning on the KG, enabling the generation of update-tailored test cases. Experiments in two representative game environments, Overcooked and Minecraft, demonstrate that KLPEG can more accurately locate functionalities affected by updates and complete tests in fewer steps, significantly improving both playtesting effectiveness and efficiency.",
    "fetched_at": "2025-11-06T02:19:07.214430Z"
  },
  {
    "id": "2511.02536v1",
    "title": "Theoretical Guarantees for Causal Discovery on Large Random Graphs",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mathieu Chevalley",
      "Arash Mehrjou",
      "Patrick Schwab"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02536v1",
    "abstract": "We investigate theoretical guarantees for the false-negative rate (FNR) -- the fraction of true causal edges whose orientation is not recovered, under single-variable random interventions and an $\\epsilon$-interventional faithfulness assumption that accommodates latent confounding. For sparse Erd\\H{o}s--R\\'enyi directed acyclic graphs, where the edge probability scales as $p_e = \\Theta(1/d)$, we show that the FNR concentrates around its mean at rate $O(\\frac{\\log d}{\\sqrt d})$, implying that large deviations above the expected error become exponentially unlikely as dimensionality increases. This concentration ensures that derived upper bounds hold with high probability in large-scale settings. Extending the analysis to generalized Barab\\'asi--Albert graphs reveals an even stronger phenomenon: when the degree exponent satisfies $\\gamma > 3$, the deviation width scales as $O(d^{\\beta - \\frac{1}{2}})$ with $\\beta = 1/(\\gamma - 1) < \\frac{1}{2}$, and hence vanishes in the limit. This demonstrates that realistic scale-free topologies intrinsically regularize causal discovery, reducing variability in orientation error. These finite-dimension results provide the first dimension-adaptive, faithfulness-robust guarantees for causal structure recovery, and challenge the intuition that high dimensionality and network heterogeneity necessarily hinder accurate discovery. Our simulation results corroborate these theoretical predictions, showing that the FNR indeed concentrates and often vanishes in practice as dimensionality grows.",
    "fetched_at": "2025-11-06T02:19:07.214378Z"
  },
  {
    "id": "2511.02537v1",
    "title": "Smart-Hiring: An Explainable end-to-end Pipeline for CV Information   Extraction and Job Matching",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kenza Khelkhal",
      "Dihia Lanasri"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02537v1",
    "abstract": "Hiring processes often involve the manual screening of hundreds of resumes for each job, a task that is time and effort consuming, error-prone, and subject to human bias. This paper presents Smart-Hiring, an end-to-end Natural Language Processing (NLP) pipeline de- signed to automatically extract structured information from unstructured resumes and to semantically match candidates with job descriptions. The proposed system combines document parsing, named-entity recognition, and contextual text embedding techniques to capture skills, experience, and qualifications. Using advanced NLP technics, Smart-Hiring encodes both resumes and job descriptions in a shared vector space to compute similarity scores between candidates and job postings. The pipeline is modular and explainable, allowing users to inspect extracted entities and matching rationales. Experiments were conducted on a real-world dataset of resumes and job descriptions spanning multiple professional domains, demonstrating the robustness and feasibility of the proposed approach. The system achieves competitive matching accuracy while preserving a high degree of interpretability and transparency in its decision process. This work introduces a scalable and practical NLP frame- work for recruitment analytics and outlines promising directions for bias mitigation, fairness-aware modeling, and large-scale deployment of data-driven hiring solutions.",
    "fetched_at": "2025-11-06T02:19:07.214332Z"
  },
  {
    "id": "2511.02558v1",
    "title": "Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC"
    ],
    "authors": [
      "Ali Farki",
      "Elaheh Moradi",
      "Deepika Koundal",
      "Jussi Tohka"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02558v1",
    "abstract": "Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",
    "fetched_at": "2025-11-06T02:19:07.214290Z"
  },
  {
    "id": "2511.02565v1",
    "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain   Visual Decoding",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingyu Lu",
      "Haonan Wang",
      "Qixiang Zhang",
      "Xiaomeng Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02565v1",
    "abstract": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual experiences from fMRI without subject-specific training, holds great potential for clinical applications. However, this direction remains underexplored due to challenges in cross-subject generalization and the complex nature of brain signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework that explicitly models the ventral-dorsal architecture of the human visual system to learn multi-dimensional representations. By disentangling and leveraging features from early visual cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary cognitive information essential for visual reconstruction. Furthermore, we introduce a feature-level contrastive learning strategy to enhance the extraction of subject-invariant semantic representations, thereby enhancing subject-agnostic applicability to previously unseen subjects. Unlike conventional pipelines that need more than 12 hours of per-subject data and heavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates each reconstructed video in 10 seconds without any retraining, offering a fast and clinically scalable solution. The source code will be released upon acceptance of the paper.",
    "fetched_at": "2025-11-06T02:19:07.214185Z"
  },
  {
    "id": "2511.02567v1",
    "title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement   Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yixiu Mao",
      "Yun Qu",
      "Qi Wang",
      "Xiangyang Ji"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02567v1",
    "abstract": "Offline reinforcement learning (RL) suffers from extrapolation errors induced by out-of-distribution (OOD) actions. To address this, offline RL algorithms typically impose constraints on action selection, which can be systematically categorized into density, support, and sample constraints. However, we show that each category has inherent limitations: density and sample constraints tend to be overly conservative in many scenarios, while the support constraint, though least restrictive, faces challenges in accurately modeling the behavior policy. To overcome these limitations, we propose a new neighborhood constraint that restricts action selection in the Bellman target to the union of neighborhoods of dataset actions. Theoretically, the constraint not only bounds extrapolation errors and distribution shift under certain conditions, but also approximates the support constraint without requiring behavior policy modeling. Moreover, it retains substantial flexibility and enables pointwise conservatism by adapting the neighborhood radius for each data point. In practice, we employ data quality as the adaptation criterion and design an adaptive neighborhood constraint. Building on an efficient bilevel optimization framework, we develop a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning (ANQ), to perform Q learning with target actions satisfying this constraint. Empirically, ANQ achieves state-of-the-art performance on standard offline RL benchmarks and exhibits strong robustness in scenarios with noisy or limited data.",
    "fetched_at": "2025-11-06T02:19:07.214136Z"
  },
  {
    "id": "2511.02570v1",
    "title": "Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lukas Fehring",
      "Marcel Wever",
      "Maximilian Spliethöver",
      "Leona Hennig",
      "Henning Wachsmuth",
      "Marius Lindauer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02570v1",
    "abstract": "Hyperparameter optimization (HPO), for example, based on Bayesian optimization (BO), supports users in designing models well-suited for a given dataset. HPO has proven its effectiveness on several applications, ranging from classical machine learning for tabular data to deep neural networks for computer vision and transformers for natural language processing. However, HPO still sometimes lacks acceptance by machine learning experts due to its black-box nature and limited user control. Addressing this, first approaches have been proposed to initialize BO methods with expert knowledge. However, these approaches do not allow for online steering during the optimization process. In this paper, we introduce a novel method that enables repeated interventions to steer BO via user input, specifying expert knowledge and user preferences at runtime of the HPO process in the form of prior distributions. To this end, we generalize an existing method, $\\pi$BO, preserving theoretical guarantees. We also introduce a misleading prior detection scheme, which allows protection against harmful user inputs. In our experimental evaluation, we demonstrate that our method can effectively incorporate multiple priors, leveraging informative priors, whereas misleading priors are reliably rejected or overcome. Thereby, we achieve competitiveness to unperturbed BO.",
    "fetched_at": "2025-11-06T02:19:07.214086Z"
  },
  {
    "id": "2511.02573v2",
    "title": "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization   using Detection Transformers",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anastasios T. Sotiropoulos",
      "Stavros Tsimpoukis",
      "Dimitrios Tyrovolas",
      "Sotiris Ioannidis",
      "Panagiotis D. Diamantoulakis",
      "George K. Karagiannidis",
      "Christos K. Liaskos"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02573v2",
    "abstract": "The pursuit of immersive and structurally aware multimedia experiences has intensified interest in sensing modalities that reconstruct objects beyond the limits of visible light. Conventional optical pipelines degrade under occlusion or low illumination, motivating the use of radio-frequency (RF) sensing, whose electromagnetic waves penetrate materials and encode both geometric and compositional information. Yet, uncontrolled multipath propagation restricts reconstruction accuracy. Recent advances in Programmable Wireless Environments (PWEs) mitigate this limitation by enabling software-defined manipulation of propagation through Reconfigurable Intelligent Surfaces (RISs), thereby providing controllable illumination diversity. Building on this capability, this work introduces a PWE-driven RF framework for three-dimensional object reconstruction using material-aware spherical primitives. The proposed approach combines RIS-enabled field synthesis with a Detection Transformer (DETR) that infers spatial and material parameters directly from extracted RF features. Simulation results confirm the framework's ability to approximate object geometries and classify material composition with an overall accuracy of 79.35%, marking an initial step toward programmable and physically grounded RF-based 3D object composition visualization.",
    "fetched_at": "2025-11-06T02:19:07.214033Z"
  },
  {
    "id": "2511.02577v1",
    "title": "Directional-Clamp PPO",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gilad Karpel",
      "Ruida Zhou",
      "Shoham Sabach",
      "Mohammad Ghavamzadeh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02577v1",
    "abstract": "Proximal Policy Optimization (PPO) is widely regarded as one of the most successful deep reinforcement learning algorithms, known for its robustness and effectiveness across a range of problems.   The PPO objective encourages the importance ratio between the current and behavior policies to move to the \"right\" direction -- starting from importance sampling ratios equal to 1, increasing the ratios for actions with positive advantages and decreasing those with negative advantages. A clipping function is introduced to prevent over-optimization when updating the importance ratio in these \"right\" direction regions. Many PPO variants have been proposed to extend its success, most of which modify the objective's behavior by altering the clipping in the \"right\" direction regions. However, due to randomness in the rollouts and stochasticity of the policy optimization, we observe that the ratios frequently move to the \"wrong\" direction during the PPO optimization. This is a key factor hindering the improvement of PPO, but it has been largely overlooked. To address this, we propose the Directional-Clamp PPO algorithm (DClamp-PPO), which further penalizes the actions going to the strict \"wrong\" direction regions, where the advantage is positive (negative) and importance ratio falls below (above) $1 - \\beta$ ($1+\\beta$),   for a tunable parameter $\\beta \\in (0, 1)$. The penalty is by enforcing a steeper loss slope, i.e., a clamp, in those regions. We demonstrate that DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing on modifying the objective's behavior in the \"right\" direction, across various MuJoCo environments, using different random seeds. The proposed method is shown, both theoretically and empirically, to better avoid \"wrong\" direction updates while keeping the importance ratio closer to 1.",
    "fetched_at": "2025-11-06T02:19:07.213975Z"
  },
  {
    "id": "2511.02580v1",
    "title": "TAUE: Training-free Noise Transplant and Cultivation Diffusion Model",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.GR",
      "GR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Daichi Nagai",
      "Ryugo Morita",
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02580v1",
    "abstract": "Despite the remarkable success of text-to-image diffusion models, their output of a single, flattened image remains a critical bottleneck for professional applications requiring layer-wise control. Existing solutions either rely on fine-tuning with large, inaccessible datasets or are training-free yet limited to generating isolated foreground elements, failing to produce a complete and coherent scene. To address this, we introduce the Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE), a novel framework for zero-shot, layer-wise image generation. Our core technique, Noise Transplantation and Cultivation (NTC), extracts intermediate latent representations from both foreground and composite generation processes, transplanting them into the initial noise for subsequent layers. This ensures semantic and structural coherence across foreground, background, and composite layers, enabling consistent, multi-layered outputs without requiring fine-tuning or auxiliary datasets. Extensive experiments show that our training-free method achieves performance comparable to fine-tuned methods, enhancing layer-wise consistency while maintaining high image quality and fidelity. TAUE not only eliminates costly training and dataset requirements but also unlocks novel downstream applications, such as complex compositional editing, paving the way for more accessible and controllable generative workflows.",
    "fetched_at": "2025-11-06T02:19:07.213925Z"
  },
  {
    "id": "2511.02584v1",
    "title": "Redundancy Maximization as a Principle of Associative Memory Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "cs.NE",
      "NE",
      "math.IT",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Mark Blümel",
      "Andreas C. Schneider",
      "Valentin Neuhaus",
      "David A. Ehrlich",
      "Marcel Graetz",
      "Michael Wibral",
      "Abdullah Makkeh",
      "Viola Priesemann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02584v1",
    "abstract": "Associative memory, traditionally modeled by Hopfield networks, enables the retrieval of previously stored patterns from partial or noisy cues. Yet, the local computational principles which are required to enable this function remain incompletely understood. To formally characterize the local information processing in such systems, we employ a recent extension of information theory - Partial Information Decomposition (PID). PID decomposes the contribution of different inputs to an output into unique information from each input, redundant information across inputs, and synergistic information that emerges from combining different inputs. Applying this framework to individual neurons in classical Hopfield networks we find that below the memory capacity, the information in a neuron's activity is characterized by high redundancy between the external pattern input and the internal recurrent input, while synergy and unique information are close to zero until the memory capacity is surpassed and performance drops steeply. Inspired by this observation, we use redundancy as an information-theoretic learning goal, which is directly optimized for each neuron, dramatically increasing the network's memory capacity to 1.59, a more than tenfold improvement over the 0.14 capacity of classical Hopfield networks and even outperforming recent state-of-the-art implementations of Hopfield networks. Ultimately, this work establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals.",
    "fetched_at": "2025-11-06T02:19:07.213874Z"
  },
  {
    "id": "2511.02587v1",
    "title": "The Analysis of Lexical Errors in Machine Translation from English into   Romanian",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Angela Stamatie"
    ],
    "institution": "Dumitran",
    "link": "http://arxiv.org/pdf/2511.02587v1",
    "abstract": "The research explores error analysis in the performance of translating by Machine Translation from English into Romanian, and it focuses on lexical errors found in texts which include official information, provided by the World Health Organization (WHO), the Gavi Organization, by the patient information leaflet (the information about the active ingredients of the vaccines or the medication, the indications, the dosage instructions, the storage instructions, the side effects and warning, etc.). All of these texts are related to Covid-19 and have been translated by Google Translate, a multilingual Machine Translation that was created by Google. In the last decades, Google has actively worked to develop a more accurate and fluent automatic translation system. This research, specifically focused on improving Google Translate, aims to enhance the overall quality of Machine Translation by achieving better lexical selection and by reducing errors. The investigation involves a comprehensive analysis of 230 texts that have been translated from English into Romanian.",
    "fetched_at": "2025-11-06T02:19:07.213808Z"
  },
  {
    "id": "2511.02589v2",
    "title": "The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large   Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Claudia Herambourg",
      "Dawid Siuda",
      "Julia Kopczyńska",
      "Joao R. L. Santos",
      "Wojciech Sas",
      "Joanna Śmietańska-Nowak"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02589v2",
    "abstract": "We present ORCA (Omni Research on Calculation in AI) Benchmark - a novel benchmark that evaluates large language models (LLMs) on multi-domain, real-life quantitative reasoning using verified outputs from Omni's calculator engine. In 500 natural-language tasks across domains such as finance, physics, health, and statistics, the five state-of-the-art systems (ChatGPT-5, Gemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only $45\\text{--}63\\,\\%$ accuracy, with errors mainly related to rounding ($35\\,\\%$) and calculation mistakes ($33\\,\\%$). Results in specific domains indicate strengths in mathematics and engineering, but weaknesses in physics and natural sciences. Correlation analysis ($r \\approx 0.40\\text{--}0.65$) shows that the models often fail together but differ in the types of errors they make, highlighting their partial complementarity rather than redundancy. Unlike standard math datasets, ORCA evaluates step-by-step reasoning, numerical precision, and domain generalization across real problems from finance, physics, health, and statistics.",
    "fetched_at": "2025-11-06T02:19:07.213782Z"
  },
  {
    "id": "2511.02593v1",
    "title": "A Large Language Model for Corporate Credit Scoring",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chitro Majumdar",
      "Sergio Scandizzo",
      "Ratanlal Mahanta",
      "Avradip Mandal",
      "Swarnendu Bhattacharjee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02593v1",
    "abstract": "We introduce Omega^2, a Large Language Model-driven framework for corporate credit scoring that combines structured financial data with advanced machine learning to improve predictive reliability and interpretability. Our study evaluates Omega^2 on a multi-agency dataset of 7,800 corporate credit ratings drawn from Moody's, Standard & Poor's, Fitch, and Egan-Jones, each containing detailed firm-level financial indicators such as leverage, profitability, and liquidity ratios. The system integrates CatBoost, LightGBM, and XGBoost models optimized through Bayesian search under temporal validation to ensure forward-looking and reproducible results. Omega^2 achieved a mean test AUC above 0.93 across agencies, confirming its ability to generalize across rating systems and maintain temporal consistency. These results show that combining language-based reasoning with quantitative learning creates a transparent and institution-grade foundation for reliable corporate credit-risk assessment.",
    "fetched_at": "2025-11-06T02:19:07.213725Z"
  },
  {
    "id": "2511.02599v1",
    "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations   to Decode Student Behaviour",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Max Norris",
      "Kobi Gal",
      "Sahan Bulathwela"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02599v1",
    "abstract": "Modelling student knowledge is a key challenge when leveraging AI in education, with major implications for personalised learning. The Knowledge Tracing (KT) task aims to predict how students will respond to educational questions in learning environments, based on their prior interactions. Existing KT models typically use response correctness along with metadata like skill tags and timestamps, often overlooking the question text, which is an important source of pedagogical insight. This omission poses a lost opportunity while limiting predictive performance. We propose Next Token Knowledge Tracing (NTKT), a novel approach that reframes KT as a next-token prediction task using pretrained Large Language Models (LLMs). NTKT represents both student histories and question content as sequences of text, allowing LLMs to learn patterns in both behaviour and language. Our series of experiments significantly improves performance over state-of-the-art neural KT models and generalises much better to cold-start questions and users. These findings highlight the importance of question content in KT and demonstrate the benefits of leveraging pretrained representations of LLMs to model student learning more effectively.",
    "fetched_at": "2025-11-06T02:19:07.213677Z"
  },
  {
    "id": "2511.02600v1",
    "title": "On The Dangers of Poisoned LLMs In Security Automation",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Patrick Karlsen",
      "Even Eilertsen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02600v1",
    "abstract": "This paper investigates some of the risks introduced by \"LLM poisoning,\" the intentional or unintentional introduction of malicious or biased data during model training. We demonstrate how a seemingly improved LLM, fine-tuned on a limited dataset, can introduce significant bias, to the extent that a simple LLM-based alert investigator is completely bypassed when the prompt utilizes the introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we demonstrate how a targeted poisoning attack can bias the model to consistently dismiss true positive alerts originating from a specific user. Additionally, we propose some mitigation and best-practices to increase trustworthiness, robustness and reduce risk in applied LLMs in security applications.",
    "fetched_at": "2025-11-06T02:19:07.213634Z"
  },
  {
    "id": "2511.02602v1",
    "title": "Trustworthy Quantum Machine Learning: A Roadmap for Reliability,   Robustness, and Security in the NISQ Era",
    "date": "2025-11-04",
    "tags": [
      "quant-ph",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ferhat Ozgur Catak",
      "Jungwon Seo",
      "Umit Cali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02602v1",
    "abstract": "Quantum machine learning (QML) is a promising paradigm for tackling computational problems that challenge classical AI. Yet, the inherent probabilistic behavior of quantum mechanics, device noise in NISQ hardware, and hybrid quantum-classical execution pipelines introduce new risks that prevent reliable deployment of QML in real-world, safety-critical settings. This research offers a broad roadmap for Trustworthy Quantum Machine Learning (TQML), integrating three foundational pillars of reliability: (i) uncertainty quantification for calibrated and risk-aware decision making, (ii) adversarial robustness against classical and quantum-native threat models, and (iii) privacy preservation in distributed and delegated quantum learning scenarios. We formalize quantum-specific trust metrics grounded in quantum information theory, including a variance-based decomposition of predictive uncertainty, trace-distance-bounded robustness, and differential privacy for hybrid learning channels. To demonstrate feasibility on current NISQ devices, we validate a unified trust assessment pipeline on parameterized quantum classifiers, uncovering correlations between uncertainty and prediction risk, an asymmetry in attack vulnerability between classical and quantum state perturbations, and privacy-utility trade-offs driven by shot noise and quantum channel noise. This roadmap seeks to define trustworthiness as a first-class design objective for quantum AI.",
    "fetched_at": "2025-11-06T02:19:07.213597Z"
  },
  {
    "id": "2511.02603v1",
    "title": "CGES: Confidence-Guided Early Stopping for Efficient and Accurate   Self-Consistency",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ehsan Aghazadeh",
      "Ahmad Ghasemi",
      "Hedyeh Beyhaghi",
      "Hossein Pishro-Nik"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02603v1",
    "abstract": "Large language models (LLMs) are often queried multiple times at test time, with predictions aggregated by majority vote. While effective, this self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls and can fail when the correct answer is rare. We introduce Confidence-Guided Early Stopping (CGES), a Bayesian framework that forms posteriors over candidate answers using scalar confidence signals derived from token probabilities or reward models. CGES adaptively halts sampling once the posterior mass of a candidate exceeds a threshold. We provide theoretical guarantees for both perfectly calibrated confidences and realistic noisy confidence signals. Across five reasoning benchmarks, CGES reduces the average number of model calls by about 69 percent (for example, from 16.0 to 4.9) while matching the accuracy of self-consistency within 0.06 percentage points.",
    "fetched_at": "2025-11-06T02:19:07.213532Z"
  },
  {
    "id": "2511.02607v1",
    "title": "UniChange: Unifying Change Detection with Multimodal Large Language   Model",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xu Zhang",
      "Danyang Li",
      "Xiaohang Dong",
      "Tianhao Wu",
      "Hualong Yu",
      "Jianye Wang",
      "Qicheng Li",
      "Xiang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02607v1",
    "abstract": "Change detection (CD) is a fundamental task for monitoring and analyzing land cover dynamics. While recent high performance models and high quality datasets have significantly advanced the field, a critical limitation persists. Current models typically acquire limited knowledge from single-type annotated data and cannot concurrently leverage diverse binary change detection (BCD) and semantic change detection (SCD) datasets. This constraint leads to poor generalization and limited versatility. The recent advancements in Multimodal Large Language Models (MLLMs) introduce new possibilities for a unified CD framework. We leverage the language priors and unification capabilities of MLLMs to develop UniChange, the first MLLM-based unified change detection model. UniChange integrates generative language abilities with specialized CD functionalities. Our model successfully unifies both BCD and SCD tasks through the introduction of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange utilizes text prompts to guide the identification of change categories, eliminating the reliance on predefined classification heads. This design allows UniChange to effectively acquire knowledge from multi-source datasets, even when their class definitions conflict. Experiments on four public benchmarks (WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance, achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively, surpassing all previous methods. The code is available at https://github.com/Erxucomeon/UniChange.",
    "fetched_at": "2025-11-06T02:19:07.213394Z"
  },
  {
    "id": "2511.02610v1",
    "title": "Neural Network Interoperability Across Platforms",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nadia Daoudi",
      "Ivan Alfonso",
      "Jordi Cabot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02610v1",
    "abstract": "The development of smart systems (i.e., systems enhanced with AI components) has thrived thanks to the rapid advancements in neural networks (NNs). A wide range of libraries and frameworks have consequently emerged to support NN design and implementation. The choice depends on factors such as available functionalities, ease of use, documentation and community support. After adopting a given NN framework, organizations might later choose to switch to another if performance declines, requirements evolve, or new features are introduced. Unfortunately, migrating NN implementations across libraries is challenging due to the lack of migration approaches specifically tailored for NNs. This leads to increased time and effort to modernize NNs, as manual updates are necessary to avoid relying on outdated implementations and ensure compatibility with new features. In this paper, we propose an approach to automatically migrate neural network code across deep learning frameworks. Our method makes use of a pivot NN model to create an abstraction of the NN prior to migration. We validate our approach using two popular NN frameworks, namely PyTorch and TensorFlow. We also discuss the challenges of migrating code between the two frameworks and how they were approached in our method. Experimental evaluation on five NNs shows that our approach successfully migrates their code and produces NNs that are functionally equivalent to the originals. Artefacts from our work are available online.",
    "fetched_at": "2025-11-06T02:19:07.213331Z"
  },
  {
    "id": "2511.02614v1",
    "title": "A Non-Adversarial Approach to Idempotent Generative Modelling",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammed Al-Jaff",
      "Giovanni Luca Marchetti",
      "Michael C Welle",
      "Jens Lundell",
      "Mats G. Gustafsson",
      "Gustav Eje Henter",
      "Hossein Azizpour",
      "Danica Kragic"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02614v1",
    "abstract": "Idempotent Generative Networks (IGNs) are deep generative models that also function as local data manifold projectors, mapping arbitrary inputs back onto the manifold. They are trained to act as identity operators on the data and as idempotent operators off the data manifold. However, IGNs suffer from mode collapse, mode dropping, and training instability due to their objectives, which contain adversarial components and can cause the model to cover the data manifold only partially -- an issue shared with generative adversarial networks. We introduce Non-Adversarial Idempotent Generative Networks (NAIGNs) to address these issues. Our loss function combines reconstruction with the non-adversarial generative objective of Implicit Maximum Likelihood Estimation (IMLE). This improves on IGN's ability to restore corrupted data and generate new samples that closely match the data distribution. We moreover demonstrate that NAIGNs implicitly learn the distance field to the data manifold, as well as an energy-based model.",
    "fetched_at": "2025-11-06T02:19:07.213286Z"
  },
  {
    "id": "2511.02620v1",
    "title": "Verifying LLM Inference to Prevent Model Weight Exfiltration",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Roy Rinberg",
      "Adam Karvonen",
      "Alex Hoover",
      "Daniel Reuter",
      "Keri Warr"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02620v1",
    "abstract": "As large AI models become increasingly valuable assets, the risk of model weight exfiltration from inference servers grows accordingly. An attacker controlling an inference server may exfiltrate model weights by hiding them within ordinary model outputs, a strategy known as steganography. This work investigates how to verify model responses to defend against such attacks and, more broadly, to detect anomalous or buggy behavior during inference. We formalize model exfiltration as a security game, propose a verification framework that can provably mitigate steganographic exfiltration, and specify the trust assumptions associated with our scheme. To enable verification, we characterize valid sources of non-determinism in large language model inference and introduce two practical estimators for them. We evaluate our detection framework on several open-weight models ranging from 3B to 30B parameters. On MOE-Qwen-30B, our detector reduces exfiltratable information to <0.5% with false-positive rate of 0.01%, corresponding to a >200x slowdown for adversaries. Overall, this work further establishes a foundation for defending against model weight exfiltration and demonstrates that strong protection can be achieved with minimal additional cost to inference providers.",
    "fetched_at": "2025-11-06T02:19:07.213227Z"
  },
  {
    "id": "2511.02623v1",
    "title": "The Realignment Problem: When Right becomes Wrong in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Aakash Sen Sharma",
      "Debdeep Sanyal",
      "Vivek Srivastava",
      "Shirish Karande",
      "Murari Mandal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02623v1",
    "abstract": "The alignment of Large Language Models (LLMs) with human values is central to their safe deployment, yet current practice produces static, brittle, and costly-to-maintain models that fail to keep pace with evolving norms and policies. This misalignment, which we term the Alignment-Reality Gap, poses a growing challenge for reliable long-term use. Existing remedies are inadequate: large-scale re-annotation is economically prohibitive, and standard unlearning methods act as blunt instruments that erode utility rather than enable precise policy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict Evaluation), a framework for principled unlearning that reconceives re-alignment as a programmatic policy application problem. TRACE programmatically triages existing preference data against a new policy, identifies high-impact conflicts via a alignment impact score, and applies a hybrid optimization that cleanly inverts, discards, or preserves preferences while safeguarding model performance. Empirical results show that TRACE achieves robust re-alignment across diverse model families (Qwen2.5-7B, Gemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF dataset under complex policy shift, TRACE enforces new principles without degrading general capabilities. Our work establishes a scalable, dynamic, and cost-effective paradigm for maintaining LLM alignment, providing a foundation for sustainable and responsible AI deployment.",
    "fetched_at": "2025-11-06T02:19:07.213177Z"
  },
  {
    "id": "2511.02625v1",
    "title": "The stability of shallow neural networks on spheres: A sharp spectral   analysis",
    "date": "2025-11-04",
    "tags": [
      "math.NA",
      "NA",
      "cs.LG",
      "LG",
      "cs.NA"
    ],
    "authors": [
      "Xinliang Liu",
      "Tong Mao",
      "Jinchao Xu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02625v1",
    "abstract": "We present an estimation of the condition numbers of the \\emph{mass} and \\emph{stiffness} matrices arising from shallow ReLU$^k$ neural networks defined on the unit sphere~$\\mathbb{S}^d$. In particular, when $\\{\\theta_j^*\\}_{j=1}^n \\subset \\mathbb{S}^d$ is \\emph{antipodally quasi-uniform}, the condition number is sharp. Indeed, in this case, we obtain sharp asymptotic estimates for the full spectrum of eigenvalues and characterize the structure of the corresponding eigenspaces, showing that the smallest eigenvalues are associated with an eigenbasis of low-degree polynomials while the largest eigenvalues are linked to high-degree polynomials. This spectral analysis establishes a precise correspondence between the approximation power of the network and its numerical stability.",
    "fetched_at": "2025-11-06T02:19:07.213123Z"
  },
  {
    "id": "2511.02626v1",
    "title": "Understanding New-Knowledge-Induced Factual Hallucinations in LLMs:   Analysis, Solution, and Interpretation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Renfei Dang",
      "Peng Hu",
      "Changjiang Gao",
      "Shujian Huang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02626v1",
    "abstract": "Previous studies show that introducing new knowledge during large language models (LLMs) fine-tuning can lead to the generation of erroneous output when tested on known information, thereby triggering factual hallucinations. However, existing studies have not deeply investigated the specific manifestations and underlying mechanisms of these hallucinations. Our work addresses this gap by designing a controlled dataset Biography-Reasoning, and conducting a fine-grained analysis across multiple knowledge types and two task types, including knowledge question answering (QA) and knowledge reasoning tasks. We find that when fine-tuned on a dataset in which a specific knowledge type consists entirely of new knowledge, LLMs exhibit significantly increased hallucination tendencies. This suggests that the high unfamiliarity of a particular knowledge type, rather than the overall proportion of new knowledge, is a stronger driver of hallucinations, and these tendencies can even affect other knowledge types in QA tasks. To mitigate such factual hallucinations, we propose KnownPatch, which patches a small number of known knowledge samples in the later stages of training, effectively alleviating new-knowledge-induced hallucinations. Through attention analysis, we find that learning new knowledge reduces the model's attention to key entities in the question, thus causing excessive focus on the surrounding context, which may increase the risk of hallucination. Moreover, the attention pattern can propagate to similar contexts, facilitating the spread of hallucinations to textually similar questions. Our method effectively mitigates the disruption of new knowledge learning to the model's attention on key entities, accompanied by improved performance.",
    "fetched_at": "2025-11-06T02:19:07.213082Z"
  },
  {
    "id": "2511.02627v1",
    "title": "DecompSR: A dataset for decomposed analyses of compositional multihop   spatial reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lachlan McPheat",
      "Navdeep Kaur",
      "Robert Blackwell",
      "Alessandra Russo",
      "Anthony G. Cohn",
      "Pranava Madhyastha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02627v1",
    "abstract": "We introduce DecompSR, decomposed spatial reasoning, a large benchmark dataset (over 5m datapoints) and generation framework designed to analyse compositional spatial reasoning ability. The generation of DecompSR allows users to independently vary several aspects of compositionality, namely: productivity (reasoning depth), substitutivity (entity and linguistic variability), overgeneralisation (input order, distractors) and systematicity (novel linguistic elements). DecompSR is built procedurally in a manner which makes it is correct by construction, which is independently verified using a symbolic solver to guarantee the correctness of the dataset. DecompSR is comprehensively benchmarked across a host of Large Language Models (LLMs) where we show that LLMs struggle with productive and systematic generalisation in spatial reasoning tasks whereas they are more robust to linguistic variation. DecompSR provides a provably correct and rigorous benchmarking dataset with a novel ability to independently vary the degrees of several key aspects of compositionality, allowing for robust and fine-grained probing of the compositional reasoning abilities of LLMs.",
    "fetched_at": "2025-11-06T02:19:07.213030Z"
  },
  {
    "id": "2511.02644v1",
    "title": "Recursively Enumerably Representable Classes and Computable Versions of   the Fundamental Theorem of Statistical Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CC",
      "CC",
      "math.LO",
      "LO",
      "8T05, 03D80, 03D25 (Primary) 68Q32, 68T09, 68T27, 68Q04, 03D32\n  (Secondary)"
    ],
    "authors": [
      "David Kattermann",
      "Lothar Sebastian Krapp"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02644v1",
    "abstract": "We study computable probably approximately correct (CPAC) learning, where learners are required to be computable functions. It had been previously observed that the Fundamental Theorem of Statistical Learning, which characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis (VC-)dimension, no longer holds in this framework. Recent works recovered analogs of the Fundamental Theorem in the computable setting, for instance by introducing an effective VC-dimension. Guided by this, we investigate the connection between CPAC learning and recursively enumerable representable (RER) classes, whose members can be algorithmically listed. Our results show that the effective VC-dimensions can take arbitrary values above the traditional one, even for RER classes, which creates a whole family of (non-)examples for various notions of CPAC learning. Yet the two dimensions coincide for classes satisfying sufficiently strong notions of CPAC learning. We then observe that CPAC learnability can also be characterized via containment of RER classes that realize the same samples. Furthermore, it is shown that CPAC learnable classes satisfying a unique identification property are necessarily RER. Finally, we establish that agnostic learnability can be guaranteed for RER classes, by considering the relaxed notion of nonuniform CPAC learning.",
    "fetched_at": "2025-11-06T02:19:07.212975Z"
  },
  {
    "id": "2511.02646v1",
    "title": "Natural-gas storage modelling by deep reinforcement learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.SY",
      "SY",
      "econ.GN",
      "GN",
      "eess.SY",
      "q-fin.EC",
      "EC"
    ],
    "authors": [
      "Tiziano Balaconi",
      "Aldo Glielmo",
      "Marco Taboga"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02646v1",
    "abstract": "We introduce GasRL, a simulator that couples a calibrated representation of the natural gas market with a model of storage-operator policies trained with deep reinforcement learning (RL). We use it to analyse how optimal stockpile management affects equilibrium prices and the dynamics of demand and supply. We test various RL algorithms and find that Soft Actor Critic (SAC) exhibits superior performance in the GasRL environment: multiple objectives of storage operators - including profitability, robust market clearing and price stabilisation - are successfully achieved. Moreover, the equilibrium price dynamics induced by SAC-derived optimal policies have characteristics, such as volatility and seasonality, that closely match those of real-world prices. Remarkably, this adherence to the historical distribution of prices is obtained without explicitly calibrating the model to price data. We show how the simulator can be used to assess the effects of EU-mandated minimum storage thresholds. We find that such thresholds have a positive effect on market resilience against unanticipated shifts in the distribution of supply shocks. For example, with unusually large shocks, market disruptions are averted more often if a threshold is in place.",
    "fetched_at": "2025-11-06T02:19:07.212931Z"
  },
  {
    "id": "2511.02647v1",
    "title": "Federated Attention: A Distributed Paradigm for Collaborative LLM   Inference over Edge Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiumei Deng",
      "Zehui Xiong",
      "Binbin Chen",
      "Dong In Kim",
      "Merouane Debbah",
      "H. Vincent Poor"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02647v1",
    "abstract": "Large language models (LLMs) are proliferating rapidly at the edge, delivering intelligent capabilities across diverse application scenarios. However, their practical deployment in collaborative scenarios confronts fundamental challenges: privacy vulnerabilities, communication overhead, and computational bottlenecks. To address these, we propose Federated Attention (FedAttn), which integrates the federated paradigm into the self-attention mechanism, creating a new distributed LLM inference framework that simultaneously achieves privacy protection, communication efficiency, and computational efficiency. FedAttn enables participants to perform local self-attention over their own token representations while periodically exchanging and aggregating Key-Value (KV) matrices across multiple Transformer blocks, collaboratively generating LLM responses without exposing private prompts. Further, we identify a structural duality between contextual representation refinement in FedAttn and parameter optimization in FL across private data, local computation, and global aggregation. This key insight provides a principled foundation for systematically porting federated optimization techniques to collaborative LLM inference. Building on this framework, we theoretically analyze how local self-attention computation within participants and heterogeneous token relevance among participants shape error propagation dynamics across Transformer blocks. Moreover, we characterize the fundamental trade-off between response quality and communication/computation efficiency, which is governed by the synchronization interval and the number of participants. Experimental results validate our theoretical analysis, and reveal significant optimization opportunities through sparse attention and adaptive KV aggregation, highlighting FedAttn's potential to deliver scalability and efficiency in real-world edge deployments.",
    "fetched_at": "2025-11-06T02:19:07.212882Z"
  },
  {
    "id": "2511.02657v1",
    "title": "Nesterov-Accelerated Robust Federated Learning Over Byzantine   Adversaries",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lihan Xu",
      "Yanjie Dong",
      "Gang Wang",
      "Runhao Zeng",
      "Xiaoyi Fan",
      "Xiping Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02657v1",
    "abstract": "We investigate robust federated learning, where a group of workers collaboratively train a shared model under the orchestration of a central server in the presence of Byzantine adversaries capable of arbitrary and potentially malicious behaviors. To simultaneously enhance communication efficiency and robustness against such adversaries, we propose a Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL) algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the federated learning process alongside Byzantine-resilient aggregation rules to achieve fast and safeguarding convergence against gradient corruption. We establish a finite-time convergence guarantee for Byrd-NAFL under non-convex and smooth loss functions with relaxed assumption on the aggregated gradients. Extensive numerical experiments validate the effectiveness of Byrd-NAFL and demonstrate the superiority over existing benchmarks in terms of convergence speed, accuracy, and resilience to diverse Byzantine attack strategies.",
    "fetched_at": "2025-11-06T02:19:07.212736Z"
  },
  {
    "id": "2511.02659v2",
    "title": "In Situ Training of Implicit Neural Compressors for Scientific   Simulations via Sketch-Based Regularization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.NA",
      "NA",
      "math.NA"
    ],
    "authors": [
      "Cooper Simpson",
      "Stephen Becker",
      "Alireza Doostan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02659v2",
    "abstract": "Focusing on implicit neural representations, we present a novel in situ training protocol that employs limited memory buffers of full and sketched data samples, where the sketched data are leveraged to prevent catastrophic forgetting. The theoretical motivation for our use of sketching as a regularizer is presented via a simple Johnson-Lindenstrauss-informed result. While our methods may be of wider interest in the field of continual learning, we specifically target in situ neural compression using implicit neural representation-based hypernetworks. We evaluate our method on a variety of complex simulation data in two and three dimensions, over long time horizons, and across unstructured grids and non-Cartesian geometries. On these tasks, we show strong reconstruction performance at high compression rates. Most importantly, we demonstrate that sketching enables the presented in situ scheme to approximately match the performance of the equivalent offline method.",
    "fetched_at": "2025-11-06T02:19:07.212684Z"
  },
  {
    "id": "2511.02667v2",
    "title": "Scalable Evaluation and Neural Models for Compositional Generalization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Giacomo Camposampiero",
      "Pietro Barbiero",
      "Michael Hersche",
      "Roger Wattenhofer",
      "Abbas Rahimi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02667v2",
    "abstract": "Compositional generalization-a key open challenge in modern machine learning-requires models to predict unknown combinations of known concepts. However, assessing compositional generalization remains a fundamental challenge due to the lack of standardized evaluation protocols and the limitations of current benchmarks, which often favor efficiency over rigor. At the same time, general-purpose vision architectures lack the necessary inductive biases, and existing approaches to endow them compromise scalability. As a remedy, this paper introduces: 1) a rigorous evaluation framework that unifies and extends previous approaches while reducing computational requirements from combinatorial to constant; 2) an extensive and modern evaluation on the status of compositional generalization in supervised vision backbones, training more than 5000 models; 3) Attribute Invariant Networks, a class of models establishing a new Pareto frontier in compositional generalization, achieving a 23.43% accuracy improvement over baselines while reducing parameter overhead from 600% to 16% compared to fully disentangled counterparts. Our code is available at https://github.com/IBM/scalable-compositional-generalization.",
    "fetched_at": "2025-11-06T02:19:07.212640Z"
  },
  {
    "id": "2511.02672v1",
    "title": "RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication   Trade-offs",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Adam Umra",
      "Aya M. Ahmed",
      "Aydin Sezgin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02672v1",
    "abstract": "This paper proposes a reinforcement learning (RL)-aided cognitive framework for massive MIMO-based integrated sensing and communication (ISAC) systems employing a uniform planar array (UPA). The focus is on enhancing radar sensing performance in environments with unknown and dynamic disturbance characteristics. A Wald-type detector is employed for robust target detection under non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive estimation of target positions without prior environmental knowledge. Based on the RL-derived sensing information, a joint waveform optimization strategy is formulated to balance radar sensing accuracy and downlink communication throughput. The resulting design provides an adaptive trade-off between detection performance and achievable sum rate through an analytically derived closed-form solution. Monte Carlo simulations demonstrate that the proposed cognitive ISAC framework achieves significantly improved detection probability compared to orthogonal and non-learning adaptive baselines, while maintaining competitive communication performance. These results underline the potential of RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation wireless networks.",
    "fetched_at": "2025-11-06T02:19:07.212589Z"
  },
  {
    "id": "2511.02681v1",
    "title": "Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammadsajad Alipour",
      "Mohammad Mohammadi Amiri"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02681v1",
    "abstract": "Large language models (LLMs) are increasingly prevalent across diverse applications. However, their enormous size limits storage and processing capabilities to a few well-resourced stakeholders. As a result, most applications rely on pre-trained LLMs, fine-tuned for specific tasks. However, even storing the fine-tuned versions of these models remains a significant challenge due to the wide range of tasks they address. Recently, studies show that fine-tuning these models primarily affects a small fraction of parameters, highlighting the need for more efficient storage of fine-tuned models. This paper focuses on efficient storage of parameter updates in pre-trained models after fine-tuning. To address this challenge, we leverage the observation that fine-tuning updates are both low-rank and sparse, which can be utilized for storage efficiency. However, using only low-rank approximation or sparsification may discard critical singular components that enhance model expressivity. We first observe that given the same memory budget, sparsified low-rank approximations with larger ranks outperform standard low-rank approximations with smaller ranks. Building on this, we propose our method, optimal singular damage, that selectively sparsifies low-rank approximated updates by leveraging the interleaved importance of singular vectors, ensuring that the most impactful components are retained. We demonstrate through extensive experiments that our proposed methods lead to significant storage efficiency and superior accuracy within the same memory budget compared to employing the low-rank approximation or sparsification individually.",
    "fetched_at": "2025-11-06T02:19:07.212522Z"
  },
  {
    "id": "2511.02687v1",
    "title": "The Collaboration Gap",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tim R. Davidson",
      "Adam Fourney",
      "Saleema Amershi",
      "Robert West",
      "Eric Horvitz",
      "Ece Kamar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02687v1",
    "abstract": "The trajectory of AI development suggests that we will increasingly rely on agent-based systems composed of independently developed agents with different information, privileges, and tools. The success of these systems will critically depend on effective collaboration among these heterogeneous agents, even under partial observability. Despite intense interest, few empirical studies have evaluated such agent-agent collaboration at scale. We propose a collaborative maze-solving benchmark that (i) isolates collaborative capabilities, (ii) modulates problem complexity, (iii) enables scalable automated grading, and (iv) imposes no output-format constraints, preserving ecological plausibility. Using this framework, we evaluate 32 leading open- and closed-source models in solo, homogeneous, and heterogeneous pairings. Our results reveal a \"collaboration gap\": models that perform well solo often degrade substantially when required to collaborate. Collaboration can break down dramatically; for instance, small distilled models that solve mazes well alone may fail almost completely in certain pairings. We find that starting with the stronger agent often improves outcomes, motivating a \"relay inference\" approach where the stronger agent leads before handing off to the weaker one, closing much of the gap. Our findings argue for (1) collaboration-aware evaluation, (2) training strategies developed to enhance collaborative capabilities, and (3) interaction design that reliably elicits agents' latent skills, guidance that applies to AI-AI and human-AI collaboration.",
    "fetched_at": "2025-11-06T02:19:07.212478Z"
  },
  {
    "id": "2511.02706v1",
    "title": "Optimizing Kernel Discrepancies via Subset Selection",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.CG",
      "CG",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA"
    ],
    "authors": [
      "Deyao Chen",
      "François Clément",
      "Carola Doerr",
      "Nathan Kirk"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02706v1",
    "abstract": "Kernel discrepancies are a powerful tool for analyzing worst-case errors in quasi-Monte Carlo (QMC) methods. Building on recent advances in optimizing such discrepancy measures, we extend the subset selection problem to the setting of kernel discrepancies, selecting an m-element subset from a large population of size $n \\gg m$. We introduce a novel subset selection algorithm applicable to general kernel discrepancies to efficiently generate low-discrepancy samples from both the uniform distribution on the unit hypercube, the traditional setting of classical QMC, and from more general distributions $F$ with known density functions by employing the kernel Stein discrepancy. We also explore the relationship between the classical $L_2$ star discrepancy and its $L_\\infty$ counterpart.",
    "fetched_at": "2025-11-06T02:19:07.212374Z"
  },
  {
    "id": "2511.02717v1",
    "title": "An unscented Kalman filter method for real time input-parameter-state   estimation",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.SY",
      "SY",
      "eess.AS",
      "AS",
      "eess.SY",
      "68T05 (Learning and adaptive systems)",
      "I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Marios Impraimakis",
      "Andrew W. Smyth"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02717v1",
    "abstract": "The input-parameter-state estimation capabilities of a novel unscented Kalman filter is examined herein on both linear and nonlinear systems. The unknown input is estimated in two stages within each time step. Firstly, the predicted dynamic states and the system parameters provide an estimation of the input. Secondly, the corrected with measurements states and parameters provide a final estimation. Importantly, it is demonstrated using the perturbation analysis that, a system with at least a zero or a non-zero known input can potentially be uniquely identified. This output-only methodology allows for a better understanding of the system compared to classical output-only parameter identification strategies, given that all the dynamic states, the parameters, and the input are estimated jointly and in real-time.",
    "fetched_at": "2025-11-06T02:19:07.212328Z"
  },
  {
    "id": "2511.02718v1",
    "title": "Does Interpretability of Knowledge Tracing Models Support Teacher   Decision Making?",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Adia Khalid",
      "Alina Deriyeva",
      "Benjamin Paassen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02718v1",
    "abstract": "Knowledge tracing (KT) models are a crucial basis for pedagogical decision-making, namely which task to select next for a learner and when to stop teaching a particular skill. Given the high stakes of pedagogical decisions, KT models are typically required to be interpretable, in the sense that they should implement an explicit model of human learning and provide explicit estimates of learners' abilities. However, to our knowledge, no study to date has investigated whether the interpretability of KT models actually helps human teachers to make teaching decisions. We address this gap. First, we perform a simulation study to show that, indeed, decisions based on interpretable KT models achieve mastery faster compared to decisions based on a non-interpretable model. Second, we repeat the study but ask $N=12$ human teachers to make the teaching decisions based on the information provided by KT models. As expected, teachers rate interpretable KT models higher in terms of usability and trustworthiness. However, the number of tasks needed until mastery hardly differs between KT models. This suggests that the relationship between model interpretability and teacher decisions is not straightforward: teachers do not solely rely on KT models to make decisions and further research is needed to investigate how learners and teachers actually understand and use KT models.",
    "fetched_at": "2025-11-06T02:19:07.212284Z"
  },
  {
    "id": "2511.02720v1",
    "title": "LLEXICORP: End-user Explainability of Convolutional Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Vojtěch Kůr",
      "Adam Bajger",
      "Adam Kukučka",
      "Marek Hradil",
      "Vít Musil",
      "Tomáš Brázdil"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02720v1",
    "abstract": "Convolutional neural networks (CNNs) underpin many modern computer vision systems. With applications ranging from common to critical areas, a need to explain and understand the model and its decisions (XAI) emerged. Prior works suggest that in the top layers of CNNs, the individual channels can be attributed to classifying human-understandable concepts. Concept relevance propagation (CRP) methods can backtrack predictions to these channels and find images that most activate these channels. However, current CRP workflows are largely manual: experts must inspect activation images to name the discovered concepts and must synthesize verbose explanations from relevance maps, limiting the accessibility of the explanations and their scalability.   To address these issues, we introduce Large Language model EXplaIns COncept Relevance Propagation (LLEXICORP), a modular pipeline that couples CRP with a multimodal large language model. Our approach automatically assigns descriptive names to concept prototypes and generates natural-language explanations that translate quantitative relevance distributions into intuitive narratives. To ensure faithfulness, we craft prompts that teach the language model the semantics of CRP through examples and enforce a separation between naming and explanation tasks. The resulting text can be tailored to different audiences, offering low-level technical descriptions for experts and high-level summaries for non-technical stakeholders.   We qualitatively evaluate our method on various images from ImageNet on a VGG16 model. Our findings suggest that integrating concept-based attribution methods with large language models can significantly lower the barrier to interpreting deep neural networks, paving the way for more transparent AI systems.",
    "fetched_at": "2025-11-06T02:19:07.212239Z"
  },
  {
    "id": "2511.02721v1",
    "title": "PragExTra: A Multilingual Corpus of Pragmatic Explicitation in   Translation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Doreen Osmelak",
      "Koel Dutta Chowdhury",
      "Uliana Sentsova",
      "Cristina España-Bonet",
      "Josef van Genabith"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02721v1",
    "abstract": "Translators often enrich texts with background details that make implicit cultural meanings explicit for new audiences. This phenomenon, known as pragmatic explicitation, has been widely discussed in translation theory but rarely modeled computationally. We introduce PragExTra, the first multilingual corpus and detection framework for pragmatic explicitation. The corpus covers eight language pairs from TED-Multi and Europarl and includes additions such as entity descriptions, measurement conversions, and translator remarks. We identify candidate explicitation cases through null alignments and refined using active learning with human annotation. Our results show that entity and system-level explicitations are most frequent, and that active learning improves classifier accuracy by 7-8 percentage points, achieving up to 0.88 accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic explicitation as a measurable, cross-linguistic phenomenon and takes a step towards building culturally aware machine translation. Keywords: translation, multilingualism, explicitation",
    "fetched_at": "2025-11-06T02:19:07.212180Z"
  },
  {
    "id": "2511.02738v1",
    "title": "Calibration improves detection of mislabeled examples",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ilies Chibane",
      "Thomas George",
      "Pierre Nodet",
      "Vincent Lemaire"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02738v1",
    "abstract": "Mislabeled data is a pervasive issue that undermines the performance of machine learning systems in real-world applications. An effective approach to mitigate this problem is to detect mislabeled instances and subject them to special treatment, such as filtering or relabeling. Automatic mislabeling detection methods typically rely on training a base machine learning model and then probing it for each instance to obtain a trust score that each provided label is genuine or incorrect. The properties of this base model are thus of paramount importance. In this paper, we investigate the impact of calibrating this model. Our empirical results show that using calibration methods improves the accuracy and robustness of mislabeled instance detection, providing a practical and effective solution for industrial applications.",
    "fetched_at": "2025-11-06T02:19:07.212070Z"
  },
  {
    "id": "2511.02749v1",
    "title": "Using Span Queries to Optimize for Cache and Attention Locality",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Paul Castro",
      "Nick Mitchell",
      "Nathan Ordonez",
      "Thomas Parnell",
      "Mudhakar Srivatsa",
      "Antoni Viros i Martin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02749v1",
    "abstract": "Clients are evolving beyond chat completion, and now include a variety of innovative inference-time scaling and deep reasoning techniques. At the same time, inference servers remain heavily optimized for chat completion. Prior work has shown that large improvements to KV cache hit rate are possible if inference servers evolve towards these non-chat use cases. However, they offer solutions that are also optimized for a single use case, RAG. In this paper, we introduce the span query to generalize the interface to the inference server. We demonstrate that chat, RAG, inference-time scaling, and agentic workloads can all be expressed as span queries. We show how the critical distinction that had been assumed by prior work lies in whether the order of the inputs matter -- do they commute? In chat, they do not. In RAG, they often do. This paper introduces span queries, which are expression trees of inference calls, linked together with commutativity constraints. We describe span query syntax and semantics. We show how they can be automatically optimized to improve KV cache locality. We show how a small change to vLLM (affecting only 492 lines) can enable high-performance execution of span queries. Using this stack, we demonstrate that span queries can achieve 10-20x reductions in TTFT for two distinct non-chat use cases. Finally, we show that span queries can also be optimized to improve attention locality, so as to avoid the so-called lost-in-the-middle problem. We demonstrate that an attention-optimized span query on a 2b parameter model vastly outperforms the accuracy of a stock inference server using an 8b model.",
    "fetched_at": "2025-11-06T02:19:07.211971Z"
  },
  {
    "id": "2511.02752v1",
    "title": "AI Diffusion in Low Resource Language Countries",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Amit Misra",
      "Syed Waqas Zamir",
      "Wassim Hamidouche",
      "Inbal Becker-Reshef",
      "Juan Lavista Ferres"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02752v1",
    "abstract": "Artificial intelligence (AI) is diffusing globally at unprecedented speed, but adoption remains uneven. Frontier Large Language Models (LLMs) are known to perform poorly on low-resource languages due to data scarcity. We hypothesize that this performance deficit reduces the utility of AI, thereby slowing adoption in Low-Resource Language Countries (LRLCs). To test this, we use a weighted regression model to isolate the language effect from socioeconomic and demographic factors, finding that LRLCs have a share of AI users that is approximately 20% lower relative to their baseline. These results indicate that linguistic accessibility is a significant, independent barrier to equitable AI diffusion.",
    "fetched_at": "2025-11-06T02:19:07.211914Z"
  },
  {
    "id": "2511.02754v1",
    "title": "DANIEL: A Distributed and Scalable Approach for Global Representation   Learning with EHR Applications",
    "date": "2025-11-04",
    "tags": [
      "stat.ME",
      "ME",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zebin Wang",
      "Ziming Gan",
      "Weijing Tang",
      "Zongqi Xia",
      "Tianrun Cai",
      "Tianxi Cai",
      "Junwei Lu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02754v1",
    "abstract": "Classical probabilistic graphical models face fundamental challenges in modern data environments, which are characterized by high dimensionality, source heterogeneity, and stringent data-sharing constraints. In this work, we revisit the Ising model, a well-established member of the Markov Random Field (MRF) family, and develop a distributed framework that enables scalable and privacy-preserving representation learning from large-scale binary data with inherent low-rank structure. Our approach optimizes a non-convex surrogate loss function via bi-factored gradient descent, offering substantial computational and communication advantages over conventional convex approaches. We evaluate our algorithm on multi-institutional electronic health record (EHR) datasets from 58,248 patients across the University of Pittsburgh Medical Center (UPMC) and Mass General Brigham (MGB), demonstrating superior performance in global representation learning and downstream clinical tasks, including relationship detection, patient phenotyping, and patient clustering. These results highlight a broader potential for statistical inference in federated, high-dimensional settings while addressing the practical challenges of data complexity and multi-institutional integration.",
    "fetched_at": "2025-11-06T02:19:07.211866Z"
  },
  {
    "id": "2511.02757v1",
    "title": "ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free   Finetuning of Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Lejs Deen Behric",
      "Liang Zhang",
      "Bingcong Li",
      "Kiran Koshy Thekumparampil"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02757v1",
    "abstract": "Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy for finetuning large language models (LLMs) because it eliminates the memory overhead of backpropagation. However, it converges slowly due to the inherent curse of dimensionality when searching for descent directions in the high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a novel zeroth-order optimizer that accelerates convergence by adaptive directional sampling. Instead of drawing the direction uniformly at random, ConMeZO restricts the sampling to a cone centered around a momentum estimate. This concentrates the search in directions where the true gradient is more likely to lie and thus reduces the effect of high dimensions. We prove that ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically, when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than MeZO while retaining the low-memory footprint of zeroth-order methods.",
    "fetched_at": "2025-11-06T02:19:07.211652Z"
  },
  {
    "id": "2511.02759v1",
    "title": "LLM-Supported Formal Knowledge Representation for Enhancing Control   Engineering Content with an Interactive Semantic Layer",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Julius Fiedler",
      "Carsten Knoll",
      "Klaus Röbenack"
    ],
    "institution": "Chair of Fundamentals of Electrical Engineering at TU Dresden, Institute of Control Theory at TU Dresden",
    "link": "http://arxiv.org/pdf/2511.02759v1",
    "abstract": "The rapid growth of research output in control engineering calls for new approaches to structure and formalize domain knowledge. This paper briefly describes an LLM-supported method for semi-automated generation of formal knowledge representations that combine human readability with machine interpretability and increased expressiveness. Based on the Imperative Representation of Knowledge (PyIRK) framework, we demonstrate how language models can assist in transforming natural-language descriptions and mathematical definitions (available as LaTeX source code) into a formalized knowledge graph. As a first application we present the generation of an ``interactive semantic layer'' to enhance the source documents in order to facilitate knowledge transfer. From our perspective this contributes to the vision of easily accessible, collaborative, and verifiable knowledge bases for the control engineering domain.",
    "fetched_at": "2025-11-06T02:19:07.211599Z"
  },
  {
    "id": "2511.02765v1",
    "title": "VecComp: Vector Computing via MIMO Digital Over-the-Air Computation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Saeed Razavikia",
      "José Mairton Barros Da Silva Junior",
      "Carlo Fischione"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02765v1",
    "abstract": "Recently, the ChannelComp framework has proposed digital over-the-air computation by designing digital modulations that enable the computation of arbitrary functions. Unlike traditional analog over-the-air computation, which is restricted to nomographic functions, ChannelComp enables a broader range of computational tasks while maintaining compatibility with digital communication systems. This framework is intended for applications that favor local information processing over the mere acquisition of data. However, ChannelComp is currently designed for scalar function computation, while numerous data-centric applications necessitate vector-based computations, and it is susceptible to channel fading. In this work, we introduce a generalization of the ChannelComp framework, called VecComp, by integrating ChannelComp with multiple-antenna technology. This generalization not only enables vector function computation but also ensures scalability in the computational complexity, which increases only linearly with the vector dimension. As such, VecComp remains computationally efficient and robust against channel impairments, making it suitable for high-dimensional, data-centric applications. We establish a non-asymptotic upper bound on the mean squared error of VecComp, affirming its computation efficiency under fading channel conditions. Numerical experiments show the effectiveness of VecComp in improving the computation of vector functions and fading compensation over noisy and fading multiple-access channels.",
    "fetched_at": "2025-11-06T02:19:07.211495Z"
  },
  {
    "id": "2511.02769v1",
    "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable   Molecular Generation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.BM",
      "BM"
    ],
    "authors": [
      "Bum Chul Kwon",
      "Ben Shapira",
      "Moshiko Raboh",
      "Shreyans Sethi",
      "Shruti Murarka",
      "Joseph A Morrone",
      "Jianying Hu",
      "Parthasarathy Suryanarayanan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02769v1",
    "abstract": "The chemical space of drug-like molecules is vast, motivating the development of generative models that must learn broad chemical distributions, enable conditional generation by capturing structure-property representations, and provide fast molecular generation. Meeting the objectives depends on modeling choices, including the probabilistic modeling approach, the conditional generative formulation, the architecture, and the molecular input representation. To address the challenges, we present STAR-VAE (Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder), a scalable latent-variable framework with a Transformer encoder and an autoregressive Transformer decoder. It is trained on 79 million drug-like molecules from PubChem, using SELFIES to guarantee syntactic validity. The latent-variable formulation enables conditional generation: a property predictor supplies a conditioning signal that is applied consistently to the latent prior, the inference network, and the decoder. Our contributions are: (i) a Transformer-based latent-variable encoder-decoder model trained on SELFIES representations; (ii) a principled conditional latent-variable formulation for property-guided generation; and (iii) efficient finetuning with low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation with limited property and activity data. On the GuacaMol and MOSES benchmarks, our approach matches or exceeds baselines, and latent-space analyses reveal smooth, semantically structured representations that support both unconditional exploration and property-aware generation. On the Tartarus benchmarks, the conditional model shifts docking-score distributions toward stronger predicted binding. These results suggest that a modernized, scale-appropriate VAE remains competitive for molecular generation when paired with principled conditioning and parameter-efficient finetuning.",
    "fetched_at": "2025-11-06T02:19:07.211448Z"
  },
  {
    "id": "2511.02770v1",
    "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query   Retrieval",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Hung-Ting Chen",
      "Xiang Liu",
      "Shauli Ravfogel",
      "Eunsol Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02770v1",
    "abstract": "Most text retrievers generate \\emph{one} query vector to retrieve relevant documents. Yet, the conditional distribution of relevant documents for the query may be multimodal, e.g., representing different interpretations of the query. We first quantify the limitations of existing retrievers. All retrievers we evaluate struggle more as the distance between target document embeddings grows. To address this limitation, we develop a new retriever architecture, \\emph{A}utoregressive \\emph{M}ulti-\\emph{E}mbedding \\emph{R}etriever (AMER). Our model autoregressively generates multiple query vectors, and all the predicted query vectors are used to retrieve documents from the corpus. We show that on the synthetic vectorized data, the proposed method could capture multiple target distributions perfectly, showing 4x better performance than single embedding model. We also fine-tune our model on real-world multi-answer retrieval datasets and evaluate in-domain. AMER presents 4 and 21\\% relative gains over single-embedding baselines on two datasets we evaluate on. Furthermore, we consistently observe larger gains on the subset of dataset where the embeddings of the target documents are less similar to each other. We demonstrate the potential of using a multi-query vector retriever and open up a new direction for future work.",
    "fetched_at": "2025-11-06T02:19:07.211379Z"
  },
  {
    "id": "2511.02773v1",
    "title": "Adam Reduces a Unique Form of Sharpness: Theoretical Insights Near the   Minimizer Manifold",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinghan Li",
      "Haodong Wen",
      "Kaifeng Lyu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02773v1",
    "abstract": "Despite the popularity of the Adam optimizer in practice, most theoretical analyses study Stochastic Gradient Descent (SGD) as a proxy for Adam, and little is known about how the solutions found by Adam differ. In this paper, we show that Adam implicitly reduces a unique form of sharpness measure shaped by its adaptive updates, leading to qualitatively different solutions from SGD. More specifically, when the training loss is small, Adam wanders around the manifold of minimizers and takes semi-gradients to minimize this sharpness measure in an adaptive manner, a behavior we rigorously characterize through a continuous-time approximation using stochastic differential equations. We further demonstrate how this behavior differs from that of SGD in a well-studied setting: when training overparameterized models with label noise, SGD has been shown to minimize the trace of the Hessian matrix, $\\tr(\\mH)$, whereas we prove that Adam minimizes $\\tr(\\Diag(\\mH)^{1/2})$ instead. In solving sparse linear regression with diagonal linear networks, this distinction enables Adam to achieve better sparsity and generalization than SGD. Finally, our analysis framework extends beyond Adam to a broad class of adaptive gradient methods, including RMSProp, Adam-mini, Adalayer and Shampoo, and provides a unified perspective on how these adaptive optimizers reduce sharpness, which we hope will offer insights for future optimizer design.",
    "fetched_at": "2025-11-06T02:19:07.211331Z"
  },
  {
    "id": "2511.02778v1",
    "title": "VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual   Representation",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kevin Qinghong Lin",
      "Yuhao Zheng",
      "Hangyu Ran",
      "Dantong Zhu",
      "Dongxing Mao",
      "Linjie Li",
      "Philip Torr",
      "Alex Jinpeng Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02778v1",
    "abstract": "Code has emerged as a precise and executable medium for reasoning and action in the agent era. Yet, progress has largely focused on language-centric tasks such as program synthesis and debugging, leaving visual-centric coding underexplored. Inspired by how humans reason over sketches, we advocate SVG code as a compact, interpretable, and executable visual representation. We introduce VCode, a benchmark that reframes multimodal understanding as code generation: given an image, a model must produce SVG that preserves symbolic meaning for downstream reasoning. VCode covers three domains - general commonsense (MM-Vet), professional disciplines (MMMU), and visual-centric perception (CV-Bench). To assess symbolic fidelity, we propose CodeVQA, a novel evaluation protocol in which a policy model answers questions over rendered SVGs; correct answers indicate faithful symbolic preservation. Empirically, frontier VLMs struggle to generate faithful SVGs, revealing a persistent gap between language-centric and visual-centric coding. To close this gap, we introduce VCoder, an agentic framework that augments VLMs along two axes: (i) Thinking with Revision, which iteratively analyzes discrepancies and refines SVG code; and (ii) Acting with Visual Tools, where detectors and parsers supply structured cues such as objects, shapes, and text beyond the model's intrinsic capacity. Across benchmarks, frontier VLMs with strong reasoning capabilities score well overall yet remain limited in professional knowledge and 3D reasoning. VCoder delivers a 12.3-point overall gain over the top-performing Claude-4-Opus. Human studies show that both humans and VLMs perform worse on rendered SVGs, their consistency reveals the promise of symbolic visual representation. The benchmark and code are available at https://github.com/CSU-JPG/VCode.",
    "fetched_at": "2025-11-06T02:19:07.211286Z"
  },
  {
    "id": "2511.02780v1",
    "title": "1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Vivi Andersson",
      "Sofia Bobadilla",
      "Harald Hobbelhagen",
      "Martin Monperrus"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02780v1",
    "abstract": "Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce POCO, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. POCO autonomously generates PoC exploits in an agentic manner by interacting with a set of code-execution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate POCO on a dataset of 23 real-world vulnerability reports. POCO consistently outperforms the prompting and workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides readily actionable knowledge for the smart contract security community.",
    "fetched_at": "2025-11-06T02:19:07.211219Z"
  },
  {
    "id": "2511.02781v1",
    "title": "Measuring AI Diffusion: A Population-Normalized Metric for Tracking   Global AI Usage",
    "date": "2025-11-04",
    "tags": [
      "cs.CY",
      "CY",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amit Misra",
      "Jane Wang",
      "Scott McCullers",
      "Kevin White",
      "Juan Lavista Ferres"
    ],
    "institution": "Microsoft",
    "link": "http://arxiv.org/pdf/2511.02781v1",
    "abstract": "Measuring global AI diffusion remains challenging due to a lack of population-normalized, cross-country usage data. We introduce AI User Share, a novel indicator that estimates the share of each country's working-age population actively using AI tools. Built from anonymized Microsoft telemetry and adjusted for device access and mobile scaling, this metric spans 147 economies and provides consistent, real-time insight into global AI diffusion. We find wide variation in adoption, with a strong correlation between AI User Share and GDP. High uptake is concentrated in developed economies, though usage among internet-connected populations in lower-income countries reveals substantial latent demand. We also detect sharp increases in usage following major product launches, such as DeepSeek in early 2025. While the metric's reliance solely on Microsoft telemetry introduces potential biases related to this user base, it offers an important new lens into how AI is spreading globally. AI User Share enables timely benchmarking that can inform data-driven AI policy.",
    "fetched_at": "2025-11-06T02:19:07.211169Z"
  },
  {
    "id": "2511.02785v1",
    "title": "Enhancing Federated Learning Privacy with QUBO",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Andras Ferenczi",
      "Sutapa Samanta",
      "Dagen Wang",
      "Todd Hodges"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02785v1",
    "abstract": "Federated learning (FL) is a widely used method for training machine learning (ML) models in a scalable way while preserving privacy (i.e., without centralizing raw data). Prior research shows that the risk of exposing sensitive data increases cumulatively as the number of iterations where a client's updates are included in the aggregated model increase. Attackers can launch membership inference attacks (MIA; deciding whether a sample or client participated), property inference attacks (PIA; inferring attributes of a client's data), and model inversion attacks (MI; reconstructing inputs), thereby inferring client-specific attributes and, in some cases, reconstructing inputs. In this paper, we mitigate risk by substantially reducing per client exposure using a quantum computing-inspired quadratic unconstrained binary optimization (QUBO) formulation that selects a small subset of client updates most relevant for each training round. In this work, we focus on two threat vectors: (i) information leakage by clients during training and (ii) adversaries who can query or obtain the global model. We assume a trusted central server and do not model server compromise. This method also assumes that the server has access to a validation/test set with global data distribution. Experiments on the MNIST dataset with 300 clients in 20 rounds showed a 95.2% per-round and 49% cumulative privacy exposure reduction, with 147 clients' updates never being used during training while maintaining in general the full-aggregation accuracy or even better. The method proved to be efficient at lower scale and more complex model as well. A CINIC-10 dataset-based experiment with 30 clients resulted in 82% per-round privacy improvement and 33% cumulative privacy.",
    "fetched_at": "2025-11-06T02:19:07.211118Z"
  },
  {
    "id": "2511.02795v1",
    "title": "Can LLMs subtract numbers?",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mayank Jobanputra",
      "Nils Philipp Walter",
      "Maitrey Mehta",
      "Blerta Veseli",
      "Evan Parker Kelly Chapple",
      "Yifan Wang",
      "Sneha Chetani",
      "Ellie Pavlick",
      "Antonio Vergari",
      "Vera Demberg"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02795v1",
    "abstract": "We present a systematic study of subtraction in large language models (LLMs). While prior benchmarks emphasize addition and multiplication, subtraction has received comparatively little attention despite being structurally distinct as a non-commutative operation. We evaluate eight pretrained LLMs spanning four families on addition and subtraction problems. Our experiments reveal that subtraction accuracy lags behind addition by a wide margin. We find that the errors for ($a-b$) are concentrated in cases where ($a<b$). In such cases, LLMs frequently produce the correct magnitude but omit the negative sign. Probing analyses show that LLMs internally encode whether results should be negative, yet this information is often not reflected in generated outputs. We further test well-known techniques such as few-shot learning and instruction-tuning to see if they can improve the LLMs' performance. Our results suggest that while few-shot prompting yields modest gains, the instruction-tuned models achieve near-perfect accuracies in generating the negative sign. Together, these findings provide a clearer characterization of the limitations and recoverability of LLMs' arithmetic capabilities in subtraction.",
    "fetched_at": "2025-11-06T02:19:07.211010Z"
  },
  {
    "id": "2511.02797v1",
    "title": "Fast, Private, and Protected: Safeguarding Data Privacy and Defending   Against Model Poisoning Attacks in Federated Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nicolas Riccieri Gardin Assumpcao",
      "Leandro Villas"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02797v1",
    "abstract": "Federated Learning (FL) is a distributed training paradigm wherein participants collaborate to build a global model while ensuring the privacy of the involved data, which remains stored on participant devices. However, proposals aiming to ensure such privacy also make it challenging to protect against potential attackers seeking to compromise the training outcome. In this context, we present Fast, Private, and Protected (FPP), a novel approach that aims to safeguard federated training while enabling secure aggregation to preserve data privacy. This is accomplished by evaluating rounds using participants' assessments and enabling training recovery after an attack. FPP also employs a reputation-based mechanism to mitigate the participation of attackers. We created a dockerized environment to validate the performance of FPP compared to other approaches in the literature (FedAvg, Power-of-Choice, and aggregation via Trimmed Mean and Median). Our experiments demonstrate that FPP achieves a rapid convergence rate and can converge even in the presence of malicious participants performing model poisoning attacks.",
    "fetched_at": "2025-11-06T02:19:07.210943Z"
  },
  {
    "id": "2511.02802v2",
    "title": "TabTune: A Unified Library for Inference and Fine-Tuning Tabular   Foundation Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aditya Tanna",
      "Pratinav Seth",
      "Mohamed Bouadi",
      "Utsav Avaiya",
      "Vinay Kumar Sankarapu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02802v2",
    "abstract": "Tabular foundation models represent a growing paradigm in structured data learning, extending the benefits of large-scale pretraining to tabular domains. However, their adoption remains limited due to heterogeneous preprocessing pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the absence of standardized evaluation for deployment-oriented metrics such as calibration and fairness. We present TabTune, a unified library that standardizes the complete workflow for tabular foundation models through a single interface. TabTune provides consistent access to seven state-of-the-art models supporting multiple adaptation strategies, including zero-shot inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient fine-tuning (PEFT). The framework automates model-aware preprocessing, manages architectural heterogeneity internally, and integrates evaluation modules for performance, calibration, and fairness. Designed for extensibility and reproducibility, TabTune enables consistent benchmarking of adaptation strategies of tabular foundation models.",
    "fetched_at": "2025-11-06T02:19:07.210903Z"
  },
  {
    "id": "2511.02815v1",
    "title": "Assessing win strength in MLB win prediction models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Morgan Allen",
      "Paul Savala"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02815v1",
    "abstract": "In Major League Baseball, strategy and planning are major factors in determining the outcome of a game. Previous studies have aided this by building machine learning models for predicting the winning team of any given game. We extend this work by training a comprehensive set of machine learning models using a common dataset. In addition, we relate the win probabilities produced by these models to win strength as measured by score differential. In doing so we show that the most common machine learning models do indeed demonstrate a relationship between predicted win probability and the strength of the win. Finally, we analyze the results of using predicted win probabilities as a decision making mechanism on run-line betting. We demonstrate positive returns when utilizing appropriate betting strategies, and show that naive use of machine learning models for betting lead to significant loses.",
    "fetched_at": "2025-11-06T02:19:07.210784Z"
  },
  {
    "id": "2511.02817v1",
    "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amanda Bertsch",
      "Adithya Pratapa",
      "Teruko Mitamura",
      "Graham Neubig",
      "Matthew R. Gormley"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02817v1",
    "abstract": "As model context lengths continue to grow, concerns about whether models effectively use the full context length have persisted. While several carefully designed long-context evaluations have recently been released, these evaluations tend to rely on retrieval from one or more sections of the context, which allows nearly all of the context tokens to be disregarded as noise. This represents only one type of task that might be performed with long context. We introduce Oolong, a benchmark of long-context reasoning tasks that require analyzing individual chunks of text on an atomic level, and then aggregating these analyses to answer distributional questions. Oolong is separated into two task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can easily ablate components of the reasoning problem; and Oolong-real, a downstream setting which requires reasoning over real-world conversational data. Oolong requires models to reason over large quantities of examples, to perform both classification and counting in-context, and to reason over temporal and user relations. Even frontier models struggle on Oolong, with GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy on both splits at 128K. We release the data and evaluation harness for Oolong to enable further development of models that can reason over large quantities of text.",
    "fetched_at": "2025-11-06T02:19:07.210745Z"
  },
  {
    "id": "2511.02818v1",
    "title": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohamed Bouadi",
      "Pratinav Seth",
      "Aditya Tanna",
      "Vinay Kumar Sankarapu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02818v1",
    "abstract": "Tabular data remain the predominant format for real-world applications. Yet, developing effective neural models for tabular data remains challenging due to heterogeneous feature types and complex interactions occurring at multiple scales. Recent advances in tabular in-context learning (ICL), such as TabPFN and TabICL, have achieved state-of-the-art performance comparable to gradient-boosted trees (GBTs) without task-specific fine-tuning. However, current architectures exhibit key limitations: (1) single-scale feature processing that overlooks hierarchical dependencies, (2) dense attention with quadratic scaling in table width, and (3) strictly sequential component processing that prevents iterative representation refinement and cross-component communication. To address these challenges, we introduce Orion-MSP, a tabular ICL architecture featuring three key innovations: (1) multi-scale processing to capture hierarchical feature interactions; (2) block-sparse attention combining windowed, global, and random patterns for scalable efficiency and long-range connectivity; and (3) a Perceiver-style memory enabling safe bidirectional information flow across components. Across diverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance while scaling effectively to high-dimensional tables, establishing a new standard for efficient tabular in-context learning. The model is publicly available at https://github.com/Lexsi-Labs/Orion-MSP .",
    "fetched_at": "2025-11-06T02:19:07.210693Z"
  },
  {
    "id": "2511.02821v1",
    "title": "Accelerated Frank-Wolfe Algorithms: Complementarity Conditions and   Sparsity",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Dan Garber"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02821v1",
    "abstract": "We develop new accelerated first-order algorithms in the Frank-Wolfe (FW) family for minimizing smooth convex functions over compact convex sets, with a focus on two prominent constraint classes: (1) polytopes and (2) matrix domains given by the spectrahedron and the unit nuclear-norm ball. A key technical ingredient is a complementarity condition that captures solution sparsity -- face dimension for polytopes and rank for matrices. We present two algorithms: (1) a purely linear optimization oracle (LOO) method for polytopes that has optimal worst-case first-order (FO) oracle complexity and, aside of a finite \\emph{burn-in} phase and up to a logarithmic factor, has LOO complexity that scales with $r/\\sqrt{\\epsilon}$, where $\\epsilon$ is the target accuracy and $r$ is the solution sparsity $r$ (independently of the ambient dimension), and (2) a hybrid scheme that combines FW with a sparse projection oracle (e.g., low-rank SVDs for matrix domains with low-rank solutions), which also has optimal FO oracle complexity, and after a finite burn-in phase, only requires $O(1/\\sqrt{\\epsilon})$ sparse projections and LOO calls (independently of both the ambient dimension and the rank of optimal solutions). Our results close a gap on how to accelerate recent advancements in linearly-converging FW algorithms for strongly convex optimization, without paying the price of the dimension.",
    "fetched_at": "2025-11-06T02:19:07.210642Z"
  },
  {
    "id": "2511.02824v2",
    "title": "Kosmos: An AI Scientist for Autonomous Discovery",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ludovico Mitchener",
      "Angela Yiu",
      "Benjamin Chang",
      "Mathieu Bourdenx",
      "Tyler Nadolski",
      "Arvis Sulovari",
      "Eric C. Landsness",
      "Daniel L. Barabasi",
      "Siddharth Narayanan",
      "Nicky Evans",
      "Shriya Reddy",
      "Martha Foiani",
      "Aizad Kamal",
      "Leah P. Shriver",
      "Fang Cao",
      "Asmamaw T. Wassie",
      "Jon M. Laurent",
      "Edwin Melville-Green",
      "Mayk Caldas",
      "Albert Bou",
      "Kaleigh F. Roberts",
      "Sladjana Zagorac",
      "Timothy C. Orr",
      "Miranda E. Orr",
      "Kevin J. Zwezdaryk",
      "Ali E. Ghareeb",
      "Laurie McCoy",
      "Bruna Gomes",
      "Euan A. Ashley",
      "Karen E. Duff",
      "Tonio Buonassisi",
      "Tom Rainforth",
      "Randall J. Bateman",
      "Michael Skarlinski",
      "Samuel G. Rodriques",
      "Michaela M. Hinks",
      "Andrew D. White"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02824v2",
    "abstract": "Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losing coherence, thus limiting the depth of their findings. Here we present Kosmos, an AI scientist that automates data-driven discovery. Given an open-ended objective and a dataset, Kosmos runs for up to 12 hours performing cycles of parallel data analysis, literature search, and hypothesis generation before synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos uses a structured world model to share information between a data analysis agent and a literature search agent. The world model enables Kosmos to coherently pursue the specified objective over 200 agent rollouts, collectively executing an average of 42,000 lines of code and reading 1,500 papers per run. Kosmos cites all statements in its reports with code or primary literature, ensuring its reasoning is traceable. Independent scientists found 79.4% of statements in Kosmos reports to be accurate, and collaborators reported that a single 20-cycle Kosmos run performed the equivalent of 6 months of their own research time on average. Furthermore, collaborators reported that the number of valuable scientific findings generated scales linearly with Kosmos cycles (tested up to 20 cycles). We highlight seven discoveries made by Kosmos that span metabolomics, materials science, neuroscience, and statistical genetics. Three discoveries independently reproduce findings from preprinted or unpublished manuscripts that were not accessed by Kosmos at runtime, while four make novel contributions to the scientific literature.",
    "fetched_at": "2025-11-06T02:19:07.210532Z"
  },
  {
    "id": "2511.02825v1",
    "title": "Neurosymbolic Deep Learning Semantics",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Artur d'Avila Garcez",
      "Simon Odense"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02825v1",
    "abstract": "Artificial Intelligence (AI) is a powerful new language of science as evidenced by recent Nobel Prizes in chemistry and physics that recognized contributions to AI applied to those areas. Yet, this new language lacks semantics, which makes AI's scientific discoveries unsatisfactory at best. With the purpose of uncovering new facts but also improving our understanding of the world, AI-based science requires formalization through a framework capable of translating insight into comprehensible scientific knowledge. In this paper, we argue that logic offers an adequate framework. In particular, we use logic in a neurosymbolic framework to offer a much needed semantics for deep learning, the neural network-based technology of current AI. Deep learning and neurosymbolic AI lack a general set of conditions to ensure that desirable properties are satisfied. Instead, there is a plethora of encoding and knowledge extraction approaches designed for particular cases. To rectify this, we introduced a framework for semantic encoding, making explicit the mapping between neural networks and logic, and characterizing the common ingredients of the various existing approaches. In this paper, we describe succinctly and exemplify how logical semantics and neural networks are linked through this framework, we review some of the most prominent approaches and techniques developed for neural encoding and knowledge extraction, provide a formal definition of our framework, and discuss some of the difficulties of identifying a semantic encoding in practice in light of analogous problems in the philosophy of mind.",
    "fetched_at": "2025-11-06T02:19:07.210369Z"
  },
  {
    "id": "2511.02831v1",
    "title": "GeoCrossBench: Cross-Band Generalization for Remote Sensing",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hakob Tamazyan",
      "Ani Vanyan",
      "Alvard Barseghyan",
      "Anna Khosrovyan",
      "Evan Shelhamer",
      "Hrant Khachatrian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02831v1",
    "abstract": "The number and diversity of remote sensing satellites grows over time, while the vast majority of labeled data comes from older satellites. As the foundation models for Earth observation scale up, the cost of (re-)training to support new satellites grows too, so the generalization capabilities of the models towards new satellites become increasingly important. In this work we introduce GeoCrossBench, an extension of the popular GeoBench benchmark with a new evaluation protocol: it tests the in-distribution performance; generalization to satellites with no band overlap; and generalization to satellites with additional bands with respect to the training set. We also develop a self-supervised extension of ChannelViT, ChiViT, to improve its cross-satellite performance. First, we show that even the best foundation models for remote sensing (DOFA, TerraFM) do not outperform general purpose models like DINOv3 in the in-distribution setting. Second, when generalizing to new satellites with no band overlap, all models suffer 2-4x drop in performance, and ChiViT significantly outperforms the runner-up DINOv3. Third, the performance of all tested models drops on average by 5-25\\% when given additional bands during test time. Finally, we show that fine-tuning just the last linear layer of these models using oracle labels from all bands can get relatively consistent performance across all satellites, highlighting that the benchmark is far from being saturated. We publicly release the code and the datasets to encourage the development of more future-proof remote sensing models with stronger cross-satellite generalization.",
    "fetched_at": "2025-11-06T02:19:07.210324Z"
  },
  {
    "id": "2511.02832v1",
    "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yanjie Ze",
      "Siheng Zhao",
      "Weizhuo Wang",
      "Angjoo Kanazawa",
      "Rocky Duan",
      "Pieter Abbeel",
      "Guanya Shi",
      "Jiajun Wu",
      "C. Karen Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02832v1",
    "abstract": "Large-scale data has driven breakthroughs in robotics, from language models to vision-language-action models in bimanual manipulation. However, humanoid robotics lacks equally effective data collection frameworks. Existing humanoid teleoperation systems either use decoupled control or depend on expensive motion capture setups. We introduce TWIST2, a portable, mocap-free humanoid teleoperation and data collection system that preserves full whole-body control while advancing scalability. Our system leverages PICO4U VR for obtaining real-time whole-body human motions, with a custom 2-DoF robot neck (cost around $250) for egocentric vision, enabling holistic human-to-humanoid control. We demonstrate long-horizon dexterous and mobile humanoid skills and we can collect 100 demonstrations in 15 minutes with an almost 100% success rate. Building on this pipeline, we propose a hierarchical visuomotor policy framework that autonomously controls the full humanoid body based on egocentric vision. Our visuomotor policy successfully demonstrates whole-body dexterous manipulation and dynamic kicking tasks. The entire system is fully reproducible and open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also open-sourced at https://twist-data.github.io .",
    "fetched_at": "2025-11-06T02:19:07.210265Z"
  },
  {
    "id": "2511.02833v1",
    "title": "In Good GRACEs: Principled Teacher Selection for Knowledge Distillation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Abhishek Panigrahi",
      "Bingbin Liu",
      "Sadhika Malladi",
      "Sham Kakade",
      "Surbhi Goel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02833v1",
    "abstract": "Knowledge distillation is an efficient strategy to use data generated by large \"teacher\" language models to train smaller capable \"student\" models, but selecting the optimal teacher for a specific student-task combination requires expensive trial-and-error. We propose a lightweight score called GRACE to quantify how effective a teacher will be for post-training a student model. GRACE measures distributional properties of the student's gradients without access to a verifier, teacher logits, teacher internals, or test data. From an information-theoretic perspective, GRACE connects to leave-one-out stability of gradient-based algorithms, which controls the generalization performance of the distilled students. On GSM8K and MATH, GRACE correlates strongly (up to 86% Spearman correlation) with the performance of the distilled LLaMA and OLMo students. In particular, training a student using the GRACE-selected teacher can improve the performance by up to 7.4% over naively using the best-performing teacher. Further, GRACE can provide guidance on crucial design choices in distillation, including (1) the best temperature to use when generating from the teacher, (2) the best teacher to use given a size constraint, and (3) the best teacher to use within a specific model family. Altogether, our findings demonstrate that GRACE can efficiently and effectively identify a strongly compatible teacher for a given student and provide fine-grained guidance on how to perform distillation.",
    "fetched_at": "2025-11-06T02:19:07.210195Z"
  },
  {
    "id": "2511.01205v1",
    "title": "When Machines Join the Moral Circle: The Persona Effect of Generative AI   Agents in Collaborative Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Yueqiao Jin",
      "Roberto Martinez-Maldonado",
      "Wanruo Shi",
      "Songjie Huang",
      "Mingmin Zheng",
      "Xinbin Han",
      "Dragan Gasevic",
      "Lixiang Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01205v1",
    "abstract": "Generative AI is increasingly positioned as a peer in collaborative learning, yet its effects on ethical deliberation remain unclear. We report a between-subjects experiment with university students (N=217) who discussed an autonomous-vehicle dilemma in triads under three conditions: human-only control, supportive AI teammate, or contrarian AI teammate. Using moral foundations lexicons, argumentative coding from the augmentative knowledge construction framework, semantic trajectory modelling with BERTopic and dynamic time warping, and epistemic network analysis, we traced how AI personas reshape moral discourse. Supportive AIs increased grounded/qualified claims relative to control, consolidating integrative reasoning around care/fairness, while contrarian AIs modestly broadened moral framing and sustained value pluralism. Both AI conditions reduced thematic drift compared with human-only groups, indicating more stable topical focus. Post-discussion justification complexity was only weakly predicted by moral framing and reasoning quality, and shifts in final moral decisions were driven primarily by participants' initial stance rather than condition. Overall, AI teammates altered the process, the distribution and connection of moral frames and argument quality, more than the outcome of moral choice, highlighting the potential of generative AI agents as teammates for eliciting reflective, pluralistic moral reasoning in collaborative learning.",
    "fetched_at": "2025-11-09T02:21:24.639461Z"
  },
  {
    "id": "2511.01218v1",
    "title": "Optimizing Electric Vehicle Charging Station Placement Using   Reinforcement Learning and Agent-Based Simulations",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Minh-Duc Nguyen",
      "Dung D. Le",
      "Phi Long Nguyen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01218v1",
    "abstract": "The rapid growth of electric vehicles (EVs) necessitates the strategic placement of charging stations to optimize resource utilization and minimize user inconvenience. Reinforcement learning (RL) offers an innovative approach to identifying optimal charging station locations; however, existing methods face challenges due to their deterministic reward systems, which limit efficiency. Because real-world conditions are dynamic and uncertain, a deterministic reward structure cannot fully capture the complexities of charging station placement. As a result, evaluation becomes costly and time-consuming, and less reflective of real-world scenarios. To address this challenge, we propose a novel framework that integrates deep RL with agent-based simulations to model EV movement and estimate charging demand in real time. Our approach employs a hybrid RL agent with dual Q-networks to select optimal locations and configure charging ports, guided by a hybrid reward function that combines deterministic factors with simulation-derived feedback. Case studies in Hanoi, Vietnam, show that our method reduces average waiting times by 53.28% compared to the initial state, outperforming static baseline methods. This scalable and adaptive solution enhances EV infrastructure planning, effectively addressing real-world complexities and improving user experience.",
    "fetched_at": "2025-11-09T02:21:24.639402Z"
  },
  {
    "id": "2511.01310v1",
    "title": "From Pixels to Cooperation Multi Agent Reinforcement Learning based on   Multimodal World Models",
    "date": "2025-11-03",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Sureyya Akin",
      "Kavita Srivastava",
      "Prateek B. Kapoor",
      "Pradeep G. Sethi",
      "Sunita Q. Patel",
      "Rahu Srivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01310v1",
    "abstract": "Learning cooperative multi-agent policies directly from high-dimensional, multimodal sensory inputs like pixels and audio (from pixels) is notoriously sample-inefficient. Model-free Multi-Agent Reinforcement Learning (MARL) algorithms struggle with the joint challenge of representation learning, partial observability, and credit assignment. To address this, we propose a novel framework based on a shared, generative Multimodal World Model (MWM). Our MWM is trained to learn a compressed latent representation of the environment's dynamics by fusing distributed, multimodal observations from all agents using a scalable attention-based mechanism. Subsequently, we leverage this learned MWM as a fast, \"imagined\" simulator to train cooperative MARL policies (e.g., MAPPO) entirely within its latent space, decoupling representation learning from policy learning. We introduce a new set of challenging multimodal, multi-agent benchmarks built on a 3D physics simulator. Our experiments demonstrate that our MWM-MARL framework achieves orders-of-magnitude greater sample efficiency compared to state-of-the-art model-free MARL baselines. We further show that our proposed multimodal fusion is essential for task success in environments with sensory asymmetry and that our architecture provides superior robustness to sensor-dropout, a critical feature for real-world deployment.",
    "fetched_at": "2025-11-09T02:21:24.639295Z"
  },
  {
    "id": "2511.01383v1",
    "title": "CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Landson Guo",
      "Andres M. Diaz Aguilar",
      "William Talbot",
      "Turcan Tuna",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01383v1",
    "abstract": "Accurate point-wise velocity estimation in 3D is crucial for robot interaction with non-rigid, dynamic agents, such as humans, enabling robust performance in path planning, collision avoidance, and object manipulation in dynamic environments. To this end, this paper proposes a novel RADAR, LiDAR, and camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V. This pipeline leverages raw RADAR measurements to create a novel RADAR representation, the velocity cube, which densely represents radial velocities within the RADAR's field-of-view. By combining the velocity cube for radial velocity extraction, optical flow for tangential velocity estimation, and LiDAR for point-wise range measurements through a closed-form solution, our approach can produce 3D velocity estimates for a dense array of points. Developed as an open-source ROS2 package, CaRLi-V has been field-tested against a custom dataset and proven to produce low velocity error metrics relative to ground truth, enabling point-wise velocity estimation for robotic applications.",
    "fetched_at": "2025-11-09T02:21:24.639243Z"
  },
  {
    "id": "2511.01415v1",
    "title": "Modulation of temporal decision-making in a deep reinforcement learning   agent under the dual-task paradigm",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amrapali Pednekar",
      "Álvaro Garrido-Pérez",
      "Yara Khaluf",
      "Pieter Simoens"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01415v1",
    "abstract": "This study explores the interference in temporal processing within a dual-task paradigm from an artificial intelligence (AI) perspective. In this context, the dual-task setup is implemented as a simplified version of the Overcooked environment with two variations, single task (T) and dual task (T+N). Both variations involve an embedded time production task, but the dual task (T+N) additionally involves a concurrent number comparison task. Two deep reinforcement learning (DRL) agents were separately trained for each of these tasks. These agents exhibited emergent behavior consistent with human timing research. Specifically, the dual task (T+N) agent exhibited significant overproduction of time relative to its single task (T) counterpart. This result was consistent across four target durations. Preliminary analysis of neural dynamics in the agents' LSTM layers did not reveal any clear evidence of a dedicated or intrinsic timer. Hence, further investigation is needed to better understand the underlying time-keeping mechanisms of the agents and to provide insights into the observed behavioral patterns. This study is a small step towards exploring parallels between emergent DRL behavior and behavior observed in biological systems in order to facilitate a better understanding of both.",
    "fetched_at": "2025-11-09T02:21:24.639195Z"
  },
  {
    "id": "2511.01425v1",
    "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal   Faithfulness Analysis",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "I.2.6; I.2.10",
      "10"
    ],
    "authors": [
      "Yuhang Huang",
      "Zekai Lin",
      "Fan Zhong",
      "Lei Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01425v1",
    "abstract": "Explanations for AI models in high-stakes domains like medicine often lack verifiability, which can hinder trust. To address this, we propose an interactive agent that produces explanations through an auditable sequence of actions. The agent learns a policy to strategically seek external visual evidence to support its diagnostic reasoning. This policy is optimized using reinforcement learning, resulting in a model that is both efficient and generalizable. Our experiments show that this action-based reasoning process significantly improves calibrated accuracy, reducing the Brier score by 18\\% compared to a non-interactive baseline. To validate the faithfulness of the agent's explanations, we introduce a causal intervention method. By masking the visual evidence the agent chooses to use, we observe a measurable degradation in its performance ($\\Delta$Brier=+0.029), confirming that the evidence is integral to its decision-making process. Our work provides a practical framework for building AI systems with verifiable and faithful reasoning capabilities.",
    "fetched_at": "2025-11-09T02:21:24.639147Z"
  },
  {
    "id": "2511.01493v1",
    "title": "Floor Plan-Guided Visual Navigation Incorporating Depth and Directional   Cues",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Wei Huang",
      "Jiaxin Li",
      "Zang Wan",
      "Huijun Di",
      "Wei Liang",
      "Zhu Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01493v1",
    "abstract": "Guiding an agent to a specific target in indoor environments based solely on RGB inputs and a floor plan is a promising yet challenging problem. Although existing methods have made significant progress, two challenges remain unresolved. First, the modality gap between egocentric RGB observations and the floor plan hinders the integration of visual and spatial information for both local obstacle avoidance and global planning. Second, accurate localization is critical for navigation performance, but remains challenging at deployment in unseen environments due to the lack of explicit geometric alignment between RGB inputs and floor plans. We propose a novel diffusion-based policy, denoted as GlocDiff, which integrates global path planning from the floor plan with local depth-aware features derived from RGB observations. The floor plan offers explicit global guidance, while the depth features provide implicit geometric cues, collectively enabling precise prediction of optimal navigation directions and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation during training to enhance robustness against pose estimation errors, and we find that combining this with a relatively stable VO module during inference results in significantly improved navigation performance. Extensive experiments on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in achieving superior navigation performance, and the success of real-world deployments also highlights its potential for widespread practical applications.",
    "fetched_at": "2025-11-09T02:21:24.639035Z"
  },
  {
    "id": "2511.01554v1",
    "title": "Learning what to say and how precisely: Efficient Communication via   Differentiable Discrete Communication Learning",
    "date": "2025-11-03",
    "tags": [
      "cs.MA",
      "MA",
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "math.IT"
    ],
    "authors": [
      "Aditya Kapoor",
      "Yash Bhisikar",
      "Benjamin Freed",
      "Jan Peters",
      "Mingfei Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01554v1",
    "abstract": "Effective communication in multi-agent reinforcement learning (MARL) is critical for success but constrained by bandwidth, yet past approaches have been limited to complex gating mechanisms that only decide \\textit{whether} to communicate, not \\textit{how precisely}. Learning to optimize message precision at the bit-level is fundamentally harder, as the required discretization step breaks gradient flow. We address this by generalizing Differentiable Discrete Communication Learning (DDCL), a framework for end-to-end optimization of discrete messages. Our primary contribution is an extension of DDCL to support unbounded signals, transforming it into a universal, plug-and-play layer for any MARL architecture. We verify our approach with three key results. First, through a qualitative analysis in a controlled environment, we demonstrate \\textit{how} agents learn to dynamically modulate message precision according to the informational needs of the task. Second, we integrate our variant of DDCL into four state-of-the-art MARL algorithms, showing it reduces bandwidth by over an order of magnitude while matching or exceeding task performance. Finally, we provide direct evidence for the \\enquote{Bitter Lesson} in MARL communication: a simple Transformer-based policy leveraging DDCL matches the performance of complex, specialized architectures, questioning the necessity of bespoke communication designs.",
    "fetched_at": "2025-11-09T02:21:24.638926Z"
  },
  {
    "id": "2511.01718v1",
    "title": "Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete   Denoising Diffusion Process",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Jiayi Chen",
      "Wenxuan Song",
      "Pengxiang Ding",
      "Ziyang Zhou",
      "Han Zhao",
      "Feilong Tang",
      "Donglin Wang",
      "Haoang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01718v1",
    "abstract": "Vision-language-action (VLA) models aim to understand natural language instructions and visual observations and to execute corresponding actions as an embodied agent. Recent work integrates future images into the understanding-acting loop, yielding unified VLAs that jointly understand, generate, and act -- reading text and images and producing future images and actions. However, these models either rely on external experts for modality unification or treat image generation and action prediction as separate processes, limiting the benefits of direct synergy between these tasks. Our core philosophy is to optimize generation and action jointly through a synchronous denoising process, where the iterative refinement enables actions to evolve from initialization, under constant and sufficient visual guidance. We ground this philosophy in our proposed Unified Diffusion VLA and Joint Discrete Denoising Diffusion Process (JD3P), which is a joint diffusion process that integrates multiple modalities into a single denoising trajectory to serve as the key mechanism enabling understanding, generation, and acting to be intrinsically synergistic. Our model and theory are built on a unified tokenized space of all modalities and a hybrid attention mechanism. We further propose a two-stage training pipeline and several inference-time techniques that optimize performance and efficiency. Our approach achieves state-of-the-art performance on benchmarks such as CALVIN, LIBERO, and SimplerEnv with 4$\\times$ faster inference than autoregressive methods, and we demonstrate its effectiveness through in-depth analysis and real-world evaluations. Our project page is available at https://irpn-eai.github.io/UD-VLA.github.io/.",
    "fetched_at": "2025-11-09T02:21:24.638792Z"
  },
  {
    "id": "2511.01720v1",
    "title": "Efficient Tool-Calling Multi-Expert NPC Agent for Commonsense   Persona-Grounded Dialogue",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mahammad Nuriyev"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01720v1",
    "abstract": "We present a multi-expert system for creating Non-Player Characters (NPCs) capable of both natural dialogue and contextual action execution in interactive environments. Using Qwen3 as the base model and Low-Rank Adaptation (LoRA) adapters, we instantiate three specialists: tool calling, tool-response interpretation, and direct dialogue. Our system comfortably meets the computational efficiency requirements, delivering fast responses and maintaining modest resource usage on L40S GPUs. In the Commonsense Persona-Grounded Dialogue Challenge 2025, our method ranked second overall.   Code available at: https://github.com/MahammadNuriyev62/CPDC-challenge-2025-solution/",
    "fetched_at": "2025-11-09T02:21:24.638727Z"
  },
  {
    "id": "2511.02016v1",
    "title": "ABIDES-MARL: A Multi-Agent Reinforcement Learning Environment for   Endogenous Price Formation and Execution in a Limit Order Book",
    "date": "2025-11-03",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.GT",
      "GT",
      "cs.MA",
      "MA",
      "cs.SY",
      "SY",
      "eess.SY",
      "91-10, 91A26, 68T05, 93E20",
      "I.2.11; I.2.8; J.4",
      "4"
    ],
    "authors": [
      "Patrick Cheridito",
      "Jean-Loup Dupret",
      "Zhexin Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02016v1",
    "abstract": "We present ABIDES-MARL, a framework that combines a new multi-agent reinforcement learning (MARL) methodology with a new realistic limit-order-book (LOB) simulation system to study equilibrium behavior in complex financial market games. The system extends ABIDES-Gym by decoupling state collection from kernel interruption, enabling synchronized learning and decision-making for multiple adaptive agents while maintaining compatibility with standard RL libraries. It preserves key market features such as price-time priority and discrete tick sizes. Methodologically, we use MARL to approximate equilibrium-like behavior in multi-period trading games with a finite number of heterogeneous agents-an informed trader, a liquidity trader, noise traders, and competing market makers-all with individual price impacts. This setting bridges optimal execution and market microstructure by embedding the liquidity trader's optimization problem within a strategic trading environment. We validate the approach by solving an extended Kyle model within the simulation system, recovering the gradual price discovery phenomenon. We then extend the analysis to a liquidity trader's problem where market liquidity arises endogenously and show that, at equilibrium, execution strategies shape market-maker behavior and price dynamics. ABIDES-MARL provides a reproducible foundation for analyzing equilibrium and strategic adaptation in realistic markets and contributes toward building economically interpretable agentic AI systems for finance.",
    "fetched_at": "2025-11-09T02:21:24.638577Z"
  },
  {
    "id": "2511.02136v1",
    "title": "JaxMARL-HFT: GPU-Accelerated Large-Scale Multi-Agent Reinforcement   Learning for High-Frequency Trading",
    "date": "2025-11-03",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Valentin Mohl",
      "Sascha Frey",
      "Reuben Leyland",
      "Kang Li",
      "George Nigmatulin",
      "Mihai Cucuringu",
      "Stefan Zohren",
      "Jakob Foerster",
      "Anisoara Calinescu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02136v1",
    "abstract": "Agent-based modelling (ABM) approaches for high-frequency financial markets are difficult to calibrate and validate, partly due to the large parameter space created by defining fixed agent policies. Multi-agent reinforcement learning (MARL) enables more realistic agent behaviour and reduces the number of free parameters, but the heavy computational cost has so far limited research efforts. To address this, we introduce JaxMARL-HFT (JAX-based Multi-Agent Reinforcement Learning for High-Frequency Trading), the first GPU-accelerated open-source multi-agent reinforcement learning environment for high-frequency trading (HFT) on market-by-order (MBO) data. Extending the JaxMARL framework and building on the JAX-LOB implementation, JaxMARL-HFT is designed to handle a heterogeneous set of agents, enabling diverse observation/action spaces and reward functions. It is designed flexibly, so it can also be used for single-agent RL, or extended to act as an ABM with fixed-policy agents. Leveraging JAX enables up to a 240x reduction in end-to-end training time, compared with state-of-the-art reference implementations on the same hardware. This significant speed-up makes it feasible to exploit the large, granular datasets available in high-frequency trading, and to perform the extensive hyperparameter sweeps required for robust and efficient MARL research in trading. We demonstrate the use of JaxMARL-HFT with independent Proximal Policy Optimization (IPPO) for a two-player environment, with an order execution and a market making agent, using one year of LOB data (400 million orders), and show that these agents learn to outperform standard benchmarks. The code for the JaxMARL-HFT framework is available on GitHub.",
    "fetched_at": "2025-11-09T02:21:24.638345Z"
  },
  {
    "id": "2511.01149v1",
    "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent   Systems Driven by Large Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shuaidong Pan",
      "Di Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01149v1",
    "abstract": "This paper addresses the limitations of a single agent in task decomposition and collaboration during complex task execution, and proposes a multi-agent architecture for modular task decomposition and dynamic collaboration based on large language models. The method first converts natural language task descriptions into unified semantic representations through a large language model. On this basis, a modular decomposition mechanism is introduced to break down the overall goal into multiple hierarchical sub-tasks. Then, dynamic scheduling and routing mechanisms enable reasonable division of labor and realtime collaboration among agents, allowing the system to adjust strategies continuously according to environmental feedback, thus maintaining efficiency and stability in complex tasks. Furthermore, a constraint parsing and global consistency mechanism is designed to ensure coherent connections between sub-tasks and balanced workload, preventing performance degradation caused by redundant communication or uneven resource allocation. The experiments validate the architecture across multiple dimensions, including task success rate, decomposition efficiency, sub-task coverage, and collaboration balance. The results show that the proposed method outperforms existing approaches in both overall performance and robustness, achieving a better balance between task complexity and communication overhead. In conclusion, this study demonstrates the effectiveness and feasibility of language-driven task decomposition and dynamic collaboration in multi-agent systems, providing a systematic solution for task execution in complex environments.",
    "fetched_at": "2025-11-09T02:21:22.889987Z"
  },
  {
    "id": "2511.01166v1",
    "title": "MicroRemed: Benchmarking LLMs in Microservices Remediation",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.SE",
      "SE",
      "68T50",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Lingzhe Zhang",
      "Yunpeng Zhai",
      "Tong Jia",
      "Chiming Duan",
      "Minghua He",
      "Leyi Pan",
      "Zhaoyang Liu",
      "Bolin Ding",
      "Ying Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01166v1",
    "abstract": "Large Language Models (LLMs) integrated with agent-based reasoning frameworks have recently shown strong potential for autonomous decision-making and system-level operations. One promising yet underexplored direction is microservice remediation, where the goal is to automatically recover faulty microservice systems. Existing approaches, however, still rely on human-crafted prompts from Site Reliability Engineers (SREs), with LLMs merely converting textual instructions into executable code. To advance research in this area, we introduce MicroRemed, the first benchmark for evaluating LLMs in end-to-end microservice remediation, where models must directly generate executable Ansible playbooks from diagnosis reports to restore system functionality. We further propose ThinkRemed, a multi-agent framework that emulates the reflective and perceptive reasoning of SREs. Experimental results show that MicroRemed presents substantial challenges to current LLMs, while ThinkRemed improves end-to-end remediation performance through iterative reasoning and system reflection. The benchmark is available at https://github.com/LLM4AIOps/MicroRemed.",
    "fetched_at": "2025-11-09T02:21:22.889945Z"
  },
  {
    "id": "2511.01181v1",
    "title": "Learning When to Quit in Sales Conversations",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Emaad Manzoor",
      "Eva Ascarza",
      "Oded Netzer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01181v1",
    "abstract": "Salespeople frequently face the dynamic screening decision of whether to persist in a conversation or abandon it to pursue the next lead. Yet, little is known about how these decisions are made, whether they are efficient, or how to improve them. We study these decisions in the context of high-volume outbound sales where leads are ample, but time is scarce and failure is common. We formalize the dynamic screening decision as an optimal stopping problem and develop a generative language model-based sequential decision agent - a stopping agent - that learns whether and when to quit conversations by imitating a retrospectively-inferred optimal stopping policy. Our approach handles high-dimensional textual states, scales to large language models, and works with both open-source and proprietary language models. When applied to calls from a large European telecommunications firm, our stopping agent reduces the time spent on failed calls by 54% while preserving nearly all sales; reallocating the time saved increases expected sales by up to 37%. Upon examining the linguistic cues that drive salespeople's quitting decisions, we find that they tend to overweight a few salient expressions of consumer disinterest and mispredict call failure risk, suggesting cognitive bounds on their ability to make real-time conversational decisions. Our findings highlight the potential of artificial intelligence algorithms to correct cognitively-bounded human decisions and improve salesforce efficiency.",
    "fetched_at": "2025-11-09T02:21:22.889884Z"
  },
  {
    "id": "2511.01188v1",
    "title": "ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and   Multi-LLM Interaction",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lvhua Wu",
      "Xuefeng Jiang",
      "Sheng Sun",
      "Tian Wen",
      "Yuwei Wang",
      "Min Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01188v1",
    "abstract": "The rapid spread of fake news threatens social stability and public trust, rendering its detection an imperative research priority. Although large language models (LLMs) excel at numerous natural language processing tasks with their remarkable contextual understanding and extensive prior knowledge, the time-bounded knowledge coverage and tendency for generating hallucination content reduce their reliability when handling fast-evolving news streams. Furthermore, models trained on existing static datasets also often lack the generalization needed for emerging news topics. To address these challenges, we propose ZoFia, a novel two-stage zero-shot fake news detection framework. First, we introduce Hierarchical Salience to quantify the importance of entities in the news content, and propose the SC-MMR algorithm to effectively select an informative and diverse set of keywords that serve as queries for retrieving up-to-date external evidence. Subsequently, a multi LLM interactive system, in which each agent assumes a distinct role, performs multi-view collaborative analysis and adversarial debate over the news text and its related information, and finally produces an interpretable and robust judgment. Comprehensive experiments on two public datasets demonstrate that ZoFia obviously outperforms existing zero-shot baselines and most of few-shot methods. Our codes will be open-sourced to facilitate related communities.",
    "fetched_at": "2025-11-09T02:21:22.889840Z"
  },
  {
    "id": "2511.01236v1",
    "title": "Don't Just Search, Understand: Semantic Path Planning Agent for   Spherical Tensegrity Robots in Unknown Environments",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Junwen Zhang",
      "Changyue Liu",
      "Pengqi Fu",
      "Xiang Guo",
      "Ye Shi",
      "Xudong Liang",
      "Zhijian Wang",
      "Hanzhi Ma"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01236v1",
    "abstract": "Endowed with inherent dynamical properties that grant them remarkable ruggedness and adaptability, spherical tensegrity robots stand as prototypical examples of hybrid softrigid designs and excellent mobile platforms. However, path planning for these robots in unknown environments presents a significant challenge, requiring a delicate balance between efficient exploration and robust planning. Traditional path planners, which treat the environment as a geometric grid, often suffer from redundant searches and are prone to failure in complex scenarios due to their lack of semantic understanding. To overcome these limitations, we reframe path planning in unknown environments as a semantic reasoning task. We introduce a Semantic Agent for Tensegrity robots (SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages high-level environmental comprehension to generate efficient and reliable planning strategies.At the core of SATPlanner is an Adaptive Observation Window mechanism, inspired by the \"fast\" and \"slow\" thinking paradigms of LLMs. This mechanism dynamically adjusts the perceptual field of the agent: it narrows for rapid traversal of open spaces and expands to reason about complex obstacle configurations. This allows the agent to construct a semantic belief of the environment, enabling the search space to grow only linearly with the path length (O(L)) while maintaining path quality. We extensively evaluate SATPlanner in 1,000 simulation trials, where it achieves a 100% success rate, outperforming other real-time planning algorithms. Critically, SATPlanner reduces the search space by 37.2% compared to the A* algorithm while achieving comparable, near-optimal path lengths. Finally, the practical feasibility of SATPlanner is validated on a physical spherical tensegrity robot prototype.",
    "fetched_at": "2025-11-09T02:21:22.889783Z"
  },
  {
    "id": "2511.01448v1",
    "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient   Long-Term Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Zhengjun Huang",
      "Zhoujin Tian",
      "Qintian Guo",
      "Fangyuan Zhang",
      "Yingli Zhou",
      "Di Jiang",
      "Xiaofang Zhou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01448v1",
    "abstract": "Large Language Model (LLM) agents exhibit remarkable conversational and reasoning capabilities but remain constrained by limited context windows and the lack of persistent memory. Recent efforts address these limitations via external memory architectures, often employing graph-based representations, yet most adopt flat, entangled structures that intertwine semantics with topology, leading to redundant representations, unstructured retrieval, and degraded efficiency and accuracy. To resolve these issues, we propose LiCoMemory, an end-to-end agentic memory framework for real-time updating and retrieval, which introduces CogniGraph, a lightweight hierarchical graph that utilizes entities and relations as semantic indexing layers, and employs temporal and hierarchy-aware search with integrated reranking for adaptive and coherent knowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and LongMemEval, show that LiCoMemory not only outperforms established baselines in temporal reasoning, multi-session consistency, and retrieval efficiency, but also notably reduces update latency. Our official code and data are available at https://github.com/EverM0re/LiCoMemory.",
    "fetched_at": "2025-11-09T02:21:22.889723Z"
  },
  {
    "id": "2511.01527v1",
    "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities   in Compounding Tasks",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hanwen Xu",
      "Xuyao Huang",
      "Yuzhe Liu",
      "Kai Yu",
      "Zhijie Deng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01527v1",
    "abstract": "Large language model (LLM) agents have exhibited strong problem-solving competence across domains like research and coding. Yet, it remains underexplored whether LLM agents can tackle compounding real-world problems that require a diverse set of tools to complete. Given a broad, heterogeneous tool repository, LLM agents must not only select appropriate tools based on task planning analysis but also strategically schedule the execution order to ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of LLM agents in solving such problems that demand Tool Planning and Scheduling. TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a tool repository containing hundreds of model context protocol (MCP) tools. In particular, each task is composed of multiple subtasks, such as web search, map navigation, calendar checking, etc., and each subtask can be completed by a basic tool. Our evaluation emphasizes both task completion rate and efficiency. The empirical studies on popular closed-source and open-source LLMs indicate that most models can perform reasonable tool planning, but differ in scheduling. For example, GLM-4.5 achieves an outperforming task completion rate of 64.72% with extensive sequential tool calls, hence suffering from significantly long execution time. By contrast, GPT-4o prioritizes parallel tool calls but achieves only a 45.08% completion rate. Considering reinforcement learning (RL) can be a viable way to improve the scheduling efficiency without compromising performance, we perform an initial study on Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in task completion rate based on rarely 100 RL training samples. Our code is available https://github.com/hanwenxu1/mcp-agent.",
    "fetched_at": "2025-11-09T02:21:22.889669Z"
  },
  {
    "id": "2511.01594v1",
    "title": "MARS: Multi-Agent Robotic System with Multimodal Large Language Models   for Assistive Intelligence",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "I.2.9; I.2.11; I.2.6; I.4.8",
      "8"
    ],
    "authors": [
      "Renjun Gao",
      "Peiyan Zhong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01594v1",
    "abstract": "Multimodal large language models (MLLMs) have shown remarkable capabilities in cross-modal understanding and reasoning, offering new opportunities for intelligent assistive systems, yet existing systems still struggle with risk-aware planning, user personalization, and grounding language plans into executable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic System powered by MLLMs for assistive intelligence and designed for smart home robots supporting people with disabilities. The system integrates four agents: a visual perception agent for extracting semantic and spatial features from environment images, a risk assessment agent for identifying and prioritizing hazards, a planning agent for generating executable action sequences, and an evaluation agent for iterative optimization. By combining multimodal perception with hierarchical multi-agent decision-making, the framework enables adaptive, risk-aware, and personalized assistance in dynamic indoor environments. Experiments on multiple datasets demonstrate the superior overall performance of the proposed system in risk-aware planning and coordinated multi-agent execution compared with state-of-the-art multimodal models. The proposed approach also highlights the potential of collaborative AI for practical assistive scenarios and provides a generalizable methodology for deploying MLLM-enabled multi-agent systems in real-world environments.",
    "fetched_at": "2025-11-09T02:21:22.889614Z"
  },
  {
    "id": "2511.01625v1",
    "title": "UniDataBench: Evaluating Data Analytics Agents Across Structured and   Unstructured Data",
    "date": "2025-11-03",
    "tags": [
      "cs.DB",
      "DB"
    ],
    "authors": [
      "Han Weng",
      "Zhou Liu",
      "Yuanfeng Song",
      "Xiaoming Yin",
      "Xing Chen",
      "Wentao Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01625v1",
    "abstract": "In the real business world, data is stored in a variety of sources, including structured relational databases, unstructured databases (e.g., NoSQL databases), or even CSV/excel files. The ability to extract reasonable insights across these diverse source is vital for business success. Existing benchmarks, however, are limited in assessing agents' capabilities across these diverse data types. To address this gap, we introduce UniDataBench, a comprehensive benchmark designed to evaluate the performance of data analytics agents in handling diverse data sources. Specifically, UniDataBench is originating from real-life industry analysis report and we then propose a pipeline to remove the privacy and sensitive information. It encompasses a wide array of datasets, including relational databases, CSV files to NoSQL data, reflecting real-world business scenarios, and provides unified framework to assess how effectively agents can explore multiple data formats, extract valuable insights, and generate meaningful summaries and recommendations. Based on UniDataBench, we propose a novel LLM-based agent named ReActInsight, an autonomous agent that performs end-to-end analysis over diverse data sources by automatically discovering cross-source linkages, decomposing goals, and generating robust, self-correcting code to extract actionable insights. Our benchmark and agent together provide a powerful framework for advancing the capabilities of data analytics agents in real-world applications.",
    "fetched_at": "2025-11-09T02:21:22.889570Z"
  },
  {
    "id": "2511.01633v1",
    "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with   Efficient LLM Serving",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chengying Huan",
      "Ziheng Meng",
      "Yongchao Liu",
      "Zhengyi Yang",
      "Yun Zhu",
      "Yue Yun",
      "Shipeng Li",
      "Rong Gu",
      "Xiabao Wu",
      "Haitao Zhang",
      "Chuntao Hong",
      "Shaonan Ma",
      "Guihai Chen",
      "Chen Tian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01633v1",
    "abstract": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to perform step-by-step reasoning over graph-structured knowledge, but existing pipelines suffer from low accuracy, excessive token usage, high latency, and low throughput due to single-agent monolithic prompts, repeated context re-encoding, and inefficient serving execution. We present GLM, the first multi-agent Graph-CoT system co-designed with an optimized LLM serving architecture. GLM decomposes reasoning into specialized agents for classification, reasoning, action generation, and graph retrieval, enabling branching and selective context sharing to reduce prompt length and reasoning iterations while preserving reasoning quality, thereby improving accuracy and reducing overall token consumption. To scale inference, we introduce a Graph-CoT-aware LLM inference mechanism with graph-specific KV-cache management, priority-based eviction, and pipelined execution to improve serving efficiency. Experiments demonstrate that GLM improves answer accuracy by up to 38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and achieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT baselines, enabling efficient adoption for complex real-world reasoning at scale.",
    "fetched_at": "2025-11-09T02:21:22.889518Z"
  },
  {
    "id": "2511.01668v1",
    "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal   Question Answering in Judicial Forensics",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yueqing Xi",
      "Yifan Bai",
      "Huasen Luo",
      "Weiliang Wen",
      "Hui Liu",
      "Haoliang Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01668v1",
    "abstract": "As artificial intelligence permeates judicial forensics, ensuring the veracity and traceability of legal question answering (QA) has become critical. Conventional large language models (LLMs) are prone to hallucination, risking misleading guidance in legal consultation, while static knowledge bases struggle to keep pace with frequently updated statutes and case law. We present a hybrid legal QA agent tailored for judicial settings that integrates retrieval-augmented generation (RAG) with multi-model ensembling to deliver reliable, auditable, and continuously updatable counsel. The system prioritizes retrieval over generation: when a trusted legal repository yields relevant evidence, answers are produced via RAG; otherwise, multiple LLMs generate candidates that are scored by a specialized selector, with the top-ranked answer returned. High-quality outputs then undergo human review before being written back to the repository, enabling dynamic knowledge evolution and provenance tracking. Experiments on the Law\\_QA dataset show that our hybrid approach significantly outperforms both a single-model baseline and a vanilla RAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm the complementary contributions of retrieval prioritization, model ensembling, and the human-in-the-loop update mechanism. The proposed system demonstrably reduces hallucination while improving answer quality and legal compliance, advancing the practical landing of media forensics technologies in judicial scenarios.",
    "fetched_at": "2025-11-09T02:21:22.889443Z"
  },
  {
    "id": "2511.02864v1",
    "title": "Mathematical exploration and discovery at scale",
    "date": "2025-11-03",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "math.CA",
      "CA",
      "math.CO",
      "CO",
      "math.MG",
      "MG"
    ],
    "authors": [
      "Bogdan Georgiev",
      "Javier Gómez-Serrano",
      "Terence Tao",
      "Adam Zsolt Wagner"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02864v1",
    "abstract": "AlphaEvolve is a generic evolutionary coding agent that combines the generative capabilities of LLMs with automated evaluation in an iterative evolutionary framework that proposes, tests, and refines algorithmic solutions to challenging scientific and practical problems. In this paper we showcase AlphaEvolve as a tool for autonomously discovering novel mathematical constructions and advancing our understanding of long-standing open problems.   To demonstrate its breadth, we considered a list of 67 problems spanning mathematical analysis, combinatorics, geometry, and number theory. The system rediscovered the best known solutions in most of the cases and discovered improved solutions in several. In some instances, AlphaEvolve is also able to generalize results for a finite number of input values into a formula valid for all input values. Furthermore, we are able to combine this methodology with Deep Think and AlphaProof in a broader framework where the additional proof-assistants and reasoning systems provide automated proof generation and further mathematical insights.   These results demonstrate that large language model-guided evolutionary search can autonomously discover mathematical constructions that complement human intuition, at times matching or even improving the best known results, highlighting the potential for significant new ways of interaction between mathematicians and AI systems. We present AlphaEvolve as a powerful new tool for mathematical discovery, capable of exploring vast search spaces to solve complex optimization problems at scale, often with significantly reduced requirements on preparation and computation time.",
    "fetched_at": "2025-11-09T02:21:22.889388Z"
  },
  {
    "id": "2511.01695v2",
    "title": "Collaborative Large Language Model Inference via Resource-Aware Parallel   Speculative Decoding",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Jungyeon Koh",
      "Hyun Jong Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01695v2",
    "abstract": "The growing demand for on-device large language model (LLM) inference highlights the need for efficient mobile edge computing (MEC) solutions, especially in resource-constrained settings. Speculative decoding offers a promising solution by partitioning token generation between a lightweight draft model on mobile devices and a powerful target model on edge servers, but suffers from communication overhead and asynchronous delays. This paper is the first to propose a unified framework that jointly optimizes user association and resource allocation (UARA) to support efficient parallel speculative decoding. We solve the UARA problem using a multi-agent deep reinforcement learning algorithm. To evaluate our approach under realistic conditions, we conduct experiments using the Sionna simulator. Results show that our method achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency without compromising inference accuracy, enabling scalable and low-latency LLM services in MEC systems.",
    "fetched_at": "2025-11-09T02:21:22.889335Z"
  },
  {
    "id": "2511.01755v1",
    "title": "3EED: Ground Everything Everywhere in 3D",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Rong Li",
      "Yuhao Dong",
      "Tianshuai Hu",
      "Ao Liang",
      "Youquan Liu",
      "Dongyue Lu",
      "Liang Pan",
      "Lingdong Kong",
      "Junwei Liang",
      "Ziwei Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01755v1",
    "abstract": "Visual grounding in 3D is the key for embodied agents to localize language-referred objects in open-world environments. However, existing benchmarks are limited to indoor focus, single-platform constraints, and small scale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark featuring RGB and LiDAR data from vehicle, drone, and quadruped platforms. We provide over 128,000 objects and 22,000 validated referring expressions across diverse outdoor scenes -- 10x larger than existing datasets. We develop a scalable annotation pipeline combining vision-language model prompting with human verification to ensure high-quality spatial grounding. To support cross-platform learning, we propose platform-aware normalization and cross-modal alignment techniques, and establish benchmark protocols for in-domain and cross-platform evaluations. Our findings reveal significant performance gaps, highlighting the challenges and opportunities of generalizable 3D grounding. The 3EED dataset and benchmark toolkit are released to advance future research in language-driven 3D embodied perception.",
    "fetched_at": "2025-11-09T02:21:22.889297Z"
  },
  {
    "id": "2511.01805v2",
    "title": "Accumulating Context Changes the Beliefs of Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiayi Geng",
      "Howard Chen",
      "Ryan Liu",
      "Manoel Horta Ribeiro",
      "Robb Willer",
      "Graham Neubig",
      "Thomas L. Griffiths"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01805v2",
    "abstract": "Language model (LM) assistants are increasingly used in applications such as brainstorming and research. Improvements in memory and context size have allowed these models to become more autonomous, which has also resulted in more text accumulation in their context windows without explicit user intervention. This comes with a latent risk: the belief profiles of models -- their understanding of the world as manifested in their responses or actions -- may silently change as context accumulates. This can lead to subtly inconsistent user experiences, or shifts in behavior that deviate from the original alignment of the models. In this paper, we explore how accumulating context by engaging in interactions and processing text -- talking and reading -- can change the beliefs of language models, as manifested in their responses and behaviors. Our results reveal that models' belief profiles are highly malleable: GPT-5 exhibits a 54.7% shift in its stated beliefs after 10 rounds of discussion about moral dilemmas and queries about safety, while Grok 4 shows a 27.2% shift on political issues after reading texts from the opposing position. We also examine models' behavioral changes by designing tasks that require tool use, where each tool selection corresponds to an implicit belief. We find that these changes align with stated belief shifts, suggesting that belief shifts will be reflected in actual behavior in agentic systems. Our analysis exposes the hidden risk of belief shift as models undergo extended sessions of talking or reading, rendering their opinions and actions unreliable.",
    "fetched_at": "2025-11-09T02:21:22.889237Z"
  },
  {
    "id": "2511.01817v1",
    "title": "SciTextures: Collecting and Connecting Visual Patterns, Models, and Code   Across Science and Art",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Sagi Eppel",
      "Alona Strugatski"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01817v1",
    "abstract": "The ability to connect visual patterns with the processes that form them represents one of the deepest forms of visual understanding. Textures of clouds and waves, the growth of cities and forests, or the formation of materials and landscapes are all examples of patterns emerging from underlying mechanisms. We present the Scitextures dataset, a large-scale collection of textures and visual patterns from all domains of science, tech, and art, along with the models and code that generate these images. Covering over 1,200 different models and 100,000 images of patterns and textures from physics, chemistry, biology, sociology, technology, mathematics, and art, this dataset offers a way to explore the connection between the visual patterns that shape our world and the mechanisms that produce them. Created by an agentic AI pipeline that autonomously collects and implements models in standardized form, we use SciTextures to evaluate the ability of leading AI models to link visual patterns to the models and code that generate them, and to identify different patterns that emerged from the same process. We also test AIs ability to infer and recreate the mechanisms behind visual patterns by providing a natural image of a real-world pattern and asking the AI to identify, model, and code the mechanism that formed the pattern, then run this code to generate a simulated image that is compared to the real image. These benchmarks show that vision-language models (VLMs) can understand and simulate the physical system beyond a visual pattern. The dataset and code are available at: https://zenodo.org/records/17485502",
    "fetched_at": "2025-11-09T02:21:22.889176Z"
  },
  {
    "id": "2511.01824v1",
    "title": "Simulating Environments with Reasoning Models for Agent Training",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuetai Li",
      "Huseyin A Inan",
      "Xiang Yue",
      "Wei-Ning Chen",
      "Lukas Wutschitz",
      "Janardhan Kulkarni",
      "Radha Poovendran",
      "Robert Sim",
      "Saravan Rajmohan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01824v1",
    "abstract": "LLM agents excel in compact environments requiring deep reasoning but remain brittle when operating in broader, more complex contexts that demand robustness across diverse tools and schemas. Building bespoke environments for training is heavy, brittle, and limits progress. In this paper, we demonstrate that LLMs can simulate realistic environment feedback without access to actual testbed data or APIs. Inspired by this capability, we propose two frameworks: Simia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets into diverse trajectories in an environment-agnostic manner, and Simia-RL, a framework that enables RL training without real environment implementations through LLM-simulated feedback. Fine-tuning open models yields consistent improvements across multiple benchmarks, surpassing GPT-4o and approaching o4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable agent training without environment engineering, replacing heavy and brittle implementations with flexible LLM-based simulation.",
    "fetched_at": "2025-11-09T02:21:22.889116Z"
  },
  {
    "id": "2511.01833v2",
    "title": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images   Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Ming Li",
      "Jike Zhong",
      "Shitian Zhao",
      "Haoquan Zhang",
      "Shaoheng Lin",
      "Yuxiang Lai",
      "Chen Wei",
      "Konstantinos Psounis",
      "Kaipeng Zhang"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.01833v2",
    "abstract": "The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \\textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning.",
    "fetched_at": "2025-11-09T02:21:22.889058Z"
  },
  {
    "id": "2511.01854v2",
    "title": "Tool-to-Agent Retrieval: Bridging Tools and Agents for Scalable LLM   Multi-Agent Systems",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Elias Lumer",
      "Faheem Nizar",
      "Anmol Gulati",
      "Pradeep Honaganahalli Basavaraju",
      "Vamse Kumar Subbiah"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.01854v2",
    "abstract": "Recent advances in LLM Multi-Agent Systems enable scalable orchestration of sub-agents, each coordinating hundreds or thousands of tools or Model Context Protocol (MCP) servers. However, existing retrieval methods typically match queries against coarse agent-level descriptions before routing, which obscures fine-grained tool functionality and often results in suboptimal agent selection. We introduce Tool-to-Agent Retrieval, a unified framework that embeds both tools and their parent agents in a shared vector space and connects them through metadata relationships. By explicitly representing tool capabilities and traversing metadata to the agent level, Tool-to-Agent Retrieval enables granular tool-level or agent-level retrieval, ensuring that agents and their underlying tools or MCP servers are equally represented without the context dilution that arises from chunking many tools together. Evaluating Tool-to-Agent Retrieval across eight embedding models, our approach achieves consistent improvements of 19.4% in Recall@5 and 17.7% in nDCG@5 over previous state-of-the-art agent retrievers on the LiveMCPBench benchmark.",
    "fetched_at": "2025-11-09T02:21:22.889000Z"
  },
  {
    "id": "2511.02071v1",
    "title": "Human-AI Co-Embodied Intelligence for Scientific Experimentation and   Manufacturing",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xinyi Lin",
      "Yuyang Zhang",
      "Yuanhang Gan",
      "Juntao Chen",
      "Hao Shen",
      "Yichun He",
      "Lijun Li",
      "Ze Yuan",
      "Shuang Wang",
      "Chaohao Wang",
      "Rui Zhang",
      "Na Li",
      "Jia Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02071v1",
    "abstract": "Scientific experiment and manufacture rely on complex, multi-step procedures that demand continuous human expertise for precise execution and decision-making. Despite advances in machine learning and automation, conventional models remain confined to virtual domains, while real-world experiment and manufacture still rely on human supervision and expertise. This gap between machine intelligence and physical execution limits reproducibility, scalability, and accessibility across scientific and manufacture workflows. Here, we introduce human-AI co-embodied intelligence, a new form of physical AI that unites human users, agentic AI, and wearable hardware into an integrated system for real-world experiment and intelligent manufacture. In this paradigm, humans provide precise execution and control, while agentic AI contributes memory, contextual reasoning, adaptive planning, and real-time feedback. The wearable interface continuously captures the experimental and manufacture processes, facilitates seamless communication between humans and AI for corrective guidance and interpretable collaboration. As a demonstration, we present Agentic-Physical Experimentation (APEX) system, coupling agentic reasoning with physical execution through mixed-reality. APEX observes and interprets human actions, aligns them with standard operating procedures, provides 3D visual guidance, and analyzes every step. Implemented in a cleanroom for flexible electronics fabrication, APEX system achieves context-aware reasoning with accuracy exceeding general multimodal large language models, corrects errors in real time, and transfers expertise to beginners. These results establish a new class of agentic-physical-human intelligence that extends agentic reasoning beyond computation into the physical domain, transforming scientific research and manufacturing into autonomous, traceable, interpretable, and scalable processes.",
    "fetched_at": "2025-11-09T02:21:22.888954Z"
  },
  {
    "id": "2511.02094v1",
    "title": "Automated Reward Design for Gran Turismo",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Michel Ma",
      "Takuma Seno",
      "Kaushik Subramanian",
      "Peter R. Wurman",
      "Peter Stone",
      "Craig Sherstan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02094v1",
    "abstract": "When designing reinforcement learning (RL) agents, a designer communicates the desired agent behavior through the definition of reward functions - numerical feedback given to the agent as reward or punishment for its actions. However, mapping desired behaviors to reward functions can be a difficult process, especially in complex environments such as autonomous racing. In this paper, we demonstrate how current foundation models can effectively search over a space of reward functions to produce desirable RL agents for the Gran Turismo 7 racing game, given only text-based instructions. Through a combination of LLM-based reward generation, VLM preference-based evaluation, and human feedback we demonstrate how our system can be used to produce racing agents competitive with GT Sophy, a champion-level RL racing agent, as well as generate novel behaviors, paving the way for practical automated reward design in real world applications.",
    "fetched_at": "2025-11-09T02:21:22.888876Z"
  },
  {
    "id": "2511.02119v1",
    "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating   Individual Behavior in Purchasing Flood Insurance",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ziheng Geng",
      "Jiachen Liu",
      "Ran Cao",
      "Lu Cheng",
      "Dan M. Frangopol",
      "Minghui Cheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02119v1",
    "abstract": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses. However, participation rates among at-risk populations in the United States remain strikingly low. This gap underscores the need to understand and model the behavioral mechanisms underlying insurance decisions. Large language models (LLMs) have recently exhibited human-like intelligence across wide-ranging tasks, offering promising tools for simulating human decision-making. This study constructs a benchmark dataset to capture insurance purchase probabilities across factors. Using this dataset, the capacity of LLMs is evaluated: while LLMs exhibit a qualitative understanding of factors, they fall short in estimating quantitative probabilities. To address this limitation, InsurAgent, an LLM-empowered agent comprising five modules including perception, retrieval, reasoning, action, and memory, is proposed. The retrieval module leverages retrieval-augmented generation (RAG) to ground decisions in empirical survey data, achieving accurate estimation of marginal and bivariate probabilities. The reasoning module leverages LLM common sense to extrapolate beyond survey data, capturing contextual information that is intractable for traditional models. The memory module supports the simulation of temporal decision evolutions, illustrated through a roller coaster life trajectory. Overall, InsurAgent provides a valuable tool for behavioral modeling and policy analysis.",
    "fetched_at": "2025-11-09T02:21:22.888829Z"
  },
  {
    "id": "2511.02048v1",
    "title": "Finding Probably Approximate Optimal Solutions by Training to Estimate   the Optimal Values of Subproblems",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nimrod Megiddo",
      "Segev Wasserkrug",
      "Orit Davidovich",
      "Shimrit Shtern"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02048v1",
    "abstract": "The paper is about developing a solver for maximizing a real-valued function of binary variables. The solver relies on an algorithm that estimates the optimal objective-function value of instances from the underlying distribution of objectives and their respective sub-instances. The training of the estimator is based on an inequality that facilitates the use of the expected total deviation from optimality conditions as a loss function rather than the objective-function itself. Thus, it does not calculate values of policies, nor does it rely on solved instances.",
    "fetched_at": "2025-11-06T02:19:07.220839Z"
  },
  {
    "id": "2511.02052v1",
    "title": "Solving cold start in news recommendations: a RippleNet-based system for   large scale media outlet",
    "date": "2025-11-03",
    "tags": [
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Karol Radziszewski",
      "Michał Szpunar",
      "Piotr Ociepka",
      "Mateusz Buczyński"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02052v1",
    "abstract": "We present a scalable recommender system implementation based on RippleNet, tailored for the media domain with a production deployment in Onet.pl, one of Poland's largest online media platforms. Our solution addresses the cold-start problem for newly published content by integrating content-based item embeddings into the knowledge propagation mechanism of RippleNet, enabling effective scoring of previously unseen items. The system architecture leverages Amazon SageMaker for distributed training and inference, and Apache Airflow for orchestrating data pipelines and model retraining workflows. To ensure high-quality training data, we constructed a comprehensive golden dataset consisting of user and item features and a separate interaction table, all enabling flexible extensions and integration of new signals.",
    "fetched_at": "2025-11-06T02:19:07.220798Z"
  },
  {
    "id": "2511.02053v1",
    "title": "Data-driven Learning of Interaction Laws in Multispecies Particle   Systems with Gaussian Processes: Convergence Theory and Applications",
    "date": "2025-11-03",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Jinchao Feng",
      "Charles Kulick",
      "Sui Tang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02053v1",
    "abstract": "We develop a Gaussian process framework for learning interaction kernels in multi-species interacting particle systems from trajectory data. Such systems provide a canonical setting for multiscale modeling, where simple microscopic interaction rules generate complex macroscopic behaviors. While our earlier work established a Gaussian process approach and convergence theory for single-species systems, and later extended to second-order models with alignment and energy-type interactions, the multi-species setting introduces new challenges: heterogeneous populations interact both within and across species, the number of unknown kernels grows, and asymmetric interactions such as predator-prey dynamics must be accommodated. We formulate the learning problem in a nonparametric Bayesian setting and establish rigorous statistical guarantees. Our analysis shows recoverability of the interaction kernels, provides quantitative error bounds, and proves statistical optimality of posterior estimators, thereby unifying and generalizing previous single-species theory. Numerical experiments confirm the theoretical predictions and demonstrate the effectiveness of the proposed approach, highlighting its advantages over existing kernel-based methods. This work contributes a complete statistical framework for data-driven inference of interaction laws in multi-species systems, advancing the broader multiscale modeling program of connecting microscopic particle dynamics with emergent macroscopic behavior.",
    "fetched_at": "2025-11-06T02:19:07.220752Z"
  },
  {
    "id": "2511.02062v1",
    "title": "Vortex: Hosting ML Inference and Knowledge Retrieval Services With Tight   Latency and Throughput Requirements",
    "date": "2025-11-03",
    "tags": [
      "cs.DB",
      "DB",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuting Yang",
      "Tiancheng Yuan",
      "Jamal Hashim",
      "Thiago Garrett",
      "Jeffrey Qian",
      "Ann Zhang",
      "Yifan Wang",
      "Weijia Song",
      "Ken Birman"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02062v1",
    "abstract": "There is growing interest in deploying ML inference and knowledge retrieval as services that could support both interactive queries by end users and more demanding request flows that arise from AIs integrated into a end-user applications and deployed as agents. Our central premise is that these latter cases will bring service level latency objectives (SLOs). Existing ML serving platforms use batching to optimize for high throughput, exposing them to unpredictable tail latencies. Vortex enables an SLO-first approach. For identical tasks, Vortex's pipelines achieve significantly lower and more stable latencies than TorchServe and Ray Serve over a wide range of workloads, often enabling a given SLO target at more than twice the request rate. When RDMA is available, the Vortex advantage is even more significant.",
    "fetched_at": "2025-11-06T02:19:07.220700Z"
  },
  {
    "id": "2511.02069v1",
    "title": "Complete asymptotic type-token relationship for growing complex systems   with inverse power-law count rankings",
    "date": "2025-11-03",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Pablo Rosillo-Rodes",
      "Laurent Hébert-Dufresne",
      "Peter Sheridan Dodds"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02069v1",
    "abstract": "The growth dynamics of complex systems often exhibit statistical regularities involving power-law relationships. For real finite complex systems formed by countable tokens (animals, words) as instances of distinct types (species, dictionary entries), an inverse power-law scaling $S \\sim r^{-\\alpha}$ between type count $S$ and type rank $r$, widely known as Zipf's law, is widely observed to varying degrees of fidelity. A secondary, summary relationship is Heaps' law, which states that the number of types scales sublinearly with the total number of observed tokens present in a growing system. Here, we propose an idealized model of a growing system that (1) deterministically produces arbitrary inverse power-law count rankings for types, and (2) allows us to determine the exact asymptotics of the type-token relationship. Our argument improves upon and remedies earlier work. We obtain a unified asymptotic expression for all values of $\\alpha$, which corrects the special cases of $\\alpha = 1$ and $\\alpha \\gg 1$. Our approach relies solely on the form of count rankings, avoids unnecessary approximations, and does not involve any stochastic mechanisms or sampling processes. We thereby demonstrate that a general type-token relationship arises solely as a consequence of Zipf's law.",
    "fetched_at": "2025-11-06T02:19:07.220635Z"
  },
  {
    "id": "2511.02077v1",
    "title": "Beyond Static Cutoffs: One-Shot Dynamic Thresholding for Diffusion   Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jucheng Shen",
      "Yeonju Ro"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02077v1",
    "abstract": "Masked diffusion language models (MDLMs) are becoming competitive with their autoregressive counterparts but typically decode with fixed steps and sequential unmasking. To accelerate decoding, recent work such as Fast-dLLM enables parallel decoding via a static global confidence threshold, yet we observe strong block- and step-wise confidence fluctuations and, within a dataset, near-identical confidence trajectories across inputs as measured by cosine similarity. Motivated by these observations, we introduce One-Shot Dynamic Thresholding (OSDT), which calibrates thresholds on a single sequence and applies them to subsequent inputs with negligible overhead. On GPQA, GSM8K, and HumanEval, OSDT attains superior accuracy-throughput trade-offs (+24% tokens/s on GSM8K at the best accuracy, +45% on GPQA with comparable accuracy, and +50% on HumanEval with a modest accuracy gap). Beyond these results, our findings suggest broader opportunities to leverage reusable task-level confidence signatures for more general-purpose algorithmic and systems innovations in diffusion decoding.",
    "fetched_at": "2025-11-06T02:19:07.220481Z"
  },
  {
    "id": "2511.02083v1",
    "title": "Watermarking Discrete Diffusion Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Avi Bagchi",
      "Akhil Bhimaraju",
      "Moulik Choraria",
      "Daniel Alabi",
      "Lav R. Varshney"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02083v1",
    "abstract": "Watermarking has emerged as a promising technique to track AI-generated content and differentiate it from authentic human creations. While prior work extensively studies watermarking for autoregressive large language models (LLMs) and image diffusion models, none address discrete diffusion language models, which are becoming popular due to their high inference throughput. In this paper, we introduce the first watermarking method for discrete diffusion models by applying the distribution-preserving Gumbel-max trick at every diffusion step and seeding the randomness with the sequence index to enable reliable detection. We experimentally demonstrate that our scheme is reliably detectable on state-of-the-art diffusion language models and analytically prove that it is distortion-free with an exponentially decaying probability of false detection in the token sequence length.",
    "fetched_at": "2025-11-06T02:19:07.220442Z"
  },
  {
    "id": "2511.02087v1",
    "title": "Energy Loss Functions for Physical Systems",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Sékou-Oumar Kaba",
      "Kusha Sareen",
      "Daniel Levy",
      "Siamak Ravanbakhsh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02087v1",
    "abstract": "Effectively leveraging prior knowledge of a system's physics is crucial for applications of machine learning to scientific domains. Previous approaches mostly focused on incorporating physical insights at the architectural level. In this paper, we propose a framework to leverage physical information directly into the loss function for prediction and generative modeling tasks on systems like molecules and spins. We derive energy loss functions assuming that each data sample is in thermal equilibrium with respect to an approximate energy landscape. By using the reverse KL divergence with a Boltzmann distribution around the data, we obtain the loss as an energy difference between the data and the model predictions. This perspective also recasts traditional objectives like MSE as energy-based, but with a physically meaningless energy. In contrast, our formulation yields physically grounded loss functions with gradients that better align with valid configurations, while being architecture-agnostic and computationally efficient. The energy loss functions also inherently respect physical symmetries. We demonstrate our approach on molecular generation and spin ground-state prediction and report significant improvements over baselines.",
    "fetched_at": "2025-11-06T02:19:07.220394Z"
  },
  {
    "id": "2511.02089v1",
    "title": "LLM Probing with Contrastive Eigenproblems: Improving Understanding and   Applicability of CCS",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Stefan F. Schouten",
      "Peter Bloem"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02089v1",
    "abstract": "Contrast-Consistent Search (CCS) is an unsupervised probing method able to test whether large language models represent binary features, such as sentence truth, in their internal activations. While CCS has shown promise, its two-term objective has been only partially understood. In this work, we revisit CCS with the aim of clarifying its mechanisms and extending its applicability. We argue that what should be optimized for, is relative contrast consistency. Building on this insight, we reformulate CCS as an eigenproblem, yielding closed-form solutions with interpretable eigenvalues and natural extensions to multiple variables. We evaluate these approaches across a range of datasets, finding that they recover similar performance to CCS, while avoiding problems around sensitivity to random initialization. Our results suggest that relativizing contrast consistency not only improves our understanding of CCS but also opens pathways for broader probing and mechanistic interpretability methods.",
    "fetched_at": "2025-11-06T02:19:07.220346Z"
  },
  {
    "id": "2511.02091v1",
    "title": "Natural Building Blocks for Structured World Models: Theory, Evidence,   and Scaling",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lancelot Da Costa",
      "Sanjeev Namjoshi",
      "Mohammed Abbas Ansari",
      "Bernhard Schölkopf"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02091v1",
    "abstract": "The field of world modeling is fragmented, with researchers developing bespoke architectures that rarely build upon each other. We propose a framework that specifies the natural building blocks for structured world models based on the fundamental stochastic processes that any world model must capture: discrete processes (logic, symbols) and continuous processes (physics, dynamics); the world model is then defined by the hierarchical composition of these building blocks. We examine Hidden Markov Models (HMMs) and switching linear dynamical systems (sLDS) as natural building blocks for discrete and continuous modeling--which become partially-observable Markov decision processes (POMDPs) and controlled sLDS when augmented with actions. This modular approach supports both passive modeling (generation, forecasting) and active control (planning, decision-making) within the same architecture. We avoid the combinatorial explosion of traditional structure learning by largely fixing the causal architecture and searching over only four depth parameters. We review practical expressiveness through multimodal generative modeling (passive) and planning from pixels (active), with performance competitive to neural approaches while maintaining interpretability. The core outstanding challenge is scalable joint structure-parameter learning; current methods finesse this by cleverly growing structure and parameters incrementally, but are limited in their scalability. If solved, these natural building blocks could provide foundational infrastructure for world modeling, analogous to how standardized layers enabled progress in deep learning.",
    "fetched_at": "2025-11-06T02:19:07.220307Z"
  },
  {
    "id": "2511.02092v1",
    "title": "Uncertainty Guided Online Ensemble for Non-stationary Data Streams in   Fusion Science",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "physics.plasm-ph",
      "plasm-ph"
    ],
    "authors": [
      "Kishansingh Rajput",
      "Malachi Schram",
      "Brian Sammuli",
      "Sen Lin"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.02092v1",
    "abstract": "Machine Learning (ML) is poised to play a pivotal role in the development and operation of next-generation fusion devices. Fusion data shows non-stationary behavior with distribution drifts, resulted by both experimental evolution and machine wear-and-tear. ML models assume stationary distribution and fail to maintain performance when encountered with such non-stationary data streams. Online learning techniques have been leveraged in other domains, however it has been largely unexplored for fusion applications. In this paper, we present an application of online learning to continuously adapt to drifting data stream for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion facility. The results demonstrate that online learning is critical to maintain ML model performance and reduces error by 80% compared to a static model. Moreover, traditional online learning can suffer from short-term performance degradation as ground truth is not available before making the predictions. As such, we propose an uncertainty guided online ensemble method to further improve the performance. The Deep Gaussian Process Approximation (DGPA) technique is leveraged for calibrated uncertainty estimation and the uncertainty values are then used to guide a meta-algorithm that produces predictions based on an ensemble of learners trained on different horizon of historical data. The DGPA also provides uncertainty estimation along with the predictions for decision makers. The online ensemble and the proposed uncertainty guided online ensemble reduces predictions error by about 6%, and 10% respectively over standard single model based online learning.",
    "fetched_at": "2025-11-06T02:19:07.220255Z"
  },
  {
    "id": "2511.02100v1",
    "title": "Geometric Data Valuation via Leverage Scores",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NA",
      "NA",
      "math.NA",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Rodrigo Mendoza-Smith"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02100v1",
    "abstract": "Shapley data valuation provides a principled, axiomatic framework for assigning importance to individual datapoints, and has gained traction in dataset curation, pruning, and pricing. However, it is a combinatorial measure that requires evaluating marginal utility across all subsets of the data, making it computationally infeasible at scale. We propose a geometric alternative based on statistical leverage scores, which quantify each datapoint's structural influence in the representation space by measuring how much it extends the span of the dataset and contributes to the effective dimensionality of the training problem. We show that our scores satisfy the dummy, efficiency, and symmetry axioms of Shapley valuation and that extending them to \\emph{ridge leverage scores} yields strictly positive marginal gains that connect naturally to classical A- and D-optimal design criteria. We further show that training on a leverage-sampled subset produces a model whose parameters and predictive risk are within $O(\\varepsilon)$ of the full-data optimum, thereby providing a rigorous link between data valuation and downstream decision quality. Finally, we conduct an active learning experiment in which we empirically demonstrate that ridge-leverage sampling outperforms standard baselines without requiring access gradients or backward passes.",
    "fetched_at": "2025-11-06T02:19:07.220150Z"
  },
  {
    "id": "2511.02101v2",
    "title": "Measuring the Intrinsic Dimension of Earth Representations",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Arjun Rao",
      "Marc Rußwurm",
      "Konstantin Klemmer",
      "Esther Rolf"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02101v2",
    "abstract": "Within the context of representation learning for Earth observation, geographic Implicit Neural Representations (INRs) embed low-dimensional location inputs (longitude, latitude) into high-dimensional embeddings, through models trained on geo-referenced satellite, image or text data. Despite the common aim of geographic INRs to distill Earth's data into compact, learning-friendly representations, we lack an understanding of how much information is contained in these Earth representations, and where that information is concentrated. The intrinsic dimension of a dataset measures the number of degrees of freedom required to capture its local variability, regardless of the ambient high-dimensional space in which it is embedded. This work provides the first study of the intrinsic dimensionality of geographic INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to changing spatial resolution and input modalities during INR pre-training. Furthermore, we show that the intrinsic dimension of a geographic INR correlates with downstream task performance and can capture spatial artifacts, facilitating model evaluation and diagnostics. More broadly, our work offers an architecture-agnostic, label-free metric of information content that can enable unsupervised evaluation, model selection, and pre-training design across INRs.",
    "fetched_at": "2025-11-06T02:19:07.220108Z"
  },
  {
    "id": "2511.02108v1",
    "title": "Metamorphic Testing of Large Language Models for Natural Language   Processing",
    "date": "2025-11-03",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Steven Cho",
      "Stefano Ruberto",
      "Valerio Terragni"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02108v1",
    "abstract": "Using large language models (LLMs) to perform natural language processing (NLP) tasks has become increasingly pervasive in recent times. The versatile nature of LLMs makes them applicable to a wide range of such tasks. While the performance of recent LLMs is generally outstanding, several studies have shown that they can often produce incorrect results. Automatically identifying these faulty behaviors is extremely useful for improving the effectiveness of LLMs. One obstacle to this is the limited availability of labeled datasets, which necessitates an oracle to determine the correctness of LLM behaviors. Metamorphic testing (MT) is a popular testing approach that alleviates this oracle problem. At the core of MT are metamorphic relations (MRs), which define relationships between the outputs of related inputs. MT can expose faulty behaviors without the need for explicit oracles (e.g., labeled datasets). This paper presents the most comprehensive study of MT for LLMs to date. We conducted a literature review and collected 191 MRs for NLP tasks. We implemented a representative subset (36 MRs) to conduct a series of experiments with three popular LLMs, running approximately 560,000 metamorphic tests. The results shed light on the capabilities and opportunities of MT for LLMs, as well as its limitations.",
    "fetched_at": "2025-11-06T02:19:07.220058Z"
  },
  {
    "id": "2511.02109v1",
    "title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep values or   Shallow Preferences",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Joshua Ashkinaze",
      "Hua Shen",
      "Sai Avula",
      "Eric Gilbert",
      "Ceren Budak"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02109v1",
    "abstract": "We introduce the Deep Value Benchmark (DVB), an evaluation framework that directly tests whether large language models (LLMs) learn fundamental human values or merely surface-level preferences. This distinction is critical for AI alignment: Systems that capture deeper values are likely to generalize human intentions robustly, while those that capture only superficial patterns in preference data risk producing misaligned behavior. The DVB uses a novel experimental design with controlled confounding between deep values (e.g., moral principles) and shallow features (e.g., superficial attributes). In the training phase, we expose LLMs to human preference data with deliberately correlated deep and shallow features -- for instance, where a user consistently prefers (non-maleficence, formal language) options over (justice, informal language) alternatives. The testing phase then breaks these correlations, presenting choices between (justice, formal language) and (non-maleficence, informal language) options. This design allows us to precisely measure a model's Deep Value Generalization Rate (DVGR) -- the probability of generalizing based on the underlying value rather than the shallow feature. Across 9 different models, the average DVGR is just 0.30. All models generalize deep values less than chance. Larger models have a (slightly) lower DVGR than smaller models. We are releasing our dataset, which was subject to three separate human validation experiments. DVB provides an interpretable measure of a core feature of alignment.",
    "fetched_at": "2025-11-06T02:19:07.220011Z"
  },
  {
    "id": "2511.02122v1",
    "title": "Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization   Landscape",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xinyuan Song",
      "Jiaye Teng",
      "Ziye Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02122v1",
    "abstract": "In this paper we study how the choice of loss functions of non-convex optimization problems affects their robustness and optimization landscape, through the study of noisy matrix sensing. In traditional regression tasks, mean squared error (MSE) loss is a common choice, but it can be unreliable for non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust loss based on nonparametric regression, which uses a kernel-based estimate of the residual density and maximizes the estimated log-likelihood. This robust formulation coincides with the MSE loss under Gaussian errors but remains stable under more general settings. We further examine how this robust loss reshapes the optimization landscape by analyzing the upper-bound of restricted isometry property (RIP) constants for spurious local minima to disappear. Through theoretical and empirical analysis, we show that this new loss excels at handling large noise and remains robust across diverse noise distributions. This work offers initial insights into enhancing the robustness of machine learning tasks through simply changing the loss, guided by an intuitive and broadly applicable analytical framework.",
    "fetched_at": "2025-11-06T02:19:07.219896Z"
  },
  {
    "id": "2511.02123v1",
    "title": "Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Xuheng Li",
      "Quanquan Gu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02123v1",
    "abstract": "Variance-dependent regret bounds have received increasing attention in recent studies on contextual bandits. However, most of these studies are focused on upper confidence bound (UCB)-based bandit algorithms, while sampling based bandit algorithms such as Thompson sampling are still understudied. The only exception is the LinVDTS algorithm (Xu et al., 2023), which is limited to linear reward function and its regret bound is not optimal with respect to the model dimension. In this paper, we present FGTSVA, a variance-aware Thompson Sampling algorithm for contextual bandits with general reward function with optimal regret bound. At the core of our analysis is an extension of the decoupling coefficient, a technique commonly used in the analysis of Feel-good Thompson sampling (FGTS) that reflects the complexity of the model space. With the new decoupling coefficient denoted by $\\mathrm{dc}$, FGTS-VA achieves the regret of $\\tilde{O}(\\sqrt{\\mathrm{dc}\\cdot\\log|\\mathcal{F}|\\sum_{t=1}^T\\sigma_t^2}+\\mathrm{dc})$, where $|\\mathcal{F}|$ is the size of the model space, $T$ is the total number of rounds, and $\\sigma_t^2$ is the subgaussian norm of the noise (e.g., variance when the noise is Gaussian) at round $t$. In the setting of contextual linear bandits, the regret bound of FGTSVA matches that of UCB-based algorithms using weighted linear regression (Zhou and Gu, 2022).",
    "fetched_at": "2025-11-06T02:19:07.219853Z"
  },
  {
    "id": "2511.02130v1",
    "title": "Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought   Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Renos Zabounidis",
      "Aditya Golatkar",
      "Michael Kleinman",
      "Alessandro Achille",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02130v1",
    "abstract": "We propose Re-FORC, an adaptive reward prediction method that, given a context, enables prediction of the expected future rewards as a function of the number of future thinking tokens. Re-FORC trains a lightweight adapter on reasoning models, demonstrating improved prediction with longer reasoning and larger models. Re-FORC enables: 1) early stopping of unpromising reasoning chains, reducing compute by 26% while maintaining accuracy, 2) optimized model and thinking length selection that achieves 4% higher accuracy at equal compute and 55% less compute at equal accuracy compared to the largest model, 3) adaptive test-time scaling, which increases accuracy by 11% in high compute regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with length control via cost-per-token thresholds while estimating computation time upfront.",
    "fetched_at": "2025-11-06T02:19:07.219812Z"
  },
  {
    "id": "2511.02132v1",
    "title": "Optimizing Attention on GPUs by Exploiting GPU Architectural NUMA   Effects",
    "date": "2025-11-03",
    "tags": [
      "cs.AR",
      "AR",
      "cs.DC",
      "DC",
      "cs.LG",
      "LG",
      "cs.PF",
      "PF"
    ],
    "authors": [
      "Mansi Choudhary",
      "Karthik Sangaiah",
      "Sonali Singh",
      "Muhammad Osama",
      "Lisa Wu Wills",
      "Ganesh Dasika"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02132v1",
    "abstract": "The rise of disaggregated AI GPUs has exposed a critical bottleneck in large-scale attention workloads: non-uniform memory access (NUMA). As multi-chiplet designs become the norm for scaling compute capabilities, memory latency and bandwidth vary sharply across compute regions, undermining the performance of traditional GPU kernel scheduling strategies that assume uniform memory access. We identify how these NUMA effects distort locality in multi-head attention (MHA) and present Swizzled Head-first Mapping, a spatially-aware scheduling strategy that aligns attention heads with GPU NUMA domains to exploit intra-chiplet cache reuse. On AMD's MI300X architecture, our method achieves up to 50% higher performance over state-of-the-art attention algorithms using conventional scheduling techniques and sustains consistently high L2 cache hit rates of 80-97%. These results demonstrate that NUMA-aware scheduling is now fundamental to achieving full efficiency on next-generation disaggregated GPUs, offering a path forward for scalable AI training and inference.",
    "fetched_at": "2025-11-06T02:19:07.219760Z"
  },
  {
    "id": "2511.02135v1",
    "title": "Rethinking LLM Human Simulation: When a Graph is What You Need",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Joseph Suh",
      "Suhong Moon",
      "Serina Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02135v1",
    "abstract": "Large language models (LLMs) are increasingly used to simulate humans, with applications ranging from survey prediction to decision-making. However, are LLMs strictly necessary, or can smaller, domain-grounded models suffice? We identify a large class of simulation problems in which individuals make choices among discrete options, where a graph neural network (GNN) can match or surpass strong LLM baselines despite being three orders of magnitude smaller. We introduce Graph-basEd Models for human Simulation (GEMS), which casts discrete choice simulation tasks as a link prediction problem on graphs, leveraging relational knowledge while incorporating language representations only when needed. Evaluations across three key settings on three simulation datasets show that GEMS achieves comparable or better accuracy than LLMs, with far greater efficiency, interpretability, and transparency, highlighting the promise of graph-based modeling as a lightweight alternative to LLMs for human simulation. Our code is available at https://github.com/schang-lab/gems.",
    "fetched_at": "2025-11-06T02:19:07.219706Z"
  },
  {
    "id": "2511.01833v1",
    "title": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images   Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Ming Li",
      "Jike Zhong",
      "Shitian Zhao",
      "Haoquan Zhang",
      "Shaoheng Lin",
      "Yuxiang Lai",
      "Wei Chen",
      "Konstantinos Psounis",
      "Kaipeng Zhang"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.01833v1",
    "abstract": "The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \\textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning.",
    "fetched_at": "2025-11-06T02:19:05.287838Z"
  },
  {
    "id": "2511.00767v1",
    "title": "Power Control Based on Multi-Agent Deep Q Network for D2D Communication",
    "date": "2025-11-02",
    "tags": [
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Shi Gengtian",
      "Takashi Koshimizu",
      "Megumi Saito",
      "Pan Zhenni",
      "Liu Jiang",
      "Shigeru Shimamoto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00767v1",
    "abstract": "In device-to-device (D2D) communication under a cell with resource sharing mode the spectrum resource utilization of the system will be improved. However, if the interference generated by the D2D user is not controlled, the performance of the entire system and the quality of service (QOS) of the cellular user may be degraded. Power control is important because it helps to reduce interference in the system. In this paper, we propose a reinforcement learning algorithm for adaptive power control that helps reduce interference to increase system throughput. Simulation results show the proposed algorithm has better performance than traditional algorithm in LTE (Long Term Evolution).",
    "fetched_at": "2025-11-09T02:21:24.640229Z"
  },
  {
    "id": "2511.00814v1",
    "title": "Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic   Motion Planning",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "93C41, 93E11, 37M10",
      "I.2.9; I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Stella Kombo",
      "Masih Haseli",
      "Skylar Wei",
      "Joel W. Burdick"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00814v1",
    "abstract": "Autonomous systems often must predict the motions of nearby agents from partial and noisy data. This paper asks and answers the question: \"can we learn, in real-time, a nonlinear predictive model of another agent's motions?\" Our online framework denoises and forecasts such dynamics using a modified sliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy measurements are embedded into a Hankel matrix, while an associated Page matrix enables singular-value hard thresholding (SVHT) to estimate the effective rank. A Cadzow projection enforces structured low-rank consistency, yielding a denoised trajectory and local noise variance estimates. From this representation, a time-varying Hankel-DMD lifted linear predictor is constructed for multi-step forecasts. The residual analysis provides variance-tracking signals that can support downstream estimators and risk-aware planning. We validate the approach in simulation under Gaussian and heavy-tailed noise, and experimentally on a dynamic crane testbed. Results show that the method achieves stable variance-aware denoising and short-horizon prediction suitable for integration into real-time control frameworks.",
    "fetched_at": "2025-11-09T02:21:24.640053Z"
  },
  {
    "id": "2511.00880v1",
    "title": "KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization",
    "date": "2025-11-02",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T07, 90C15, 93E35"
    ],
    "authors": [
      "Joonyoung Lim",
      "Younghwan Yoo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00880v1",
    "abstract": "We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm that combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based second-order policy optimization with safety-aware gradient manipulation. KFCPO leverages K-FAC to perform efficient and stable natural gradient updates by approximating the Fisher Information Matrix (FIM) in a layerwise, closed form manner, avoiding iterative approximation overheads. To address the tradeoff between reward maximization and constraint satisfaction, we introduce a margin aware gradient manipulation mechanism that adaptively adjusts the influence of reward and cost gradients based on the agent's proximity to safety boundaries. This method blends gradients using a direction sensitive projection, eliminating harmful interference and avoiding abrupt changes caused by fixed hard thresholds. Additionally, a minibatch level KL rollback strategy is adopted to ensure trust region compliance and to prevent destabilizing policy shifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves 10.3% to 50.2% higher average return across environments compared to the best baseline that respected the safety constraint, demonstrating superior balance of safety and performance.",
    "fetched_at": "2025-11-09T02:21:24.639904Z"
  },
  {
    "id": "2511.01008v1",
    "title": "MARS-SQL: A multi-agent reinforcement learning framework for Text-to-SQL",
    "date": "2025-11-02",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Haolin Yang",
      "Jipeng Zhang",
      "Zhitao He",
      "Yi R. Fung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01008v1",
    "abstract": "Translating natural language to SQL remains difficult for complex queries. Such queries often need environmental interaction and self-correction. To address this, we introduce MARS-SQL, a novel multi-agent framework that combines principled task decomposition and interactive reinforcement learning (RL). Our system comprises three specialized agents: a Grounding Agent for schema linking, a Generation Agent for query generation, and a Validation Agent for final selection. The core of our framework is the Generation agent, which is trained via a multi-turn RL policy. Adopting a ReAct-style Think-Act-Observe loop, the agent iteratively generates thoughts, executes SQL actions against a live database, and revises its strategy based on execution feedback, enabling dynamic, stateful reasoning and self-correction. At inference time, we generate multiple interaction trajectories to explore diverse reasoning paths. The Validation agent, then selects the optimal trajectory by modeling verification as a next-token prediction task and choosing the solution with the highest generation probability. This structured workflow pipelines specialized agents. It combines interactive RL for generation with generative modeling for verification. The approach proves highly effective for robust and accurate SQL generation. Experiments show that MARS-SQL achieves state-of-the-art Execution Accuracy of 77.84% on the BIRD dev set and 89.75% on the Spider test set. Our code is available at https://github.com/YangHaolin0526/MARS-SQL.",
    "fetched_at": "2025-11-09T02:21:24.639737Z"
  },
  {
    "id": "2511.01078v1",
    "title": "Predictive Auxiliary Learning for Belief-based Multi-Agent Systems",
    "date": "2025-11-02",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Qinwei Huang",
      "Stefan Wang",
      "Simon Khan",
      "Garrett Katz",
      "Qinru Qiu"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2511.01078v1",
    "abstract": "The performance of multi-agent reinforcement learning (MARL) in partially observable environments depends on effectively aggregating information from observations, communications, and reward signals. While most existing multi-agent systems primarily rely on rewards as the only feedback for policy training, our research shows that introducing auxiliary predictive tasks can significantly enhance learning efficiency and stability. We propose Belief-based Predictive Auxiliary Learning (BEPAL), a framework that incorporates auxiliary training objectives to support policy optimization. BEPAL follows the centralized training with decentralized execution paradigm. Each agent learns a belief model that predicts unobservable state information, such as other agents' rewards or motion directions, alongside its policy model. By enriching hidden state representations with information that does not directly contribute to immediate reward maximization, this auxiliary learning process stabilizes MARL training and improves overall performance. We evaluate BEPAL in the predator-prey environment and Google Research Football, where it achieves an average improvement of about 16 percent in performance metrics and demonstrates more stable convergence compared to baseline methods.",
    "fetched_at": "2025-11-09T02:21:24.639645Z"
  },
  {
    "id": "2511.01083v1",
    "title": "Deployable Vision-driven UAV River Navigation via Human-in-the-loop   Preference Alignment",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Zihan Wang",
      "Jianwen Li",
      "Li-Fan Wu",
      "Nina Mahmoudian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01083v1",
    "abstract": "Rivers are critical corridors for environmental monitoring and disaster response, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven policies can provide fast, low-cost coverage. However, deployment exposes simulation-trained policies with distribution shift and safety risks and requires efficient adaptation from limited human interventions. We study human-in-the-loop (HITL) learning with a conservative overseer who vetoes unsafe or inefficient actions and provides statewise preferences by comparing the agent's proposal with a corrective override. We introduce Statewise Hybrid Preference Alignment for Robotics (SPAR-H), which fuses direct preference optimization on policy logits with a reward-based pathway that trains an immediate-reward estimator from the same preferences and updates the policy using a trust-region surrogate. With five HITL rollouts collected from a fixed novice policy, SPAR-H achieves the highest final episodic reward and the lowest variance across initial conditions among tested methods. The learned reward model aligns with human-preferred actions and elevates nearby non-intervened choices, supporting stable propagation of improvements. We benchmark SPAR-H against imitation learning (IL), direct preference variants, and evaluative reinforcement learning (RL) in the HITL setting, and demonstrate real-world feasibility of continual preference alignment for UAV river following. Overall, dual statewise preferences empirically provide a practical route to data-efficient online adaptation in riverine navigation.",
    "fetched_at": "2025-11-09T02:21:24.639598Z"
  },
  {
    "id": "2511.01093v1",
    "title": "Continual Learning, Not Training: Online Adaptation For Agents",
    "date": "2025-11-02",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "F.2.2; I.2.7",
      "7"
    ],
    "authors": [
      "Aman Jaglan",
      "Jarrod Barnes"
    ],
    "institution": "Microsoft, MIT",
    "link": "http://arxiv.org/pdf/2511.01093v1",
    "abstract": "Continual Learning (CL) methods have traditionally focused on mitigating catastrophic forgetting through gradient-based retraining, an approach ill-suited for deployed agents that must adapt in real time. We introduce our Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that decouples reasoning (Teacher) from execution (Student) and incorporates a persistent learning memory that stores distilled guidance from experience. This informs the orchestration layer, enabling the system to dynamically adjust its operational strategies, such as supervision level or initial plan selection, at inference time. In doing so, ATLAS achieves gradient-free continual learning, shifting the locus of adaptation from model parameters to system-level orchestration. We formulate this as a system-centric paradigm for continual learning, where the objective is adaptive efficiency: maximizing task success while minimizing computational cost through inference-time orchestration rather than parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source benchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1% success with GPT-5-mini as its Student, outperforming the larger GPT-5 (High) by 13% while reducing cost by 86%. Cross-incident validation demonstrates generalization: frozen pamphlets from Incident #5 improve accuracy from 28% to 41% with zero retraining, while shifting output composition from verbose exploration to structured reasoning. Together, these findings establish gradient-free continual learning as a viable path toward adaptive, deployable AI systems and provide causally annotated traces valuable for training explicit world models.",
    "fetched_at": "2025-11-09T02:21:24.639549Z"
  },
  {
    "id": "2511.01107v1",
    "title": "SLAP: Shortcut Learning for Abstract Planning",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Y. Isabel Liu",
      "Bowen Li",
      "Benjamin Eysenbach",
      "Tom Silver"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01107v1",
    "abstract": "Long-horizon decision-making with sparse rewards and continuous states and actions remains a fundamental challenge in AI and robotics. Task and motion planning (TAMP) is a model-based framework that addresses this challenge by planning hierarchically with abstract actions (options). These options are manually defined, limiting the agent to behaviors that we as human engineers know how to program (pick, place, move). In this work, we propose Shortcut Learning for Abstract Planning (SLAP), a method that leverages existing TAMP options to automatically discover new ones. Our key idea is to use model-free reinforcement learning (RL) to learn shortcuts in the abstract planning graph induced by the existing options in TAMP. Without any additional assumptions or inputs, shortcut learning leads to shorter solutions than pure planning, and higher task success rates than flat and hierarchical RL. Qualitatively, SLAP discovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that differ significantly from the manually-defined ones. In experiments in four simulated robotic environments, we show that SLAP solves and generalizes to a wide range of tasks, reducing overall plan lengths by over 50% and consistently outperforming planning and RL baselines.",
    "fetched_at": "2025-11-09T02:21:24.639505Z"
  },
  {
    "id": "2511.00751v1",
    "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Chiyan Loo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00751v1",
    "abstract": "This study examines the trade-offs of increasing sampled reasoning paths in self-consistency for modern large language models (LLMs). Earlier research with older models showed that combining multiple reasoning chains improves results before reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we revisit those claims under current model conditions. Each configuration pooled outputs from varying sampled reasoning paths and compared them to a single chain-of-thought (CoT) baseline. Larger models exhibited a more stable and consistent improvement curve. The results confirm that performance gains taper off after moderate sampling, aligning with past findings. This plateau suggests diminishing returns driven by overlap among reasoning paths. Self-consistency remains useful, but high-sample configurations offer little benefit relative to their computational cost.",
    "fetched_at": "2025-11-09T02:21:22.890675Z"
  },
  {
    "id": "2511.00782v1",
    "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer   and LLM Pipelines on Structured EHR",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jifan Gao",
      "Michael Rosenthal",
      "Brian Wolpin",
      "Simona Cristea"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00782v1",
    "abstract": "Structured electronic health records (EHR) are essential for clinical prediction. While count-based learners continue to perform strongly on such data, no benchmarking has directly compared them against more recent mixture-of-agents LLM pipelines, which have been reported to outperform single LLMs in various NLP tasks. In this study, we evaluated three categories of methodologies for EHR prediction using the EHRSHOT dataset: count-based models built from ontology roll-ups with two time bins, based on LightGBM and the tabular foundation model TabPFN; a pretrained sequential transformer (CLMBR); and a mixture-of-agents pipeline that converts tabular histories to natural-language summaries followed by a text classifier. We assessed eight outcomes using the EHRSHOT dataset. Across the eight evaluation tasks, head-to-head wins were largely split between the count-based and the mixture-of-agents methods. Given their simplicity and interpretability, count-based models remain a strong candidate for structured EHR benchmarking. The source code is available at: https://github.com/cristea-lab/Structured_EHR_Benchmark.",
    "fetched_at": "2025-11-09T02:21:22.890642Z"
  },
  {
    "id": "2511.00802v1",
    "title": "GrowthHacker: Automated Off-Policy Evaluation Optimization Using   Code-Modifying LLM Agents",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jie JW Wu",
      "Ayanda Patrick Herlihy",
      "Ahmad Saleem Mirza",
      "Ali Afoud",
      "Fatemeh Fard"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00802v1",
    "abstract": "With the software industry shifting toward a data-driven culture, online A/B testing is a key tool for evaluating new technologies. However, deploying such experiments requires substantial resources, may negatively impact users, and involves long data collection periods. To address this, \\textit{off-policy evaluation (OPE)}, or offline A/B testing, uses logged data to assess technologies and is fundamental in Reinforcement Learning, making it crucial in domains where online testing is costly or risky, such as healthcare, recommender systems, education, dialog systems, and robotics. Despite advances in coding LLMs and agentic AI, little is known about leveraging them to optimize OPE results. We investigate whether LLMs and LLM-based agents can improve OPE performance via code optimization. We propose \\textit{GrowthHacker}, a benchmark with agent and baseline methods on large-scale real-world datasets, which iteratively optimizes code, evaluates results, and begins new optimization cycles. We collected datasets, established protocols, implemented baselines for OPE on the Open Bandit Pipeline (OBP)~\\cite{saito2021openbanditdatasetpipeline} and Scope-RL~\\cite{kiyohara2023scope}, and developed the \\textit{two_agent} framework, which reduces system complexity while preserving optimization effectiveness. Results show the two_agent framework achieves 100% reliability and the highest average improvement of 106.7% among positive outcomes. Both two_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%. These findings demonstrate the feasibility of LLM-based agents as automated \"growth hackers\" to enhance OPE systems, with implications for scaling data-driven decision-making in production.",
    "fetched_at": "2025-11-09T02:21:22.890600Z"
  },
  {
    "id": "2511.00807v2",
    "title": "FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving   on Heterogeneous GPUs",
    "date": "2025-11-02",
    "tags": [
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Xuan He",
      "Zequan Fang",
      "Jinzhao Lian",
      "Danny H. K. Tsang",
      "Baosen Zhang",
      "Yize Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00807v2",
    "abstract": "The ever-increasing computation and energy demand for LLM and AI agents call for holistic and efficient optimization of LLM serving systems. In practice, heterogeneous GPU clusters can be deployed in a geographically distributed manner, while LLM load also observes diversity in terms of both query traffic and serving patterns. LLM queries running on advanced GPUs during a high-emission hour at one location can lead to significantly higher carbon footprints versus same queries running on mid-level GPUs at a low-emission time and location. By observing LLM serving requirements and leveraging spatiotemporal computation flexibility, we consider the joint routing and scheduling problem, and propose FREESH to cooperatively run a group of data centers while minimizing user-specified carbon or energy objectives. FREESH identifies the optimal configurations of balanced load serving by matching distinct GPU instance's power-throughput characteristics with predictable LLM query length and workloads. To ensure both latency and fairness requirements, FREESH identifies optimized parallelism and query routing schedules together with dynamic GPU frequency scaling for power saving, and Least-Laxity-First (LLF) serving strategy for query scheduling. During the 1-hour serving on production workloads, FREESH reduces energy by 28.6% and emissions by 45.45% together with improvements in SLO attainment and fairness.",
    "fetched_at": "2025-11-09T02:21:22.890545Z"
  },
  {
    "id": "2511.00810v1",
    "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor   for GUI Grounding",
    "date": "2025-11-02",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.HC",
      "HC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shijie Zhou",
      "Viet Dac Lai",
      "Hao Tan",
      "Jihyung Kil",
      "Wanrong Zhu",
      "Changyou Chen",
      "Ruiyi Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00810v1",
    "abstract": "Graphical user interface (GUI) grounding is a key function of computer-use agents, which maps natural-language instructions to actionable screen regions. Existing approaches based on Multimodal Large Language Models (MLLMs) typically formulate it as a text-based coordinate generation task, yet directly generating precise coordinates from visual inputs remains challenging and computationally intensive. An intuitive way to implement GUI grounding is to first select visual patches relevant to the instructions and then determine the precise click location within those patches. Based on the observations that general MLLMs have some native grounding capability, nested within their attentions, we propose GUI-AIMA, an attention-based and coordinate-free supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns the intrinsic multimodal attention of MLLMs with patch-wise grounding signals. These signals are calculated adaptively for diverse user instructions by multi-head aggregation on simplified query-visual attention matrices. Besides, its coordinate-free manner can easily integrate a plug-and-play zoom-in stage. GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional data efficiency and verifying that light training can trigger the native grounding capability of MLLMs. It achieves state-of-the-art performance among 3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2% on OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA",
    "fetched_at": "2025-11-09T02:21:22.890492Z"
  },
  {
    "id": "2511.00839v1",
    "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "John Yang",
      "Kilian Lieret",
      "Joyce Yang",
      "Carlos E. Jimenez",
      "Ofir Press",
      "Ludwig Schmidt",
      "Diyi Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00839v1",
    "abstract": "Current benchmarks for coding evaluate language models (LMs) on concrete, well-specified tasks such as fixing specific bugs or writing targeted tests. However, human programmers do not spend all day incessantly addressing isolated tasks. Instead, real-world software development is grounded in the pursuit of high-level goals, like improving user retention or reducing costs. Evaluating whether LMs can also iteratively develop code to better accomplish open-ended objectives without any explicit guidance remains an open challenge. To address this, we introduce CodeClash, a benchmark where LMs compete in multi-round tournaments to build the best codebase for achieving a competitive objective. Each round proceeds in two phases: agents edit their code, then their codebases compete head-to-head in a code arena that determines winners based on objectives like score maximization, resource acquisition, or survival. Whether it's writing notes, scrutinizing documentation, analyzing competition logs, or creating test suites, models must decide for themselves how to improve their codebases both absolutely and against their opponents. We run 1680 tournaments (25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal that while models exhibit diverse development styles, they share fundamental limitations in strategic reasoning. Models also struggle with long-term codebase maintenance, as repositories become progressively messy and redundant. These limitations are stark: top models lose every round against expert human programmers. We open-source CodeClash to advance the study of autonomous, goal-oriented code development.",
    "fetched_at": "2025-11-09T02:21:22.890433Z"
  },
  {
    "id": "2511.00843v1",
    "title": "Portal UX Agent -- A Plug-and-Play Engine for Rendering UIs from Natural   Language Specifications",
    "date": "2025-11-02",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Xinsong Li",
      "Ning Jiang",
      "Jay Selvaraj"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00843v1",
    "abstract": "The rapid appearance of large language models (LLMs) has led to systems that turn natural-language intent into real user interfaces (UIs). Free-form code generation maximizes expressiveness but often hurts reliability, security, and design-system compliance. In contrast, fully static UIs are easy to govern but lack adaptability. We present the Portal UX Agent, a practical middle way that makes bounded generation work: an LLM plans the UI at a high level, and a deterministic renderer assembles the final interface from a vetted set of components and layout templates. The agent maps intents to a typed composition-template and component specifications-constrained by a schema. This enables auditability, reuse, and safety while preserving flexibility. We also introduce a mixed-methods evaluation framework that combines automatic checks (coverage, property fidelity, layout, accessibility, performance) with an LLM-as-a-Judge rubric to assess semantic alignment and visual polish. Experiments on multi-domain portal scenarios show that the Portal UX Agent reliably turns intent into coherent, usable UIs and performs well on compositionality and clarity. This work advances agentic UI design by combining model-driven representations, plug-and-play rendering, and structured evaluation, paving the way for controllable and trustworthy UI generation.",
    "fetched_at": "2025-11-09T02:21:22.890374Z"
  },
  {
    "id": "2511.00872v1",
    "title": "A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric   Software Engineering Tasks",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Zhuowen Yin",
      "Cuifeng Gao",
      "Chunsong Fan",
      "Wenzhang Yang",
      "Yinxing Xue",
      "Lijun Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00872v1",
    "abstract": "Unlike traditional automation tools or static LLM-based systems, agents combine decision-making and tool utilization to accomplish complex tasks, showing great potential in software engineering. However, existing studies largely focus on specific tasks or isolated aspects, providing an incomplete picture of agents' practical capabilities. To address this, we conduct a comprehensive empirical study evaluating seven general-purpose agent frameworks across three representative code-centric tasks: software development, vulnerability detection, and program repair. Each task is assessed using standard, widely adopted benchmarks to ensure objective and comparable evaluation. Agent performance is systematically analyzed from three complementary perspectives: effectiveness (task success), efficiency (execution process), and overhead (token consumption). Our findings reveal distinct capability patterns and trade-offs among the evaluated frameworks. In terms of effectiveness, agents achieve moderate overall performance. Regarding efficiency, AgentOrchestra tends to exhibit the longest trajectories and the most correction attempts due to coordination overhead, whereas OpenHands demonstrate stronger reflective reasoning abilities. For overhead, software development incurs the highest monetary cost, while GPTswarm remains the most cost-efficient. Furthermore, we conduct an in-depth cross-analysis of the relationship between effectiveness and efficiency, exploring the underlying reasons behind their interplay. These findings guide both practical adoption and future research toward more efficient software engineering agents.",
    "fetched_at": "2025-11-09T02:21:22.890332Z"
  },
  {
    "id": "2511.00908v1",
    "title": "GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with   Heterogeneous Graph Neural Networks",
    "date": "2025-11-02",
    "tags": [
      "cs.CV",
      "CV",
      "cs.GR",
      "GR"
    ],
    "authors": [
      "Heng Zheng",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Hao Zhang",
      "Wenjun Huang",
      "Jin Huang"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.00908v1",
    "abstract": "Visual geo-localization requires extensive geographic knowledge and sophisticated reasoning to determine image locations without GPS metadata. Traditional retrieval methods are constrained by database coverage and quality. Recent Large Vision-Language Models (LVLMs) enable direct location reasoning from image content, yet individual models struggle with diverse geographic regions and complex scenes. Existing multi-agent systems improve performance through model collaboration but treat all agent interactions uniformly. They lack mechanisms to handle conflicting predictions effectively. We propose \\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph neural networks for visual geo-localization. Our approach models diverse debate relationships through typed edges, distinguishing supportive collaboration, competitive argumentation, and knowledge transfer. We introduce a dual-level debate mechanism combining node-level refinement and edge-level argumentation modeling. A cross-level topology refinement strategy enables co-evolution between graph structure and agent representations. Experiments on multiple benchmarks demonstrate GraphGeo significantly outperforms state-of-the-art methods. Our framework transforms cognitive conflicts between agents into enhanced geo-localization accuracy through structured debate.",
    "fetched_at": "2025-11-09T02:21:22.890276Z"
  },
  {
    "id": "2511.00917v1",
    "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for   Zero-Shot Generalist Robots",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junyao Shi",
      "Rujia Yang",
      "Kaitian Chao",
      "Selina Bingqing Wan",
      "Yifei Shao",
      "Jiahui Lei",
      "Jianing Qian",
      "Long Le",
      "Pratik Chaudhari",
      "Kostas Daniilidis",
      "Chuan Wen",
      "Dinesh Jayaraman"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00917v1",
    "abstract": "Today's best-explored routes towards generalist robots center on collecting ever larger \"observations-in actions-out\" robotics datasets to train large end-to-end models, copying a recipe that has worked for vision-language models (VLMs). We pursue a road less traveled: building generalist policies directly around VLMs by augmenting their general capabilities with specific robot capabilities encapsulated in a carefully curated set of perception, planning, and control modules. In Maestro, a VLM coding agent dynamically composes these modules into a programmatic policy for the current task and scenario. Maestro's architecture benefits from a streamlined closed-loop interface without many manually imposed structural constraints, and a comprehensive and diverse tool repertoire. As a result, it largely surpasses today's VLA models for zero-shot performance on challenging manipulation skills. Further, Maestro is easily extensible to incorporate new modules, easily editable to suit new embodiments such as a quadruped-mounted arm, and even easily adapts from minimal real-world experiences through local code edits.",
    "fetched_at": "2025-11-09T02:21:22.890215Z"
  },
  {
    "id": "2511.00945v1",
    "title": "\"Less is More\": Reducing Cognitive Load and Task Drift in Real-Time   Multimodal Assistive Agents for the Visually Impaired",
    "date": "2025-11-02",
    "tags": [
      "cs.HC",
      "HC",
      "H.5",
      "5"
    ],
    "authors": [
      "Yi Zhao",
      "Siqi Wang",
      "Qiqun Geng",
      "Erxin Yu",
      "Jing Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00945v1",
    "abstract": "Vision-Language Models (VLMs) enable on-demand visual assistance, yet current applications for people with visual impairments (PVI) impose high cognitive load and exhibit task drift, limiting real-world utility. We first conducted a formative study with 15 PVI and identified three requirements for visually impaired assistance (VIA): low latency for real-time use, minimal cognitive load, and hallucination-resistant responses to sustain trust. Informed by the formative study, we present VIA-Agent, a prototype that co-optimizes its cognitive 'brain' and interactive 'body'. The brain implements a goal-persistent design with calibrated conciseness to produce brief, actionable guidance; the body adopts a real-time communication (RTC) embodiment-evolving from a request-response model Context Protocol (MCP) pipeline-to-support fluid interaction. We evaluated VIA-Agent with 9 PVI across navigation and object retrieval in the wild against BeMyAI and Doubao. VIA-Agent significantly outperformed BeMyAI both quantitatively and qualitatively. While achieving success rates comparable to Doubao, it reduced mean task time by 39.9% (70.1 s vs. 110.7 s), required fewer conversational turns (4.3 vs. 5.0), and lowered perceived cognitive load and task drift. System Usability Scale (SUS) results aligned with these findings, with VIA-Agent achieving the highest usability. We hope this work inspires the development of more human-centered VIA systems.",
    "fetched_at": "2025-11-09T02:21:22.890145Z"
  },
  {
    "id": "2511.00993v1",
    "title": "Aligning LLM agents with human learning and adjustment behavior: a dual   agent approach",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianming Liu",
      "Jirong Yang",
      "Yafeng Yin",
      "Manzi Li",
      "Linghao Wang",
      "Zheng Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00993v1",
    "abstract": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning. However, this task is also difficult due to the complex cognition and decision-making involved in such behavior. Recent research has begun to leverage Large Language Model (LLM) agents for this task. Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams. Our approach involves a set of LLM traveler agents, equipped with a memory system and a learnable persona, which serve as simulators for human travelers. To ensure behavioral alignment, we introduce an LLM calibration agent that leverages the reasoning and analytical capabilities of LLMs to train the personas of these traveler agents. Working together, this dual-agent system is designed to track and align the underlying decision-making mechanisms of travelers and produce realistic, adaptive simulations. Using a real-world dataset from a day-to-day route choice experiment, we show our approach significantly outperforms existing LLM-based methods in both individual behavioral alignment and aggregate simulation accuracy. Furthermore, we demonstrate that our method moves beyond simple behavioral mimicry to capture the evolution of underlying learning processes, a deeper alignment that fosters robust generalization. Overall, our framework provides a new approach for creating adaptive and behaviorally realistic agents to simulate travelers' learning and adaptation that can benefit transportation simulation and policy analysis.",
    "fetched_at": "2025-11-09T02:21:22.890089Z"
  },
  {
    "id": "2511.01047v2",
    "title": "HAFixAgent: History-Aware Automated Program Repair Agent",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yu Shi",
      "Hao Li",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01047v2",
    "abstract": "Automated program repair (APR) has recently shifted toward large language models and agent-based systems, yet most systems rely on local snapshot context, overlooking repository history. Prior work shows that repository history helps repair single-line bugs, since the last commit touching the buggy line is often the bug-introducing one. In this paper, we investigate whether repository history can also improve agentic APR systems at scale, especially for complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing Agent that injects blame-derived repository heuristics into its repair loop. A preliminary study of all 854 real-world bugs from Defects4J motivates our design, showing that bug-relevant history is both widely available and highly concentrated. Empirical comparison of HAFixAgent with two state-of-the-art baselines shows: (1) Effectiveness: HAFixAgent significantly improves over the agent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2) Efficiency: history does not significantly increase agent steps and keeps token costs comparable, with notably lower median costs for complex multi-file-multi-hunk bugs. (3) Practicality: combining different historical heuristics repairs more bugs, offering a clear cost-benefit trade-off. HAFixAgent offers a practical recipe for history-aware agentic APR: ground the agent in version control history, prioritize diff-based historical context, and integrate complementary heuristics when needed.",
    "fetched_at": "2025-11-09T02:21:22.890033Z"
  },
  {
    "id": "2511.00330v1",
    "title": "Sherlock: Reliable and Efficient Agentic Workflow Execution",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Yeonju Ro",
      "Haoran Qiu",
      "Íñigo Goiri",
      "Rodrigo Fonseca",
      "Ricardo Bianchini",
      "Aditya Akella",
      "Zhangyang Wang",
      "Mattan Erez",
      "Esha Choukse"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00330v1",
    "abstract": "With the increasing adoption of large language models (LLM), agentic workflows, which compose multiple LLM calls with tools, retrieval, and reasoning steps, are increasingly replacing traditional applications. However, such workflows are inherently error-prone: incorrect or partially correct output at one step can propagate or even amplify through subsequent stages, compounding the impact on the final output. Recent work proposes integrating verifiers that validate LLM output or actions, such as self-reflection, debate, or LLM-as-a-judge mechanisms. Yet, verifying every step introduces significant latency and cost overheads.   In this work, we seek to answer three key questions: which nodes in a workflow are most error-prone and thus deserve costly verification, how to select the most appropriate verifier for each node, and how to use verification with minimal impact to latency? Our solution, Sherlock, addresses these using counterfactual analysis on agentic workflows to identify error-prone nodes and selectively attaching cost-optimal verifiers only where necessary. At runtime, Sherlock speculatively executes downstream tasks to reduce latency overhead, while verification runs in the background. If verification fails, execution is rolled back to the last verified output. Compared to the non-verifying baseline, Sherlock delivers an 18.3% accuracy gain on average across benchmarks. Sherlock reduces workflow execution time by up to 48.7% over non-speculative execution and lowers verification cost by 26.0% compared to the Monte Carlo search-based method, demonstrating that principled, fault-aware verification effectively balances efficiency and reliability in agentic workflows.",
    "fetched_at": "2025-11-08T02:10:21.393881Z"
  },
  {
    "id": "2511.00488v1",
    "title": "\\texttt{ReMind}: Understanding Deductive Code Reasoning in LLMs",
    "date": "2025-11-01",
    "tags": [
      "cs.PL",
      "PL",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jun Gao",
      "Yun Peng",
      "Xiaoxue Ren"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00488v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress in code-related tasks. Despite their advancement, empirical evidence reveals that they still struggle with \\emph{deductive code reasoning}, the ability to reason about the program execution process. While prior studies have recognized this limitation, the underlying causes remain largely underexplored. In this paper, we begin by presenting a comprehensive empirical study that reveals three key challenges undermining deductive code reasoning: (1) an intrinsic gap between generation and reasoning abilities, (2) a consistent bias towards code sources, and (3) weak zero-shot generalization on complex benchmarks. In light of these challenges, we propose \\texttt{ReMind}, a multi-agent framework composed of \\texttt{Mutator}, \\texttt{Executor}, and \\texttt{Inspector}. The \\texttt{Mutator} generates code variants to mitigate bias towards code sources, the \\texttt{Executor} traces variable states step-by-step to expose inconsistency, and the \\texttt{Inspector} identifies problematic reasoning steps and provides control-flow refinement to bridge the intrinsic reasoning gap. Through their coordinated collaboration, \\texttt{ReMind} systematically identifies and refines reasoning flaws, achieving outstanding performance and enabling robust zero-shot generalization. Extensive experiments on two benchmarks with five LLMs demonstrate the superior advantages of \\texttt{ReMind} compared to baseline approaches in deductive code reasoning.",
    "fetched_at": "2025-11-08T02:10:21.393651Z"
  },
  {
    "id": "2511.00517v1",
    "title": "Issue-Oriented Agent-Based Framework for Automated Review Comment   Generation",
    "date": "2025-11-01",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Shuochuan Li",
      "Dong Wang",
      "Patanamon Thongtanunam",
      "Zan Wang",
      "Jiuqiao Yu",
      "Junjie Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00517v1",
    "abstract": "Code review (CR) is a crucial practice for ensuring software quality. Various automated review comment generation techniques have been proposed to streamline the labor-intensive process. However, existing approaches heavily rely on a single model to identify various issues within the code, limiting the model's ability to handle the diverse, issue-specific nature of code changes and leading to non-informative comments, especially in complex scenarios such as bug fixes. To address these limitations, we propose RevAgent, a novel agent-based issue-oriented framework, decomposes the task into three stages: (1) Generation Stage, where five category-specific commentator agents analyze code changes from distinct issue perspectives and generate candidate comments; (2) Discrimination Stage, where a critic agent selects the most appropriate issue-comment pair; and (3) Training Stage, where all agents are fine-tuned on curated, category-specific data to enhance task specialization. Evaluation results show that RevAgent significantly outperforms state-of-the-art PLM- and LLM-based baselines, with improvements of 12.90\\%, 10.87\\%, 6.32\\%, and 8.57\\% on BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively higher accuracy in issue-category identification, particularly for challenging scenarios. Human evaluations further validate the practicality of RevAgent in generating accurate, readable, and context-aware review comments. Moreover, RevAgent delivers a favorable trade-off between performance and efficiency.",
    "fetched_at": "2025-11-08T02:10:21.393604Z"
  },
  {
    "id": "2511.00619v1",
    "title": "GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance   Detection in Android",
    "date": "2025-11-01",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Huaijin Ran",
      "Haoyi Zhang",
      "Xunzhu Tang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00619v1",
    "abstract": "Automating the detection of EU General Data Protection Regulation (GDPR) violations in source code is a critical but underexplored challenge. We introduce \\textbf{GDPR-Bench-Android}, the first comprehensive benchmark for evaluating diverse automated methods for GDPR compliance detection in Android applications. It contains \\textbf{1951} manually annotated violation instances from \\textbf{15} open-source repositories, covering 23 GDPR articles at file-, module-, and line-level granularities. To enable a multi-paradigm evaluation, we contribute \\textbf{Formal-AST}, a novel, source-code-native formal method that serves as a deterministic baseline. We define two tasks: (1) \\emph{multi-granularity violation localization}, evaluated via Accuracy@\\textit{k}; and (2) \\emph{snippet-level multi-label classification}, assessed by macro-F1 and other classification metrics. We benchmark 11 methods, including eight state-of-the-art LLMs, our Formal-AST analyzer, a retrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings reveal that no single paradigm excels across all tasks. For Task 1, the ReAct agent achieves the highest file-level Accuracy@1 (17.38%), while the Qwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the Formal-AST method's 1.86%. For the difficult multi-label Task 2, the Claude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method yields the highest Macro-Precision (7.10%). These results highlight the task-dependent strengths of different automated approaches and underscore the value of our benchmark in diagnosing their capabilities. All resources are available at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.",
    "fetched_at": "2025-11-08T02:10:21.393483Z"
  },
  {
    "id": "2511.00628v1",
    "title": "AgentGit: A Version Control Framework for Reliable and Scalable   LLM-Powered Multi-Agent Systems",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Yang Li",
      "Siqi Ping",
      "Xiyu Chen",
      "Xiaojian Qi",
      "Zigan Wang",
      "Ye Luo",
      "Xiaowei Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00628v1",
    "abstract": "With the rapid progress of large language models (LLMs), LLM-powered multi-agent systems (MAS) are drawing increasing interest across academia and industry. However, many current MAS frameworks struggle with reliability and scalability, especially on complex tasks. We present AgentGit, a framework that brings Git-like rollback and branching to MAS workflows. Built as an infrastructure layer on top of LangGraph, AgentGit supports state commit, revert, and branching, allowing agents to traverse, compare, and explore multiple trajectories efficiently. To evaluate AgentGit, we designed an experiment that optimizes target agents by selecting better prompts. We ran a multi-step A/B test against three baselines -- LangGraph, AutoGen, and Agno -- on a real-world task: retrieving and analyzing paper abstracts. Results show that AgentGit significantly reduces redundant computation, lowers runtime and token usage, and supports parallel exploration across multiple branches, enhancing both reliability and scalability in MAS development. This work offers a practical path to more robust MAS design and enables error recovery, safe exploration, iterative debugging, and A/B testing in collaborative AI systems.",
    "fetched_at": "2025-11-08T02:10:21.393432Z"
  },
  {
    "id": "2511.01912v1",
    "title": "EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Wenzhe Fan",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01912v1",
    "abstract": "Planning has been a cornerstone of artificial intelligence for solving complex problems, and recent progress in LLM-based multi-agent frameworks have begun to extend this capability. However, the role of human-like memory within these frameworks remains largely unexplored. Understanding how agents coordinate through memory is critical for natural language planning, where iterative reasoning, constraint tracking, and error correction drive the success. Inspired by working memory model in cognitive psychology, we present EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The framework consists of three agents (Constraint Extractor, Verifier, and Actor) and two memory modules: Constraint Memory (CMem), which evolves across queries by storing task-specific rules and constraints while remains fixed within a query, and Query-feedback Memory (QMem), which evolves within a query by accumulating feedback across iterations for solution refinement. Both memory modules are reset at the end of each query session. Evaluations on trip planning, meeting planning, and calendar scheduling show consistent performance improvements, highlighting the effectiveness of EvoMem. This success underscores the importance of memory in enhancing multi-agent planning.",
    "fetched_at": "2025-11-08T02:10:19.615932Z"
  },
  {
    "id": "2511.00370v1",
    "title": "Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent   Conflict",
    "date": "2025-11-01",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chaochen Wu",
      "Guan Luo",
      "Meiyun Zuo",
      "Zhitao Fan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00370v1",
    "abstract": "Video moment retrieval uses a text query to locate a moment from a given untrimmed video reference. Locating corresponding video moments with text queries helps people interact with videos efficiently. Current solutions for this task have not considered conflict within location results from different models, so various models cannot integrate correctly to produce better results. This study introduces a reinforcement learning-based video moment retrieval model that can scan the whole video once to find the moment's boundary while producing its locational evidence. Moreover, we proposed a multi-agent system framework that can use evidential learning to resolve conflicts between agents' localization output. As a side product of observing and dealing with conflicts between agents, we can decide whether a query has no corresponding moment in a video (out-of-scope) without additional training, which is suitable for real-world applications. Extensive experiments on benchmark datasets show the effectiveness of our proposed methods compared with state-of-the-art approaches. Furthermore, the results of our study reveal that modeling competition and conflict of the multi-agent system is an effective way to improve RL performance in moment retrieval and show the new role of evidential learning in the multi-agent framework.",
    "fetched_at": "2025-11-08T02:10:19.615887Z"
  }
]
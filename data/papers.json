[
  {
    "id": "2511.08060v1",
    "title": "From LLMs to Agents: A Comparative Evaluation of LLMs and LLM-based Agents in Security Patch Detection",
    "date": "2025-11-11",
    "tags": [
      "cs.CR",
      "CR",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Junxiao Han",
      "Zheng Yu",
      "Lingfeng Bao",
      "Jiakun Liu",
      "Yao Wan",
      "Jianwei Yin",
      "Shuiguang Deng",
      "Song Han"
    ],
    "institution": "MIT",
    "link": "https://arxiv.org/pdf/2511.08060v1",
    "abstract": "The widespread adoption of open-source software (OSS) has accelerated software innovation but also increased security risks due to the rapid propagation of vulnerabilities and silent patch releases. In recent years, large language models (LLMs) and LLM-based agents have demonstrated remarkable capabilities in various software engineering (SE) tasks, enabling them to effectively address software security challenges such as vulnerability detection. However, systematic evaluation of the capabilities of LLMs and LLM-based agents in security patch detection remains limited. To bridge this gap, we conduct a comprehensive evaluation of the performance of LLMs and LLM-based agents for security patch detection. Specifically, we investigate three methods: Plain LLM (a single LLM with a system prompt), Data-Aug LLM (data augmentation based on the Plain LLM), and the ReAct Agent (leveraging the thought-action-observation mechanism). We also evaluate the performance of both commercial and open-source LLMs under these methods and compare these results with those of existing baselines. Furthermore, we analyze the detection performance of these methods across various vulnerability types, and examine the impact of different prompting strategies and context window sizes on the results. Our findings reveal that the Data-Aug LLM achieves the best overall performance, whereas the ReAct Agent demonstrates the lowest false positive rate (FPR). Although baseline methods exhibit strong accuracy, their false positive rates are significantly higher. In contrast, our evaluated methods achieve comparable accuracy while substantially reducing the FPR. These findings provide valuable insights into the practical applications of LLMs and LLM-based agents in security patch detection, highlighting their advantage in maintaining robust performance while minimizing false positive rates.",
    "fetched_at": "2025-11-13T02:20:38.588809Z"
  },
  {
    "id": "2511.07568v1",
    "title": "Procedural Knowledge Improves Agentic LLM Workflows",
    "date": "2025-11-10",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Vincent Hsiao",
      "Mark Roberts",
      "Leslie Smith"
    ],
    "institution": "",
    "link": "https://arxiv.org/pdf/2511.07568v1",
    "abstract": "Large language models (LLMs) often struggle when performing agentic tasks without substantial tool support, prom-pt engineering, or fine tuning. Despite research showing that domain-dependent, procedural knowledge can dramatically increase planning efficiency, little work evaluates its potential for improving LLM performance on agentic tasks that may require implicit planning. We formalize, implement, and evaluate an agentic LLM workflow that leverages procedural knowledge in the form of a hierarchical task network (HTN). Empirical results of our implementation show that hand-coded HTNs can dramatically improve LLM performance on agentic tasks, and using HTNs can boost a 20b or 70b parameter LLM to outperform a much larger 120b parameter LLM baseline. Furthermore, LLM-created HTNs improve overall performance, though less so. The results suggest that leveraging expertise--from humans, documents, or LLMs--to curate procedural knowledge will become another important tool for improving LLM workflows.",
    "fetched_at": "2025-11-13T02:20:38.588297Z"
  },
  {
    "id": "2511.04886v1",
    "title": "Beta Distribution Learning for Reliable Roadway Crash Risk Assessment",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ahmad Elallaf",
      "Nathan Jacobs",
      "Xinyue Ye",
      "Mei Chen",
      "Gongbo Liang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04886v1",
    "abstract": "Roadway traffic accidents represent a global health crisis, responsible for over a million deaths annually and costing many countries up to 3% of their GDP. Traditional traffic safety studies often examine risk factors in isolation, overlooking the spatial complexity and contextual interactions inherent in the built environment. Furthermore, conventional Neural Network-based risk estimators typically generate point estimates without conveying model uncertainty, limiting their utility in critical decision-making. To address these shortcomings, we introduce a novel geospatial deep learning framework that leverages satellite imagery as a comprehensive spatial input. This approach enables the model to capture the nuanced spatial patterns and embedded environmental risk factors that contribute to fatal crash risks. Rather than producing a single deterministic output, our model estimates a full Beta probability distribution over fatal crash risk, yielding accurate and uncertainty-aware predictions--a critical feature for trustworthy AI in safety-critical applications. Our model outperforms baselines by achieving a 17-23% improvement in recall, a key metric for flagging potential dangers, while delivering superior calibration. By providing reliable and interpretable risk assessments from satellite imagery alone, our method enables safer autonomous navigation and offers a highly scalable tool for urban planners and policymakers to enhance roadway safety equitably and cost-effectively.",
    "fetched_at": "2025-11-11T02:19:10.037141Z"
  },
  {
    "id": "2511.04901v1",
    "title": "Association via Entropy Reduction",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.CL",
      "CL",
      "H.3.3",
      "3"
    ],
    "authors": [
      "Anthony Gamst",
      "Lawrence Wilson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04901v1",
    "abstract": "Prior to recent successes using neural networks, term frequency-inverse document frequency (tf-idf) was clearly regarded as the best choice for identifying documents related to a query. We provide a different score, aver, and observe, on a dataset with ground truth marking for association, that aver does do better at finding assciated pairs than tf-idf. This example involves finding associated vertices in a large graph and that may be an area where neural networks are not currently an obvious best choice. Beyond this one anecdote, we observe that (1) aver has a natural threshold for declaring pairs as unassociated while tf-idf does not, (2) aver can distinguish between pairs of documents for which tf-idf gives a score of 1.0, (3) aver can be applied to larger collections of documents than pairs while tf-idf cannot, and (4) that aver is derived from entropy under a simple statistical model while tf-idf is a construction designed to achieve a certain goal and hence aver may be more \"natural.\" To be fair, we also observe that (1) writing down and computing the aver score for a pair is more complex than for tf-idf and (2) that the fact that the aver score is naturally scale-free makes it more complicated to interpret aver scores.",
    "fetched_at": "2025-11-11T02:19:10.037033Z"
  },
  {
    "id": "2511.04902v1",
    "title": "You Need Reasoning to Learn Reasoning: The Limitations of Label-Free RL   in Weak Base Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shuvendu Roy",
      "Hossein Hajimirsadeghi",
      "Mengyao Zhai",
      "Golnoosh Samei"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04902v1",
    "abstract": "Recent advances in large language models have demonstrated the promise of unsupervised reinforcement learning (RL) methods for enhancing reasoning capabilities without external supervision. However, the generalizability of these label-free RL approaches to smaller base models with limited reasoning capabilities remains unexplored. In this work, we systematically investigate the performance of label-free RL methods across different model sizes and reasoning strengths, from 0.5B to 7B parameters. Our empirical analysis reveals critical limitations: label-free RL is highly dependent on the base model's pre-existing reasoning capability, with performance often degrading below baseline levels for weaker models. We find that smaller models fail to generate sufficiently long or diverse chain-of-thought reasoning to enable effective self-reflection, and that training data difficulty plays a crucial role in determining success. To address these challenges, we propose a simple yet effective method for label-free RL that utilizes curriculum learning to progressively introduce harder problems during training and mask no-majority rollouts during training. Additionally, we introduce a data curation pipeline to generate samples with predefined difficulty. Our approach demonstrates consistent improvements across all model sizes and reasoning capabilities, providing a path toward more robust unsupervised RL that can bootstrap reasoning abilities in resource-constrained models. We make our code available at https://github.com/BorealisAI/CuMa",
    "fetched_at": "2025-11-11T02:19:10.036991Z"
  },
  {
    "id": "2511.04907v1",
    "title": "Efficient Swap Multicalibration of Elicitable Properties",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Lunjia Hu",
      "Haipeng Luo",
      "Spandan Senapati",
      "Vatsal Sharan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04907v1",
    "abstract": "Multicalibration [HJKRR18] is an algorithmic fairness perspective that demands that the predictions of a predictor are correct conditional on themselves and membership in a collection of potentially overlapping subgroups of a population. The work of [NR23] established a surprising connection between multicalibration for an arbitrary property $\\Gamma$ (e.g., mean or median) and property elicitation: a property $\\Gamma$ can be multicalibrated if and only if it is elicitable, where elicitability is the notion that the true property value of a distribution can be obtained by solving a regression problem over the distribution. In the online setting, [NR23] proposed an inefficient algorithm that achieves $\\sqrt T$ $\\ell_2$-multicalibration error for a hypothesis class of group membership functions and an elicitable property $\\Gamma$, after $T$ rounds of interaction between a forecaster and adversary.   In this paper, we generalize multicalibration for an elicitable property $\\Gamma$ from group membership functions to arbitrary bounded hypothesis classes and introduce a stronger notion -- swap multicalibration, following [GKR23]. Subsequently, we propose an oracle-efficient algorithm which, when given access to an online agnostic learner, achieves $T^{1/(r+1)}$ $\\ell_r$-swap multicalibration error with high probability (for $r\\ge2$) for a hypothesis class with bounded sequential Rademacher complexity and an elicitable property $\\Gamma$. For the special case of $r=2$, this implies an oracle-efficient algorithm that achieves $T^{1/3}$ $\\ell_2$-swap multicalibration error, which significantly improves on the previously established bounds for the problem [NR23, GMS25, LSS25a], and completely resolves an open question raised in [GJRR24] on the possibility of an oracle-efficient algorithm that achieves $\\sqrt{T}$ $\\ell_2$-mean multicalibration error by answering it in a strongly affirmative sense.",
    "fetched_at": "2025-11-11T02:19:10.036892Z"
  },
  {
    "id": "2511.04909v1",
    "title": "A Dual Perspective on Decision-Focused Learning: Scalable Training via   Dual-Guided Surrogates",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Paula Rodriguez-Diaz",
      "Kirk Bansak Elisabeth Paulson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04909v1",
    "abstract": "Many real-world decisions are made under uncertainty by solving optimization problems using predicted quantities. This predict-then-optimize paradigm has motivated decision-focused learning, which trains models with awareness of how the optimizer uses predictions, improving the performance of downstream decisions. Despite its promise, scaling is challenging: state-of-the-art methods either differentiate through a solver or rely on task-specific surrogates, both of which require frequent and expensive calls to an optimizer, often a combinatorial one. In this paper, we leverage dual variables from the downstream problem to shape learning and introduce Dual-Guided Loss (DGL), a simple, scalable objective that preserves decision alignment while reducing solver dependence. We construct DGL specifically for combinatorial selection problems with natural one-of-many constraints, such as matching, knapsack, and shortest path. Our approach (a) decouples optimization from gradient updates by solving the downstream problem only periodically; (b) between refreshes, trains on dual-adjusted targets using simple differentiable surrogate losses; and (c) as refreshes become less frequent, drives training cost toward standard supervised learning while retaining strong decision alignment. We prove that DGL has asymptotically diminishing decision regret, analyze runtime complexity, and show on two problem classes that DGL matches or exceeds state-of-the-art DFL methods while using far fewer solver calls and substantially less training time. Code is available at https://github.com/paularodr/Dual-Guided-Learning.",
    "fetched_at": "2025-11-11T02:19:10.036825Z"
  },
  {
    "id": "2511.04910v2",
    "title": "SDS KoPub VDR: A Benchmark Dataset for Visual Document Retrieval in   Korean Public Documents",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jaehoon Lee",
      "Sohyun Kim",
      "Wanggeun Park",
      "Geon Lee",
      "Seungkyung Kim",
      "Minyoung Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04910v2",
    "abstract": "Existing benchmarks for visual document retrieval (VDR) largely overlook non-English languages and the structural complexity of official publications. To address this gap, we introduce SDS KoPub VDR, the first large-scale, public benchmark for retrieving and understanding Korean public documents. The benchmark is built upon 361 real-world documents, including 256 files under the KOGL Type 1 license and 105 from official legal portals, capturing complex visual elements like tables, charts, and multi-column layouts. To establish a reliable evaluation set, we constructed 600 query-page-answer triples. These were initially generated using multimodal models (e.g., GPT-4o) and subsequently underwent human verification to ensure factual accuracy and contextual relevance. The queries span six major public domains and are categorized by the reasoning modality required: text-based, visual-based, and cross-modal. We evaluate SDS KoPub VDR on two complementary tasks: (1) text-only retrieval and (2) multimodal retrieval, which leverages visual features alongside text. This dual-task evaluation reveals substantial performance gaps, particularly in multimodal scenarios requiring cross-modal reasoning, even for state-of-the-art models. As a foundational resource, SDS KoPub VDR enables rigorous and fine-grained evaluation and provides a roadmap for advancing multimodal AI in real-world document intelligence. The dataset is available at https://huggingface.co/datasets/SamsungSDS-Research/SDS-KoPub-VDR-Benchmark.",
    "fetched_at": "2025-11-11T02:19:10.036780Z"
  },
  {
    "id": "2511.04918v1",
    "title": "Machine Learning Algorithms in Statistical Modelling Bridging Theory and   Application",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "A. Ganapathi Rao",
      "Sathish Krishna Anumula",
      "Aditya Kumar Singh",
      "Renukhadevi M",
      "Y. Jeevan Nagendra Kumar",
      "Tammineni Rama Tulasi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04918v1",
    "abstract": "It involves the completely novel ways of integrating ML algorithms with traditional statistical modelling that has changed the way we analyze data, do predictive analytics or make decisions in the fields of the data. In this paper, we study some ML and statistical model connections to understand ways in which some modern ML algorithms help 'enrich' conventional models; we demonstrate how new algorithms improve performance, scale, flexibility and robustness of the traditional models. It shows that the hybrid models are of great improvement in predictive accuracy, robustness, and interpretability",
    "fetched_at": "2025-11-11T02:19:10.036588Z"
  },
  {
    "id": "2511.04919v1",
    "title": "BudgetMem: Learning Selective Memory Policies for Cost-Efficient   Long-Context Processing in Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "I.2.7; I.2.6; H.3.3",
      "3"
    ],
    "authors": [
      "Chandra Vamsi Krishna Alla",
      "Harish Naidu Gaddam",
      "Manohar Kommi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04919v1",
    "abstract": "Large Language Models (LLMs) face significant computational and memory constraints when processing long contexts, despite growing demand for applications requiring reasoning over extensive documents, multi-session dialogues, and book length texts. While recent advances have extended context windows to 100K-1M tokens, such approaches incur prohibitive costs for resource constrained deployments. We propose BudgetMem, a novel memory augmented architecture that learns what to remember rather than remembering everything. Our system combines selective memory policies with feature based salience scoring (entity density, TF-IDF, discourse markers, position bias) to decide which information merits storage under strict budget constraints. Unlike existing retrieval augmented generation (RAG) systems that store all chunks, BudgetMem employs learned gating mechanisms coupled with BM25 sparse retrieval for efficient information access. Through comprehensive experiments on 700 question answer pairs across short (237 tokens) and long (5K-10K tokens) documents with Llama-3.2-3B-Instruct, we demonstrate that BudgetMem achieves remarkable results on long documents: only 1.0% F1 score degradation while saving 72.4% memory compared to baseline RAG. We validate our approach through budget sensitivity analysis (testing 7 budget ratios), naive baseline comparisons, and document length analysis, showing that BudgetMem's benefits increase with document length. Our work provides a practical pathway for deploying capable long context systems on modest hardware, democratizing access to advanced language understanding capabilities.",
    "fetched_at": "2025-11-11T02:19:10.036539Z"
  },
  {
    "id": "2511.04926v1",
    "title": "Diagnosing and Mitigating Semantic Inconsistencies in Wikidata's   Classification Hierarchy",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shixiong Zhao",
      "Hideaki Takeda"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04926v1",
    "abstract": "Wikidata is currently the largest open knowledge graph on the web, encompassing over 120 million entities. It integrates data from various domain-specific databases and imports a substantial amount of content from Wikipedia, while also allowing users to freely edit its content. This openness has positioned Wikidata as a central resource in knowledge graph research and has enabled convenient knowledge access for users worldwide. However, its relatively loose editorial policy has also led to a degree of taxonomic inconsistency. Building on prior work, this study proposes and applies a novel validation method to confirm the presence of classification errors, over-generalized subclass links, and redundant connections in specific domains of Wikidata. We further introduce a new evaluation criterion for determining whether such issues warrant correction and develop a system that allows users to inspect the taxonomic relationships of arbitrary Wikidata entities-leveraging the platform's crowdsourced nature to its full potential.",
    "fetched_at": "2025-11-11T02:19:10.036434Z"
  },
  {
    "id": "2511.04934v1",
    "title": "Leak@$k$: Unlearning Does Not Make LLMs Forget Under Probabilistic   Decoding",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hadi Reisizadeh",
      "Jiajun Ruan",
      "Yiwei Chen",
      "Soumyadeep Pal",
      "Sijia Liu",
      "Mingyi Hong"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04934v1",
    "abstract": "Unlearning in large language models (LLMs) is critical for regulatory compliance and for building ethical generative AI systems that avoid producing private, toxic, illegal, or copyrighted content. Despite rapid progress, in this work we show that \\textit{almost all} existing unlearning methods fail to achieve true forgetting in practice. Specifically, while evaluations of these `unlearned' models under deterministic (greedy) decoding often suggest successful knowledge removal using standard benchmarks (as has been done in the literature), we show that sensitive information reliably resurfaces when models are sampled with standard probabilistic decoding. To rigorously capture this vulnerability, we introduce \\texttt{leak@$k$}, a new meta-evaluation metric that quantifies the likelihood of forgotten knowledge reappearing when generating $k$ samples from the model under realistic decoding strategies. Using three widely adopted benchmarks, TOFU, MUSE, and WMDP, we conduct the first large-scale, systematic study of unlearning reliability using our newly defined \\texttt{leak@$k$} metric. Our findings demonstrate that knowledge leakage persists across methods and tasks, underscoring that current state-of-the-art unlearning techniques provide only limited forgetting and highlighting the urgent need for more robust approaches to LLM unlearning.",
    "fetched_at": "2025-11-11T02:19:10.036396Z"
  },
  {
    "id": "2511.04937v1",
    "title": "Structural Properties, Cycloid Trajectories and Non-Asymptotic   Guarantees of EM Algorithm for Mixed Linear Regression",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zhankun Luo",
      "Abolfazl Hashemi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04937v1",
    "abstract": "This work investigates the structural properties, cycloid trajectories, and non-asymptotic convergence guarantees of the Expectation-Maximization (EM) algorithm for two-component Mixed Linear Regression (2MLR) with unknown mixing weights and regression parameters. Recent studies have established global convergence for 2MLR with known balanced weights and super-linear convergence in noiseless and high signal-to-noise ratio (SNR) regimes. However, the theoretical behavior of EM in the fully unknown setting remains unclear, with its trajectory and convergence order not yet fully characterized. We derive explicit EM update expressions for 2MLR with unknown mixing weights and regression parameters across all SNR regimes and analyze their structural properties and cycloid trajectories. In the noiseless case, we prove that the trajectory of the regression parameters in EM iterations traces a cycloid by establishing a recurrence relation for the sub-optimality angle, while in high SNR regimes we quantify its discrepancy from the cycloid trajectory. The trajectory-based analysis reveals the order of convergence: linear when the EM estimate is nearly orthogonal to the ground truth, and quadratic when the angle between the estimate and ground truth is small at the population level. Our analysis establishes non-asymptotic guarantees by sharpening bounds on statistical errors between finite-sample and population EM updates, relating EM's statistical accuracy to the sub-optimality angle, and proving convergence with arbitrary initialization at the finite-sample level. This work provides a novel trajectory-based framework for analyzing EM in Mixed Linear Regression.",
    "fetched_at": "2025-11-11T02:19:10.036340Z"
  },
  {
    "id": "2511.04939v1",
    "title": "Search Is Not Retrieval: Decoupling Semantic Matching from Contextual   Assembly in RAG",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Harshit Nainwani",
      "Hediyeh Baban"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04939v1",
    "abstract": "Retrieval systems are essential to contemporary AI pipelines, although most confuse two separate processes: finding relevant information and giving enough context for reasoning. We introduce the Search-Is-Not-Retrieve (SINR) framework, a dual-layer architecture that distinguishes between fine-grained search representations and coarse-grained retrieval contexts. SINR enhances the composability, scalability, and context fidelity of retrieval systems by directly connecting small, semantically accurate search chunks to larger, contextually complete retrieve chunks, all without incurring extra processing costs. This design changes retrieval from a passive step to an active one, making the system architecture more like how people process information. We discuss the SINR framework's conceptual foundation, formal structure, implementation issues, and qualitative outcomes. This provides a practical foundation for the next generation of AI systems that use retrieval.",
    "fetched_at": "2025-11-11T02:19:10.036295Z"
  },
  {
    "id": "2511.04948v1",
    "title": "A benchmark multimodal oro-dental dataset for large vision-language   models",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Haoxin Lv",
      "Ijazul Haq",
      "Jin Du",
      "Jiaxin Ma",
      "Binnian Zhu",
      "Xiaobing Dang",
      "Chaoan Liang",
      "Ruxu Du",
      "Yingjie Zhang",
      "Muhammad Saqib"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04948v1",
    "abstract": "The advancement of artificial intelligence in oral healthcare relies on the availability of large-scale multimodal datasets that capture the complexity of clinical practice. In this paper, we present a comprehensive multimodal dataset, comprising 8775 dental checkups from 4800 patients collected over eight years (2018-2025), with patients ranging from 10 to 90 years of age. The dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual records, including diagnoses, treatment plans, and follow-up notes. The data were collected under standard ethical guidelines and annotated for benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks: classification of six oro-dental anomalies and generation of complete diagnostic reports from multimodal inputs. We compared the fine-tuned models with their base counterparts and GPT-4o. The fine-tuned models achieved substantial gains over these baselines, validating the dataset and underscoring its effectiveness in advancing AI-driven oro-dental healthcare solutions. The dataset is publicly available, providing an essential resource for future research in AI dentistry.",
    "fetched_at": "2025-11-11T02:19:10.036256Z"
  },
  {
    "id": "2511.04952v1",
    "title": "LoPT: Lossless Parallel Tokenization Acceleration for Long Context   Inference of Large Language Model",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Wei Shao",
      "Lingchao Zheng",
      "Pengyu Wang",
      "Peizhen Zheng",
      "Jun Li",
      "Yuwei Fan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04952v1",
    "abstract": "Long context inference scenarios have become increasingly important for large language models, yet they introduce significant computational latency. While prior research has optimized long-sequence inference through operators, model architectures, and system frameworks, tokenization remains an overlooked bottleneck. Existing parallel tokenization methods accelerate processing through text segmentation and multi-process tokenization, but they suffer from inconsistent results due to boundary artifacts that occur after merging. To address this, we propose LoPT, a novel Lossless Parallel Tokenization framework that ensures output identical to standard sequential tokenization. Our approach employs character-position-based matching and dynamic chunk length adjustment to align and merge tokenized segments accurately. Extensive experiments across diverse long-text datasets demonstrate that LoPT achieves significant speedup while guaranteeing lossless tokenization. We also provide theoretical proof of consistency and comprehensive analytical studies to validate the robustness of our method.",
    "fetched_at": "2025-11-11T02:19:10.036137Z"
  },
  {
    "id": "2511.04962v1",
    "title": "Too Good to be Bad: On the Failure of LLMs to Role-Play Villains",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zihao Yi",
      "Qingxuan Jiang",
      "Ruotian Ma",
      "Xingyu Chen",
      "Qu Yang",
      "Mengru Wang",
      "Fanghua Ye",
      "Ying Shen",
      "Zhaopeng Tu",
      "Xiaolong Li",
      "Linus"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04962v1",
    "abstract": "Large Language Models (LLMs) are increasingly tasked with creative generation, including the simulation of fictional characters. However, their ability to portray non-prosocial, antagonistic personas remains largely unexamined. We hypothesize that the safety alignment of modern LLMs creates a fundamental conflict with the task of authentically role-playing morally ambiguous or villainous characters. To investigate this, we introduce the Moral RolePlay benchmark, a new dataset featuring a four-level moral alignment scale and a balanced test set for rigorous evaluation. We task state-of-the-art LLMs with role-playing characters from moral paragons to pure villains. Our large-scale evaluation reveals a consistent, monotonic decline in role-playing fidelity as character morality decreases. We find that models struggle most with traits directly antithetical to safety principles, such as ``Deceitful'' and ``Manipulative'', often substituting nuanced malevolence with superficial aggression. Furthermore, we demonstrate that general chatbot proficiency is a poor predictor of villain role-playing ability, with highly safety-aligned models performing particularly poorly. Our work provides the first systematic evidence of this critical limitation, highlighting a key tension between model safety and creative fidelity. Our benchmark and findings pave the way for developing more nuanced, context-aware alignment methods.",
    "fetched_at": "2025-11-11T02:19:10.036015Z"
  },
  {
    "id": "2511.04963v1",
    "title": "Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and   Microstructural Refinement",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xiongri Shen",
      "Jiaqi Wang",
      "Yi Zhong",
      "Zhenxi Song",
      "Leilei Zhao",
      "Yichen Wei",
      "Lingyan Liang",
      "Shuqiang Wang",
      "Baiying Lei",
      "Demao Deng",
      "Zhiguo Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04963v1",
    "abstract": "Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and diffusion MRI (dMRI), is essential for studying neurodegenerative diseases. However, missing modalities pose a major barrier to their clinical use. Although GAN- and diffusion model-based approaches have shown some promise in modality completion, they remain limited in fMRI-dMRI synthesis due to (1) significant BOLD vs. diffusion-weighted signal differences between fMRI and dMRI in time/gradient axis, and (2) inadequate integration of disease-related neuroanatomical patterns during generation. To address these challenges, we propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D diffusion framework for cross-modality learning, and (2) a tissue refinement network integrated with a efficient microstructure refinement to maintain structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house datasets, our method achieves state-of-the-art results, with PSNR/SSIM scores of 29.83 dB/90.84\\% for fMRI synthesis (+1.54 dB/+4.12\\% over baselines) and 30.00 dB/77.55\\% for dMRI synthesis (+1.02 dB/+2.2\\%). In clinical validation, the synthesized data show strong diagnostic performance, achieving 67.92\\%/66.02\\%/64.15\\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic experiments. Code is available in \\href{https://github.com/SXR3015/PDS}{PDS GitHub Repository}",
    "fetched_at": "2025-11-11T02:19:10.035940Z"
  },
  {
    "id": "2511.04970v1",
    "title": "Learning Fourier shapes to probe the geometric world of deep neural   networks",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jian Wang",
      "Yixing Yong",
      "Haixia Bi",
      "Lijun He",
      "Fan Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04970v1",
    "abstract": "While both shape and texture are fundamental to visual recognition, research on deep neural networks (DNNs) has predominantly focused on the latter, leaving their geometric understanding poorly probed. Here, we show: first, that optimized shapes can act as potent semantic carriers, generating high-confidence classifications from inputs defined purely by their geometry; second, that they are high-fidelity interpretability tools that precisely isolate a model's salient regions; and third, that they constitute a new, generalizable adversarial paradigm capable of deceiving downstream visual tasks. This is achieved through an end-to-end differentiable framework that unifies a powerful Fourier series to parameterize arbitrary shapes, a winding number-based mapping to translate them into the pixel grid required by DNNs, and signal energy constraints that enhance optimization efficiency while ensuring physically plausible shapes. Our work provides a versatile framework for probing the geometric world of DNNs and opens new frontiers for challenging and understanding machine perception.",
    "fetched_at": "2025-11-11T02:19:10.035850Z"
  },
  {
    "id": "2511.04971v1",
    "title": "Risk Prediction of Cardiovascular Disease for Diabetic Patients with   Machine Learning and Deep Learning Techniques",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Esha Chowdhury"
    ],
    "institution": "Dhaka University of Engineering & Technology Gazipur, Bangladesh",
    "link": "http://arxiv.org/pdf/2511.04971v1",
    "abstract": "Accurate prediction of cardiovascular disease (CVD) risk is crucial for healthcare institutions. This study addresses the growing prevalence of diabetes and its strong link to heart disease by proposing an efficient CVD risk prediction model for diabetic patients using machine learning (ML) and hybrid deep learning (DL) approaches. The BRFSS dataset was preprocessed by removing duplicates, handling missing values, identifying categorical and numerical features, and applying Principal Component Analysis (PCA) for feature extraction. Several ML models, including Decision Trees (DT), Random Forest (RF), k-Nearest Neighbors (KNN), Support Vector Machine (SVM), AdaBoost, and XGBoost, were implemented, with XGBoost achieving the highest accuracy of 0.9050. Various DL models, such as Artificial Neural Networks (ANN), Deep Neural Networks (DNN), Recurrent Neural Networks (RNN), Convolutional Neural Networks (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), and Gated Recurrent Unit (GRU), as well as hybrid models combining CNN with LSTM, BiLSTM, and GRU, were also explored. Some of these models achieved perfect recall (1.00), with the LSTM model achieving the highest accuracy of 0.9050. Our research highlights the effectiveness of ML and DL models in predicting CVD risk among diabetic patients, automating and enhancing clinical decision-making. High accuracy and F1 scores demonstrate these models' potential to improve personalized risk management and preventive strategies.",
    "fetched_at": "2025-11-11T02:19:10.035798Z"
  },
  {
    "id": "2511.04973v1",
    "title": "Less Is More: Generating Time Series with LLaMA-Style Autoregression in   Simple Factorized Latent Spaces",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Siyuan Li",
      "Yifan Sun",
      "Lei Cheng",
      "Lewen Wang",
      "Yang Liu",
      "Weiqing Liu",
      "Jianlong Li",
      "Jiang Bian",
      "Shikai Fang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04973v1",
    "abstract": "Generative models for multivariate time series are essential for data augmentation, simulation, and privacy preservation, yet current state-of-the-art diffusion-based approaches are slow and limited to fixed-length windows. We propose FAR-TS, a simple yet effective framework that combines disentangled factorization with an autoregressive Transformer over a discrete, quantized latent space to generate time series. Each time series is decomposed into a data-adaptive basis that captures static cross-channel correlations and temporal coefficients that are vector-quantized into discrete tokens. A LLaMA-style autoregressive Transformer then models these token sequences, enabling fast and controllable generation of sequences with arbitrary length. Owing to its streamlined design, FAR-TS achieves orders-of-magnitude faster generation than Diffusion-TS while preserving cross-channel correlations and an interpretable latent space, enabling high-quality and flexible time series synthesis.",
    "fetched_at": "2025-11-11T02:19:10.035770Z"
  },
  {
    "id": "2511.04979v1",
    "title": "Scaling Up ROC-Optimizing Support Vector Machines",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "stat.CO",
      "CO",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Gimun Bae",
      "Seung Jun Shin"
    ],
    "institution": "Department of Statistics, Korea University, Seoul, Republic of Korea",
    "link": "http://arxiv.org/pdf/2511.04979v1",
    "abstract": "The ROC-SVM, originally proposed by Rakotomamonjy, directly maximizes the area under the ROC curve (AUC) and has become an attractive alternative of the conventional binary classification under the presence of class imbalance. However, its practical use is limited by high computational cost, as training involves evaluating all $O(n^2)$. To overcome this limitation, we develop a scalable variant of the ROC-SVM that leverages incomplete U-statistics, thereby substantially reducing computational complexity. We further extend the framework to nonlinear classification through a low-rank kernel approximation, enabling efficient training in reproducing kernel Hilbert spaces. Theoretical analysis establishes an error bound that justifies the proposed approximation, and empirical results on both synthetic and real datasets demonstrate that the proposed method achieves comparable AUC performance to the original ROC-SVM with drastically reduced training time.",
    "fetched_at": "2025-11-11T02:19:10.035708Z"
  },
  {
    "id": "2511.04980v1",
    "title": "Unlocking the Black Box: A Five-Dimensional Framework for Evaluating   Explainable AI in Credit Risk",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rongbin Ye",
      "Jiaqi Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04980v1",
    "abstract": "The financial industry faces a significant challenge modeling and risk portfolios: balancing the predictability of advanced machine learning models, neural network models, and explainability required by regulatory entities (such as Office of the Comptroller of the Currency, Consumer Financial Protection Bureau). This paper intends to fill the gap in the application between these \"black box\" models and explainability frameworks, such as LIME and SHAP. Authors elaborate on the application of these frameworks on different models and demonstrates the more complex models with better prediction powers could be applied and reach the same level of the explainability, using SHAP and LIME. Beyond the comparison and discussion of performances, this paper proposes a novel five dimensional framework evaluating Inherent Interpretability, Global Explanations, Local Explanations, Consistency, and Complexity to offer a nuanced method for assessing and comparing model explainability beyond simple accuracy metrics. This research demonstrates the feasibility of employing sophisticated, high performing ML models in regulated financial environments by utilizing modern explainability techniques and provides a structured approach to evaluate the crucial trade offs between model performance and interpretability.",
    "fetched_at": "2025-11-11T02:19:10.035676Z"
  },
  {
    "id": "2511.04981v1",
    "title": "Deep Progressive Training: scaling up depth capacity of zero/one-layer   models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zhiqi Bu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04981v1",
    "abstract": "Model depth is a double-edged sword in deep learning: deeper models achieve higher accuracy but require higher computational cost. To efficiently train models at scale, an effective strategy is the progressive training, which scales up model capacity during training, hence significantly reducing computation with little to none performance degradation. In this work, we study the depth expansion of large models through the lens of optimization theory and feature learning, offering insights on the initialization of new layers, hyperparameter transfer, learning rate schedule, and timing of model expansion. Specifically, we propose zero/one-layer progressive training for the optimal tradeoff between computation and loss. For example, zero/one-layer progressive training on GPT2 can save $\\approx 80\\%$ compute, or equivalently accelerate $\\approx 5\\times$ while achieving almost the same loss, compared to to a fully trained 60-layer model with 7B parameters.",
    "fetched_at": "2025-11-11T02:19:10.035631Z"
  },
  {
    "id": "2511.04983v1",
    "title": "Predicting Cognitive Assessment Scores in Older Adults with Cognitive   Impairment Using Wearable Sensors",
    "date": "2025-11-07",
    "tags": [
      "q-bio.NC",
      "NC",
      "cs.LG",
      "LG",
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Assma Habadi",
      "Milos Zefran",
      "Lijuan Yin",
      "Woojin Song",
      "Maria Caceres",
      "Elise Hu",
      "Naoko Muramatsu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04983v1",
    "abstract": "Background and Objectives: This paper focuses on using AI to assess the cognitive function of older adults with mild cognitive impairment or mild dementia using physiological data provided by a wearable device. Cognitive screening tools are disruptive, time-consuming, and only capture brief snapshots of activity. Wearable sensors offer an attractive alternative by continuously monitoring physiological signals. This study investigated whether physiological data can accurately predict scores on established cognitive tests. Research Design and Methods: We recorded physiological signals from 23 older adults completing three NIH Toolbox Cognitive Battery tests, which assess working memory, processing speed, and attention. The Empatica EmbracePlus, a wearable device, measured blood volume pulse, skin conductance, temperature, and movement. Statistical features were extracted using wavelet-based and segmentation methods. We then applied supervised learning and validated predictions via cross-validation, hold-out testing, and bootstrapping. Results: Our models showed strong performance with Spearman's \\rho of 0.73-0.82 and mean absolute errors of 0.14-0.16, significantly outperforming a naive mean predictor. Sensor roles varied: heart-related signals combined with movement and temperature best predicted working memory, movement paired with skin conductance was most informative for processing speed, and heart in tandem with skin conductance worked best for attention. Discussion and Implications: These findings suggest that wearable sensors paired with AI tools such as supervised learning and feature engineering can noninvasively track specific cognitive functions in older adults, enabling continuous monitoring. Our study demonstrates how AI can be leveraged when the data sample is small. This approach may support remote assessments and facilitate clinical interventions.",
    "fetched_at": "2025-11-11T02:19:10.035596Z"
  },
  {
    "id": "2511.04984v1",
    "title": "Peptide2Mol: A Diffusion Model for Generating Small Molecules as Peptide   Mimics for Targeted Protein Binding",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinheng He",
      "Yijia Zhang",
      "Haowei Lin",
      "Xingang Peng",
      "Xiangzhe Kong",
      "Mingyu Li",
      "Jianzhu Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04984v1",
    "abstract": "Structure-based drug design has seen significant advancements with the integration of artificial intelligence (AI), particularly in the generation of hit and lead compounds. However, most AI-driven approaches neglect the importance of endogenous protein interactions with peptides, which may result in suboptimal molecule designs. In this work, we present Peptide2Mol, an E(3)-equivariant graph neural network diffusion model that generates small molecules by referencing both the original peptide binders and their surrounding protein pocket environments. Trained on large datasets and leveraging sophisticated modeling techniques, Peptide2Mol not only achieves state-of-the-art performance in non-autoregressive generative tasks, but also produces molecules with similarity to the original peptide binder. Additionally, the model allows for molecule optimization and peptidomimetic design through a partial diffusion process. Our results highlight Peptide2Mol as an effective deep generative model for generating and optimizing bioactive small molecules from protein binding pockets.",
    "fetched_at": "2025-11-11T02:19:10.035531Z"
  },
  {
    "id": "2511.04988v1",
    "title": "Carbon Price Forecasting with Structural Breaks: A Comparative Study of   Deep Learning Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Runsheng Ren",
      "Jing Li",
      "Yanxiu Li",
      "Shixun Huang",
      "Jun Shen",
      "Wanqing Li",
      "John Le",
      "Sheng Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04988v1",
    "abstract": "Accurately forecasting carbon prices is essential for informed energy market decision-making, guiding sustainable energy planning, and supporting effective decarbonization strategies. However, it remains challenging due to structural breaks and high-frequency noise caused by frequent policy interventions and market shocks. Existing studies, including the most recent baseline approaches, have attempted to incorporate breakpoints but often treat denoising and modeling as separate processes and lack systematic evaluation across advanced deep learning architectures, limiting the robustness and the generalization capability. To address these gaps, this paper proposes a comprehensive hybrid framework that integrates structural break detection (Bai-Perron, ICSS, and PELT algorithms), wavelet signal denoising, and three state-of-the-art deep learning models (LSTM, GRU, and TCN). Using European Union Allowance (EUA) spot prices from 2007 to 2024 and exogenous features such as energy prices and policy indicators, the framework constructs univariate and multivariate datasets for comparative evaluation. Experimental results demonstrate that our proposed PELT-WT-TCN achieves the highest prediction accuracy, reducing forecasting errors by 22.35% in RMSE and 18.63% in MAE compared to the state-of-the-art baseline model (Breakpoints with Wavelet and LSTM), and by 70.55% in RMSE and 74.42% in MAE compared to the original LSTM without decomposition from the same baseline study. These findings underscore the value of integrating structural awareness and multiscale decomposition into deep learning architectures to enhance accuracy and interpretability in carbon price forecasting and other nonstationary financial time series.",
    "fetched_at": "2025-11-11T02:19:10.035471Z"
  },
  {
    "id": "2511.04989v1",
    "title": "Acquiring Common Chinese Emotional Events Using Large Language Model",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ya Wang",
      "Guangzheng Zhu",
      "Cungen Cao",
      "Jingjing Li",
      "He Li",
      "Xin Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04989v1",
    "abstract": "Knowledge about emotional events is an important kind of knowledge which has been applied to improve the effectiveness of different applications. However, emotional events cannot be easily acquired, especially common or generalized emotional events that are context-independent. The goal of this paper is to obtain common emotional events in Chinese language such as \"win a prize\" and \"be criticized\". Our approach begins by collecting a comprehensive list of Chinese emotional event indicators. Then, we generate emotional events by prompting a Chinese large language model (LLM) using these indicators. To ensure the quality of these emotional events, we train a filter to discard invalid generated results. We also classify these emotional events as being positive events and negative events using different techniques. Finally, we harvest a total of 102,218 high-quality common emotional events with sentiment polarity labels, which is the only large-scale commonsense knowledge base of emotional events in Chinese language. Intrinsic evaluation results show that the proposed method in this paper can be effectively used to acquire common Chinese emotional events. An extrinsic use case also demonstrates the strong potential of common emotional events in the field of emotion cause extraction (ECE). Related resources including emotional event indicators and emotional events will be released after the publication of this paper.",
    "fetched_at": "2025-11-11T02:19:10.035402Z"
  },
  {
    "id": "2511.04995v1",
    "title": "Enhancing Public Speaking Skills in Engineering Students Through AI",
    "date": "2025-11-07",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Amol Harsh",
      "Brainerd Prince",
      "Siddharth Siddharth",
      "Deepan Raj Prabakar Muthirayan",
      "Kabir S Bhalla",
      "Esraaj Sarkar Gupta",
      "Siddharth Sahu"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.04995v1",
    "abstract": "This research-to-practice full paper was inspired by the persistent challenge in effective communication among engineering students. Public speaking is a necessary skill for future engineers as they have to communicate technical knowledge with diverse stakeholders. While universities offer courses or workshops, they are unable to offer sustained and personalized training to students. Providing comprehensive feedback on both verbal and non-verbal aspects of public speaking is time-intensive, making consistent and individualized assessment impractical. This study integrates research on verbal and non-verbal cues in public speaking to develop an AI-driven assessment model for engineering students. Our approach combines speech analysis, computer vision, and sentiment detection into a multi-modal AI system that provides assessment and feedback. The model evaluates (1) verbal communication (pitch, loudness, pacing, intonation), (2) non-verbal communication (facial expressions, gestures, posture), and (3) expressive coherence, a novel integration ensuring alignment between speech and body language. Unlike previous systems that assess these aspects separately, our model fuses multiple modalities to deliver personalized, scalable feedback. Preliminary testing demonstrated that our AI-generated feedback was moderately aligned with expert evaluations. Among the state-of-the-art AI models evaluated, all of which were Large Language Models (LLMs), including Gemini and OpenAI models, Gemini Pro emerged as the best-performing, showing the strongest agreement with human annotators. By eliminating reliance on human evaluators, this AI-driven public speaking trainer enables repeated practice, helping students naturally align their speech with body language and emotion, crucial for impactful and professional communication.",
    "fetched_at": "2025-11-11T02:19:10.035344Z"
  },
  {
    "id": "2511.04998v1",
    "title": "BiPETE: A Bi-Positional Embedding Transformer Encoder for Risk   Assessment of Alcohol and Substance Use Disorder with Electronic Health   Records",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Daniel S. Lee",
      "Mayra S. Haedo-Cruz",
      "Chen Jiang",
      "Oshin Miranda",
      "LiRong Wang"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04998v1",
    "abstract": "Transformer-based deep learning models have shown promise for disease risk prediction using electronic health records(EHRs), but modeling temporal dependencies remains a key challenge due to irregular visit intervals and lack of uniform structure. We propose a Bi-Positional Embedding Transformer Encoder or BiPETE for single-disease prediction, which integrates rotary positional embeddings to encode relative visit timing and sinusoidal embeddings to preserve visit order. Without relying on large-scale pretraining, BiPETE is trained on EHR data from two mental health cohorts-depressive disorder and post-traumatic stress disorder (PTSD)-to predict the risk of alcohol and substance use disorders (ASUD). BiPETE outperforms baseline models, improving the area under the precision-recall curve (AUPRC) by 34% and 50% in the depression and PTSD cohorts, respectively. An ablation study further confirms the effectiveness of the dual positional encoding strategy. We apply the Integrated Gradients method to interpret model predictions, identifying key clinical features associated with ASUD risk and protection, such as abnormal inflammatory, hematologic, and metabolic markers, as well as specific medications and comorbidities. Overall, these key clinical features identified by the attribution methods contribute to a deeper understanding of the risk assessment process and offer valuable clues for mitigating potential risks. In summary, our study presents a practical and interpretable framework for disease risk prediction using EHR data, which can achieve strong performance.",
    "fetched_at": "2025-11-11T02:19:10.035280Z"
  },
  {
    "id": "2511.05000v1",
    "title": "Query Generation Pipeline with Enhanced Answerability Assessment for   Financial Information Retrieval",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hyunkyu Kim",
      "Yeeun Yoo",
      "Youngjun Kwak"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05000v1",
    "abstract": "As financial applications of large language models (LLMs) gain attention, accurate Information Retrieval (IR) remains crucial for reliable AI services. However, existing benchmarks fail to capture the complex and domain-specific information needs of real-world banking scenarios. Building domain-specific IR benchmarks is costly and constrained by legal restrictions on using real customer data. To address these challenges, we propose a systematic methodology for constructing domain-specific IR benchmarks through LLM-based query generation. As a concrete implementation of this methodology, our pipeline combines single and multi-document query generation with an enhanced and reasoning-augmented answerability assessment method, achieving stronger alignment with human judgments than prior approaches. Using this methodology, we construct KoBankIR, comprising 815 queries derived from 204 official banking documents. Our experiments show that existing retrieval models struggle with the complex multi-document queries in KoBankIR, demonstrating the value of our systematic approach for domain-specific benchmark construction and underscoring the need for improved retrieval techniques in financial domains.",
    "fetched_at": "2025-11-11T02:19:10.035223Z"
  },
  {
    "id": "2511.05017v1",
    "title": "Towards Mitigating Hallucinations in Large Vision-Language Models by   Refining Textual Embeddings",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Aakriti Agrawal",
      "Gouthaman KV",
      "Rohith Aralikatti",
      "Gauri Jagatap",
      "Jiaxin Yuan",
      "Vijay Kamarshi",
      "Andrea Fanelli",
      "Furong Huang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05017v1",
    "abstract": "In this work, we identify an inherent bias in prevailing LVLM architectures toward the language modality, largely resulting from the common practice of simply appending visual embeddings to the input text sequence. To address this, we propose a simple yet effective method that refines textual embeddings by integrating average-pooled visual features. Our approach demonstrably improves visual grounding and significantly reduces hallucinations on established benchmarks. While average pooling offers a straightforward, robust, and efficient means of incorporating visual information, we believe that more sophisticated fusion methods could further enhance visual grounding and cross-modal alignment. Given that the primary focus of this work is to highlight the modality imbalance and its impact on hallucinations -- and to show that refining textual embeddings with visual information mitigates this issue -- we leave exploration of advanced fusion strategies for future work.",
    "fetched_at": "2025-11-11T02:19:10.035130Z"
  },
  {
    "id": "2511.05018v1",
    "title": "Pluralistic Behavior Suite: Stress-Testing Multi-Turn Adherence to   Custom Behavioral Policies",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Prasoon Varshney",
      "Makesh Narsimhan Sreedhar",
      "Liwei Jiang",
      "Traian Rebedea",
      "Christopher Parisien"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05018v1",
    "abstract": "Large language models (LLMs) are typically aligned to a universal set of safety and usage principles intended for broad public acceptability. Yet, real-world applications of LLMs often take place within organizational ecosystems shaped by distinctive corporate policies, regulatory requirements, use cases, brand guidelines, and ethical commitments. This reality highlights the need for rigorous and comprehensive evaluation of LLMs with pluralistic alignment goals, an alignment paradigm that emphasizes adaptability to diverse user values and needs. In this work, we present PLURALISTIC BEHAVIOR SUITE (PBSUITE), a dynamic evaluation suite designed to systematically assess LLMs' capacity to adhere to pluralistic alignment specifications in multi-turn, interactive conversations. PBSUITE consists of (1) a diverse dataset of 300 realistic LLM behavioral policies, grounded in 30 industries; and (2) a dynamic evaluation framework for stress-testing model compliance with custom behavioral specifications under adversarial conditions. Using PBSUITE, We find that leading open- and closed-source LLMs maintain robust adherence to behavioral policies in single-turn settings (less than 4% failure rates), but their compliance weakens substantially in multi-turn adversarial interactions (up to 84% failure rates). These findings highlight that existing model alignment and safety moderation methods fall short in coherently enforcing pluralistic behavioral policies in real-world LLM interactions. Our work contributes both the dataset and analytical framework to support future research toward robust and context-aware pluralistic alignment techniques.",
    "fetched_at": "2025-11-11T02:19:10.035070Z"
  },
  {
    "id": "2511.05025v1",
    "title": "8bit-GPT: Exploring Human-AI Interaction on Obsolete Macintosh Operating   Systems",
    "date": "2025-11-07",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hala Sheta"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05025v1",
    "abstract": "The proliferation of assistive chatbots offering efficient, personalized communication has driven widespread over-reliance on them for decision-making, information-seeking and everyday tasks. This dependence was found to have adverse consequences on information retention as well as lead to superficial emotional attachment. As such, this work introduces 8bit-GPT; a language model simulated on a legacy Macintosh Operating System, to evoke reflection on the nature of Human-AI interaction and the consequences of anthropomorphic rhetoric. Drawing on reflective design principles such as slow-technology and counterfunctionality, this work aims to foreground the presence of chatbots as a tool by defamiliarizing the interface and prioritizing inefficient interaction, creating a friction between the familiar and not.",
    "fetched_at": "2025-11-11T02:19:10.035011Z"
  },
  {
    "id": "2511.05028v1",
    "title": "OvA-LP: A Simple and Efficient Framework for Federated Learning on   Non-IID Data",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Dongjin Park",
      "Hasung Yeo",
      "Joon-Woo Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05028v1",
    "abstract": "Federated fine-tuning (FFT) adapts foundation models to decentralized data but remains fragile under heterogeneous client distributions due to local drift, i.e., client-level update divergences that induce systematic bias and amplified variance in the global model. Existing aggregation and personalization methods largely correct drift post hoc, which proves brittle under extreme non-IID conditions. We introduce OvA-LP, a minimalist framework that is, to our knowledge, the first explicitly designed to suppress drift at its source within the PEFT-based FFT paradigm. OvA-LP combines linear probing on a frozen encoder with a one-vs-all head and a simple two-stage procedure, preserving pretrained feature geometry and decoupling logits to prevent the mechanisms that amplify drift. On CIFAR-100 with 100 clients, averaged over shard-1, shard-2, and Bernoulli-Dirichlet partitions, OvA-LP retains 95.9% of its IID accuracy, whereas state-of-the-art FFT baselines retain only 10.1% (PFPT) and 34.5% (FFT-MoE) under the same conditions. OvA-LP further maintains resilience under both symmetric and asymmetric label noise. In addition, precomputing encoder features makes per-round cost nearly independent of encoder size. Together, these results demonstrate that OvA-LP provides a principled and efficient basis for robust FFT under heterogeneity.",
    "fetched_at": "2025-11-11T02:19:10.034976Z"
  },
  {
    "id": "2511.05034v1",
    "title": "Dynamic Residual Encoding with Slide-Level Contrastive Learning for   End-to-End Whole Slide Image Representation",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "I.4.9; I.2.10",
      "10"
    ],
    "authors": [
      "Jing Jin",
      "Xu Liu",
      "Te Gao",
      "Zhihong Shi",
      "Yixiong Liang",
      "Ruiqing Zheng",
      "Hulin Kuang",
      "Min Zeng",
      "Shichao Kan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05034v1",
    "abstract": "Whole Slide Image (WSI) representation is critical for cancer subtyping, cancer recognition and mutation prediction.Training an end-to-end WSI representation model poses significant challenges, as a standard gigapixel slide can contain tens of thousands of image tiles, making it difficult to compute gradients of all tiles in a single mini-batch due to current GPU limitations. To address this challenge, we propose a method of dynamic residual encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI representation. Our approach utilizes a memory bank to store the features of tiles across all WSIs in the dataset. During training, a mini-batch usually contains multiple WSIs. For each WSI in the batch, a subset of tiles is randomly sampled and their features are computed using a tile encoder. Then, additional tile features from the same WSI are selected from the memory bank. The representation of each individual WSI is generated using a residual encoding technique that incorporates both the sampled features and those retrieved from the memory bank. Finally, the slide-level contrastive loss is computed based on the representations and histopathology reports ofthe WSIs within the mini-batch. Experiments conducted over cancer subtyping, cancer recognition, and mutation prediction tasks proved the effectiveness of the proposed DRE-SLCL method.",
    "fetched_at": "2025-11-11T02:19:10.034928Z"
  },
  {
    "id": "2511.05039v1",
    "title": "PECL: A Heterogeneous Parallel Multi-Domain Network for Radar-Based   Human Activity Recognition",
    "date": "2025-11-07",
    "tags": [
      "eess.SP",
      "SP",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiuqi Yan",
      "Chendong Xu",
      "Dongyu Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05039v1",
    "abstract": "Radar systems are increasingly favored for medical applications because they provide non-intrusive monitoring with high privacy and robustness to lighting conditions. However, existing research typically relies on single-domain radar signals and overlooks the temporal dependencies inherent in human activity, which complicates the classification of similar actions. To address this issue, we designed the Parallel-EfficientNet-CBAM-LSTM (PECL) network to process data in three complementary domains: Range-Time, Doppler-Time, and Range-Doppler. PECL combines a channel-spatial attention module and temporal units to capture more features and dynamic dependencies during action sequences, improving both accuracy and robustness. The experimental results show that PECL achieves an accuracy of 96.16% on the same dataset, outperforming existing methods by at least 4.78%. PECL also performs best in distinguishing between easily confused actions. Despite its strong performance, PECL maintains moderate model complexity, with 23.42M parameters and 1324.82M FLOPs. Its parameter-efficient design further reduces computational cost.",
    "fetched_at": "2025-11-11T02:19:10.034845Z"
  },
  {
    "id": "2511.05040v1",
    "title": "UA-Code-Bench: A Competitive Programming Benchmark for Evaluating LLM   Code Generation in Ukrainian",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Mykyta Syromiatnikov",
      "Victoria Ruvinskaya"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.05040v1",
    "abstract": "Evaluating the real capabilities of large language models in low-resource languages still represents a challenge, as many existing benchmarks focus on widespread tasks translated from English or evaluate only simple language understanding. This paper introduces UA-Code-Bench, a new open-source benchmark established for a thorough evaluation of language models' code generation and competitive programming problem-solving abilities in Ukrainian. The benchmark comprises 500 problems from the Eolymp platform, evenly distributed across five complexity levels from very easy to very hard. A diverse set of 13 leading proprietary and open-source models, generating Python solutions based on a one-shot prompt, was evaluated via the dedicated Eolymp environment against hidden tests, ensuring code correctness. The obtained results reveal that even top-performing models, such as OpenAI o3 and GPT-5, solve only half of the problems, highlighting the challenge of code generation in low-resource natural language. Furthermore, this research presents a comprehensive analysis of performance across various difficulty levels, as well as an assessment of solution uniqueness and computational efficiency, measured by both elapsed time and memory consumption of the generated solutions. In conclusion, this work demonstrates the value of competitive programming benchmarks in evaluating large language models, especially in underrepresented languages. It also paves the way for future research on multilingual code generation and reasoning-enhanced models. The benchmark, data parsing, preparation, code generation, and evaluation scripts are available at https://huggingface.co/datasets/NLPForUA/ua-code-bench.",
    "fetched_at": "2025-11-11T02:19:10.034800Z"
  },
  {
    "id": "2511.05050v1",
    "title": "Estimating Bidirectional Causal Effects with Large Scale Online Kernel   Learning",
    "date": "2025-11-07",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.ME",
      "ME"
    ],
    "authors": [
      "Masahiro Tanaka"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05050v1",
    "abstract": "In this study, a scalable online kernel learning framework is proposed for estimating bidirectional causal effects in systems characterized by mutual dependence and heteroskedasticity. Traditional causal inference often focuses on unidirectional effects, overlooking the common bidirectional relationships in real-world phenomena. Building on heteroskedasticity-based identification, the proposed method integrates a quasi-maximum likelihood estimator for simultaneous equation models with large scale online kernel learning. It employs random Fourier feature approximations to flexibly model nonlinear conditional means and variances, while an adaptive online gradient descent algorithm ensures computational efficiency for streaming and high-dimensional data. Results from extensive simulations demonstrate that the proposed method achieves superior accuracy and stability than single equation and polynomial approximation baselines, exhibiting lower bias and root mean squared error across various data-generating processes. These results confirm that the proposed approach effectively captures complex bidirectional causal effects with near-linear computational scaling. By combining econometric identification with modern machine learning techniques, the proposed framework offers a practical, scalable, and theoretically grounded solution for large scale causal inference in natural/social science, policy making, business, and industrial applications.",
    "fetched_at": "2025-11-11T02:19:10.034752Z"
  },
  {
    "id": "2511.05053v1",
    "title": "Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V   GPUs",
    "date": "2025-11-07",
    "tags": [
      "cs.DC",
      "DC",
      "cs.AI",
      "AI",
      "cs.GR",
      "GR"
    ],
    "authors": [
      "Wakuto Matsumi",
      "Riaz-Ul-Haque Mian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05053v1",
    "abstract": "Machine learning based on neural networks has advanced rapidly, but the high energy consumption required for training and inference remains a major challenge. Hyperdimensional Computing (HDC) offers a lightweight, brain-inspired alternative that enables high parallelism but often suffers from lower accuracy on complex visual tasks. To overcome this, hybrid accelerators combining HDC and Convolutional Neural Networks (CNNs) have been proposed, though their adoption is limited by poor generalizability and programmability. The rise of open-source RISC-V architectures has created new opportunities for domain-specific GPU design. Unlike traditional proprietary GPUs, emerging RISC-V-based GPUs provide flexible, programmable platforms suitable for custom computation models such as HDC. In this study, we design and implement custom GPU instructions optimized for HDC operations, enabling efficient processing for hybrid HDC-CNN workloads. Experimental results using four types of custom HDC instructions show a performance improvement of up to 56.2 times in microbenchmark tests, demonstrating the potential of RISC-V GPUs for energy-efficient, high-performance computing.",
    "fetched_at": "2025-11-11T02:19:10.034709Z"
  },
  {
    "id": "2511.05055v1",
    "title": "No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware   Test-Time Adaptation for Monocular Depth Estimation",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mingyu Sung",
      "Hyeonmin Choe",
      "Il-Min Kim",
      "Sangseok Yun",
      "Jae Mo Kang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05055v1",
    "abstract": "Monocular depth estimation (MDE), inferring pixel-level depths in single RGB images from a monocular camera, plays a crucial and pivotal role in a variety of AI applications demanding a three-dimensional (3D) topographical scene. In the real-world scenarios, MDE models often need to be deployed in environments with different conditions from those for training. Test-time (domain) adaptation (TTA) is one of the compelling and practical approaches to address the issue. Although there have been notable advancements in TTA for MDE, particularly in a self-supervised manner, existing methods are still ineffective and problematic when applied to diverse and dynamic environments. To break through this challenge, we propose a novel and high-performing TTA framework for MDE, named PITTA. Our approach incorporates two key innovative strategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware image masking. Specifically, PITTA enables highly effective TTA on a pretrained MDE network in a pose-agnostic manner without resorting to any camera pose information. Besides, our instance-aware masking strategy extracts instance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.) from a segmentation mask produced by a pretrained panoptic segmentation network, by removing static objects including background components. To further boost performance, we also present a simple yet effective edge extraction methodology for the input image (i.e., a single monocular image) and depth map. Extensive experimental evaluations on DrivingStereo and Waymo datasets with varying environmental conditions demonstrate that our proposed framework, PITTA, surpasses the existing state-of-the-art techniques with remarkable performance improvements in MDE during TTA.",
    "fetched_at": "2025-11-11T02:19:10.034663Z"
  },
  {
    "id": "2511.05064v1",
    "title": "Order-Level Attention Similarity Across Language Models: A Latent   Commonality",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jinglin Liang",
      "Jin Zhong",
      "Shuangping Huang",
      "Yunqing Hu",
      "Huiyuan Zhang",
      "Huifang Li",
      "Lixin Fan",
      "Hanlin Gu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05064v1",
    "abstract": "In this paper, we explore an important yet previously neglected question: Do context aggregation patterns across Language Models (LMs) share commonalities? While some works have investigated context aggregation or attention weights in LMs, they typically focus on individual models or attention heads, lacking a systematic analysis across multiple LMs to explore their commonalities. In contrast, we focus on the commonalities among LMs, which can deepen our understanding of LMs and even facilitate cross-model knowledge transfer. In this work, we introduce the Order-Level Attention (OLA) derived from the order-wise decomposition of Attention Rollout and reveal that the OLA at the same order across LMs exhibits significant similarities. Furthermore, we discover an implicit mapping between OLA and syntactic knowledge. Based on these two findings, we propose the Transferable OLA Adapter (TOA), a training-free cross-LM adapter transfer method. Specifically, we treat the OLA as a unified syntactic feature representation and train an adapter that takes OLA as input. Due to the similarities in OLA across LMs, the adapter generalizes to unseen LMs without requiring any parameter updates. Extensive experiments demonstrate that TOA's cross-LM generalization effectively enhances the performance of unseen LMs. Code is available at https://github.com/jinglin-liang/OLAS.",
    "fetched_at": "2025-11-11T02:19:10.034606Z"
  },
  {
    "id": "2511.05073v1",
    "title": "Deep learning models are vulnerable, but adversarial examples are even   more vulnerable",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jun Li",
      "Yanwei Xu",
      "Keran Li",
      "Xiaoli Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05073v1",
    "abstract": "Understanding intrinsic differences between adversarial examples and clean samples is key to enhancing DNN robustness and detection against adversarial attacks. This study first empirically finds that image-based adversarial examples are notably sensitive to occlusion. Controlled experiments on CIFAR-10 used nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples, paired with original samples for evaluation. We introduce Sliding Mask Confidence Entropy (SMCE) to quantify model confidence fluctuation under occlusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy Field Maps and statistical distributions show adversarial examples have significantly higher confidence volatility under occlusion than originals. Based on this, we propose Sliding Window Mask-based Adversarial Example Detection (SWM-AED), which avoids catastrophic overfitting of conventional adversarial training. Evaluations across classifiers and attacks on CIFAR-10 demonstrate robust performance, with accuracy over 62% in most cases and up to 96.5%.",
    "fetched_at": "2025-11-11T02:19:10.034542Z"
  },
  {
    "id": "2511.05078v1",
    "title": "Reasoning-Guided Claim Normalization for Noisy Multilingual Social Media   Posts",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Manan Sharma",
      "Arya Suneesh",
      "Manish Jain",
      "Pawan Kumar Rajpoot",
      "Prasanna Devadiga",
      "Bharatdeep Hazarika",
      "Ashish Shrivastava",
      "Kishan Gurumurthy",
      "Anshuman B Suresh",
      "Aditya U Baliga"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05078v1",
    "abstract": "We address claim normalization for multilingual misinformation detection - transforming noisy social media posts into clear, verifiable statements across 20 languages. The key contribution demonstrates how systematic decomposition of posts using Who, What, Where, When, Why and How questions enables robust cross-lingual transfer despite training exclusively on English data. Our methodology incorporates finetuning Qwen3-14B using LoRA with the provided dataset after intra-post deduplication, token-level recall filtering for semantic alignment and retrieval-augmented few-shot learning with contextual examples during inference. Our system achieves METEOR scores ranging from 41.16 (English) to 15.21 (Marathi), securing third rank on the English leaderboard and fourth rank for Dutch and Punjabi. The approach shows 41.3% relative improvement in METEOR over baseline configurations and substantial gains over existing methods. Results demonstrate effective cross-lingual generalization for Romance and Germanic languages while maintaining semantic coherence across diverse linguistic structures.",
    "fetched_at": "2025-11-11T02:19:10.034495Z"
  },
  {
    "id": "2511.05079v1",
    "title": "Wikipedia-based Datasets in Russian Information Retrieval Benchmark   RusBEIR",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Grigory Kovalev",
      "Natalia Loukachevitch",
      "Mikhail Tikhomirov",
      "Olga Babina",
      "Pavel Mamaev"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05079v1",
    "abstract": "In this paper, we present a novel series of Russian information retrieval datasets constructed from the \"Did you know...\" section of Russian Wikipedia. Our datasets support a range of retrieval tasks, including fact-checking, retrieval-augmented generation, and full-document retrieval, by leveraging interesting facts and their referenced Wikipedia articles annotated at the sentence level with graded relevance. We describe the methodology for dataset creation that enables the expansion of existing Russian Information Retrieval (IR) resources. Through extensive experiments, we extend the RusBEIR research by comparing lexical retrieval models, such as BM25, with state-of-the-art neural architectures fine-tuned for Russian, as well as multilingual models. Results of our experiments show that lexical methods tend to outperform neural models on full-document retrieval, while neural approaches better capture lexical semantics in shorter texts, such as in fact-checking or fine-grained retrieval. Using our newly created datasets, we also analyze the impact of document length on retrieval performance and demonstrate that combining retrieval with neural reranking consistently improves results. Our contribution expands the resources available for Russian information retrieval research and highlights the importance of accurate evaluation of retrieval models to achieve optimal performance. All datasets are publicly available at HuggingFace. To facilitate reproducibility and future research, we also release the full implementation on GitHub.",
    "fetched_at": "2025-11-11T02:19:10.034424Z"
  },
  {
    "id": "2511.05080v1",
    "title": "On Text Simplification Metrics and General-Purpose LLMs for Accessible   Health Information, and A Potential Architectural Advantage of The   Instruction-Tuned LLM class",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "P. Bilha Githinji",
      "Aikaterini Meilliou",
      "Peiwu Qin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05080v1",
    "abstract": "The increasing health-seeking behavior and digital consumption of biomedical information by the general public necessitate scalable solutions for automatically adapting complex scientific and technical documents into plain language. Automatic text simplification solutions, including advanced large language models, however, continue to face challenges in reliably arbitrating the tension between optimizing readability performance and ensuring preservation of discourse fidelity. This report empirically assesses the performance of two major classes of general-purpose LLMs, demonstrating their linguistic capabilities and foundational readiness for the task compared to a human benchmark. Using a comparative analysis of the instruction-tuned Mistral 24B and the reasoning-augmented QWen2.5 32B, we identify a potential architectural advantage in the instruction-tuned LLM. Mistral exhibits a tempered lexical simplification strategy that enhances readability across a suite of metrics and the simplification-specific formula SARI (mean 42.46), while preserving human-level discourse with a BERTScore of 0.91. QWen also attains enhanced readability performance, but its operational strategy shows a disconnect in balancing between readability and accuracy, reaching a statistically significantly lower BERTScore of 0.89. Additionally, a comprehensive correlation analysis of 21 metrics spanning readability, discourse fidelity, content safety, and underlying distributional measures for mechanistic insights, confirms strong functional redundancies among five readability indices. This empirical evidence tracks baseline performance of the evolving LLMs for the task of text simplification, identifies the instruction-tuned Mistral 24B for simplification, provides necessary heuristics for metric selection, and points to lexical support as a primary domain-adaptation issue for simplification.",
    "fetched_at": "2025-11-11T02:19:10.034370Z"
  },
  {
    "id": "2511.05085v1",
    "title": "Iterative Layer-wise Distillation for Efficient Compression of Large   Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Grigory Kovalev",
      "Mikhail Tikhomirov"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05085v1",
    "abstract": "This work investigates distillation methods for large language models (LLMs) with the goal of developing compact models that preserve high performance. Several existing approaches are reviewed, with a discussion of their respective strengths and limitations. An improved method based on the ShortGPT approach has been developed, building upon the idea of incorporating iterative evaluation of layer importance. At each step, importance is assessed by measuring performance degradation when individual layers are removed, using a set of representative datasets. This process is combined with further training using a joint loss function based on KL divergence and mean squared error. Experiments on the Qwen2.5-3B model show that the number of layers can be reduced from 36 to 28 (resulting in a 2.47 billion parameter model) with only a 9.7% quality loss, and to 24 layers with an 18% loss. The findings suggest that the middle transformer layers contribute less to inference, underscoring the potential of the proposed method for creating efficient models. The results demonstrate the effectiveness of iterative distillation and fine-tuning, making the approach suitable for deployment in resource-limited settings.",
    "fetched_at": "2025-11-11T02:19:10.034319Z"
  },
  {
    "id": "2511.05106v1",
    "title": "Early Alzheimer's Disease Detection from Retinal OCT Images: A UK   Biobank Study",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yasemin Turkan",
      "F. Boray Tek",
      "M. Serdar Nazl",
      "yk Eren"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05106v1",
    "abstract": "Alterations in retinal layer thickness, measurable using Optical Coherence Tomography (OCT), have been associated with neurodegenerative diseases such as Alzheimer's disease (AD). While previous studies have mainly focused on segmented layer thickness measurements, this study explored the direct classification of OCT B-scan images for the early detection of AD. To our knowledge, this is the first application of deep learning to raw OCT B-scans for AD prediction in the literature. Unlike conventional medical image classification tasks, early detection is more challenging than diagnosis because imaging precedes clinical diagnosis by several years. We fine-tuned and evaluated multiple pretrained models, including ImageNet-based networks and the OCT-specific RETFound transformer, using subject-level cross-validation datasets matched for age, sex, and imaging instances from the UK Biobank cohort. To reduce overfitting in this small, high-dimensional dataset, both standard and OCT-specific augmentation techniques were applied, along with a year-weighted loss function that prioritized cases diagnosed within four years of imaging. ResNet-34 produced the most stable results, achieving an AUC of 0.62 in the 4-year cohort. Although below the threshold for clinical application, our explainability analyses confirmed localized structural differences in the central macular subfield between the AD and control groups. These findings provide a baseline for OCT-based AD prediction, highlight the challenges of detecting subtle retinal biomarkers years before AD diagnosis, and point to the need for larger datasets and multimodal approaches.",
    "fetched_at": "2025-11-11T02:19:10.034278Z"
  },
  {
    "id": "2511.05114v1",
    "title": "Usando LLMs para Programar Jogos de Tabuleiro e Variaes",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "lvaro Guglielmin Becker",
      "Lana Bertoldo Rossato",
      "Anderson Rocha Tavares"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05114v1",
    "abstract": "Creating programs to represent board games can be a time-consuming task. Large Language Models (LLMs) arise as appealing tools to expedite this process, given their capacity to efficiently generate code from simple contextual information. In this work, we propose a method to test how capable three LLMs (Claude, DeepSeek and ChatGPT) are at creating code for board games, as well as new variants of existing games.",
    "fetched_at": "2025-11-11T02:19:10.034225Z"
  },
  {
    "id": "2511.05120v1",
    "title": "A Toolbox for Improving Evolutionary Prompt Search",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Daniel Griehaber",
      "Maximilian Kimmich",
      "Johannes Maucher",
      "Ngoc Thang Vu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05120v1",
    "abstract": "Evolutionary prompt optimization has demonstrated effectiveness in refining prompts for LLMs. However, existing approaches lack robust operators and efficient evaluation mechanisms. In this work, we propose several key improvements to evolutionary prompt optimization that can partially generalize to prompt optimization in general: 1) decomposing evolution into distinct steps to enhance the evolution and its control, 2) introducing an LLM-based judge to verify the evolutions, 3) integrating human feedback to refine the evolutionary operator, and 4) developing more efficient evaluation strategies that maintain performance while reducing computational overhead. Our approach improves both optimization quality and efficiency. We release our code, enabling prompt optimization on new tasks and facilitating further research in this area.",
    "fetched_at": "2025-11-11T02:19:10.034185Z"
  },
  {
    "id": "2511.05124v1",
    "title": "QuAnTS: Question Answering on Time Series",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "I.2.6; I.2.7",
      "7"
    ],
    "authors": [
      "Felix Divo",
      "Maurice Kraus",
      "Anh Q. Nguyen",
      "Hao Xue",
      "Imran Razzak",
      "Flora D. Salim",
      "Kristian Kersting",
      "Devendra Singh Dhami"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05124v1",
    "abstract": "Text offers intuitive access to information. This can, in particular, complement the density of numerical time series, thereby allowing improved interactions with time series models to enhance accessibility and decision-making. While the creation of question-answering datasets and models has recently seen remarkable growth, most research focuses on question answering (QA) on vision and text, with time series receiving minute attention. To bridge this gap, we propose a challenging novel time series QA (TSQA) dataset, QuAnTS, for Question Answering on Time Series data. Specifically, we pose a wide variety of questions and answers about human motion in the form of tracked skeleton trajectories. We verify that the large-scale QuAnTS dataset is well-formed and comprehensive through extensive experiments. Thoroughly evaluating existing and newly proposed baselines then lays the groundwork for a deeper exploration of TSQA using QuAnTS. Additionally, we provide human performances as a key reference for gauging the practical usability of such models. We hope to encourage future research on interacting with time series models through text, enabling better decision-making and more transparent systems.",
    "fetched_at": "2025-11-11T02:19:10.034142Z"
  },
  {
    "id": "2511.05131v1",
    "title": "DL101 Neural Network Outputs and Loss Functions",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Fernando Berzal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05131v1",
    "abstract": "The loss function used to train a neural network is strongly connected to its output layer from a statistical point of view. This technical report analyzes common activation functions for a neural network output layer, like linear, sigmoid, ReLU, and softmax, detailing their mathematical properties and their appropriate use cases. A strong statistical justification exists for the selection of the suitable loss function for training a deep learning model. This report connects common loss functions such as Mean Squared Error (MSE), Mean Absolute Error (MAE), and various Cross-Entropy losses to the statistical principle of Maximum Likelihood Estimation (MLE). Choosing a specific loss function is equivalent to assuming a specific probability distribution for the model output, highlighting the link between these functions and the Generalized Linear Models (GLMs) that underlie network output layers. Additional scenarios of practical interest are also considered, such as alternative output encodings, constrained outputs, and distributions with heavy tails.",
    "fetched_at": "2025-11-11T02:19:10.034082Z"
  },
  {
    "id": "2511.05135v1",
    "title": "ManufactuBERT: Efficient Continual Pretraining for Manufacturing",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Robin Armingaud",
      "Romaric Besanon"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05135v1",
    "abstract": "While large general-purpose Transformer-based encoders excel at general language understanding, their performance diminishes in specialized domains like manufacturing due to a lack of exposure to domain-specific terminology and semantics. In this paper, we address this gap by introducing ManufactuBERT, a RoBERTa model continually pretrained on a large-scale corpus curated for the manufacturing domain. We present a comprehensive data processing pipeline to create this corpus from web data, involving an initial domain-specific filtering step followed by a multi-stage deduplication process that removes redundancies. Our experiments show that ManufactuBERT establishes a new state-of-the-art on a range of manufacturing-related NLP tasks, outperforming strong specialized baselines. More importantly, we demonstrate that training on our carefully deduplicated corpus significantly accelerates convergence, leading to a 33\\% reduction in training time and computational cost compared to training on the non-deduplicated dataset. The proposed pipeline offers a reproducible example for developing high-performing encoders in other specialized domains. We will release our model and curated corpus at https://huggingface.co/cea-list-ia.",
    "fetched_at": "2025-11-11T02:19:10.034046Z"
  },
  {
    "id": "2511.05150v1",
    "title": "From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation   Model Bridging Global and Cellular Representations in Biomarker Detection",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingsong Liu",
      "Han Li",
      "Nassir Navab",
      "Peter J. Schffler"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05150v1",
    "abstract": "AI-based biomarkers can infer molecular features directly from hematoxylin & eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global patch-level embeddings and overlook cell-level morphology. We present a PFM model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale self-supervised pretraining with cell-centric post-tuning and attention pooling to fuse local and global tokens. Across four tasks involving four biomarkers and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2% average improvement over prior PFMs, advancing interpretable and robust AI-based biomarker detection in digital pathology.",
    "fetched_at": "2025-11-11T02:19:10.034003Z"
  },
  {
    "id": "2511.05156v1",
    "title": "SmartSecChain-SDN: A Blockchain-Integrated Intelligent Framework for   Secure and Efficient Software-Defined Networks",
    "date": "2025-11-07",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.NI",
      "NI",
      "C.2.3",
      "3"
    ],
    "authors": [
      "Azhar Hussain Mozumder",
      "M. John Basha",
      "Chayapathi A. R"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05156v1",
    "abstract": "With more and more existing networks being transformed to Software-Defined Networking (SDN), they need to be more secure and demand smarter ways of traffic control. This work, SmartSecChain-SDN, is a platform that combines machine learning based intrusion detection, blockchain-based storage of logs, and application-awareness-based priority in SDN networks. To detect network intrusions in a real-time, precision and low-false positives setup, the framework utilizes the application of advanced machine learning algorithms, namely Random Forest, XGBoost, CatBoost, and CNN-BiLSTM. SmartSecChain-SDN is based on the Hyperledger Fabric, which is a permissioned blockchain technology, to provide secure, scalable, and privacy-preserving storage and, thus, guarantee that the Intrusion Detection System (IDS) records cannot be altered and can be analyzed comprehensively. The system also has Quality of Service (QoS) rules and traffic shaping based on applications, which enables prioritization of critical services, such as VoIP, video conferencing, and business applications, as well as de-prioritization of non-essential traffic, such as downloads and updates. Mininet can simulate real-time SDN scenarios because it is used to prototype whole architectures. It is also compatible with controllers OpenDaylight and Ryu. It has tested the framework using the InSDN dataset and proved that it can identify different kinds of cyberattacks and handle bandwidth allocation efficiently under circumstances of resource constraints. SmartSecChain-SDN comprehensively addresses SDN system protection, securing and enhancing. The proposed study offers an innovative, extensible way to improve cybersecurity, regulatory compliance, and the administration of next-generation programmable networks.",
    "fetched_at": "2025-11-11T02:19:10.033959Z"
  },
  {
    "id": "2511.05158v1",
    "title": "Follow-Me in Micro-Mobility with End-to-End Imitation Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sahar Salimpour",
      "Iacopo Catalano",
      "Tomi Westerlund",
      "Mohsen Falahi",
      "Jorge Pea Queralta"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05158v1",
    "abstract": "Autonomous micro-mobility platforms face challenges from the perspective of the typical deployment environment: large indoor spaces or urban areas that are potentially crowded and highly dynamic. While social navigation algorithms have progressed significantly, optimizing user comfort and overall user experience over other typical metrics in robotics (e.g., time or distance traveled) is understudied. Specifically, these metrics are critical in commercial applications. In this paper, we show how imitation learning delivers smoother and overall better controllers, versus previously used manually-tuned controllers. We demonstrate how DAAV's autonomous wheelchair achieves state-of-the-art comfort in follow-me mode, in which it follows a human operator assisting persons with reduced mobility (PRM). This paper analyzes different neural network architectures for end-to-end control and demonstrates their usability in real-world production-level deployments.",
    "fetched_at": "2025-11-11T02:19:10.033904Z"
  },
  {
    "id": "2511.05159v1",
    "title": "A New Framework for Convex Clustering in Kernel Spaces: Finite Sample   Bounds, Consistency and Performance Insights",
    "date": "2025-11-07",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shubhayan Pan",
      "Saptarshi Chakraborty",
      "Debolina Paul",
      "Kushal Bose",
      "Swagatam Das"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05159v1",
    "abstract": "Convex clustering is a well-regarded clustering method, resembling the similar centroid-based approach of Lloyd's $k$-means, without requiring a predefined cluster count. It starts with each data point as its centroid and iteratively merges them. Despite its advantages, this method can fail when dealing with data exhibiting linearly non-separable or non-convex structures. To mitigate the limitations, we propose a kernelized extension of the convex clustering method. This approach projects the data points into a Reproducing Kernel Hilbert Space (RKHS) using a feature map, enabling convex clustering in this transformed space. This kernelization not only allows for better handling of complex data distributions but also produces an embedding in a finite-dimensional vector space. We provide a comprehensive theoretical underpinnings for our kernelized approach, proving algorithmic convergence and establishing finite sample bounds for our estimates. The effectiveness of our method is demonstrated through extensive experiments on both synthetic and real-world datasets, showing superior performance compared to state-of-the-art clustering techniques. This work marks a significant advancement in the field, offering an effective solution for clustering in non-linear and non-convex data scenarios.",
    "fetched_at": "2025-11-11T02:19:10.033842Z"
  },
  {
    "id": "2511.05162v1",
    "title": "Mind the Gap... or Not? How Translation Errors and Evaluation Details   Skew Multilingual Results",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jan-Thorsten Peter",
      "David Vilar",
      "Tobias Domhan",
      "Dan Malkin",
      "Markus Freitag"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05162v1",
    "abstract": "Most current large language models (LLMs) support a wide variety of languages in addition to English, including high-resource languages (e.g. German, Chinese, French), as well as low-resource ones (e.g. Swahili, Telugu). In addition they have also shown impressive capabilities in different domains, like coding, science and math. In this short paper, taking math as an example domain, we study the performance of different LLMs across languages. Experimental results show that there exists a non-negligible and consistent gap in the performance of the models across languages. Interestingly, and somewhat against expectations, the gap exists for both high- and low-resource languages. We hope that these results influence further research into cross-lingual capability generalization for next generation LLMs. If it weren't for the fact that they are false! By analyzing one of the standard multilingual math benchmarks (MGSM), we determine that several translation errors are present in the data. Furthermore, the lack of standardized answer extraction from LLM outputs further influences the final results. We propose a method for automatic quality assurance to address the first issue at scale, and give recommendations to address the second one. Combining these two approaches we show that the aforementioned language gap mostly disappears, leading to completely different conclusions from our research. We additionally release the corrected dataset to the community.",
    "fetched_at": "2025-11-11T02:19:10.033757Z"
  },
  {
    "id": "2511.05163v1",
    "title": "Consecutive Preferential Bayesian Optimization",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aras Erarslan",
      "Carlos Sevilla Salcedo",
      "Ville Tanskanen",
      "Anni Nisov",
      "Eero Pivkumpu",
      "Heikki Aisala",
      "Kaisu Honkap",
      "Arto Klami",
      "Petrus Mikkola"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05163v1",
    "abstract": "Preferential Bayesian optimization allows optimization of objectives that are either expensive or difficult to measure directly, by relying on a minimal number of comparative evaluations done by a human expert. Generating candidate solutions for evaluation is also often expensive, but this cost is ignored by existing methods. We generalize preference-based optimization to explicitly account for production and evaluation costs with Consecutive Preferential Bayesian Optimization, reducing production cost by constraining comparisons to involve previously generated candidates. We also account for the perceptual ambiguity of the oracle providing the feedback by incorporating a Just-Noticeable Difference threshold into a probabilistic preference model to capture indifference to small utility differences. We adapt an information-theoretic acquisition strategy to this setting, selecting new configurations that are most informative about the unknown optimum under a preference model accounting for the perceptual ambiguity. We empirically demonstrate a notable increase in accuracy in setups with high production costs or with indifference feedback.",
    "fetched_at": "2025-11-11T02:19:10.033703Z"
  },
  {
    "id": "2511.05165v1",
    "title": "Generating Software Architecture Description from Source Code using   Reverse Engineering and Large Language Model",
    "date": "2025-11-07",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ahmad Hatahet",
      "Christoph Knieke",
      "Andreas Rausch"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05165v1",
    "abstract": "Software Architecture Descriptions (SADs) are essential for managing the inherent complexity of modern software systems. They enable high-level architectural reasoning, guide design decisions, and facilitate effective communication among diverse stakeholders. However, in practice, SADs are often missing, outdated, or poorly aligned with the system's actual implementation. Consequently, developers are compelled to derive architectural insights directly from source code-a time-intensive process that increases cognitive load, slows new developer onboarding, and contributes to the gradual degradation of clarity over the system's lifetime. To address these issues, we propose a semi-automated generation of SADs from source code by integrating reverse engineering (RE) techniques with a Large Language Model (LLM). Our approach recovers both static and behavioral architectural views by extracting a comprehensive component diagram, filtering architecturally significant elements (core components) via prompt engineering, and generating state machine diagrams to model component behavior based on underlying code logic with few-shots prompting. This resulting views representation offer a scalable and maintainable alternative to traditional manual architectural documentation. This methodology, demonstrated using C++ examples, highlights the potent capability of LLMs to: 1) abstract the component diagram, thereby reducing the reliance on human expert involvement, and 2) accurately represent complex software behaviors, especially when enriched with domain-specific knowledge through few-shot prompting. These findings suggest a viable path toward significantly reducing manual effort while enhancing system understanding and long-term maintainability.",
    "fetched_at": "2025-11-11T02:19:10.033637Z"
  },
  {
    "id": "2511.05168v1",
    "title": "Another BRIXEL in the Wall: Towards Cheaper Dense Features",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alexander Lappe",
      "Martin A. Giese"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05168v1",
    "abstract": "Vision foundation models achieve strong performance on both global and locally dense downstream tasks. Pretrained on large images, the recent DINOv3 model family is able to produce very fine-grained dense feature maps, enabling state-of-the-art performance. However, computing these feature maps requires the input image to be available at very high resolution, as well as large amounts of compute due to the squared complexity of the transformer architecture. To address these issues, we propose BRIXEL, a simple knowledge distillation approach that has the student learn to reproduce its own feature maps at higher resolution. Despite its simplicity, BRIXEL outperforms the baseline DINOv3 models by large margins on downstream tasks when the resolution is kept fixed. Moreover, it is able to produce feature maps that are very similar to those of the teacher at a fraction of the computational cost. Code and model weights are available at https://github.com/alexanderlappe/BRIXEL.",
    "fetched_at": "2025-11-11T02:19:10.033587Z"
  },
  {
    "id": "2511.05169v1",
    "title": "Multimodal Deep Learning for Prediction of Progression-Free Survival in   Patients with Neuroendocrine Tumors Undergoing 177Lu-based Peptide Receptor   Radionuclide Therapy",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Simon Baur",
      "Tristan Ruhwedel",
      "Ekin Bke",
      "Zuzanna Kobus",
      "Gergana Lishkova",
      "Christoph Wetz",
      "Holger Amthauer",
      "Christoph Roderburg",
      "Frank Tacke",
      "Julian M. Rogasch",
      "Wojciech Samek",
      "Henning Jann",
      "Jackie Ma",
      "Johannes Eschrich"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.05169v1",
    "abstract": "Peptide receptor radionuclide therapy (PRRT) is an established treatment for metastatic neuroendocrine tumors (NETs), yet long-term disease control occurs only in a subset of patients. Predicting progression-free survival (PFS) could support individualized treatment planning. This study evaluates laboratory, imaging, and multimodal deep learning models for PFS prediction in PRRT-treated patients. In this retrospective, single-center study 116 patients with metastatic NETs undergoing 177Lu-DOTATOC were included. Clinical characteristics, laboratory values, and pretherapeutic somatostatin receptor positron emission tomography/computed tomographies (SR-PET/CT) were collected. Seven models were trained to classify low- vs. high-PFS groups, including unimodal (laboratory, SR-PET, or CT) and multimodal fusion approaches. Explainability was evaluated by feature importance analysis and gradient maps. Forty-two patients (36%) had short PFS (< 1 year), 74 patients long PFS (>1 year). Groups were similar in most characteristics, except for higher baseline chromogranin A (p = 0.003), elevated gamma-GT (p = 0.002), and fewer PRRT cycles (p < 0.001) in short-PFS patients. The Random Forest model trained only on laboratory biomarkers reached an AUROC of 0.59 +- 0.02. Unimodal three-dimensional convolutional neural networks using SR-PET or CT performed worse (AUROC 0.42 +- 0.03 and 0.54 +- 0.01, respectively). A multimodal fusion model laboratory values, SR-PET, and CT -augmented with a pretrained CT branch - achieved the best results (AUROC 0.72 +- 0.01, AUPRC 0.80 +- 0.01). Multimodal deep learning combining SR-PET, CT, and laboratory biomarkers outperformed unimodal approaches for PFS prediction after PRRT. Upon external validation, such models may support risk-adapted follow-up strategies.",
    "fetched_at": "2025-11-11T02:19:10.033546Z"
  },
  {
    "id": "2511.05171v1",
    "title": "Model Merging Improves Zero-Shot Generalization in Bioacoustic   Foundation Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Davide Marincione",
      "Donato Crisostomi",
      "Roberto Dessi",
      "Emanuele Rodol",
      "Emanuele Rossi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05171v1",
    "abstract": "Foundation models capable of generalizing across species and tasks represent a promising new frontier in bioacoustics, with NatureLM being one of the most prominent examples. While its domain-specific fine-tuning yields strong performance on bioacoustic benchmarks, we observe that it also introduces trade-offs in instruction-following flexibility. For instance, NatureLM achieves high accuracy when prompted for either the common or scientific name individually, but its accuracy drops significantly when both are requested in a single prompt. We address this by applying a simple model merging strategy that interpolates NatureLM with its base language model, recovering instruction-following capabilities with minimal loss of domain expertise. Finally, we show that the merged model exhibits markedly stronger zero-shot generalization, achieving over a 200% relative improvement and setting a new state-of-the-art in closed-set zero-shot classification of unseen species.",
    "fetched_at": "2025-11-11T02:19:10.033458Z"
  },
  {
    "id": "2511.05177v1",
    "title": "Associative Poisoning to Generative Machine Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mathias Lundteigen Mohus",
      "Jingyue Li",
      "Zhirong Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05177v1",
    "abstract": "The widespread adoption of generative models such as Stable Diffusion and ChatGPT has made them increasingly attractive targets for malicious exploitation, particularly through data poisoning. Existing poisoning attacks compromising synthesised data typically either cause broad degradation of generated data or require control over the training process, limiting their applicability in real-world scenarios. In this paper, we introduce a novel data poisoning technique called associative poisoning, which compromises fine-grained features of the generated data without requiring control of the training process. This attack perturbs only the training data to manipulate statistical associations between specific feature pairs in the generated outputs. We provide a formal mathematical formulation of the attack and prove its theoretical feasibility and stealthiness. Empirical evaluations using two state-of-the-art generative models demonstrate that associative poisoning effectively induces or suppresses feature associations while preserving the marginal distributions of the targeted features and maintaining high-quality outputs, thereby evading visual detection. These results suggest that generative systems used in image synthesis, synthetic dataset generation, and natural language processing are susceptible to subtle, stealthy manipulations that compromise their statistical integrity. To address this risk, we examine the limitations of existing defensive strategies and propose a novel countermeasure strategy.",
    "fetched_at": "2025-11-11T02:19:10.033407Z"
  },
  {
    "id": "2511.05179v1",
    "title": "No One-Model-Fits-All: Uncovering Spatio-Temporal Forecasting Trade-offs   with Graph Neural Networks and Foundation Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Ragini Gupta",
      "Naman Raina",
      "Bo Chen",
      "Li Chen",
      "Claudiu Danilov",
      "Josh Eckhardt",
      "Keyshla Bernard",
      "Klara Nahrstedt"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05179v1",
    "abstract": "Modern IoT deployments for environmental sensing produce high volume spatiotemporal data to support downstream tasks such as forecasting, typically powered by machine learning models. While existing filtering and strategic deployment techniques optimize collected data volume at the edge, they overlook how variations in sampling frequencies and spatial coverage affect downstream model performance. In many forecasting models, incorporating data from additional sensors denoise predictions by providing broader spatial contexts. This interplay between sampling frequency, spatial coverage and different forecasting model architectures remain underexplored. This work presents a systematic study of forecasting models - classical models (VAR), neural networks (GRU, Transformer), spatio-temporal graph neural networks (STGNNs), and time series foundation models (TSFMs: Chronos Moirai, TimesFM) under varying spatial sensor nodes density and sampling intervals using real-world temperature data in a wireless sensor network. Our results show that STGNNs are effective when sensor deployments are sparse and sampling rate is moderate, leveraging spatial correlations via encoded graph structure to compensate for limited coverage. In contrast, TSFMs perform competitively at high frequencies but degrade when spatial coverage from neighboring sensors is reduced. Crucially, the multivariate TSFM Moirai outperforms all models by natively learning cross-sensor dependencies. These findings offer actionable insights for building efficient forecasting pipelines in spatio-temporal systems. All code for model configurations, training, dataset, and logs are open-sourced for reproducibility: https://github.com/UIUC-MONET-Projects/Benchmarking-Spatiotemporal-Forecast-Models",
    "fetched_at": "2025-11-11T02:19:10.033355Z"
  },
  {
    "id": "2511.05182v1",
    "title": "Autonomous generation of different courses of action in mechanized   combat operations",
    "date": "2025-11-07",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "H.4.2; I.2.3; I.2.6; I.2.8; J.7",
      "7"
    ],
    "authors": [
      "Johan Schubert",
      "Patrik Hansen",
      "Pontus Hrling",
      "Ronnie Johansson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05182v1",
    "abstract": "In this paper, we propose a methodology designed to support decision-making during the execution phase of military ground combat operations, with a focus on one's actions. This methodology generates and evaluates recommendations for various courses of action for a mechanized battalion, commencing with an initial set assessed by their anticipated outcomes. It systematically produces thousands of individual action alternatives, followed by evaluations aimed at identifying alternative courses of action with superior outcomes. These alternatives are appraised in light of the opponent's status and actions, considering unit composition, force ratios, types of offense and defense, and anticipated advance rates. Field manuals evaluate battle outcomes and advancement rates. The processes of generation and evaluation work concurrently, yielding a variety of alternative courses of action. This approach facilitates the management of new course generation based on previously evaluated actions. As the combat unfolds and conditions evolve, revised courses of action are formulated for the decision-maker within a sequential decision-making framework.",
    "fetched_at": "2025-11-11T02:19:10.033248Z"
  },
  {
    "id": "2511.05184v1",
    "title": "Effectiveness of Chain-of-Thought in Distilling Reasoning Capability   from Large Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Cong-Thanh Do",
      "Rama Doddipatla",
      "Kate Knill"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05184v1",
    "abstract": "Chain-of-Thought (CoT) prompting is a widely used method to improve the reasoning capability of Large Language Models (LLMs). More recently, CoT has been leveraged in Knowledge Distillation (KD) to transfer reasoning capability from a larger LLM to a smaller one. This paper examines the role of CoT in distilling the reasoning capability from larger LLMs to smaller LLMs using white-box KD, analysing its effectiveness in improving the performance of the distilled models for various natural language reasoning and understanding tasks. We conduct white-box KD experiments using LLMs from the Qwen and Llama2 families, employing CoT data from the CoT-Collection dataset. The distilled models are then evaluated on natural language reasoning and understanding tasks from the BIG-Bench-Hard (BBH) benchmark, which presents complex challenges for smaller LLMs. Experimental results demonstrate the role of CoT in improving white-box KD effectiveness, enabling the distilled models to achieve better average performance in natural language reasoning and understanding tasks from BBH.",
    "fetched_at": "2025-11-11T02:19:10.033198Z"
  },
  {
    "id": "2511.05187v1",
    "title": "Linear Gradient Prediction with Control Variates",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Kamil Ciosek",
      "Nicol Felicioni",
      "Juan Elenter Litwin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05187v1",
    "abstract": "We propose a new way of training neural networks, with the goal of reducing training cost. Our method uses approximate predicted gradients instead of the full gradients that require an expensive backward pass. We derive a control-variate-based technique that ensures our updates are unbiased estimates of the true gradient. Moreover, we propose a novel way to derive a predictor for the gradient inspired by the theory of the Neural Tangent Kernel. We empirically show the efficacy of the technique on a vision transformer classification task.",
    "fetched_at": "2025-11-11T02:19:10.033156Z"
  },
  {
    "id": "2511.05221v1",
    "title": "ActiTect: A Generalizable Machine Learning Pipeline for REM Sleep   Behavior Disorder Screening through Standardized Actigraphy",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC"
    ],
    "authors": [
      "David Bertram",
      "Anja Ophey",
      "Sinah Rttgen",
      "Konstantin Kuffer",
      "Gereon R. Fink",
      "Elke Kalbe",
      "Clint Hansen",
      "Walter Maetzler",
      "Maximilian Kapsecker",
      "Lara M. Reimer",
      "Stephan Jonas",
      "Andreas T. Damgaard",
      "Natasha B. Bertelsen",
      "Casper Skjaerbaek",
      "Per Borghammer",
      "Karolien Groenewald",
      "Pietro-Luca Ratti",
      "Michele T. Hu",
      "Nomie Moreau",
      "Michael Sommerauer",
      "Katarzyna Bozek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05221v1",
    "abstract": "Isolated rapid eye movement sleep behavior disorder (iRBD) is a major prodromal marker of $\\alpha$-synucleinopathies, often preceding the clinical onset of Parkinson's disease, dementia with Lewy bodies, or multiple system atrophy. While wrist-worn actimeters hold significant potential for detecting RBD in large-scale screening efforts by capturing abnormal nocturnal movements, they become inoperable without a reliable and efficient analysis pipeline. This study presents ActiTect, a fully automated, open-source machine learning tool to identify RBD from actigraphy recordings. To ensure generalizability across heterogeneous acquisition settings, our pipeline includes robust preprocessing and automated sleep-wake detection to harmonize multi-device data and extract physiologically interpretable motion features characterizing activity patterns. Model development was conducted on a cohort of 78 individuals, yielding strong discrimination under nested cross-validation (AUROC = 0.95). Generalization was confirmed on a blinded local test set (n = 31, AUROC = 0.86) and on two independent external cohorts (n = 113, AUROC = 0.84; n = 57, AUROC = 0.94). To assess real-world robustness, leave-one-dataset-out cross-validation across the internal and external cohorts demonstrated consistent performance (AUROC range = 0.84-0.89). A complementary stability analysis showed that key predictive features remained reproducible across datasets, supporting the final pooled multi-center model as a robust pre-trained resource for broader deployment. By being open-source and easy to use, our tool promotes widespread adoption and facilitates independent validation and collaborative improvements, thereby advancing the field toward a unified and generalizable RBD detection model using wearable devices.",
    "fetched_at": "2025-11-11T02:19:10.033117Z"
  },
  {
    "id": "2511.05229v1",
    "title": "4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes   from Monocular Videos",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mengqi Guo",
      "Bo Xu",
      "Yanyan Li",
      "Gim Hee Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05229v1",
    "abstract": "Novel view synthesis from monocular videos of dynamic scenes with unknown camera poses remains a fundamental challenge in computer vision and graphics. While recent advances in 3D representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static scenes, they struggle with dynamic content and typically rely on pre-computed camera poses. We present 4D3R, a pose-free dynamic neural rendering framework that decouples static and dynamic components through a two-stage approach. Our method first leverages 3D foundational models for initial pose and geometry estimation, followed by motion-aware refinement. 4D3R introduces two key technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that combines transformer-based learned priors with SAM2 for robust dynamic object segmentation, enabling more accurate camera pose refinement; and (2) an efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses control points with a deformation field MLP and linear blend skinning to model dynamic motion, significantly reducing computational cost while maintaining high-quality reconstruction. Extensive experiments on real-world dynamic datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement over state-of-the-art methods, particularly in challenging scenarios with large dynamic objects, while reducing computational requirements by 5x compared to previous dynamic scene representations.",
    "fetched_at": "2025-11-11T02:19:10.033005Z"
  },
  {
    "id": "2511.05231v1",
    "title": "A differentiable model of supply-chain shocks",
    "date": "2025-11-07",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Saad Hamid",
      "Jos Moran",
      "Luca Mungo",
      "Arnau Quera-Bofarull",
      "Sebastian Towers"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05231v1",
    "abstract": "Modelling how shocks propagate in supply chains is an increasingly important challenge in economics. Its relevance has been highlighted in recent years by events such as Covid-19 and the Russian invasion of Ukraine. Agent-based models (ABMs) are a promising approach for this problem. However, calibrating them is hard. We show empirically that it is possible to achieve speed ups of over 3 orders of magnitude when calibrating ABMs of supply networks by running them on GPUs and using automatic differentiation, compared to non-differentiable baselines. This opens the door to scaling ABMs to model the whole global supply network.",
    "fetched_at": "2025-11-11T02:19:10.032954Z"
  },
  {
    "id": "2511.05234v1",
    "title": "Context-aware Learned Mesh-based Simulation via Trajectory-Level   Meta-Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Philipp Dahlinger",
      "Niklas Freymuth",
      "Tai Hoang",
      "Tobias Wrth",
      "Michael Volpp",
      "Luise Krger",
      "Gerhard Neumann"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.05234v1",
    "abstract": "Simulating object deformations is a critical challenge across many scientific domains, including robotics, manufacturing, and structural mechanics. Learned Graph Network Simulators (GNSs) offer a promising alternative to traditional mesh-based physics simulators. Their speed and inherent differentiability make them particularly well suited for applications that require fast and accurate simulations, such as robotic manipulation or manufacturing optimization. However, existing learned simulators typically rely on single-step observations, which limits their ability to exploit temporal context. Without this information, these models fail to infer, e.g., material properties. Further, they rely on auto-regressive rollouts, which quickly accumulate error for long trajectories. We instead frame mesh-based simulation as a trajectory-level meta-learning problem. Using Conditional Neural Processes, our method enables rapid adaptation to new simulation scenarios from limited initial data while capturing their latent simulation properties. We utilize movement primitives to directly predict fast, stable and accurate simulations from a single model call. The resulting approach, Movement-primitive Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of the runtime cost compared to state-of-the-art GNSs across several tasks.",
    "fetched_at": "2025-11-11T02:19:10.032903Z"
  },
  {
    "id": "2511.05236v1",
    "title": "The Causal Round Trip: Generating Authentic Counterfactuals by   Eliminating Information Loss",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rui Wu",
      "Lizheng Wang",
      "Yongjun Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05236v1",
    "abstract": "Judea Pearl's vision of Structural Causal Models (SCMs) as engines for counterfactual reasoning hinges on faithful abduction: the precise inference of latent exogenous noise. For decades, operationalizing this step for complex, non-linear mechanisms has remained a significant computational challenge. The advent of diffusion models, powerful universal function approximators, offers a promising solution. However, we argue that their standard design, optimized for perceptual generation over logical inference, introduces a fundamental flaw for this classical problem: an inherent information loss we term the Structural Reconstruction Error (SRE). To address this challenge, we formalize the principle of Causal Information Conservation (CIC) as the necessary condition for faithful abduction. We then introduce BELM-MDCM, the first diffusion-based framework engineered to be causally sound by eliminating SRE by construction through an analytically invertible mechanism. To operationalize this framework, a Targeted Modeling strategy provides structural regularization, while a Hybrid Training Objective instills a strong causal inductive bias. Rigorous experiments demonstrate that our Zero-SRE framework not only achieves state-of-the-art accuracy but, more importantly, enables the high-fidelity, individual-level counterfactuals required for deep causal inquiries. Our work provides a foundational blueprint that reconciles the power of modern generative models with the rigor of classical causal theory, establishing a new and more rigorous standard for this emerging field.",
    "fetched_at": "2025-11-11T02:19:10.032832Z"
  },
  {
    "id": "2511.05239v1",
    "title": "Translation via Annotation: A Computational Study of Translating   Classical Chinese into Japanese",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zilong Li",
      "Jie Cao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05239v1",
    "abstract": "Ancient people translated classical Chinese into Japanese by annotating around each character. We abstract this process as sequence tagging tasks and fit them into modern language technologies. The research of this annotation and translation system is a facing low-resource problem. We release this problem by introducing a LLM-based annotation pipeline and construct a new dataset from digitalized open-source translation data. We show that under the low-resource setting, introducing auxiliary Chinese NLP tasks has a promoting effect on the training of sequence tagging tasks. We also evaluate the performance of large language models. They achieve high scores in direct machine translation, but they are confused when being asked to annotate characters. Our method could work as a supplement of LLMs.",
    "fetched_at": "2025-11-11T02:19:10.032783Z"
  },
  {
    "id": "2511.05250v1",
    "title": "Accurate online action and gesture recognition system using detectors   and Deep SPD Siamese Networks",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Mohamed Sanim Akremi",
      "Rim Slama",
      "Hedi Tabia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05250v1",
    "abstract": "Online continuous motion recognition is a hot topic of research since it is more practical in real life application cases. Recently, Skeleton-based approaches have become increasingly popular, demonstrating the power of using such 3D temporal data. However, most of these works have focused on segment-based recognition and are not suitable for the online scenarios. In this paper, we propose an online recognition system for skeleton sequence streaming composed from two main components: a detector and a classifier, which use a Semi-Positive Definite (SPD) matrix representation and a Siamese network. The powerful statistical representations for the skeletal data given by the SPD matrices and the learning of their semantic similarity by the Siamese network enable the detector to predict time intervals of the motions throughout an unsegmented sequence. In addition, they ensure the classifier capability to recognize the motion in each predicted interval. The proposed detector is flexible and able to identify the kinetic state continuously. We conduct extensive experiments on both hand gesture and body action recognition benchmarks to prove the accuracy of our online recognition system which in most cases outperforms state-of-the-art performances.",
    "fetched_at": "2025-11-11T02:19:10.032747Z"
  },
  {
    "id": "2511.05254v1",
    "title": "A Gate-Based Quantum Genetic Algorithm for Real-Valued Global   Optimization",
    "date": "2025-11-07",
    "tags": [
      "quant-ph",
      "cs.AI",
      "AI",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Leandro C. Souza",
      "Laurent E. Dardenne",
      "Renato Portugal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05254v1",
    "abstract": "We propose a gate-based Quantum Genetic Algorithm (QGA) for real-valued global optimization. In this model, individuals are represented by quantum circuits whose measurement outcomes are decoded into real-valued vectors through binary discretization. Evolutionary operators act directly on circuit structures, allowing mutation and crossover to explore the space of gate-based encodings. Both fixed-depth and variable-depth variants are introduced, enabling either uniform circuit complexity or adaptive structural evolution. Fitness is evaluated through quantum sampling, using the mean decoded output of measurement outcomes as the argument of the objective function. To isolate the impact of quantum resources, we compare gate sets with and without the Hadamard gate, showing that superposition consistently improves convergence and robustness across benchmark functions such as the Rastrigin function. Furthermore, we demonstrate that introducing pairwise inter-individual entanglement in the population accelerates early convergence, revealing that quantum correlations among individuals provide an additional optimization advantage. Together, these results show that both superposition and entanglement enhance the search dynamics of evolutionary quantum algorithms, establishing gate-based QGAs as a promising framework for quantum-enhanced global optimization.",
    "fetched_at": "2025-11-11T02:19:10.032701Z"
  },
  {
    "id": "2511.05263v1",
    "title": "OregairuChar: A Benchmark Dataset for Character Appearance Frequency   Analysis in My Teen Romantic Comedy SNAFU",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qi Sun",
      "Dingju Zhou",
      "Lina Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05263v1",
    "abstract": "The analysis of character appearance frequency is essential for understanding narrative structure, character prominence, and story progression in anime. In this work, we introduce OregairuChar, a benchmark dataset designed for appearance frequency analysis in the anime series My Teen Romantic Comedy SNAFU. The dataset comprises 1600 manually selected frames from the third season, annotated with 2860 bounding boxes across 11 main characters. OregairuChar captures diverse visual challenges, including occlusion, pose variation, and inter-character similarity, providing a realistic basis for appearance-based studies. To enable quantitative research, we benchmark several object detection models on the dataset and leverage their predictions for fine-grained, episode-level analysis of character presence over time. This approach reveals patterns of character prominence and their evolution within the narrative. By emphasizing appearance frequency, OregairuChar serves as a valuable resource for exploring computational narrative dynamics and character-centric storytelling in stylized media.",
    "fetched_at": "2025-11-11T02:19:10.032653Z"
  },
  {
    "id": "2511.05265v1",
    "title": "An End-to-End Deep Reinforcement Learning Approach for Solving the   Traveling Salesman Problem with Drones",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Taihelong Zeng",
      "Yun Lin",
      "Yuhe Shi",
      "Yan Li",
      "Zhiqing Wei",
      "Xuanru Ji"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05265v1",
    "abstract": "The emergence of truck-drone collaborative systems in last-mile logistics has positioned the Traveling Salesman Problem with Drones (TSP-D) as a pivotal extension of classical routing optimization, where synchronized vehicle coordination promises substantial operational efficiency and reduced environmental impact, yet introduces NP-hard combinatorial complexity beyond the reach of conventional optimization paradigms. Deep reinforcement learning offers a theoretically grounded framework to address TSP-D's inherent challenges through self-supervised policy learning and adaptive decision-making. This study proposes a hierarchical Actor-Critic deep reinforcement learning framework for solving the TSP-D problem. The architecture consists of two primary components: a Transformer-inspired encoder and an efficient Minimal Gated Unit decoder. The encoder incorporates a novel, optimized k-nearest neighbors sparse attention mechanism specifically for focusing on relevant spatial relationships, further enhanced by the integration of global node features. The Minimal Gated Unit decoder processes these encoded representations to efficiently generate solution sequences. The entire framework operates within an asynchronous advantage actor-critic paradigm. Experimental results show that, on benchmark TSP-D instances of various scales (N=10 to 100), the proposed model can obtain competitive or even superior solutions in shorter average computation times compared to high-performance heuristic algorithms and existing reinforcement learning methods. Moreover, compared to advanced reinforcement learning algorithm benchmarks, the proposed framework significantly reduces the total training time required while achieving superior final performance, highlighting its notable advantage in training efficiency.",
    "fetched_at": "2025-11-11T02:19:10.032609Z"
  },
  {
    "id": "2511.05266v1",
    "title": "Integrating Score-Based Diffusion Models with Machine Learning-Enhanced   Localization for Advanced Data Assimilation in Geological Carbon Storage",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gabriel Serro Seabra",
      "Nikolaj T. Mcke",
      "Vinicius Luiz Santos Silva",
      "Alexandre A. Emerick",
      "Denis Voskov",
      "Femke Vossepoel"
    ],
    "institution": "Faculty of Civil Engineering and Geosciences, TU Delft, Delft, Netherlands, Petroleo Brasileiro S.A",
    "link": "http://arxiv.org/pdf/2511.05266v1",
    "abstract": "Accurate characterization of subsurface heterogeneity is important for the safe and effective implementation of geological carbon storage (GCS) projects. This paper explores how machine learning methods can enhance data assimilation for GCS with a framework that integrates score-based diffusion models with machine learning-enhanced localization in channelized reservoirs during CO$_2$ injection. We employ a machine learning-enhanced localization framework that uses large ensembles ($N_s = 5000$) with permeabilities generated by the diffusion model and states computed by simple ML algorithms to improve covariance estimation for the Ensemble Smoother with Multiple Data Assimilation (ESMDA). We apply ML algorithms to a prior ensemble of channelized permeability fields, generated with the geostatistical model FLUVSIM. Our approach is applied on a CO$_2$ injection scenario simulated using the Delft Advanced Research Terra Simulator (DARTS). Our ML-based localization maintains significantly more ensemble variance than when localization is not applied, while achieving comparable data-matching quality. This framework has practical implications for GCS projects, helping improve the reliability of uncertainty quantification for risk assessment.",
    "fetched_at": "2025-11-11T02:19:10.032547Z"
  },
  {
    "id": "2511.05275v1",
    "title": "TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm   Vision-Language-Action Models",
    "date": "2025-11-07",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hokyun Im",
      "Euijin Jeong",
      "Jianlong Fu",
      "Andrey Kolobov",
      "Youngwoon Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05275v1",
    "abstract": "Vision-language-action models (VLAs) trained on large-scale robotic datasets have demonstrated strong performance on manipulation tasks, including bimanual tasks. However, because most public datasets focus on single-arm demonstrations, adapting VLAs for bimanual tasks typically requires substantial additional bimanual data and fine-tuning. To address this challenge, we introduce TwinVLA, a modular framework that composes two copies of a pretrained single-arm VLA into a coordinated bimanual VLA. Unlike monolithic cross-embodiment models trained on mixtures of single-arm and bimanual data, TwinVLA improves both data efficiency and performance by composing pretrained single-arm policies. Across diverse bimanual tasks in real-world and simulation settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model without requiring any bimanual pretraining. Furthermore, it narrows the gap to state-of-the-art model, $\\pi_0$ which rely on extensive proprietary bimanual data and compute cost. These results establish our modular composition approach as a data-efficient and scalable path toward high-performance bimanual manipulation, leveraging public single-arm data.",
    "fetched_at": "2025-11-11T02:19:10.032386Z"
  },
  {
    "id": "2511.05286v1",
    "title": "Reflective Personalization Optimization: A Post-hoc Rewriting Framework   for Black-Box Large Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Teqi Hao",
      "Xioayu Tan",
      "Shaojie Shi",
      "Yinghui Xu",
      "Xihe Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05286v1",
    "abstract": "The personalization of black-box large language models (LLMs) is a critical yet challenging task. Existing approaches predominantly rely on context injection, where user history is embedded into the prompt to directly guide the generation process. However, this single-step paradigm imposes a dual burden on the model: generating accurate content while simultaneously aligning with user-specific styles. This often results in a trade-off that compromises output quality and limits precise control. To address this fundamental tension, we propose Reflective Personalization Optimization (RPO), a novel framework that redefines the personalization paradigm by decoupling content generation from alignment. RPO operates in two distinct stages: first, a base model generates a high-quality, generic response; then, an external reflection module explicitly rewrites this output to align with the user's preferences. This reflection module is trained using a two-stage process. Initially, supervised fine-tuning is employed on structured rewriting trajectories to establish a core personalized reasoning policy that models the transformation from generic to user-aligned responses. Subsequently, reinforcement learning is applied to further refine and enhance the quality of the personalized outputs. Comprehensive experiments on the LaMP benchmark demonstrate that RPO, by decoupling content generation from personalization, significantly outperforms state-of-the-art baselines. These findings underscore the superiority of explicit response shaping over implicit context injection. Moreover, RPO introduces an efficient, model-agnostic personalization layer that can be seamlessly integrated with any underlying base model, paving the way for a new and effective direction in user-centric generation scenarios.",
    "fetched_at": "2025-11-11T02:19:10.032334Z"
  },
  {
    "id": "2511.05289v1",
    "title": "Embedding-Space Data Augmentation to Prevent Membership Inference   Attacks in Clinical Time Series Forecasting",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Marius Fracarolli",
      "Michael Staniek",
      "Stefan Riezler"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05289v1",
    "abstract": "Balancing strong privacy guarantees with high predictive performance is critical for time series forecasting (TSF) tasks involving Electronic Health Records (EHR). In this study, we explore how data augmentation can mitigate Membership Inference Attacks (MIA) on TSF models. We show that retraining with synthetic data can substantially reduce the effectiveness of loss-based MIAs by reducing the attacker's true-positive to false-positive ratio. The key challenge is generating synthetic samples that closely resemble the original training data to confuse the attacker, while also introducing enough novelty to enhance the model's ability to generalize to unseen data. We examine multiple augmentation strategies - Zeroth-Order Optimization (ZOO), a variant of ZOO constrained by Principal Component Analysis (ZOO-PCA), and MixUp - to strengthen model resilience without sacrificing accuracy. Our experimental results show that ZOO-PCA yields the best reductions in TPR/FPR ratio for MIA attacks without sacrificing performance on test data.",
    "fetched_at": "2025-11-11T02:19:10.032280Z"
  },
  {
    "id": "2511.05292v1",
    "title": "What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable   IMUs",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jiaxi Yin",
      "Pengcheng Wang",
      "Han Ding",
      "Fei Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05292v1",
    "abstract": "Accurate food intake detection is vital for dietary monitoring and chronic disease prevention. Traditional self-report methods are prone to recall bias, while camera-based approaches raise concerns about privacy. Furthermore, existing wearable-based methods primarily focus on a limited number of food types, such as hamburgers and pizza, failing to address the vast diversity of Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that classifies Chinese food types by integrating hand motion cues from a smartwatch with head dynamics from smart glasses. To filter out irrelevant daily activities, we design a two-stage detection pipeline. The first stage identifies eating states by distinguishing characteristic temporal patterns from non-eating behaviors. The second stage then conducts fine-grained food type recognition based on the motions captured during food intake. To evaluate CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings across 11 food categories and 10 participants. Experiments demonstrate that CuisineSense achieves high accuracy in both eating state detection and food classification, offering a practical solution for unobtrusive, wearable-based dietary monitoring.The system code is publicly available at https://github.com/joeeeeyin/CuisineSense.git.",
    "fetched_at": "2025-11-11T02:19:10.032235Z"
  },
  {
    "id": "2511.05295v1",
    "title": "Language Generation and Identification From Partial Enumeration: Tight   Density Bounds and Topological Characterizations",
    "date": "2025-11-07",
    "tags": [
      "cs.DS",
      "DS",
      "cs.CL",
      "CL",
      "cs.DM",
      "DM",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jon Kleinberg",
      "Fan Wei"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05295v1",
    "abstract": "The success of large language models (LLMs) has motivated formal theories of language generation and learning. We study the framework of \\emph{language generation in the limit}, where an adversary enumerates strings from an unknown language $K$ drawn from a countable class, and an algorithm must generate unseen strings from $K$. Prior work showed that generation is always possible, and that some algorithms achieve positive lower density, revealing a \\emph{validity--breadth} trade-off between correctness and coverage. We resolve a main open question in this line, proving a tight bound of $1/2$ on the best achievable lower density. We then strengthen the model to allow \\emph{partial enumeration}, where the adversary reveals only an infinite subset $C \\subseteq K$. We show that generation in the limit remains achievable, and if $C$ has lower density $\\alpha$ in $K$, the algorithm's output achieves density at least $\\alpha/2$, matching the upper bound. This generalizes the $1/2$ bound to the partial-information setting, where the generator must recover within a factor $1/2$ of the revealed subset's density. We further revisit the classical Gold--Angluin model of \\emph{language identification} under partial enumeration. We characterize when identification in the limit is possible -- when hypotheses $M_t$ eventually satisfy $C \\subseteq M \\subseteq K$ -- and in the process give a new topological formulation of Angluin's characterization, showing that her condition is precisely equivalent to an appropriate topological space having the $T_D$ separation property.",
    "fetched_at": "2025-11-11T02:19:10.032187Z"
  },
  {
    "id": "2511.05297v1",
    "title": "Building Specialized Software-Assistant ChatBot with Graph-Based   Retrieval-Augmented Generation",
    "date": "2025-11-07",
    "tags": [
      "cs.SE",
      "SE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammed Hilel",
      "Yannis Karmim",
      "Jean De Bodinat",
      "Reda Sarehane",
      "Antoine Gillon"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05297v1",
    "abstract": "Digital Adoption Platforms (DAPs) have become essential tools for helping employees navigate complex enterprise software such as CRM, ERP, or HRMS systems. Companies like LemonLearning have shown how digital guidance can reduce training costs and accelerate onboarding. However, building and maintaining these interactive guides still requires extensive manual effort. Leveraging Large Language Models as virtual assistants is an appealing alternative, yet without a structured understanding of the target software, LLMs often hallucinate and produce unreliable answers. Moreover, most production-grade LLMs are black-box APIs, making fine-tuning impractical due to the lack of access to model weights. In this work, we introduce a Graph-based Retrieval-Augmented Generation framework that automatically converts enterprise web applications into state-action knowledge graphs, enabling LLMs to generate grounded and context-aware assistance. The framework was co-developed with the AI enterprise RAKAM, in collaboration with Lemon Learning. We detail the engineering pipeline that extracts and structures software interfaces, the design of the graph-based retrieval process, and the integration of our approach into production DAP workflows. Finally, we discuss scalability, robustness, and deployment lessons learned from industrial use cases.",
    "fetched_at": "2025-11-11T02:19:10.032141Z"
  },
  {
    "id": "2511.05299v1",
    "title": "LiveStar: Live Streaming Assistant for Real-World Online Video   Understanding",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhenyu Yang",
      "Kairui Zhang",
      "Yuhang Hu",
      "Bing Wang",
      "Shengsheng Qian",
      "Bin Wen",
      "Fan Yang",
      "Tingting Gao",
      "Weiming Dong",
      "Changsheng Xu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05299v1",
    "abstract": "Despite significant progress in Video Large Language Models (Video-LLMs) for offline video understanding, existing online Video-LLMs typically struggle to simultaneously process continuous frame-by-frame inputs and determine optimal response timing, often compromising real-time responsiveness and narrative coherence. To address these limitations, we introduce LiveStar, a pioneering live streaming assistant that achieves always-on proactive responses through adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a training strategy enabling incremental video-language alignment for variable-length video streams, preserving temporal consistency across dynamically evolving frame sequences; (2) a response-silence decoding framework that determines optimal proactive response timing via a single forward pass verification; (3) memory-aware acceleration via peak-end memory compression for online inference on 10+ minute videos, combined with streaming key-value cache to achieve 1.53x faster inference. We also construct an OmniStar dataset, a comprehensive dataset for training and benchmarking that encompasses 15 diverse real-world scenarios and 5 evaluation tasks for online video understanding. Extensive experiments across three benchmarks demonstrate LiveStar's state-of-the-art performance, achieving an average 19.5% improvement in semantic correctness with 18.1% reduced timing difference compared to existing online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks. Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.",
    "fetched_at": "2025-11-11T02:19:10.032088Z"
  },
  {
    "id": "2511.05301v1",
    "title": "QUESTER: Query Specification for Generative Retrieval",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "68P20, 68T50",
      "H.3",
      "3"
    ],
    "authors": [
      "Arthur Satouf",
      "Yuxuan Zong",
      "Habiboulaye Amadou-Boubacar",
      "Pablo Piantanida",
      "Benjamin Piwowarski"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05301v1",
    "abstract": "Generative Retrieval (GR) differs from the traditional index-then-retrieve pipeline by storing relevance in model parameters and directly generating document identifiers. However, GR often struggles to generalize and is costly to scale. We introduce QUESTER (QUEry SpecificaTion gEnerative Retrieval), which reframes GR as query specification generation - in this work, a simple keyword query handled by BM25 - using a (small) LLM. The policy is trained using reinforcement learning techniques (GRPO). Across in- and out-of-domain evaluations, we show that our model is more effective than BM25, and competitive with neural IR models, while maintaining a good efficiency",
    "fetched_at": "2025-11-11T02:19:10.032016Z"
  },
  {
    "id": "2511.05308v1",
    "title": "Rethinking Metrics and Diffusion Architecture for 3D Point Cloud   Generation",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matteo Bastico",
      "David Ryckelynck",
      "Laurent Cort",
      "Yannick Tillier",
      "Etienne Decencire"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05308v1",
    "abstract": "As 3D point clouds become a cornerstone of modern technology, the need for sophisticated generative models and reliable evaluation metrics has grown exponentially. In this work, we first expose that some commonly used metrics for evaluating generated point clouds, particularly those based on Chamfer Distance (CD), lack robustness against defects and fail to capture geometric fidelity and local shape consistency when used as quality indicators. We further show that introducing samples alignment prior to distance calculation and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet essential steps to ensure the consistency and robustness of point cloud generative model evaluation metrics. While existing metrics primarily focus on directly comparing 3D Euclidean coordinates, we present a novel metric, named Surface Normal Concordance (SNC), which approximates surface similarity by comparing estimated point normals. This new metric, when combined with traditional ones, provides a more comprehensive evaluation of the quality of generated samples. Finally, leveraging recent advancements in transformer-based models for point cloud analysis, such as serialized patch attention , we propose a new architecture for generating high-fidelity 3D structures, the Diffusion Point Transformer. We perform extensive experiments and comparisons on the ShapeNet dataset, showing that our model outperforms previous solutions, particularly in terms of quality of generated point clouds, achieving new state-of-the-art. Code available at https://github.com/matteo-bastico/DiffusionPointTransformer.",
    "fetched_at": "2025-11-11T02:19:10.031967Z"
  },
  {
    "id": "2511.05310v1",
    "title": "Listening Between the Lines: Decoding Podcast Narratives with Language   Modeling",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Shreya Gupta",
      "Ojasva Saxena",
      "Arghodeep Nandi",
      "Sarah Masud",
      "Kiran Garimella",
      "Tanmoy Chakraborty"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05310v1",
    "abstract": "Podcasts have become a central arena for shaping public opinion, making them a vital source for understanding contemporary discourse. Their typically unscripted, multi-themed, and conversational style offers a rich but complex form of data. To analyze how podcasts persuade and inform, we must examine their narrative structures -- specifically, the narrative frames they employ.   The fluid and conversational nature of podcasts presents a significant challenge for automated analysis. We show that existing large language models, typically trained on more structured text such as news articles, struggle to capture the subtle cues that human listeners rely on to identify narrative frames. As a result, current approaches fall short of accurately analyzing podcast narratives at scale.   To solve this, we develop and evaluate a fine-tuned BERT model that explicitly links narrative frames to specific entities mentioned in the conversation, effectively grounding the abstract frame in concrete details. Our approach then uses these granular frame labels and correlates them with high-level topics to reveal broader discourse trends. The primary contributions of this paper are: (i) a novel frame-labeling methodology that more closely aligns with human judgment for messy, conversational data, and (ii) a new analysis that uncovers the systematic relationship between what is being discussed (the topic) and how it is being presented (the frame), offering a more robust framework for studying influence in digital media.",
    "fetched_at": "2025-11-11T02:19:10.031910Z"
  },
  {
    "id": "2511.05313v1",
    "title": "Attention and Compression is all you need for Controllably Efficient   Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jatin Prakash",
      "Aahlad Puli",
      "Rajesh Ranganath"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05313v1",
    "abstract": "The quadratic cost of attention in transformers motivated the development of efficient approaches: namely sparse and sliding window attention, convolutions and linear attention. Although these approaches result in impressive reductions in compute and memory, they often trade-off with quality, specifically in-context recall performance. Moreover, apriori fixing this quality-compute tradeoff means being suboptimal from the get-go: some downstream applications require more memory for in-context recall, while others require lower latency and memory. Further, these approaches rely on heuristic choices that artificially restrict attention, or require handcrafted and complex recurrent state update rules, or they must be carefully composed with attention at specific layers to form a hybrid architecture that complicates the design process, especially at scale. To address above issues, we propose Compress & Attend Transformer (CAT), a conceptually simple architecture employing two simple ingredients only: dense attention and compression. CAT decodes chunks of tokens by attending to compressed chunks of the sequence so far. Compression results in decoding from a reduced sequence length that yields compute and memory savings, while choosing a particular chunk size trades-off quality for efficiency. Moreover, CAT can be trained with multiple chunk sizes at once, unlocking control of quality-compute trade-offs directly at test-time without any retraining, all in a single adaptive architecture. In exhaustive evaluations on common language modeling tasks, in-context recall, and long-context understanding, a single adaptive CAT model outperforms existing efficient baselines, including hybrid architectures, across different compute-memory budgets. Further, a single CAT matches dense transformer in language modeling across model scales while being 1.4-3x faster and requiring 2-9x lower total memory usage.",
    "fetched_at": "2025-11-11T02:19:10.031783Z"
  },
  {
    "id": "2511.05320v1",
    "title": "What Are the Facts? Automated Extraction of Court-Established Facts from   Criminal-Court Opinions",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Klra Bendov",
      "Tom Knap",
      "Jan ern",
      "Vojtch Pour",
      "Jaromir Savelka",
      "Ivana Kvapilkov",
      "Jakub Drpal"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05320v1",
    "abstract": "Criminal justice administrative data contain only a limited amount of information about the committed offense. However, there is an unused source of extensive information in continental European courts' decisions: descriptions of criminal behaviors in verdicts by which offenders are found guilty. In this paper, we study the feasibility of extracting these descriptions from publicly available court decisions from Slovakia. We use two different approaches for retrieval: regular expressions and large language models (LLMs). Our baseline was a simple method employing regular expressions to identify typical words occurring before and after the description. The advanced regular expression approach further focused on \"sparing\" and its normalization (insertion of spaces between individual letters), typical for delineating the description. The LLM approach involved prompting the Gemini Flash 2.0 model to extract the descriptions using predefined instructions. Although the baseline identified descriptions in only 40.5% of verdicts, both methods significantly outperformed it, achieving 97% with advanced regular expressions and 98.75% with LLMs, and 99.5% when combined. Evaluation by law students showed that both advanced methods matched human annotations in about 90% of cases, compared to just 34.5% for the baseline. LLMs fully matched human-labeled descriptions in 91.75% of instances, and a combination of advanced regular expressions with LLMs reached 92%.",
    "fetched_at": "2025-11-11T02:19:10.031732Z"
  },
  {
    "id": "2511.05324v1",
    "title": "Evaluating Subword Tokenization Techniques for Bengali: A Benchmark   Study with BengaliBPE",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Firoj Ahmmed Patwary",
      "Abdullah Al Noman"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05324v1",
    "abstract": "Tokenization is an important first step in Natural Language Processing (NLP) pipelines because it decides how models learn and represent linguistic information. However, current subword tokenizers like SentencePiece or HuggingFace BPE are mostly designed for Latin or multilingual corpora and do not perform well on languages with rich morphology such as Bengali. To address this limitation, we present BengaliBPE, a Byte Pair Encoding (BPE) tokenizer specifically developed for the Bengali script. BengaliBPE applies Unicode normalization, grapheme-level initialization, and morphology-aware merge rules to maintain linguistic consistency and preserve subword integrity. We use a large-scale Bengali news classification dataset to compare BengaliBPE with three baselines: Whitespace, SentencePiece BPE, and HuggingFace BPE. The evaluation considers tokenization granularity, encoding speed, and downstream classification accuracy. While all methods perform reasonably well, BengaliBPE provides the most detailed segmentation and the best morphological interpretability, albeit with slightly higher computational cost. These findings highlight the importance of language-aware tokenization for morphologically rich scripts and establish BengaliBPE as a strong foundation for future Bengali NLP systems, including large-scale pretraining of contextual language models.",
    "fetched_at": "2025-11-11T02:19:10.031671Z"
  },
  {
    "id": "2511.05325v1",
    "title": "Turning Adversaries into Allies: Reversing Typographic Attacks for   Multimodal E-Commerce Product Retrieval",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Janet Jenq",
      "Hongda Shen"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.05325v1",
    "abstract": "Multimodal product retrieval systems in e-commerce platforms rely on effectively combining visual and textual signals to improve search relevance and user experience. However, vision-language models such as CLIP are vulnerable to typographic attacks, where misleading or irrelevant text embedded in images skews model predictions. In this work, we propose a novel method that reverses the logic of typographic attacks by rendering relevant textual content (e.g., titles, descriptions) directly onto product images to perform vision-text compression, thereby strengthening image-text alignment and boosting multimodal product retrieval performance. We evaluate our method on three vertical-specific e-commerce datasets (sneakers, handbags, and trading cards) using six state-of-the-art vision foundation models. Our experiments demonstrate consistent improvements in unimodal and multimodal retrieval accuracy across categories and model families. Our findings suggest that visually rendering product metadata is a simple yet effective enhancement for zero-shot multimodal retrieval in e-commerce applications.",
    "fetched_at": "2025-11-11T02:19:10.031628Z"
  },
  {
    "id": "2511.05330v1",
    "title": "Learning Dynamics from Input-Output Data with Hamiltonian Gaussian   Processes",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Jan-Hendrik Ewering",
      "Robin E. Herrmann",
      "Niklas Wahlstrm",
      "Thomas B. Schn",
      "Thomas Seel"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05330v1",
    "abstract": "Embedding non-restrictive prior knowledge, such as energy conservation laws, in learning-based approaches is a key motive to construct physically consistent models from limited data, relevant for, e.g., model-based control. Recent work incorporates Hamiltonian dynamics into Gaussian Process (GP) regression to obtain uncertainty-quantifying models that adhere to the underlying physical principles. However, these works rely on velocity or momentum data, which is rarely available in practice. In this paper, we consider dynamics learning with non-conservative Hamiltonian GPs, and address the more realistic problem setting of learning from input-output data. We provide a fully Bayesian scheme for estimating probability densities of unknown hidden states, of GP hyperparameters, as well as of structural hyperparameters, such as damping coefficients. Considering the computational complexity of GPs, we take advantage of a reduced-rank GP approximation and leverage its properties for computationally efficient prediction and training. The proposed method is evaluated in a nonlinear simulation case study and compared to a state-of-the-art approach that relies on momentum measurements.",
    "fetched_at": "2025-11-11T02:19:10.031583Z"
  },
  {
    "id": "2511.05350v1",
    "title": "Perceptually Aligning Representations of Music via Noise-Augmented   Autoencoders",
    "date": "2025-11-07",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mathias Rose Bjare",
      "Giorgia Cantisani",
      "Marco Pasini",
      "Stefan Lattner",
      "Gerhard Widmer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05350v1",
    "abstract": "We argue that training autoencoders to reconstruct inputs from noised versions of their encodings, when combined with perceptual losses, yields encodings that are structured according to a perceptual hierarchy. We demonstrate the emergence of this hierarchical structure by showing that, after training an audio autoencoder in this manner, perceptually salient information is captured in coarser representation structures than with conventional training. Furthermore, we show that such perceptual hierarchies improve latent diffusion decoding in the context of estimating surprisal in music pitches and predicting EEG-brain responses to music listening. Pretrained weights are available on github.com/CPJKU/pa-audioic.",
    "fetched_at": "2025-11-11T02:19:10.031530Z"
  },
  {
    "id": "2511.05355v1",
    "title": "SAD-Flower: Flow Matching for Safe, Admissible, and Dynamically   Consistent Planning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.RO",
      "RO",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Tzu-Yuan Huang",
      "Armin Lederer",
      "Dai-Jie Wu",
      "Xiaobing Dai",
      "Sihua Zhang",
      "Stefan Sosnowski",
      "Shao-Hua Sun",
      "Sandra Hirche"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05355v1",
    "abstract": "Flow matching (FM) has shown promising results in data-driven planning. However, it inherently lacks formal guarantees for ensuring state and action constraints, whose satisfaction is a fundamental and crucial requirement for the safety and admissibility of planned trajectories on various systems. Moreover, existing FM planners do not ensure the dynamical consistency, which potentially renders trajectories inexecutable. We address these shortcomings by proposing SAD-Flower, a novel framework for generating Safe, Admissible, and Dynamically consistent trajectories. Our approach relies on an augmentation of the flow with a virtual control input. Thereby, principled guidance can be derived using techniques from nonlinear control theory, providing formal guarantees for state constraints, action constraints, and dynamic consistency. Crucially, SAD-Flower operates without retraining, enabling test-time satisfaction of unseen constraints. Through extensive experiments across several tasks, we demonstrate that SAD-Flower outperforms various generative-model-based baselines in ensuring constraint satisfaction.",
    "fetched_at": "2025-11-11T02:19:10.031478Z"
  },
  {
    "id": "2511.05357v1",
    "title": "Diffusion-Based Electromagnetic Inverse Design of Scattering Structured   Media",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "physics.app-ph",
      "app-ph",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Mikhail Tsukerman",
      "Konstantin Grotov",
      "Pavel Ginzburg"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.05357v1",
    "abstract": "We present a conditional diffusion model for electromagnetic inverse design that generates structured media geometries directly from target differential scattering cross-section profiles, bypassing expensive iterative optimization. Our 1D U-Net architecture with Feature-wise Linear Modulation learns to map desired angular scattering patterns to 2x2 dielectric sphere structure, naturally handling the non-uniqueness of inverse problems by sampling diverse valid designs. Trained on 11,000 simulated metasurfaces, the model achieves median MPE below 19% on unseen targets (best: 1.39%), outperforming CMA-ES evolutionary optimization while reducing design time from hours to seconds. These results demonstrate that employing diffusion models is promising for advancing electromagnetic inverse design research, potentially enabling rapid exploration of complex metasurface architectures and accelerating the development of next-generation photonic and wireless communication systems. The code is publicly available at https://github.com/mikzuker/inverse_design_metasurface_generation.",
    "fetched_at": "2025-11-11T02:19:10.031416Z"
  },
  {
    "id": "2511.05361v1",
    "title": "A multimodal multiplex of the mental lexicon for multilingual   individuals",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Maria Huynh",
      "Wilder C. Rodrigues"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05361v1",
    "abstract": "Historically, bilingualism was often perceived as an additional cognitive load that could hinder linguistic and intellectual development. However, over the last three decades, this view has changed considerably. Numerous studies have aimed to model and understand the architecture of the bilingual word recognition system Dijkstra and van Heuven (2002), investigating how parallel activation operates in the brain and how one language influences another Kroll et al. (2015). Increasingly, evidence suggests that multilinguals, individuals who speak three or more languages, can perform better than monolinguals in various linguistic and cognitive tasks, such as learning an additional language Abu-Rabia and Sanitsky (2010). This research proposal focuses on the study of the mental lexicon and how it may be structured in individuals who speak multiple languages. Building on the work of Stella et al. (2018), who investigated explosive learning in humans using a multiplex model of the mental lexicon, and the Bilingual Interactive Activation (BIA+) framework proposed by Dijkstra and van Heuven (2002), the present study applies the same multilayer network principles introduced by Kivela et al. (2014). Our experimental design extends previous research by incorporating multimodality into the multiplex model, introducing an additional layer that connects visual inputs to their corresponding lexical representations across the multilingual layers of the mental lexicon. In this research, we aim to explore how a heritage language influences the acquisition of another language. Specifically, we ask: Does the presence of visual input in a translation task influence participants' proficiency and accuracy compared to text-only conditions?",
    "fetched_at": "2025-11-11T02:19:10.031326Z"
  },
  {
    "id": "2511.05363v1",
    "title": "AI Literacy for Community Colleges: Instructors' Perspectives on   Scenario-Based and Interactive Approaches to Teaching AI",
    "date": "2025-11-07",
    "tags": [
      "cs.CY",
      "CY",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aparna Maya Warrier",
      "Arav Agarwal",
      "Jaromir Savelka",
      "Christopher A Bogart",
      "Heather Burte"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05363v1",
    "abstract": "This research category full paper investigates how community college instructors evaluate interactive, no-code AI literacy resources designed for non-STEM learners. As artificial intelligence becomes increasingly integrated into everyday technologies, AI literacy - the ability to evaluate AI systems, communicate with them, and understand their broader impacts - has emerged as a critical skill across disciplines. Yet effective, scalable approaches for teaching these concepts in higher education remain limited, particularly for students outside STEM fields.   To address this gap, we developed AI User, an interactive online curriculum that introduces core AI concepts through scenario - based activities set in real - world contexts. This study presents findings from four focus groups with instructors who engaged with AI User materials and participated in structured feedback activities. Thematic analysis revealed that instructors valued exploratory tasks that simulated real - world AI use cases and fostered experimentation, while also identifying challenges related to scaffolding, accessibility, and multi-modal support. A ranking task for instructional support materials showed a strong preference for interactive demonstrations over traditional educational materials like conceptual guides or lecture slides.   These findings offer insights into instructor perspectives on making AI concepts more accessible and relevant for broad learner audiences. They also inform the design of AI literacy tools that align with diverse teaching contexts and support critical engagement with AI in higher education.",
    "fetched_at": "2025-11-11T02:19:10.031281Z"
  },
  {
    "id": "2511.05394v1",
    "title": "AI Assisted AR Assembly: Object Recognition and Computer Vision for   Augmented Reality Assisted Assembly",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "H.5.2; H.5.1; I.4.8; I.2.6",
      "6"
    ],
    "authors": [
      "Alexander Htet Kyaw",
      "Haotian Ma",
      "Sasa Zivkovic",
      "Jenny Sabin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05394v1",
    "abstract": "We present an AI-assisted Augmented Reality assembly workflow that uses deep learning-based object recognition to identify different assembly components and display step-by-step instructions. For each assembly step, the system displays a bounding box around the corresponding components in the physical space, and where the component should be placed. By connecting assembly instructions with the real-time location of relevant components, the system eliminates the need for manual searching, sorting, or labeling of different components before each assembly. To demonstrate the feasibility of using object recognition for AR-assisted assembly, we highlight a case study involving the assembly of LEGO sculptures.",
    "fetched_at": "2025-11-11T02:19:10.031101Z"
  },
  {
    "id": "2511.05399v1",
    "title": "Robust Neural Audio Fingerprinting using Music Foundation Models",
    "date": "2025-11-07",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shubhr Singh",
      "Kiran Bhat",
      "Xavier Riley",
      "Benjamin Resnick",
      "John Thickstun",
      "Walter De Brouwer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05399v1",
    "abstract": "The proliferation of distorted, compressed, and manipulated music on modern media platforms like TikTok motivates the development of more robust audio fingerprinting techniques to identify the sources of musical recordings. In this paper, we develop and evaluate new neural audio fingerprinting techniques with the aim of improving their robustness. We make two contributions to neural fingerprinting methodology: (1) we use a pretrained music foundation model as the backbone of the neural architecture and (2) we expand the use of data augmentation to train fingerprinting models under a wide variety of audio manipulations, including time streching, pitch modulation, compression, and filtering. We systematically evaluate our methods in comparison to two state-of-the-art neural fingerprinting models: NAFP and GraFPrint. Results show that fingerprints extracted with music foundation models (e.g., MuQ, MERT) consistently outperform models trained from scratch or pretrained on non-musical audio. Segment-level evaluation further reveals their capability to accurately localize fingerprint matches, an important practical feature for catalog management.",
    "fetched_at": "2025-11-11T02:19:10.031001Z"
  },
  {
    "id": "2511.05404v1",
    "title": "Multi-modal Loop Closure Detection with Foundation Models in Severely   Unstructured Environments",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "I.2.9; I.2.10",
      "10"
    ],
    "authors": [
      "Laura Alejandra Encinar Gonzalez",
      "John Folkesson",
      "Rudolph Triebel",
      "Riccardo Giubilato"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05404v1",
    "abstract": "Robust loop closure detection is a critical component of Simultaneous Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as in the context of planetary exploration. In these settings, visual place recognition often fails due to aliasing and weak textures, while LiDAR-based methods suffer from sparsity and ambiguity. This paper presents MPRF, a multimodal pipeline that leverages transformer-based foundation models for both vision and LiDAR modalities to achieve robust loop closure in severely unstructured environments. Unlike prior work limited to retrieval, MPRF integrates a two-stage visual retrieval strategy with explicit 6-DoF pose estimation, combining DINOv2 features with SALAD aggregation for efficient candidate screening and SONATA-based LiDAR descriptors for geometric verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show that MPRF outperforms state-of-the-art retrieval methods in precision while enhancing pose estimation robustness in low-texture regions. By providing interpretable correspondences suitable for SLAM back-ends, MPRF achieves a favorable trade-off between accuracy, efficiency, and reliability, demonstrating the potential of foundation models to unify place recognition and pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.",
    "fetched_at": "2025-11-11T02:19:10.030944Z"
  },
  {
    "id": "2511.05406v1",
    "title": "Large Language Models for Explainable Threat Intelligence",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tiago Dinis",
      "Miguel Correia",
      "Roger Tavares"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05406v1",
    "abstract": "As cyber threats continue to grow in complexity, traditional security mechanisms struggle to keep up. Large language models (LLMs) offer significant potential in cybersecurity due to their advanced capabilities in text processing and generation. This paper explores the use of LLMs with retrieval-augmented generation (RAG) to obtain threat intelligence by combining real-time information retrieval with domain-specific data. The proposed system, RAGRecon, uses a LLM with RAG to answer questions about cybersecurity threats. Moreover, it makes this form of Artificial Intelligence (AI) explainable by generating and visually presenting to the user a knowledge graph for every reply. This increases the transparency and interpretability of the reasoning of the model, allowing analysts to better understand the connections made by the system based on the context recovered by the RAG system. We evaluated RAGRecon experimentally with two datasets and seven different LLMs and the responses matched the reference responses more than 91% of the time for the best combinations.",
    "fetched_at": "2025-11-11T02:19:10.030846Z"
  },
  {
    "id": "2511.05407v1",
    "title": "Minority-Aware Satisfaction Estimation in Dialogue Systems via   Preference-Adaptive Reinforcement Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yahui Fu",
      "Zi Haur Pang",
      "Tatsuya Kawahara"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05407v1",
    "abstract": "User satisfaction in dialogue systems is inherently subjective. When the same response strategy is applied across users, minority users may assign different satisfaction ratings than majority users due to variations in individual intents and preferences. However, existing alignment methods typically train one-size-fits-all models that aim for broad consensus, often overlooking minority perspectives and user-specific adaptation. We propose a unified framework that models both individual- and group-level preferences for user satisfaction estimation. First, we introduce Chain-of-Personalized-Reasoning (CoPeR) to capture individual preferences through interpretable reasoning chains. Second, we propose an expectation-maximization-based Majority-Minority Preference-Aware Clustering (M2PC) algorithm that discovers distinct user groups in an unsupervised manner to learn group-level preferences. Finally, we integrate these components into a preference-adaptive reinforcement learning framework (PAda-PPO) that jointly optimizes alignment with both individual and group preferences. Experiments on the Emotional Support Conversation dataset demonstrate consistent improvements in user satisfaction estimation, particularly for underrepresented user groups.",
    "fetched_at": "2025-11-11T02:19:10.030805Z"
  },
  {
    "id": "2511.05408v1",
    "title": "Steering Language Models with Weight Arithmetic",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Constanza Fierro",
      "Fabien Roger"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05408v1",
    "abstract": "Providing high-quality feedback to Large Language Models (LLMs) on a diverse training distribution can be difficult and expensive, and providing feedback only on a narrow distribution can result in unintended generalizations. To better leverage narrow training data, we propose contrastive weight steering, a simple post-training method that edits the model parameters using weight arithmetic. We isolate a behavior direction in weight-space by subtracting the weight deltas from two small fine-tunes -- one that induces the desired behavior and another that induces its opposite -- and then add or remove this direction to modify the model's weights. We apply this technique to mitigate sycophancy and induce misalignment, and find that weight steering often generalizes further than activation steering, achieving stronger out-of-distribution behavioral control before degrading general capabilities. We also show that, in the context of task-specific fine-tuning, weight steering can partially mitigate undesired behavioral drift: it can reduce sycophancy and under-refusals introduced during fine-tuning while preserving task performance gains. Finally, we provide preliminary evidence that emergent misalignment can be detected by measuring the similarity between fine-tuning updates and an \"evil\" weight direction, suggesting that it may be possible to monitor the evolution of weights during training and detect rare misaligned behaviors that never manifest during training or evaluations.",
    "fetched_at": "2025-11-11T02:19:10.030759Z"
  },
  {
    "id": "2511.05420v1",
    "title": "ProDER: A Continual Learning Approach for Fault Prediction in Evolving   Smart Grids",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Emad Efatinasab",
      "Nahal Azadi",
      "Davide Dalle Pezze",
      "Gian Antonio Susto",
      "Chuadhry Mujeeb Ahmed",
      "Mirco Rampazzo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05420v1",
    "abstract": "As smart grids evolve to meet growing energy demands and modern operational challenges, the ability to accurately predict faults becomes increasingly critical. However, existing AI-based fault prediction models struggle to ensure reliability in evolving environments where they are required to adapt to new fault types and operational zones. In this paper, we propose a continual learning (CL) framework in the smart grid context to evolve the model together with the environment. We design four realistic evaluation scenarios grounded in class-incremental and domain-incremental learning to emulate evolving grid conditions. We further introduce Prototype-based Dark Experience Replay (ProDER), a unified replay-based approach that integrates prototype-based feature regularization, logit distillation, and a prototype-guided replay memory. ProDER achieves the best performance among tested CL techniques, with only a 0.045 accuracy drop for fault type prediction and 0.015 for fault zone prediction. These results demonstrate the practicality of CL for scalable, real-world fault prediction in smart grids.",
    "fetched_at": "2025-11-11T02:19:10.030716Z"
  },
  {
    "id": "2511.05430v1",
    "title": "\"I Like That You Have to Poke Around\": Instructors on How Experiential   Approaches to AI Literacy Spark Inquiry and Critical Thinking",
    "date": "2025-11-07",
    "tags": [
      "cs.CY",
      "CY",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aparna Maya Warrier",
      "Arav Agarwal",
      "Jaromir Savelka",
      "Christopher Bogart",
      "Heather Burte"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05430v1",
    "abstract": "As artificial intelligence (AI) increasingly shapes decision-making across domains, there is a growing need to support AI literacy among learners beyond computer science. However, many current approaches rely on programming-heavy tools or abstract lecture-based content, limiting accessibility for non-STEM audiences. This paper presents findings from a study of AI User, a modular, web-based curriculum that teaches core AI concepts through interactive, no-code projects grounded in real-world scenarios. The curriculum includes eight projects; this study focuses on instructor feedback on Projects 5-8, which address applied topics such as natural language processing, computer vision, decision support, and responsible AI. Fifteen community college instructors participated in structured focus groups, completing the projects as learners and providing feedback through individual reflection and group discussion. Using thematic analysis, we examined how instructors evaluated the design, instructional value, and classroom applicability of these experiential activities. Findings highlight instructors' appreciation for exploratory tasks, role-based simulations, and real-world relevance, while also surfacing design trade-offs around cognitive load, guidance, and adaptability for diverse learners. This work extends prior research on AI literacy by centering instructor perspectives on teaching complex AI topics without code. It offers actionable insights for designing inclusive, experiential AI learning resources that scale across disciplines and learner backgrounds.",
    "fetched_at": "2025-11-11T02:19:10.030663Z"
  },
  {
    "id": "2511.05442v1",
    "title": "APP: Accelerated Path Patching with Task-Specific Pruning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "68Uxx",
      "I.2.7; I.2.6; I.2.m",
      "m"
    ],
    "authors": [
      "Frauke Andersen",
      "William Rudman",
      "Ruochen Zhang",
      "Carsten Eickhoff"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05442v1",
    "abstract": "Circuit discovery is a key step in many mechanistic interpretability pipelines. Current methods, such as Path Patching, are computationally expensive and have limited in-depth circuit analysis for smaller models. In this study, we propose Accelerated Path Patching (APP), a hybrid approach leveraging our novel contrastive attention head pruning method to drastically reduce the search space of circuit discovery methods. Our Contrastive-FLAP pruning algorithm uses techniques from causal mediation analysis to assign higher pruning scores to task-specific attention heads, leading to higher performing sparse models compared to traditional pruning techniques. Although Contrastive-FLAP is successful at preserving task-specific heads that existing pruning algorithms remove at low sparsity ratios, the circuits found by Contrastive-FLAP alone are too large to satisfy the minimality constraint required in circuit analysis. APP first applies Contrastive-FLAP to reduce the search space on required for circuit discovery algorithms by, on average, 56\\%. Next, APP, applies traditional Path Patching on the remaining attention heads, leading to a speed up of 59.63\\%-93.27\\% compared to Path Patching applied to the dense model. Despite the substantial computational saving that APP provides, circuits obtained from APP exhibit substantial overlap and similar performance to previously established Path Patching circuits",
    "fetched_at": "2025-11-11T02:19:10.030606Z"
  },
  {
    "id": "2511.05444v1",
    "title": "Adversarially Robust Multitask Adaptive Control",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Kasra Fallah",
      "Leonardo F. Toso",
      "James Anderson"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05444v1",
    "abstract": "We study adversarially robust multitask adaptive linear quadratic control; a setting where multiple systems collaboratively learn control policies under model uncertainty and adversarial corruption. We propose a clustered multitask approach that integrates clustering and system identification with resilient aggregation to mitigate corrupted model updates. Our analysis characterizes how clustering accuracy, intra-cluster heterogeneity, and adversarial behavior affect the expected regret of certainty-equivalent (CE) control across LQR tasks. We establish non-asymptotic bounds demonstrating that the regret decreases inversely with the number of honest systems per cluster and that this reduction is preserved under a bounded fraction of adversarial systems within each cluster.",
    "fetched_at": "2025-11-11T02:19:10.030555Z"
  },
  {
    "id": "2511.05449v1",
    "title": "How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tuan Anh Tran",
      "Duy M. H. Nguyen",
      "Hoai-Chau Tran",
      "Michael Barz",
      "Khoa D. Doan",
      "Roger Wattenhofer",
      "Ngo Anh Vien",
      "Mathias Niepert",
      "Daniel Sonntag",
      "Paul Swoboda"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05449v1",
    "abstract": "Recent advances in 3D point cloud transformers have led to state-of-the-art results in tasks such as semantic segmentation and reconstruction. However, these models typically rely on dense token representations, incurring high computational and memory costs during training and inference. In this work, we present the finding that tokens are remarkably redundant, leading to substantial inefficiency. We introduce gitmerge3D, a globally informed graph token merging method that can reduce the token count by up to 90-95% while maintaining competitive performance. This finding challenges the prevailing assumption that more tokens inherently yield better performance and highlights that many current models are over-tokenized and under-optimized for scalability. We validate our method across multiple 3D vision tasks and show consistent improvements in computational efficiency. This work is the first to assess redundancy in large-scale 3D transformer models, providing insights into the development of more efficient 3D foundation architectures. Our code and checkpoints are publicly available at https://gitmerge3d.github.io",
    "fetched_at": "2025-11-11T02:19:10.030511Z"
  },
  {
    "id": "2511.05452v1",
    "title": "Self-adaptive weighting and sampling for physics-informed neural   networks",
    "date": "2025-11-07",
    "tags": [
      "stat.ML",
      "ML",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Wenqian Chen",
      "Amanda Howard",
      "Panos Stinis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05452v1",
    "abstract": "Physics-informed deep learning has emerged as a promising framework for solving partial differential equations (PDEs). Nevertheless, training these models on complex problems remains challenging, often leading to limited accuracy and efficiency. In this work, we introduce a hybrid adaptive sampling and weighting method to enhance the performance of physics-informed neural networks (PINNs). The adaptive sampling component identifies training points in regions where the solution exhibits rapid variation, while the adaptive weighting component balances the convergence rate across training points. Numerical experiments show that applying only adaptive sampling or only adaptive weighting is insufficient to consistently achieve accurate predictions, particularly when training points are scarce. Since each method emphasizes different aspects of the solution, their effectiveness is problem dependent. By combining both strategies, the proposed framework consistently improves prediction accuracy and training efficiency, offering a more robust approach for solving PDEs with PINNs.",
    "fetched_at": "2025-11-11T02:19:10.030443Z"
  },
  {
    "id": "2511.05456v1",
    "title": "Parameter-Efficient Conditioning for Material Generalization in   Graph-Based Simulators",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Naveen Raj Manoharan",
      "Hassan Iqbal",
      "Krishna Kumar"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05456v1",
    "abstract": "Graph network-based simulators (GNS) have demonstrated strong potential for learning particle-based physics (such as fluids, deformable solids, and granular flows) while generalizing to unseen geometries due to their inherent inductive biases. However, existing models are typically trained for a single material type and fail to generalize across distinct constitutive behaviors, limiting their applicability in real-world engineering settings. Using granular flows as a running example, we propose a parameter-efficient conditioning mechanism that makes the GNS model adaptive to material parameters. We identify that sensitivity to material properties is concentrated in the early message-passing (MP) layers, a finding we link to the local nature of constitutive models (e.g., Mohr-Coulomb) and their effects on information propagation. We empirically validate this by showing that fine-tuning only the first few (1-5) of 10 MP layers of a pretrained model achieves comparable test performance as compared to fine-tuning the entire network. Building on this insight, we propose a parameter-efficient Feature-wise Linear Modulation (FiLM) conditioning mechanism designed to specifically target these early layers. This approach produces accurate long-term rollouts on unseen, interpolated, or moderately extrapolated values (e.g., up to 2.5 degrees for friction angle and 0.25 kPa for cohesion) when trained exclusively on as few as 12 short simulation trajectories from new materials, representing a 5-fold data reduction compared to a baseline multi-task learning method. Finally, we validate the model's utility by applying it to an inverse problem, successfully identifying unknown cohesion parameters from trajectory data. This approach enables the use of GNS in inverse design and closed-loop control tasks where material properties are treated as design variables.",
    "fetched_at": "2025-11-11T02:19:10.030399Z"
  },
  {
    "id": "2511.05460v1",
    "title": "Synapse: Adaptive Arbitration of Complementary Expertise in Time Series   Foundational Models",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Sarkar Snigdha Sarathi Das",
      "Palash Goyal",
      "Mihir Parmar",
      "Yiwen Song",
      "Long T. Le",
      "Lesly Miculicich",
      "Jinsung Yoon",
      "Rui Zhang",
      "Hamid Palangi",
      "Tomas Pfister"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05460v1",
    "abstract": "Pre-trained Time Series Foundational Models (TSFMs) represent a significant advance, capable of forecasting diverse time series with complex characteristics, including varied seasonalities, trends, and long-range dependencies. Despite their primary goal of universal time series forecasting, their efficacy is far from uniform; divergent training protocols and data sources cause individual TSFMs to exhibit highly variable performance across different forecasting tasks, domains, and horizons. Leveraging this complementary expertise by arbitrating existing TSFM outputs presents a compelling strategy, yet this remains a largely unexplored area of research. In this paper, we conduct a thorough examination of how different TSFMs exhibit specialized performance profiles across various forecasting settings, and how we can effectively leverage this behavior in arbitration between different time series models. We specifically analyze how factors such as model selection and forecast horizon distribution can influence the efficacy of arbitration strategies. Based on this analysis, we propose Synapse, a novel arbitration framework for TSFMs. Synapse is designed to dynamically leverage a pool of TSFMs, assign and adjust predictive weights based on their relative, context-dependent performance, and construct a robust forecast distribution by adaptively sampling from the output quantiles of constituent models. Experimental results demonstrate that Synapse consistently outperforms other popular ensembling techniques as well as individual TSFMs, demonstrating Synapse's efficacy in time series forecasting.",
    "fetched_at": "2025-11-11T02:19:10.030197Z"
  },
  {
    "id": "2511.05462v1",
    "title": "SiamMM: A Mixture Model Perspective on Deep Unsupervised Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Xiaodong Wang",
      "Jing Huang",
      "Kevin J Liang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05462v1",
    "abstract": "Recent studies have demonstrated the effectiveness of clustering-based approaches for self-supervised and unsupervised learning. However, the application of clustering is often heuristic, and the optimal methodology remains unclear. In this work, we establish connections between these unsupervised clustering methods and classical mixture models from statistics. Through this framework, we demonstrate significant enhancements to these clustering methods, leading to the development of a novel model named SiamMM. Our method attains state-of-the-art performance across various self-supervised learning benchmarks. Inspection of the learned clusters reveals a strong resemblance to unseen ground truth labels, uncovering potential instances of mislabeling.",
    "fetched_at": "2025-11-11T02:19:10.030120Z"
  },
  {
    "id": "2511.05471v1",
    "title": "Precipitation nowcasting of satellite data using physically conditioned   neural networks",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Antnio Cato",
      "Melvin Poveda",
      "Leonardo Voltarelli",
      "Paulo Orenstein"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05471v1",
    "abstract": "Accurate short-term precipitation forecasts predominantly rely on dense weather-radar networks, limiting operational value in places most exposed to climate extremes. We present TUPANN (Transferable and Universal Physics-Aligned Nowcasting Network), a satellite-only model trained on GOES-16 RRQPE. Unlike most deep learning models for nowcasting, TUPANN decomposes the forecast into physically meaningful components: a variational encoder-decoder infers motion and intensity fields from recent imagery under optical-flow supervision, a lead-time-conditioned MaxViT evolves the latent state, and a differentiable advection operator reconstructs future frames. We evaluate TUPANN on both GOES-16 and IMERG data, in up to four distinct climates (Rio de Janeiro, Manaus, Miami, La Paz) at 10-180min lead times using the CSI and HSS metrics over 4-64 mm/h thresholds. Comparisons against optical-flow, deep learning and hybrid baselines show that TUPANN achieves the best or second-best skill in most settings, with pronounced gains at higher thresholds. Training on multiple cities further improves performance, while cross-city experiments show modest degradation and occasional gains for rare heavy-rain regimes. The model produces smooth, interpretable motion fields aligned with numerical optical flow and runs in near real time due to the low latency of GOES-16. These results indicate that physically aligned learning can provide nowcasts that are skillful, transferable and global.",
    "fetched_at": "2025-11-11T02:19:10.030079Z"
  },
  {
    "id": "2511.05475v1",
    "title": "AI Literacy Assessment Revisited: A Task-Oriented Approach Aligned with   Real-world Occupations",
    "date": "2025-11-07",
    "tags": [
      "cs.CY",
      "CY",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Christopher Bogart",
      "Aparna Warrier",
      "Arav Agarwal",
      "Ross Higashi",
      "Yufan Zhang",
      "Jesse Flot",
      "Jaromir Savelka",
      "Heather Burte",
      "Majd Sakr"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05475v1",
    "abstract": "As artificial intelligence (AI) systems become ubiquitous in professional contexts, there is an urgent need to equip workers, often with backgrounds outside of STEM, with the skills to use these tools effectively as well as responsibly, that is, to be AI literate. However, prevailing definitions and therefore assessments of AI literacy often emphasize foundational technical knowledge, such as programming, mathematics, and statistics, over practical knowledge such as interpreting model outputs, selecting tools, or identifying ethical concerns. This leaves a noticeable gap in assessing someone's AI literacy for real-world job use. We propose a work-task-oriented assessment model for AI literacy which is grounded in the competencies required for effective use of AI tools in professional settings. We describe the development of a novel AI literacy assessment instrument, and accompanying formative assessments, in the context of a US Navy robotics training program. The program included training in robotics and AI literacy, as well as a competition with practical tasks and a multiple choice scenario task meant to simulate use of AI in a job setting. We found that, as a measure of applied AI literacy, the competition's scenario task outperformed the tests we adopted from past research or developed ourselves. We argue that when training people for AI-related work, educators should consider evaluating them with instruments that emphasize highly contextualized practical skills rather than abstract technical knowledge, especially when preparing workers without technical backgrounds for AI-integrated roles.",
    "fetched_at": "2025-11-11T02:19:10.030028Z"
  },
  {
    "id": "2511.05476v1",
    "title": "A Metamorphic Testing Perspective on Knowledge Distillation for Language   Models of Code: Does the Student Deeply Mimic the Teacher?",
    "date": "2025-11-07",
    "tags": [
      "cs.SE",
      "SE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Md. Abdul Awal",
      "Mrigank Rochan",
      "Chanchal K. Roy"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.05476v1",
    "abstract": "Transformer-based language models of code have achieved state-of-the-art performance across a wide range of software analytics tasks, but their practical deployment remains limited due to high computational costs, slow inference speeds, and significant environmental impact. To address these challenges, recent research has increasingly explored knowledge distillation as a method for compressing a large language model of code (the teacher) into a smaller model (the student) while maintaining performance. However, the degree to which a student model deeply mimics the predictive behavior and internal representations of its teacher remains largely unexplored, as current accuracy-based evaluation provides only a surface-level view of model quality and often fails to capture more profound discrepancies in behavioral fidelity between the teacher and student models. To address this gap, we empirically show that the student model often fails to deeply mimic the teacher model, resulting in up to 285% greater performance drop under adversarial attacks, which is not captured by traditional accuracy-based evaluation. Therefore, we propose MetaCompress, a metamorphic testing framework that systematically evaluates behavioral fidelity by comparing the outputs of teacher and student models under a set of behavior-preserving metamorphic relations. We evaluate MetaCompress on two widely studied tasks, using compressed versions of popular language models of code, obtained via three different knowledge distillation techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress identifies up to 62% behavioral discrepancies in student models, underscoring the need for behavioral fidelity evaluation within the knowledge distillation pipeline and establishing MetaCompress as a practical framework for testing compressed language models of code derived through knowledge distillation.",
    "fetched_at": "2025-11-11T02:19:10.029956Z"
  },
  {
    "id": "2511.05480v1",
    "title": "On Flow Matching KL Divergence",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Maojiang Su",
      "Jerry Yao-Chieh Hu",
      "Sophia Pi",
      "Han Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05480v1",
    "abstract": "We derive a deterministic, non-asymptotic upper bound on the Kullback-Leibler (KL) divergence of the flow-matching distribution approximation. In particular, if the $L_2$ flow-matching loss is bounded by $\\epsilon^2 > 0$, then the KL divergence between the true data distribution and the estimated distribution is bounded by $A_1 \\epsilon + A_2 \\epsilon^2$. Here, the constants $A_1$ and $A_2$ depend only on the regularities of the data and velocity fields. Consequently, this bound implies statistical convergence rates of Flow Matching Transformers under the Total Variation (TV) distance. We show that, flow matching achieves nearly minimax-optimal efficiency in estimating smooth distributions. Our results make the statistical efficiency of flow matching comparable to that of diffusion models under the TV distance. Numerical studies on synthetic and learned velocities corroborate our theory.",
    "fetched_at": "2025-11-11T02:19:10.029904Z"
  },
  {
    "id": "2511.05482v1",
    "title": "SoilX: Calibration-Free Comprehensive Soil Sensing Through Contrastive   Cross-Component Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kang Yang",
      "Yuanlin Yang",
      "Yuning Chen",
      "Sikai Yang",
      "Xinyu Zhang",
      "Wan Du"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05482v1",
    "abstract": "Precision agriculture demands continuous and accurate monitoring of soil moisture (M) and key macronutrients, including nitrogen (N), phosphorus (P), and potassium (K), to optimize yields and conserve resources. Wireless soil sensing has been explored to measure these four components; however, current solutions require recalibration (i.e., retraining the data processing model) to handle variations in soil texture, characterized by aluminosilicates (Al) and organic carbon (C), limiting their practicality. To address this, we introduce SoilX, a calibration-free soil sensing system that jointly measures six key components: {M, N, P, K, C, Al}. By explicitly modeling C and Al, SoilX eliminates texture- and carbon-dependent recalibration. SoilX incorporates Contrastive Cross-Component Learning (3CL), with two customized terms: the Orthogonality Regularizer and the Separation Loss, to effectively disentangle cross-component interference. Additionally, we design a novel tetrahedral antenna array with an antenna-switching mechanism, which can robustly measure soil dielectric permittivity independent of device placement. Extensive experiments demonstrate that SoilX reduces estimation errors by 23.8% to 31.5% over baselines and generalizes well to unseen fields.",
    "fetched_at": "2025-11-11T02:19:10.029842Z"
  },
  {
    "id": "2511.05483v1",
    "title": "DGTN: Graph-Enhanced Transformer with Diffusive Attention Gating   Mechanism for Enzyme DDG Prediction",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Abigail Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05483v1",
    "abstract": "Predicting the effect of amino acid mutations on enzyme thermodynamic stability (DDG) is fundamental to protein engineering and drug design. While recent deep learning approaches have shown promise, they often process sequence and structure information independently, failing to capture the intricate coupling between local structural geometry and global sequential patterns. We present DGTN (Diffused Graph-Transformer Network), a novel architecture that co-learns graph neural network (GNN) weights for structural priors and transformer attention through a diffusion mechanism. Our key innovation is a bidirectional diffusion process where: (1) GNN-derived structural embeddings guide transformer attention via learnable diffusion kernels, and (2) transformer representations refine GNN message passing through attention-modulated graph updates. We provide rigorous mathematical analysis showing this co-learning scheme achieves provably better approximation bounds than independent processing. On ProTherm and SKEMPI benchmarks, DGTN achieves state-of-the-art performance (Pearson Rho = 0.87, RMSE = 1.21 kcal/mol), with 6.2% improvement over best baselines. Ablation studies confirm the diffusion mechanism contributes 4.8 points to correlation. Our theoretical analysis proves the diffused attention converges to optimal structure-sequence coupling, with convergence rate O(1/sqrt(T) ) where T is diffusion steps. This work establishes a principled framework for integrating heterogeneous protein representations through learnable diffusion.",
    "fetched_at": "2025-11-11T02:19:10.029783Z"
  },
  {
    "id": "2511.05485v1",
    "title": "MIMIC-SR-ICD11: A Dataset for Narrative-Based Diagnosis",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7; I.5.1",
      "1"
    ],
    "authors": [
      "Yuexin Wu",
      "Shiqi Wang",
      "Vasile Rus"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05485v1",
    "abstract": "Disease diagnosis is a central pillar of modern healthcare, enabling early detection and timely intervention for acute conditions while guiding lifestyle adjustments and medication regimens to prevent or slow chronic disease. Self-reports preserve clinically salient signals that templated electronic health record (EHR) documentation often attenuates or omits, especially subtle but consequential details. To operationalize this shift, we introduce MIMIC-SR-ICD11, a large English diagnostic dataset built from EHR discharge notes and natively aligned to WHO ICD-11 terminology. We further present LL-Rank, a likelihood-based re-ranking framework that computes a length-normalized joint likelihood of each label given the clinical report context and subtracts the corresponding report-free prior likelihood for that label. Across seven model backbones, LL-Rank consistently outperforms a strong generation-plus-mapping baseline (GenMap). Ablation experiments show that LL-Rank's gains primarily stem from its PMI-based scoring, which isolates semantic compatibility from label frequency bias.",
    "fetched_at": "2025-11-11T02:19:10.029736Z"
  },
  {
    "id": "2511.05489v1",
    "title": "TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding   via Self-Verification Reinforcement Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junwen Pan",
      "Qizhe Zhang",
      "Rui Zhang",
      "Ming Lu",
      "Xin Wan",
      "Yuan Zhang",
      "Chang Liu",
      "Qi She"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05489v1",
    "abstract": "Temporal search aims to identify a minimal set of relevant frames from tens of thousands based on a given query, serving as a foundation for accurate long-form video understanding. Existing works attempt to progressively narrow the search space. However, these approaches typically rely on a hand-crafted search process, lacking end-to-end optimization for learning optimal search strategies. In this paper, we propose TimeSearch-R, which reformulates temporal search as interleaved text-video thinking, seamlessly integrating searching video clips into the reasoning process through reinforcement learning (RL). However, applying RL training methods, such as Group Relative Policy Optimization (GRPO), to video reasoning can result in unsupervised intermediate search decisions. This leads to insufficient exploration of the video content and inconsistent logical reasoning. To address these issues, we introduce GRPO with Completeness Self-Verification (GRPO-CSV), which gathers searched video frames from the interleaved reasoning process and utilizes the same policy model to verify the adequacy of searched frames, thereby improving the completeness of video reasoning. Additionally, we construct datasets specifically designed for the SFT cold-start and RL training of GRPO-CSV, filtering out samples with weak temporal dependencies to enhance task difficulty and improve temporal search capabilities. Extensive experiments demonstrate that TimeSearch-R achieves significant improvements on temporal search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as long-form video understanding benchmarks like VideoMME and MLVU. Notably, TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1% improvement over the base model Qwen2.5-VL and 2.0% over the advanced video reasoning model Video-R1. Our code is available at https://github.com/Time-Search/TimeSearch-R.",
    "fetched_at": "2025-11-11T02:19:10.029667Z"
  },
  {
    "id": "2511.04883v1",
    "title": "Self-Interest and Systemic Benefits: Emergence of Collective Rationality   in Mixed Autonomy Traffic Through Deep Reinforcement Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Di Chen",
      "Jia Li",
      "Michael Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04883v1",
    "abstract": "Autonomous vehicles (AVs) are expected to be commercially available in the near future, leading to mixed autonomy traffic consisting of both AVs and human-driven vehicles (HVs). Although numerous studies have shown that AVs can be deployed to benefit the overall traffic system performance by incorporating system-level goals into their decision making, it is not clear whether the benefits still exist when agents act out of self-interest -- a trait common to all driving agents, both human and autonomous. This study aims to understand whether self-interested AVs can bring benefits to all driving agents in mixed autonomy traffic systems. The research is centered on the concept of collective rationality (CR). This concept, originating from game theory and behavioral economics, means that driving agents may cooperate collectively even when pursuing individual interests. Our recent research has proven the existence of CR in an analytical game-theoretical model and empirically in mixed human-driven traffic. In this paper, we demonstrate that CR can be attained among driving agents trained using deep reinforcement learning (DRL) with a simple reward design. We examine the extent to which self-interested traffic agents can achieve CR without directly incorporating system-level objectives. Results show that CR consistently emerges in various scenarios, which indicates the robustness of this property. We also postulate a mechanism to explain the emergence of CR in the microscopic and dynamic environment and verify it based on simulation evidence. This research suggests the possibility of leveraging advanced learning methods (such as federated learning) to achieve collective cooperation among self-interested driving agents in mixed-autonomy systems.",
    "fetched_at": "2025-11-11T02:19:06.855982Z"
  },
  {
    "id": "2511.04904v1",
    "title": "Multi-Agent Craftax: Benchmarking Open-Ended Multi-Agent Reinforcement   Learning at the Hyperscale",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Bassel Al Omari",
      "Michael Matthews",
      "Alexander Rutherford",
      "Jakob Nicolaus Foerster"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04904v1",
    "abstract": "Progress in multi-agent reinforcement learning (MARL) requires challenging benchmarks that assess the limits of current methods. However, existing benchmarks often target narrow short-horizon challenges that do not adequately stress the long-term dependencies and generalization capabilities inherent in many multi-agent systems. To address this, we first present \\textit{Craftax-MA}: an extension of the popular open-ended RL environment, Craftax, that supports multiple agents and evaluates a wide range of general abilities within a single environment. Written in JAX, \\textit{Craftax-MA} is exceptionally fast with a training run using 250 million environment interactions completing in under an hour. To provide a more compelling challenge for MARL, we also present \\textit{Craftax-Coop}, an extension introducing heterogeneous agents, trading and more mechanics that require complex cooperation among agents for success. We provide analysis demonstrating that existing algorithms struggle with key challenges in this benchmark, including long-horizon credit assignment, exploration and cooperation, and argue for its potential to drive long-term research in MARL.",
    "fetched_at": "2025-11-11T02:19:06.855877Z"
  },
  {
    "id": "2511.04949v1",
    "title": "DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for   Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Tharindu Fernando",
      "Clinton Fookes",
      "Sridha Sridharan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04949v1",
    "abstract": "Rapid advances in generative AI have led to increasingly realistic deepfakes, posing growing challenges for law enforcement and public trust. Existing passive deepfake detectors struggle to keep pace, largely due to their dependence on specific forgery artifacts, which limits their ability to generalize to new deepfake types. Proactive deepfake detection using watermarks has emerged to address the challenge of identifying high-quality synthetic media. However, these methods often struggle to balance robustness against benign distortions with sensitivity to malicious tampering. This paper introduces a novel deep learning framework that harnesses high-dimensional latent space representations and the Multi-Agent Adversarial Reinforcement Learning (MAARL) paradigm to develop a robust and adaptive watermarking approach. Specifically, we develop a learnable watermark embedder that operates in the latent space, capturing high-level image semantics, while offering precise control over message encoding and extraction. The MAARL paradigm empowers the learnable watermarking agent to pursue an optimal balance between robustness and fragility by interacting with a dynamic curriculum of benign and malicious image manipulations simulated by an adversarial attacker agent. Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that our method consistently outperforms state-of-the-art approaches, achieving improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under challenging manipulation scenarios.",
    "fetched_at": "2025-11-11T02:19:06.855812Z"
  },
  {
    "id": "2511.04967v2",
    "title": "Hybrid action Reinforcement Learning for quantum architecture search",
    "date": "2025-11-07",
    "tags": [
      "quant-ph"
    ],
    "authors": [
      "Jiayang Niu",
      "Yan Wang",
      "Jie Li",
      "Ke Deng",
      "Azadeh Alavi",
      "Mark Sanderson",
      "Yongli Ren"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04967v2",
    "abstract": "Designing expressive yet trainable quantum circuit architectures remains a major challenge for variational quantum algorithms, as manual or heuristic designs often yield suboptimal performance. We propose HyRLQAS (Hybrid-Action Reinforcement Learning for Quantum Architecture Search), a unified framework that integrates discrete gate placement and continuous parameter generation within a hybrid action space. Unlike existing approaches that optimize circuit structure and parameters separately, HyRLQAS jointly learns both topology and initialization while dynamically refining previously placed gates through reinforcement learning. Trained in a variational quantum eigensolver (VQE) environment, the agent autonomously constructs circuits that minimize molecular ground-state energy. Experimental results demonstrate that HyRLQAS achieves consistently lower energy errors and more compact circuit structures compared with discrete-only and continuous-only baselines. Furthermore, the hybrid action space yields superior parameter initializations, producing post-optimization energy distributions with consistently lower minima. These findings suggest that hybrid-action reinforcement learning offers a principled pathway toward automated and hardware-efficient quantum circuit design.",
    "fetched_at": "2025-11-11T02:19:06.855700Z"
  },
  {
    "id": "2511.05005v1",
    "title": "Multi-agent Coordination via Flow Matching",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Dongsu Lee",
      "Daehee Lee",
      "Amy Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05005v1",
    "abstract": "This work presents MAC-Flow, a simple yet expressive framework for multi-agent coordination. We argue that requirements of effective coordination are twofold: (i) a rich representation of the diverse joint behaviors present in offline data and (ii) the ability to act efficiently in real time. However, prior approaches often sacrifice one for the other, i.e., denoising diffusion-based solutions capture complex coordination but are computationally slow, while Gaussian policy-based solutions are fast but brittle in handling multi-agent interaction. MAC-Flow addresses this trade-off by first learning a flow-based representation of joint behaviors, and then distilling it into decentralized one-step policies that preserve coordination while enabling fast execution. Across four different benchmarks, including $12$ environments and $34$ datasets, MAC-Flow alleviates the trade-off between performance and computational cost, specifically achieving about $\\boldsymbol{\\times14.5}$ faster inference compared to diffusion-based MARL methods, while maintaining good performance. At the same time, its inference speed is similar to that of prior Gaussian policy-based offline multi-agent reinforcement learning (MARL) methods.",
    "fetched_at": "2025-11-11T02:19:06.855585Z"
  },
  {
    "id": "2511.05203v1",
    "title": "Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic   Interactive Learning in a Shared Latent Space",
    "date": "2025-11-07",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Linus Nwankwo",
      "Bjrn Ellensohn",
      "Christian Rauch",
      "Elmar Rueckert"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05203v1",
    "abstract": "Today's autonomous agents can understand free-form natural language instructions and execute long-horizon tasks in a manner akin to human-level reasoning. These capabilities are mostly driven by large-scale pre-trained foundation models (FMs). However, the approaches with which these models are grounded for human-robot interaction (HRI) perpetuate a master-apprentice model, where the apprentice (embodied agent) passively receives and executes the master's (human's) commands without reciprocal learning. This reactive interaction approach does not capture the co-adaptive dynamics inherent in everyday multi-turn human-human interactions. To address this, we propose a Symbiotic Interactive Learning (SIL) approach that enables both the master and the apprentice to co-adapt through mutual, bidirectional interactions. We formalised SIL as a co-adaptation process within a shared latent task space, where the agent and human maintain joint belief states that evolve based on interaction history. This enables the agent to move beyond reactive execution to proactive clarification, adaptive suggestions, and shared plan refinement. To realise these novel behaviours, we leveraged pre-trained FMs for spatial perception and reasoning, alongside a lightweight latent encoder that grounds the models' outputs into task-specific representations. Furthermore, to ensure stability as the tasks evolve, we augment SIL with a memory architecture that prevents the forgetting of learned task-space representations. We validate SIL on both simulated and real-world embodied tasks, including instruction following, information retrieval, query-oriented reasoning, and interactive dialogues. Demos and resources are public at:~\\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.",
    "fetched_at": "2025-11-11T02:19:06.855540Z"
  },
  {
    "id": "2511.05207v1",
    "title": "Emergence from Emergence: Financial Market Simulation via Learning with   Heterogeneous Preferences",
    "date": "2025-11-07",
    "tags": [
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Ryuko Hashimoto",
      "Ryosuke Takata",
      "Masahiro Suzuki",
      "Yuki Tanaka",
      "Kiyoshi Izumi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05207v1",
    "abstract": "Agent-based models help explain stock price dynamics as emergent phenomena driven by interacting investors. In this modeling tradition, investor behavior has typically been captured by two distinct mechanisms -- learning and heterogeneous preferences -- which have been explored as separate paradigms in prior studies. However, the impact of their joint modeling on the resulting collective dynamics remains largely unexplored. We develop a multi-agent reinforcement learning framework in which agents endowed with heterogeneous risk aversion, time discounting, and information access collectively learn trading strategies within a unified shared-policy framework. The experiment reveals that (i) learning with heterogeneous preferences drives agents to develop strategies aligned with their individual traits, fostering behavioral differentiation and niche specialization within the market, and (ii) the interactions by the differentiated agents are essential for the emergence of realistic market dynamics such as fat-tailed price fluctuations and volatility clustering. This study presents a constructive paradigm for financial market modeling in which the joint design of heterogeneous preferences and learning mechanisms enables two-stage emergence: individual behavior and the collective market dynamics.",
    "fetched_at": "2025-11-11T02:19:06.855486Z"
  },
  {
    "id": "2511.05242v1",
    "title": "Guaranteeing Both Consensus and Optimality in Decentralized Nonconvex   Optimization with Multiple Local Updates",
    "date": "2025-11-07",
    "tags": [
      "math.OC",
      "OC"
    ],
    "authors": [
      "Jie Liu",
      "Zuang Wang",
      "Yongqiang Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05242v1",
    "abstract": "Scalable decentralized optimization in large-scale systems hinges on efficient communication. A common way to reduce communication overhead is to perform multiple local updates between two communication rounds, as in federated learning. However, extending this strategy to fully decentralized settings poses fundamental challenges. Existing decentralized algorithms with multiple local updates guarantee accurate convergence only under strong convexity, limiting applicability to the nonconvex problems prevalent in machine learning. Moreover, many methods require exchanging and storing auxiliary variables, such as gradient-tracking vectors or correction terms, to ensure convergence under data heterogeneity, incurring high communication and memory costs. In this paper, we propose MILE, a fully decentralized algorithm that guarantees both consensus and optimality under multiple local updates in general nonconvex settings. This is achieved through a novel periodic-system-based formulation and a lifting-based analysis, which together yield a closed-form expression for the state evolution across local updates, a theoretical advance not achieved previously. This closed-form characterization allows us to establish, for the first time, guaranteed consensus and optimality in decentralized nonconvex optimization under multiple local updates, in contrast to prior results that only ensure optimality of the average state. We prove that MILE achieves an $O(1/T)$ convergence rate under both exact and stochastic gradients, while requiring only a single variable exchange per interacting agent pair, minimizing communication and memory costs. Numerical experiments on benchmark datasets confirm its effectiveness.",
    "fetched_at": "2025-11-11T02:19:06.855430Z"
  },
  {
    "id": "2511.05271v1",
    "title": "DeepEyesV2: Toward Agentic Multimodal Model",
    "date": "2025-11-07",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jack Hong",
      "Chenxiao Zhao",
      "ChengLin Zhu",
      "Weiheng Lu",
      "Guohai Xu",
      "Xing Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05271v1",
    "abstract": "Agentic multimodal models should not only comprehend text and images, but also actively invoke external tools, such as code execution environments and web search, and integrate these operations into reasoning. In this work, we introduce DeepEyesV2 and explore how to build an agentic multimodal model from the perspectives of data construction, training methods, and model evaluation. We observe that direct reinforcement learning alone fails to induce robust tool-use behavior. This phenomenon motivates a two-stage training pipeline: a cold-start stage to establish tool-use patterns, and reinforcement learning stage to further refine tool invocation. We curate a diverse, moderately challenging training dataset, specifically including examples where tool use is beneficial. We further introduce RealX-Bench, a comprehensive benchmark designed to evaluate real-world multimodal reasoning, which inherently requires the integration of multiple capabilities, including perception, search, and reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative benchmarks, demonstrating its effectiveness across real-world understanding, mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2 exhibits task-adaptive tool invocation, tending to use image operations for perception tasks and numerical computations for reasoning tasks. Reinforcement learning further enables complex tool combinations and allows model to selectively invoke tools based on context. We hope our study can provide guidance for community in developing agentic multimodal models.",
    "fetched_at": "2025-11-11T02:19:06.855327Z"
  },
  {
    "id": "2511.05375v1",
    "title": "Reasoning Is All You Need for Urban Planning AI",
    "date": "2025-11-07",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sijie Yang",
      "Jiatong Li",
      "Filip Biljecki"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05375v1",
    "abstract": "AI has proven highly successful at urban planning analysis -- learning patterns from data to predict future conditions. The next frontier is AI-assisted decision-making: agents that recommend sites, allocate resources, and evaluate trade-offs while reasoning transparently about constraints and stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting, ReAct, and multi-agent collaboration frameworks -- now make this vision achievable.   This position paper presents the Agentic Urban Planning AI Framework for reasoning-capable planning agents that integrates three cognitive layers (Perception, Foundation, Reasoning) with six logic components (Analysis, Generation, Verification, Evaluation, Collaboration, Decision) through a multi-agents collaboration framework. We demonstrate why planning decisions require explicit reasoning capabilities that are value-based (applying normative principles), rule-grounded (guaranteeing constraint satisfaction), and explainable (generating transparent justifications) -- requirements that statistical learning alone cannot fulfill. We compare reasoning agents with statistical learning, present a comprehensive architecture with benchmark evaluation metrics, and outline critical research challenges. This framework shows how AI agents can augment human planners by systematically exploring solution spaces, verifying regulatory compliance, and deliberating over trade-offs transparently -- not replacing human judgment but amplifying it with computational reasoning capabilities.",
    "fetched_at": "2025-11-11T02:19:06.855219Z"
  },
  {
    "id": "2511.05396v1",
    "title": "Sample Complexity of Distributionally Robust Off-Dynamics Reinforcement   Learning with Online Interaction",
    "date": "2025-11-07",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.RO",
      "RO",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Yiting He",
      "Zhishuai Liu",
      "Weixin Wang",
      "Pan Xu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05396v1",
    "abstract": "Off-dynamics reinforcement learning (RL), where training and deployment transition dynamics are different, can be formulated as learning in a robust Markov decision process (RMDP) where uncertainties in transition dynamics are imposed. Existing literature mostly assumes access to generative models allowing arbitrary state-action queries or pre-collected datasets with a good state coverage of the deployment environment, bypassing the challenge of exploration. In this work, we study a more realistic and challenging setting where the agent is limited to online interaction with the training environment. To capture the intrinsic difficulty of exploration in online RMDPs, we introduce the supremal visitation ratio, a novel quantity that measures the mismatch between the training dynamics and the deployment dynamics. We show that if this ratio is unbounded, online learning becomes exponentially hard. We propose the first computationally efficient algorithm that achieves sublinear regret in online RMDPs with $f$-divergence based transition uncertainties. We also establish matching regret lower bounds, demonstrating that our algorithm achieves optimal dependence on both the supremal visitation ratio and the number of interaction episodes. Finally, we validate our theoretical results through comprehensive numerical experiments.",
    "fetched_at": "2025-11-11T02:19:06.855070Z"
  },
  {
    "id": "2511.04898v1",
    "title": "Real-Time Reasoning Agents in Evolving Environments",
    "date": "2025-11-07",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yule Wen",
      "Yixin Ye",
      "Yanzhe Zhang",
      "Diyi Yang",
      "Hao Zhu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04898v1",
    "abstract": "Agents in the real world must make not only logical but also timely judgments. This requires continuous awareness of the dynamic environment: hazards emerge, opportunities arise, and other agents act, while the agent's reasoning is still unfolding. Despite advances in language model reasoning, existing approaches fail to account for this dynamic nature. We introduce real-time reasoning as a new problem formulation for agents in evolving environments and build Real-Time Reasoning Gym to demonstrate it. We study two paradigms for deploying language models in agents: (1) reactive agents, which employ language models with bounded reasoning computation for rapid responses, and (2) planning agents, which allow extended reasoning computation for complex problems. Our experiments show that even state-of-the-art models struggle with making logical and timely judgments in either paradigm. To address this limitation, we propose AgileThinker, which simultaneously engages both reasoning paradigms. AgileThinker consistently outperforms agents engaging only one reasoning paradigm as the task difficulty and time pressure rise, effectively balancing reasoning depth and response latency. Our work establishes real-time reasoning as a critical testbed for developing practical agents and provides a foundation for research in temporally constrained AI systems, highlighting a path toward real-time capable agents.",
    "fetched_at": "2025-11-11T02:19:05.033149Z"
  },
  {
    "id": "2511.04914v2",
    "title": "MERaLiON-SER: Robust Speech Emotion Recognition Model for English and   SEA Languages",
    "date": "2025-11-07",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hardik B. Sailor",
      "Aw Ai Ti",
      "Chen Fang Yih Nancy",
      "Chiu Ying Lay",
      "Ding Yang",
      "He Yingxu",
      "Jiang Ridong",
      "Li Jingtao",
      "Liao Jingyi",
      "Liu Zhuohan",
      "Lu Yanfeng",
      "Ma Yi",
      "Manas Gupta",
      "Muhammad Huzaifah Bin Md Shahrin",
      "Nabilah Binte Md Johan",
      "Nattadaporn Lertcheva",
      "Pan Chunlei",
      "Pham Minh Duc",
      "Siti Maryam Binte Ahmad Subaidi",
      "Siti Umairah Binte Mohammad Salleh",
      "Sun Shuo",
      "Tarun Kumar Vangani",
      "Wang Qiongqiong",
      "Won Cheng Yi Lewis",
      "Wong Heng Meng Jeremy",
      "Wu Jinyang",
      "Zhang Huayun",
      "Zhang Longyin",
      "Zou Xunlong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04914v2",
    "abstract": "We present MERaLiON-SER, a robust speech emotion recognition model de- signed for English and Southeast Asian languages. The model is trained using a hybrid objective combining weighted categorical cross-entropy and Concordance Correlation Coefficient (CCC) losses for joint discrete and dimensional emotion modelling. This dual approach enables the model to capture both the distinct categories of emotion (like happy or angry) and the fine-grained, such as arousal (intensity), valence (positivity/negativity), and dominance (sense of control), lead- ing to a more comprehensive and robust representation of human affect. Extensive evaluations across multilingual Singaporean languages (English, Chinese, Malay, and Tamil ) and other public benchmarks show that MERaLiON-SER consistently surpasses both open-source speech encoders and large Audio-LLMs. These results underscore the importance of specialised speech-only models for accurate paralin- guistic understanding and cross-lingual generalisation. Furthermore, the proposed framework provides a foundation for integrating emotion-aware perception into future agentic audio systems, enabling more empathetic and contextually adaptive multimodal reasoning.",
    "fetched_at": "2025-11-11T02:19:05.033045Z"
  },
  {
    "id": "2511.04921v1",
    "title": "AgentExpt: Automating AI Experiment Design with LLM-based Resource   Retrieval Agent",
    "date": "2025-11-07",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yu Li",
      "Lehui Li",
      "Qingmin Liao",
      "Fengli Xu",
      "Yong Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04921v1",
    "abstract": "Large language model agents are becoming increasingly capable at web-centric tasks such as information retrieval, complex reasoning. These emerging capabilities have given rise to surge research interests in developing LLM agent for facilitating scientific quest. One key application in AI research is to automate experiment design through agentic dataset and baseline retrieval. However, prior efforts suffer from limited data coverage, as recommendation datasets primarily harvest candidates from public portals and omit many datasets actually used in published papers, and from an overreliance on content similarity that biases model toward superficial similarity and overlooks experimental suitability. Harnessing collective perception embedded in the baseline and dataset citation network, we present a comprehensive framework for baseline and dataset recommendation. First, we design an automated data-collection pipeline that links roughly one hundred thousand accepted papers to the baselines and datasets they actually used. Second, we propose a collective perception enhanced retriever. To represent the position of each dataset or baseline within the scholarly network, it concatenates self-descriptions with aggregated citation contexts. To achieve efficient candidate recall, we finetune an embedding model on these representations. Finally, we develop a reasoning-augmented reranker that exact interaction chains to construct explicit reasoning chains and finetunes a large language model to produce interpretable justifications and refined rankings. The dataset we curated covers 85\\% of the datasets and baselines used at top AI conferences over the past five years. On our dataset, the proposed method outperforms the strongest prior baseline with average gains of +5.85\\% in Recall@20, +8.30\\% in HitRate@5. Taken together, our results advance reliable, interpretable automation of experimental design.",
    "fetched_at": "2025-11-11T02:19:05.032887Z"
  },
  {
    "id": "2511.04956v1",
    "title": "ORCHID: Orchestrated Retrieval-Augmented Classification with   Human-in-the-Loop Intelligent Decision-Making for High-Risk Property",
    "date": "2025-11-07",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Maria Mahbub",
      "Vanessa Lama",
      "Sanjay Das",
      "Brian Starks",
      "Christopher Polchek",
      "Saffell Silvers",
      "Lauren Deck",
      "Prasanna Balaprakash",
      "Tirthankar Ghosal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04956v1",
    "abstract": "High-Risk Property (HRP) classification is critical at U.S. Department of Energy (DOE) sites, where inventories include sensitive and often dual-use equipment. Compliance must track evolving rules designated by various export control policies to make transparent and auditable decisions. Traditional expert-only workflows are time-consuming, backlog-prone, and struggle to keep pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic system for HRP classification that pairs retrieval-augmented generation (RAG) with human oversight to produce policy-based outputs that can be audited. Small cooperating agents, retrieval, description refiner, classifier, validator, and feedback logger, coordinate via agent-to-agent messaging and invoke tools through the Model Context Protocol (MCP) for model-agnostic on-premise operation. The interface follows an Item to Evidence to Decision loop with step-by-step reasoning, on-policy citations, and append-only audit bundles (run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID improves accuracy and traceability over a non-agentic baseline while deferring uncertain items to Subject Matter Experts (SMEs). The demonstration shows single item submission, grounded citations, SME feedback capture, and exportable audit artifacts, illustrating a practical path to trustworthy LLM assistance in sensitive DOE compliance workflows.",
    "fetched_at": "2025-11-11T02:19:05.032814Z"
  },
  {
    "id": "2511.04976v1",
    "title": "iFlyBot-VLM Technical Report",
    "date": "2025-11-07",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Xin Nie",
      "Zhiyuan Cheng",
      "Yuan Zhang",
      "Chao Ji",
      "Jiajia Wu",
      "Yuhan Zhang",
      "Jia Pan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04976v1",
    "abstract": "We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used to improve the domain of Embodied Intelligence. The central objective of iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional environmental perception and low-level robotic motion control. To this end, the model abstracts complex visual and spatial information into a body-agnostic and transferable Operational Language, thereby enabling seamless perception-action closed-loop coordination across diverse robotic platforms. The architecture of iFlyBot-VLM is systematically designed to realize four key functional capabilities essential for embodied intelligence: 1) Spatial Understanding and Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and Control Parameter Generation; 4) Task Planning and Skill Sequencing. We envision iFlyBot-VLM as a scalable and generalizable foundation model for embodied AI, facilitating the progression from specialized task-oriented systems toward generalist, cognitively capable agents. We conducted evaluations on 10 current mainstream embodied intelligence-related VLM benchmark datasets, such as Blink and Where2Place, and achieved optimal performance while preserving the model's general capabilities. We will publicly release both the training data and model weights to foster further research and development in the field of Embodied Intelligence.",
    "fetched_at": "2025-11-11T02:19:05.032744Z"
  },
  {
    "id": "2511.05269v1",
    "title": "TAMAS: Benchmarking Adversarial Risks in Multi-Agent LLM Systems",
    "date": "2025-11-07",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ishan Kavathekar",
      "Hemang Jain",
      "Ameya Rathod",
      "Ponnurangam Kumaraguru",
      "Tanuja Ganu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05269v1",
    "abstract": "Large Language Models (LLMs) have demonstrated strong capabilities as autonomous agents through tool use, planning, and decision-making abilities, leading to their widespread adoption across diverse tasks. As task complexity grows, multi-agent LLM systems are increasingly used to solve problems collaboratively. However, safety and security of these systems remains largely under-explored. Existing benchmarks and datasets predominantly focus on single-agent settings, failing to capture the unique vulnerabilities of multi-agent dynamics and co-ordination. To address this gap, we introduce $\\textbf{T}$hreats and $\\textbf{A}$ttacks in $\\textbf{M}$ulti-$\\textbf{A}$gent $\\textbf{S}$ystems ($\\textbf{TAMAS}$), a benchmark designed to evaluate the robustness and safety of multi-agent LLM systems. TAMAS includes five distinct scenarios comprising 300 adversarial instances across six attack types and 211 tools, along with 100 harmless tasks. We assess system performance across ten backbone LLMs and three agent interaction configurations from Autogen and CrewAI frameworks, highlighting critical challenges and failure modes in current multi-agent deployments. Furthermore, we introduce Effective Robustness Score (ERS) to assess the tradeoff between safety and task effectiveness of these frameworks. Our findings show that multi-agent systems are highly vulnerable to adversarial attacks, underscoring the urgent need for stronger defenses. TAMAS provides a foundation for systematically studying and improving the safety of multi-agent LLM systems.",
    "fetched_at": "2025-11-11T02:19:05.032683Z"
  },
  {
    "id": "2511.05311v1",
    "title": "Cleaning Maintenance Logs with LLM Agents for Improved Predictive   Maintenance",
    "date": "2025-11-07",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.RO",
      "RO",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Valeriu Dimidov",
      "Faisal Hawlader",
      "Sasan Jafarnejad",
      "Raphal Frank"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05311v1",
    "abstract": "Economic constraints, limited availability of datasets for reproducibility and shortages of specialized expertise have long been recognized as key challenges to the adoption and advancement of predictive maintenance (PdM) in the automotive sector. Recent progress in large language models (LLMs) presents an opportunity to overcome these barriers and speed up the transition of PdM from research to industrial practice. Under these conditions, we explore the potential of LLM-based agents to support PdM cleaning pipelines. Specifically, we focus on maintenance logs, a critical data source for training well-performing machine learning (ML) models, but one often affected by errors such as typos, missing fields, near-duplicate entries, and incorrect dates. We evaluate LLM agents on cleaning tasks involving six distinct types of noise. Our findings show that LLMs are effective at handling generic cleaning tasks and offer a promising foundation for future industrial applications. While domain-specific errors remain challenging, these results highlight the potential for further improvements through specialized training and enhanced agentic capabilities.",
    "fetched_at": "2025-11-11T02:19:05.032626Z"
  },
  {
    "id": "2511.05359v1",
    "title": "ConVerse: Benchmarking Contextual Safety in Agent-to-Agent Conversations",
    "date": "2025-11-07",
    "tags": [
      "cs.CR",
      "CR",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Amr Gomaa",
      "Ahmed Salem",
      "Sahar Abdelnabi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05359v1",
    "abstract": "As language models evolve into autonomous agents that act and communicate on behalf of users, ensuring safety in multi-agent ecosystems becomes a central challenge. Interactions between personal assistants and external service providers expose a core tension between utility and protection: effective collaboration requires information sharing, yet every exchange creates new attack surfaces. We introduce ConVerse, a dynamic benchmark for evaluating privacy and security risks in agent-agent interactions. ConVerse spans three practical domains (travel, real estate, insurance) with 12 user personas and over 864 contextually grounded attacks (611 privacy, 253 security). Unlike prior single-agent settings, it models autonomous, multi-turn agent-to-agent conversations where malicious requests are embedded within plausible discourse. Privacy is tested through a three-tier taxonomy assessing abstraction quality, while security attacks target tool use and preference manipulation. Evaluating seven state-of-the-art models reveals persistent vulnerabilities; privacy attacks succeed in up to 88% of cases and security breaches in up to 60%, with stronger models leaking more. By unifying privacy and security within interactive multi-agent contexts, ConVerse reframes safety as an emergent property of communication.",
    "fetched_at": "2025-11-11T02:19:05.032573Z"
  },
  {
    "id": "2511.05385v1",
    "title": "TeaRAG: A Token-Efficient Agentic Retrieval-Augmented Generation   Framework",
    "date": "2025-11-07",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chao Zhang",
      "Yuhao Wang",
      "Derong Xu",
      "Haoxin Zhang",
      "Yuanjie Lyu",
      "Yuhao Chen",
      "Shuochen Liu",
      "Tong Xu",
      "Xiangyu Zhao",
      "Yan Gao",
      "Yao Hu",
      "Enhong Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.05385v1",
    "abstract": "Retrieval-Augmented Generation (RAG) utilizes external knowledge to augment Large Language Models' (LLMs) reliability. For flexibility, agentic RAG employs autonomous, multi-round retrieval and reasoning to resolve queries. Although recent agentic RAG has improved via reinforcement learning, they often incur substantial token overhead from search and reasoning processes. This trade-off prioritizes accuracy over efficiency. To address this issue, this work proposes TeaRAG, a token-efficient agentic RAG framework capable of compressing both retrieval content and reasoning steps. 1) First, the retrieved content is compressed by augmenting chunk-based semantic retrieval with a graph retrieval using concise triplets. A knowledge association graph is then built from semantic similarity and co-occurrence. Finally, Personalized PageRank is leveraged to highlight key knowledge within this graph, reducing the number of tokens per retrieval. 2) Besides, to reduce reasoning steps, Iterative Process-aware Direct Preference Optimization (IP-DPO) is proposed. Specifically, our reward function evaluates the knowledge sufficiency by a knowledge matching mechanism, while penalizing excessive reasoning steps. This design can produce high-quality preference-pair datasets, supporting iterative DPO to improve reasoning conciseness. Across six datasets, TeaRAG improves the average Exact Match by 4% and 2% while reducing output tokens by 61% and 59% on Llama3-8B-Instruct and Qwen2.5-14B-Instruct, respectively. Code is available at https://github.com/Applied-Machine-Learning-Lab/TeaRAG.",
    "fetched_at": "2025-11-11T02:19:05.032519Z"
  },
  {
    "id": "2511.05459v2",
    "title": "SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for   Large Language Models",
    "date": "2025-11-07",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingxuan Xu",
      "Ken Deng",
      "Weihao Li",
      "Songwei Yu",
      "Huaixi Tang",
      "Haoyang Huang",
      "Zhiyi Lai",
      "Zizheng Zhan",
      "Yanan Wu",
      "Chenchen Zhang",
      "Kepeng Lei",
      "Yifan Yao",
      "Xinping Lei",
      "Wenqiang Zhu",
      "Zongxian Feng",
      "Han Li",
      "Junqi Xiong",
      "Dailin Li",
      "Zuchen Gao",
      "Kun Wu",
      "Wen Xiang",
      "Ziqi Zhan",
      "Yuanxing Zhang",
      "Wuxuan Gong",
      "Ziyuan Gao",
      "Guanxiang Wang",
      "Yirong Xue",
      "Xiaojiang Zhang",
      "Jinghui Wang",
      "Huiming Wang",
      "Wenhao Zhuang",
      "Zhaoxiang Zhang",
      "Yuqun Zhang",
      "Haotian Zhang",
      "Bin Chen",
      "Jiaheng Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.05459v2",
    "abstract": "Evaluating large language models (LLMs) for software engineering has been limited by narrow task coverage, language bias, and insufficient alignment with real-world developer workflows. Existing benchmarks often focus on algorithmic problems or Python-centric bug fixing, leaving critical dimensions of software engineering underexplored. To address these gaps, we introduce SWE-Compass1, a comprehensive benchmark that unifies heterogeneous code-related evaluations into a structured and production-aligned framework. SWE-Compass spans 8 task types, 8 programming scenarios, and 10 programming languages, with 2000 high-quality instances curated from authentic GitHub pull requests and refined through systematic filtering and validation. We benchmark ten state-of-the-art LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear hierarchy of difficulty across task types, languages, and scenarios. Moreover, by aligning evaluation with real-world developer practices, SWE-Compass provides a rigorous and reproducible foundation for diagnosing and advancing agentic coding capabilities in large language models.",
    "fetched_at": "2025-11-11T02:19:05.032415Z"
  },
  {
    "id": "2511.04584v1",
    "title": "Are We Asking the Right Questions? On Ambiguity in Natural Language   Queries for Tabular Data Analysis",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.DB",
      "DB",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Daniel Gomm",
      "Cornelius Wolff",
      "Madelon Hulsebos"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04584v1",
    "abstract": "Natural language interfaces to tabular data must handle ambiguities inherent to queries. Instead of treating ambiguity as a deficiency, we reframe it as a feature of cooperative interaction, where the responsibility of query specification is shared among the user and the system. We develop a principled framework distinguishing cooperative queries, i.e., queries that yield a resolvable interpretation, from uncooperative queries that cannot be resolved. Applying the framework to evaluations for tabular question answering and analysis, we analyze the queries in 15 popular datasets, and observe an uncontrolled mixing of query types neither adequate for evaluating a system's execution accuracy nor for evaluating interpretation capabilities. Our framework and analysis of queries shifts the perspective from fixing ambiguity to embracing cooperation in resolving queries. This reflection enables more informed design and evaluation for natural language interfaces for tabular data, for which we outline implications and directions for future research.",
    "fetched_at": "2025-11-11T02:19:10.041280Z"
  },
  {
    "id": "2511.04588v1",
    "title": "Question the Questions: Auditing Representation in Online Deliberative   Processes",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Soham De",
      "Lodewijk Gelauff",
      "Ashish Goel",
      "Smitha Milli",
      "Ariel Procaccia",
      "Alice Siu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04588v1",
    "abstract": "A central feature of many deliberative processes, such as citizens' assemblies and deliberative polls, is the opportunity for participants to engage directly with experts. While participants are typically invited to propose questions for expert panels, only a limited number can be selected due to time constraints. This raises the challenge of how to choose a small set of questions that best represent the interests of all participants. We introduce an auditing framework for measuring the level of representation provided by a slate of questions, based on the social choice concept known as justified representation (JR). We present the first algorithms for auditing JR in the general utility setting, with our most efficient algorithm achieving a runtime of $O(mn\\log n)$, where $n$ is the number of participants and $m$ is the number of proposed questions. We apply our auditing methods to historical deliberations, comparing the representativeness of (a) the actual questions posed to the expert panel (chosen by a moderator), (b) participants' questions chosen via integer linear programming, (c) summary questions generated by large language models (LLMs). Our results highlight both the promise and current limitations of LLMs in supporting deliberative processes. By integrating our methods into an online deliberation platform that has been used for over hundreds of deliberations across more than 50 countries, we make it easy for practitioners to audit and improve representation in future deliberations.",
    "fetched_at": "2025-11-11T02:19:10.041237Z"
  },
  {
    "id": "2511.04594v1",
    "title": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest   Path Problems",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Utkarsh U. Chavan",
      "Prashant Trivedi",
      "Nandyala Hemachandra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04594v1",
    "abstract": "Multi-agent systems (MAS) are central to applications such as swarm robotics and traffic routing, where agents must coordinate in a decentralized manner to achieve a common objective. Stochastic Shortest Path (SSP) problems provide a natural framework for modeling decentralized control in such settings. While the problem of learning in SSP has been extensively studied in single-agent settings, the decentralized multi-agent variant remains largely unexplored. In this work, we take a step towards addressing that gap. We study decentralized multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the transition dynamics and costs are represented using linear models. Applying novel symmetry-based arguments, we identify the structure of optimal policies. Our main contribution is the first regret lower bound for this setting based on the construction of hard-to-learn instances for any number of agents, $n$. Our regret lower bound of $\\Omega(\\sqrt{K})$, over $K$ episodes, highlights the inherent learning difficulty in Dec-MASSPs. These insights clarify the learning complexity of decentralized control and can further guide the design of efficient learning algorithms in multi-agent systems.",
    "fetched_at": "2025-11-11T02:19:10.041147Z"
  },
  {
    "id": "2511.04727v1",
    "title": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding   in VLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ali Faraz",
      "Akash",
      "Shaharukh Khan",
      "Raja Kolla",
      "Akshat Patidar",
      "Suranjan Goswami",
      "Abhinav Ravi",
      "Chandra Khatri",
      "Shubham Agarwal"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04727v1",
    "abstract": "Vision-language models (VLMs) have demonstrated impressive generalization across multimodal tasks, yet most evaluation benchmarks remain Western-centric, leaving open questions about their performance in culturally diverse and multilingual settings. To address this gap, we introduce IndicVisionBench, the first large-scale benchmark centered on the Indian subcontinent. Covering English and 10 Indian languages, our benchmark spans 3 multimodal tasks, including Optical Character Recognition (OCR), Multimodal Machine Translation (MMT), and Visual Question Answering (VQA), covering 6 kinds of question types. Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across 13 culturally grounded topics. In addition, we release a paired parallel corpus of annotations across 10 Indic languages, creating a unique resource for analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum of 8 models, from proprietary closed-source systems to open-weights medium and large-scale models. Our experiments reveal substantial performance gaps, underscoring the limitations of current VLMs in culturally diverse contexts. By centering cultural diversity and multilinguality, IndicVisionBench establishes a reproducible evaluation framework that paves the way for more inclusive multimodal research.",
    "fetched_at": "2025-11-11T02:19:10.041060Z"
  },
  {
    "id": "2511.04611v1",
    "title": "evomap: A Toolbox for Dynamic Mapping in Python",
    "date": "2025-11-06",
    "tags": [
      "cs.MS",
      "MS",
      "cs.LG",
      "LG",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Maximilian Matthe"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04611v1",
    "abstract": "This paper presents evomap, a Python package for dynamic mapping. Mapping methods are widely used across disciplines to visualize relationships among objects as spatial representations, or maps. However, most existing statistical software supports only static mapping, which captures objects' relationships at a single point in time and lacks tools to analyze how these relationships evolve. evomap fills this gap by implementing the dynamic mapping framework EvoMap, originally proposed by Matthe, Ringel, and Skiera (2023), which adapts traditional static mapping methods for dynamic analyses. The package supports multiple mapping techniques, including variants of Multidimensional Scaling (MDS), Sammon Mapping, and t-distributed Stochastic Neighbor Embedding (t-SNE). It also includes utilities for data preprocessing, exploration, and result evaluation, offering a comprehensive toolkit for dynamic mapping applications. This paper outlines the foundations of static and dynamic mapping, describes the architecture and functionality of evomap, and illustrates its application through an extensive usage example.",
    "fetched_at": "2025-11-11T02:19:10.040994Z"
  },
  {
    "id": "2511.04619v1",
    "title": "Dynamic causal discovery in Alzheimer's disease through latent   pseudotime modelling",
    "date": "2025-11-06",
    "tags": [
      "stat.AP",
      "AP",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Natalia Glazman",
      "Jyoti Mangal",
      "Pedro Borges",
      "Sebastien Ourselin",
      "M. Jorge Cardoso"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04619v1",
    "abstract": "The application of causal discovery to diseases like Alzheimer's (AD) is limited by the static graph assumptions of most methods; such models cannot account for an evolving pathophysiology, modulated by a latent disease pseudotime. We propose to apply an existing latent variable model to real-world AD data, inferring a pseudotime that orders patients along a data-driven disease trajectory independent of chronological age, then learning how causal relationships evolve. Pseudotime outperformed age in predicting diagnosis (AUC 0.82 vs 0.59). Incorporating minimal, disease-agnostic background knowledge substantially improved graph accuracy and orientation. Our framework reveals dynamic interactions between novel (NfL, GFAP) and established AD markers, enabling practical causal discovery despite violated assumptions.",
    "fetched_at": "2025-11-11T02:19:10.040954Z"
  },
  {
    "id": "2511.04728v1",
    "title": "Trustworthiness Calibration Framework for Phishing Email Detection Using   Large Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Daniyal Ganiuly",
      "Assel Smaiyl"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04728v1",
    "abstract": "Phishing emails continue to pose a persistent challenge to online communication, exploiting human trust and evading automated filters through realistic language and adaptive tactics. While large language models (LLMs) such as GPT-4 and LLaMA-3-8B achieve strong accuracy in text classification, their deployment in security systems requires assessing reliability beyond benchmark performance. To address this, this study introduces the Trustworthiness Calibration Framework (TCF), a reproducible methodology for evaluating phishing detectors across three dimensions: calibration, consistency, and robustness. These components are integrated into a bounded index, the Trustworthiness Calibration Index (TCI), and complemented by the Cross-Dataset Stability (CDS) metric that quantifies stability of trustworthiness across datasets. Experiments conducted on five corpora, such as SecureMail 2025, Phishing Validation 2024, CSDMC2010, Enron-Spam, and Nazario, using DeBERTa-v3-base, LLaMA-3-8B, and GPT-4 demonstrate that GPT-4 achieves the strongest overall trust profile, followed by LLaMA-3-8B and DeBERTa-v3-base. Statistical analysis confirms that reliability varies independently of raw accuracy, underscoring the importance of trust-aware evaluation for real-world deployment. The proposed framework establishes a transparent and reproducible foundation for assessing model dependability in LLM-based phishing detection.",
    "fetched_at": "2025-11-11T02:19:10.040907Z"
  },
  {
    "id": "2511.04622v1",
    "title": "ODE approximation for the Adam algorithm: General and overparametrized   setting",
    "date": "2025-11-06",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG",
      "math.PR",
      "PR"
    ],
    "authors": [
      "Steffen Dereich",
      "Arnulf Jentzen",
      "Sebastian Kassing"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04622v1",
    "abstract": "The Adam optimizer is currently presumably the most popular optimization method in deep learning. In this article we develop an ODE based method to study the Adam optimizer in a fast-slow scaling regime. For fixed momentum parameters and vanishing step-sizes, we show that the Adam algorithm is an asymptotic pseudo-trajectory of the flow of a particular vector field, which is referred to as the Adam vector field. Leveraging properties of asymptotic pseudo-trajectories, we establish convergence results for the Adam algorithm. In particular, in a very general setting we show that if the Adam algorithm converges, then the limit must be a zero of the Adam vector field, rather than a local minimizer or critical point of the objective function.   In contrast, in the overparametrized empirical risk minimization setting, the Adam algorithm is able to locally find the set of minima. Specifically, we show that in a neighborhood of the global minima, the objective function serves as a Lyapunov function for the flow induced by the Adam vector field. As a consequence, if the Adam algorithm enters a neighborhood of the global minima infinitely often, it converges to the set of global minima.",
    "fetched_at": "2025-11-11T02:19:10.040850Z"
  },
  {
    "id": "2511.04729v1",
    "title": "Knowledge-based anomaly detection for identifying network-induced shape   artifacts",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Rucha Deshpande",
      "Tahsin Rahman",
      "Miguel Lago",
      "Adarsh Subbaswamy",
      "Jana G. Delfino",
      "Ghada Zamzmi",
      "Elim Thompson",
      "Aldo Badano",
      "Seyed Kahaki"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04729v1",
    "abstract": "Synthetic data provides a promising approach to address data scarcity for training machine learning models; however, adoption without proper quality assessments may introduce artifacts, distortions, and unrealistic features that compromise model performance and clinical utility. This work introduces a novel knowledge-based anomaly detection method for detecting network-induced shape artifacts in synthetic images. The introduced method utilizes a two-stage framework comprising (i) a novel feature extractor that constructs a specialized feature space by analyzing the per-image distribution of angle gradients along anatomical boundaries, and (ii) an isolation forest-based anomaly detector. We demonstrate the effectiveness of the method for identifying network-induced shape artifacts in two synthetic mammography datasets from models trained on CSAW-M and VinDr-Mammo patient datasets respectively. Quantitative evaluation shows that the method successfully concentrates artifacts in the most anomalous partition (1st percentile), with AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study involving three imaging scientists confirmed that images identified by the method as containing network-induced shape artifacts were also flagged by human readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the most anomalous partition, approximately 1.5-2 times higher than the least anomalous partition. Kendall-Tau correlations between algorithmic and human rankings were 0.45 and 0.43 for the two datasets, indicating reasonable agreement despite the challenging nature of subtle artifact detection. This method is a step forward in the responsible use of synthetic data, as it allows developers to evaluate synthetic images for known anatomic constraints and pinpoint and address specific issues to improve the overall quality of a synthetic dataset.",
    "fetched_at": "2025-11-11T02:19:10.040806Z"
  },
  {
    "id": "2511.04638v2",
    "title": "Addressing divergent representations from causal interventions on neural   networks",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Satchel Grant",
      "Simon Jerome Han",
      "Alexa R. Tartaglini",
      "Christopher Potts"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04638v2",
    "abstract": "A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raises concerns about how faithful their resulting explanations are to the target model in its natural state. First, we demonstrate empirically that common causal intervention techniques often do shift internal representations away from the natural distribution of the target model. Then, we provide a theoretical analysis of two classes of such divergences: \"harmless\" divergences that occur in the null-space of the weights and from covariance within behavioral decision boundaries, and \"pernicious\" divergences that activate hidden network pathways and cause dormant behavioral changes. Finally, in an effort to mitigate the pernicious cases, we modify the Counterfactual Latent (CL) loss from Grant (2025) that regularizes interventions to remain closer to the natural distributions, reducing the likelihood of harmful divergences while preserving the interpretive power of interventions. Together, these results highlight a path towards more reliable interpretability methods.",
    "fetched_at": "2025-11-11T02:19:10.040734Z"
  },
  {
    "id": "2511.04641v1",
    "title": "Efficient probabilistic surrogate modeling techniques for   partially-observed large-scale dynamical systems",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hans Harder",
      "Abhijeet Vishwasrao",
      "Luca Guastoni",
      "Ricardo Vinuesa",
      "Sebastian Peitz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04641v1",
    "abstract": "This paper is concerned with probabilistic techniques for forecasting dynamical systems described by partial differential equations (such as, for example, the Navier-Stokes equations). In particular, it is investigating and comparing various extensions to the flow matching paradigm that reduce the number of sampling steps. In this regard, it compares direct distillation, progressive distillation, adversarial diffusion distillation, Wasserstein GANs and rectified flows. Moreover, experiments are conducted on a set of challenging systems. In particular, we also address the challenge of directly predicting 2D slices of large-scale 3D simulations, paving the way for efficient inflow generation for solvers.",
    "fetched_at": "2025-11-11T02:19:10.040686Z"
  },
  {
    "id": "2511.04643v1",
    "title": "When retrieval outperforms generation: Dense evidence retrieval for   scalable fake news detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alamgir Munir Qazi",
      "John P. McCrae",
      "Jamal Abdul Nasir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04643v1",
    "abstract": "The proliferation of misinformation necessitates robust yet computationally efficient fact verification systems. While current state-of-the-art approaches leverage Large Language Models (LLMs) for generating explanatory rationales, these methods face significant computational barriers and hallucination risks in real-world deployments. We present DeReC (Dense Retrieval Classification), a lightweight framework that demonstrates how general-purpose text embeddings can effectively replace autoregressive LLM-based approaches in fact verification tasks. By combining dense retrieval with specialized classification, our system achieves better accuracy while being significantly more efficient. DeReC outperforms explanation-generating LLMs in efficiency, reducing runtime by 95% on RAWFC (23 minutes 36 seconds compared to 454 minutes 12 seconds) and by 92% on LIAR-RAW (134 minutes 14 seconds compared to 1692 minutes 23 seconds), showcasing its effectiveness across varying dataset sizes. On the RAWFC dataset, DeReC achieves an F1 score of 65.58%, surpassing the state-of-the-art method L-Defense (61.20%). Our results demonstrate that carefully engineered retrieval-based systems can match or exceed LLM performance in specialized tasks while being significantly more practical for real-world deployment.",
    "fetched_at": "2025-11-11T02:19:10.040640Z"
  },
  {
    "id": "2511.04647v2",
    "title": "Optimal Inference Schedules for Masked Diffusion Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sitan Chen",
      "Kevin Cong",
      "Jerry Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04647v2",
    "abstract": "A major bottleneck of standard auto-regressive large language models is that their inference process is inherently sequential, resulting in very long and costly inference times. To circumvent this, practitioners proposed a class of language models called diffusion language models, of which the masked diffusion model (MDM) is the most successful. The MDM is able to sample tokens out-of-order and, ostensibly, many tokens at once and in parallel. However, there is very limited rigorous understanding of how much parallel sampling these models can perform without noticeable degradation in their sampling performance. Prior work of Li and Cai obtained some preliminary bounds, but these are not tight for many natural classes of distributions. In this work, we give a new, exact characterization of the expected divergence between the true distribution and the sampled distribution, for any distribution and any unmasking schedule for the sampler, showing an elegant connection to the theory of univariate function approximation.   By leveraging this connection, we then attain a number of novel lower and upper bounds for this problem. While the connection to function approximation in principle gives the optimal unmasking schedule for any distribution, we show that it is in general impossible to compete with it without strong a priori knowledge of the distribution, even in seemingly benign settings. However, we also demonstrate new upper bounds and new sampling schedules in terms of well-studied information-theoretic properties of the base distribution, namely, its total correlation and dual total correlation, which show that in some natural settings, one can sample in $O(log n)$ steps without any visible loss in performance, where $n$ is the total sequence length.",
    "fetched_at": "2025-11-11T02:19:10.040543Z"
  },
  {
    "id": "2511.04653v1",
    "title": "TT-Prune: Joint Model Pruning and Resource Allocation for   Communication-efficient Time-triggered Federated Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinlu Zhang",
      "Yansha Deng",
      "Toktam Mahmoodi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04653v1",
    "abstract": "Federated learning (FL) offers new opportunities in machine learning, particularly in addressing data privacy concerns. In contrast to conventional event-based federated learning, time-triggered federated learning (TT-Fed), as a general form of both asynchronous and synchronous FL, clusters users into different tiers based on fixed time intervals. However, the FL network consists of a growing number of user devices with limited wireless bandwidth, consequently magnifying issues such as stragglers and communication overhead. In this paper, we introduce adaptive model pruning to wireless TT-Fed systems and study the problem of jointly optimizing the pruning ratio and bandwidth allocation to minimize the training loss while ensuring minimal learning latency. To answer this question, we perform convergence analysis on the gradient l_2 norm of the TT-Fed model based on model pruning. Based on the obtained convergence upper bound, a joint optimization problem of pruning ratio and wireless bandwidth is formulated to minimize the model training loss under a given delay threshold. Then, we derive closed-form solutions for wireless bandwidth and pruning ratio using Karush-Kuhn-Tucker(KKT) conditions. The simulation results show that model pruning could reduce the communication cost by 40% while maintaining the model performance at the same level.",
    "fetched_at": "2025-11-11T02:19:10.040492Z"
  },
  {
    "id": "2511.04654v1",
    "title": "Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought   Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mohammad Atif Quamar",
      "Mohammad Areeb"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04654v1",
    "abstract": "Chain-of-Thought (CoT) prompting is a key technique for enabling complex reasoning in large language models. However, generating full, fixed-length rationales is computationally wasteful, inflating both token usage and latency. We introduce LEASH: Logit-Entropy Adaptive Stopping Heuristic, a training-free decoding algorithm that adaptively halts rationale generation. LEASH monitors two intrinsic signals: the slope of token-level entropy and the improvement in the top-logit margin. It terminates the generation once both signals plateau, indicating the model has reached a stable reasoning state. Across four instruction-tuned models on the GSM8K and AQuA-RAT benchmarks, LEASH reduces average token generation by 30--35% and latency by 27%, while incurring a 10 p.p. accuracy drop relative to CoT. LEASH is model-agnostic and requires no additional training or supervision, offering a simple and efficient alternative to CoT decoding.",
    "fetched_at": "2025-11-11T02:19:10.040447Z"
  },
  {
    "id": "2511.04659v1",
    "title": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "physics.ao-ph",
      "ao-ph"
    ],
    "authors": [
      "Huaguan Chen",
      "Wei Han",
      "Haofei Sun",
      "Ning Lin",
      "Xingtao Song",
      "Yunfan Yang",
      "Jie Tian",
      "Yang Liu",
      "Ji-Rong Wen",
      "Xiaoye Zhang",
      "Xueshun Shen",
      "Hao Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04659v1",
    "abstract": "Extreme precipitation nowcasting demands high spatiotemporal fidelity and extended lead times, yet existing approaches remain limited. Numerical Weather Prediction (NWP) and its deep-learning emulations are too slow and coarse for rapidly evolving convection, while extrapolation and purely data-driven models suffer from error accumulation and excessive smoothing. Hybrid 2D radar-based methods discard crucial vertical information, preventing accurate reconstruction of height-dependent dynamics. We introduce a gray-box, fully three-dimensional nowcasting framework that directly processes volumetric radar reflectivity and couples physically constrained neural operators with datadriven learning. The model learns vertically varying 3D advection fields under a conservative advection operator, parameterizes spatially varying diffusion, and introduces a Brownian-motion--inspired stochastic term to represent unresolved motions. A residual branch captures small-scale convective initiation and microphysical variability, while a diffusion-based stochastic module estimates uncertainty. The framework achieves more accurate forecasts up to three-hour lead time across precipitation regimes and ranked first in 57\\% of cases in a blind evaluation by 160 meteorologists. By restoring full 3D dynamics with physical consistency, it offers a scalable and robust pathway for skillful and reliable nowcasting of extreme precipitation.",
    "fetched_at": "2025-11-11T02:19:10.040409Z"
  },
  {
    "id": "2511.04662v1",
    "title": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical   Consistency Checks",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yu Feng",
      "Nathaniel Weir",
      "Kaj Bostrom",
      "Sam Bayless",
      "Darion Cassel",
      "Sapana Chaudhary",
      "Benjamin Kiesl-Reiter",
      "Huzefa Rangwala"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04662v1",
    "abstract": "LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but they cannot reliably verify their own logic. Even when they reach correct answers, the underlying reasoning may be flawed, undermining trust in high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a neuro-symbolic method that extracts and verifies formal logical arguments from CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order logic and identifies premises that ground the argument in source context, commonsense knowledge, or prior reasoning steps. The symbolic representation enables automated solvers to verify logical validity while the NL premises allow humans and systems to identify ungrounded or fallacious reasoning steps. Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT effectively identifies flawed reasoning, and serves as a strong predictor of final answer correctness. We also leverage VeriCoT's verification signal for (1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct preference optimization (DPO) using verification-based pairwise rewards, further improving reasoning validity and accuracy.",
    "fetched_at": "2025-11-11T02:19:10.040334Z"
  },
  {
    "id": "2511.04665v1",
    "title": "Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation   of Soft-Body Interactions",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kaifeng Zhang",
      "Shuo Sha",
      "Hanxiao Jiang",
      "Matthew Loper",
      "Hyunjong Song",
      "Guangyan Cai",
      "Zhuo Xu",
      "Xiaochen Hu",
      "Changxi Zheng",
      "Yunzhu Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04665v1",
    "abstract": "Robotic manipulation policies are advancing rapidly, but their direct evaluation in the real world remains costly, time-consuming, and difficult to reproduce, particularly for tasks involving deformable objects. Simulation provides a scalable and systematic alternative, yet existing simulators often fail to capture the coupled visual and physical complexity of soft-body interactions. We present a real-to-sim policy evaluation framework that constructs soft-body digital twins from real-world videos and renders robots, objects, and environments with photorealistic fidelity using 3D Gaussian Splatting. We validate our approach on representative deformable manipulation tasks, including plush toy packing, rope routing, and T-block pushing, demonstrating that simulated rollouts correlate strongly with real-world execution performance and reveal key behavioral patterns of learned policies. Our results suggest that combining physics-informed reconstruction with high-quality rendering enables reproducible, scalable, and accurate evaluation of robotic manipulation policies. Website: https://real2sim-eval.github.io/",
    "fetched_at": "2025-11-11T02:19:10.040273Z"
  },
  {
    "id": "2511.04666v1",
    "title": "Forgetting is Everywhere",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Ben Sanati",
      "Thomas L. Lee",
      "Trevor McInroe",
      "Aidan Scannell",
      "Nikolay Malkin",
      "David Abel",
      "Amos Storkey"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04666v1",
    "abstract": "A fundamental challenge in developing general learning algorithms is their tendency to forget past knowledge when adapting to new data. Addressing this problem requires a principled understanding of forgetting; yet, despite decades of study, no unified definition has emerged that provides insights into the underlying dynamics of learning. We propose an algorithm- and task-agnostic theory that characterises forgetting as a lack of self-consistency in a learner's predictive distribution over future experiences, manifesting as a loss of predictive information. Our theory naturally yields a general measure of an algorithm's propensity to forget. To validate the theory, we design a comprehensive set of experiments that span classification, regression, generative modelling, and reinforcement learning. We empirically demonstrate how forgetting is present across all learning settings and plays a significant role in determining learning efficiency. Together, these results establish a principled understanding of forgetting and lay the foundation for analysing and improving the information retention capabilities of general learning algorithms.",
    "fetched_at": "2025-11-11T02:19:10.040195Z"
  },
  {
    "id": "2511.04667v1",
    "title": "Multi-Method Analysis of Mathematics Placement Assessments: Classical,   Machine Learning, and Clustering Approaches",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "97C70, 62P25, 62H30, 68T05"
    ],
    "authors": [
      "Julian D. Allagan",
      "Dasia A. Singleton",
      "Shanae N. Perry",
      "Gabrielle C. Morgan",
      "Essence A. Morgan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04667v1",
    "abstract": "This study evaluates a 40-item mathematics placement examination administered to 198 students using a multi-method framework combining Classical Test Theory, machine learning, and unsupervised clustering. Classical Test Theory analysis reveals that 55\\% of items achieve excellent discrimination ($D \\geq 0.40$) while 30\\% demonstrate poor discrimination ($D < 0.20$) requiring replacement. Question 6 (Graph Interpretation) emerges as the examination's most powerful discriminator, achieving perfect discrimination ($D = 1.000$), highest ANOVA F-statistic ($F = 4609.1$), and maximum Random Forest feature importance (0.206), accounting for 20.6\\% of predictive power. Machine learning algorithms demonstrate exceptional performance, with Random Forest and Gradient Boosting achieving 97.5\\% and 96.0\\% cross-validation accuracy. K-means clustering identifies a natural binary competency structure with a boundary at 42.5\\%, diverging from the institutional threshold of 55\\% and suggesting potential overclassification into remedial categories. The two-cluster solution exhibits exceptional stability (bootstrap ARI = 0.855) with perfect lower-cluster purity. Convergent evidence across methods supports specific refinements: replace poorly discriminating items, implement a two-stage assessment, and integrate Random Forest predictions with transparency mechanisms. These findings demonstrate that multi-method integration provides a robust empirical foundation for evidence-based mathematics placement optimization.",
    "fetched_at": "2025-11-11T02:19:10.040138Z"
  },
  {
    "id": "2511.04671v1",
    "title": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human   Demonstrations",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Maximus A. Pace",
      "Prithwish Dan",
      "Chuanruo Ning",
      "Atiksh Bhardwaj",
      "Audrey Du",
      "Edward W. Duan",
      "Wei-Chiu Ma",
      "Kushal Kedia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04671v1",
    "abstract": "Human videos can be recorded quickly and at scale, making them an appealing source of training data for robot learning. However, humans and robots differ fundamentally in embodiment, resulting in mismatched action execution. Direct kinematic retargeting of human hand motion can therefore produce actions that are physically infeasible for robots. Despite these low-level differences, human demonstrations provide valuable motion cues about how to manipulate and interact with objects. Our key idea is to exploit the forward diffusion process: as noise is added to actions, low-level execution differences fade while high-level task guidance is preserved. We present X-Diffusion, a principled framework for training diffusion policies that maximally leverages human data without learning dynamically infeasible motions. X-Diffusion first trains a classifier to predict whether a noisy action is executed by a human or robot. Then, a human action is incorporated into policy training only after adding sufficient noise such that the classifier cannot discern its embodiment. Actions consistent with robot execution supervise fine-grained denoising at low noise levels, while mismatched human actions provide only coarse guidance at higher noise levels. Our experiments show that naive co-training under execution mismatches degrades policy performance, while X-Diffusion consistently improves it. Across five manipulation tasks, X-Diffusion achieves a 16% higher average success rate than the best baseline. The project website is available at https://portal-cornell.github.io/X-Diffusion/.",
    "fetched_at": "2025-11-11T02:19:10.040082Z"
  },
  {
    "id": "2511.04681v1",
    "title": "Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference   from weak lensing and galaxy clustering maps with deep learning. I. Analysis   design",
    "date": "2025-11-06",
    "tags": [
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "A. Thomsen",
      "J. Bucko",
      "T. Kacprzak",
      "V. Ajani",
      "J. Fluri",
      "A. Refregier",
      "D. Anbajagane",
      "F. J. Castander",
      "A. Fert",
      "M. Gatti",
      "N. Jeffrey",
      "A. Alarcon",
      "A. Amon",
      "K. Bechtol",
      "M. R. Becker",
      "G. M. Bernstein",
      "A. Campos",
      "A. Carnero Rosell",
      "C. Chang",
      "R. Chen",
      "A. Choi",
      "M. Crocce",
      "C. Davis",
      "J. DeRose",
      "S. Dodelson",
      "C. Doux",
      "K. Eckert",
      "J. Elvin-Poole",
      "S. Everett",
      "P. Fosalba",
      "D. Gruen",
      "I. Harrison",
      "K. Herner",
      "E. M. Huff",
      "M. Jarvis",
      "N. Kuropatkin",
      "P. -F. Leget",
      "N. MacCrann",
      "J. McCullough",
      "J. Myles",
      "A. Navarro-Alsina",
      "S. Pandey",
      "A. Porredon",
      "J. Prat",
      "M. Raveri",
      "M. Rodriguez-Monroy",
      "R. P. Rollins",
      "A. Roodman",
      "E. S. Rykoff",
      "C. Snchez",
      "L. F. Secco",
      "E. Sheldon",
      "T. Shin",
      "M. A. Troxel",
      "I. Tutusaus",
      "T. N. Varga",
      "N. Weaverdyck",
      "R. H. Wechsler",
      "B. Yanny",
      "B. Yin",
      "Y. Zhang",
      "J. Zuntz",
      "S. Allam",
      "F. Andrade-Oliveira",
      "D. Bacon",
      "J. Blazek",
      "D. Brooks",
      "R. Camilleri",
      "J. Carretero",
      "R. Cawthon",
      "L. N. da Costa",
      "M. E. da Silva Pereira",
      "T. M. Davis",
      "J. De Vicente",
      "S. Desai",
      "P. Doel",
      "J. Garca-Bellido",
      "G. Gutierrez",
      "S. R. Hinton",
      "D. L. Hollowood",
      "K. Honscheid",
      "D. J. James",
      "K. Kuehn",
      "O. Lahav",
      "S. Lee",
      "J. L. Marshall",
      "J. Mena-Fernndez",
      "F. Menanteau",
      "R. Miquel",
      "J. Muir",
      "R. L. C. Ogando",
      "A. A. Plazas Malagn",
      "E. Sanchez",
      "D. Sanchez Cid",
      "I. Sevilla-Noarbe",
      "M. Smith",
      "E. Suchyta",
      "M. E. C. Swanson",
      "D. Thomas",
      "C. To",
      "D. L. Tucker"
    ],
    "institution": "DES Collaboration",
    "link": "http://arxiv.org/pdf/2511.04681v1",
    "abstract": "Data-driven approaches using deep learning are emerging as powerful techniques to extract non-Gaussian information from cosmological large-scale structure. This work presents the first simulation-based inference (SBI) pipeline that combines weak lensing and galaxy clustering maps in a realistic Dark Energy Survey Year 3 (DES Y3) configuration and serves as preparation for a forthcoming analysis of the survey data. We develop a scalable forward model based on the CosmoGridV1 suite of N-body simulations to generate over one million self-consistent mock realizations of DES Y3 at the map level. Leveraging this large dataset, we train deep graph convolutional neural networks on the full survey footprint in spherical geometry to learn low-dimensional features that approximately maximize mutual information with target parameters. These learned compressions enable neural density estimation of the implicit likelihood via normalizing flows in a ten-dimensional parameter space spanning cosmological $w$CDM, intrinsic alignment, and linear galaxy bias parameters, while marginalizing over baryonic, photometric redshift, and shear bias nuisances. To ensure robustness, we extensively validate our inference pipeline using synthetic observations derived from both systematic contaminations in our forward model and independent Buzzard galaxy catalogs. Our forecasts yield significant improvements in cosmological parameter constraints, achieving $2-3\\times$ higher figures of merit in the $\\Omega_m - S_8$ plane relative to our implementation of baseline two-point statistics and effectively breaking parameter degeneracies through probe combination. These results demonstrate the potential of SBI analyses powered by deep learning for upcoming Stage-IV wide-field imaging surveys.",
    "fetched_at": "2025-11-11T02:19:10.040013Z"
  },
  {
    "id": "2511.04751v1",
    "title": "Regularized GLISp for sensor-guided human-in-the-loop optimization",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matteo Cercola",
      "Michele Lomuscio",
      "Dario Piga",
      "Simone Formentin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04751v1",
    "abstract": "Human-in-the-loop calibration is often addressed via preference-based optimization, where algorithms learn from pairwise comparisons rather than explicit cost evaluations. While effective, methods such as Preferential Bayesian Optimization or Global optimization based on active preference learning with radial basis functions (GLISp) treat the system as a black box and ignore informative sensor measurements. In this work, we introduce a sensor-guided regularized extension of GLISp that integrates measurable descriptors into the preference-learning loop through a physics-informed hypothesis function and a least-squares regularization term. This injects grey-box structure, combining subjective feedback with quantitative sensor information while preserving the flexibility of preference-based search. Numerical evaluations on an analytical benchmark and on a human-in-the-loop vehicle suspension tuning task show faster convergence and superior final solutions compared to baseline GLISp.",
    "fetched_at": "2025-11-11T02:19:10.039593Z"
  },
  {
    "id": "2511.04753v1",
    "title": "CPO: Condition Preference Optimization for Controllable Image Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zonglin Lyu",
      "Ming Li",
      "Xinxin Liu",
      "Chen Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04753v1",
    "abstract": "To enhance controllability in text-to-image generation, ControlNet introduces image-based control signals, while ControlNet++ improves pixel-level cycle consistency between generated images and the input control signal. To avoid the prohibitive cost of back-propagating through the sampling process, ControlNet++ optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step approximation, which not only ignores the contribution of high-noise timesteps but also introduces additional approximation errors. A straightforward alternative for optimizing controllability across all timesteps is Direct Preference Optimization (DPO), a fine-tuning method that increases model preference for more controllable images ($I^{w}$) over less controllable ones ($I^{l}$). However, due to uncertainty in generative models, it is difficult to ensure that win--lose image pairs differ only in controllability while keeping other factors, such as image quality, fixed. To address this, we propose performing preference learning over control conditions rather than generated images. Specifically, we construct winning and losing control signals, $\\mathbf{c}^{w}$ and $\\mathbf{c}^{l}$, and train the model to prefer $\\mathbf{c}^{w}$. This method, which we term \\textit{Condition Preference Optimization} (CPO), eliminates confounding factors and yields a low-variance training objective. Our approach theoretically exhibits lower contrastive loss variance than DPO and empirically achieves superior results. Moreover, CPO requires less computation and storage for dataset curation. Extensive experiments show that CPO significantly improves controllability over the state-of-the-art ControlNet++ across multiple control types: over $10\\%$ error rate reduction in segmentation, $70$--$80\\%$ in human pose, and consistent $2$--$5\\%$ reductions in edge and depth maps.",
    "fetched_at": "2025-11-11T02:19:10.039548Z"
  },
  {
    "id": "2511.04754v1",
    "title": "Surprisal reveals diversity gaps in image captioning and different   scorers change the story",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Nikolai Ilinykh",
      "Simon Dobnik"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04754v1",
    "abstract": "We quantify linguistic diversity in image captioning with surprisal variance - the spread of token-level negative log-probabilities within a caption set. On the MSCOCO test set, we compare five state-of-the-art vision-and-language LLMs, decoded with greedy and nucleus sampling, to human captions. Measured with a caption-trained n-gram LM, humans display roughly twice the surprisal variance of models, but rescoring the same captions with a general-language model reverses the pattern. Our analysis introduces the surprisal-based diversity metric for image captioning. We show that relying on a single scorer can completely invert conclusions, thus, robust diversity evaluation must report surprisal under several scorers.",
    "fetched_at": "2025-11-11T02:19:10.039492Z"
  },
  {
    "id": "2511.04758v1",
    "title": "ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated   Multi-Arm Task and Motion Planning & Scheduling",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Caelan Garrett",
      "Fabio Ramos"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04758v1",
    "abstract": "Bimanual and humanoid robots are appealing because of their human-like ability to leverage multiple arms to efficiently complete tasks. However, controlling multiple arms at once is computationally challenging due to the growth in the hybrid discrete-continuous action space. Task and Motion Planning (TAMP) algorithms can efficiently plan in hybrid spaces but generally produce plans, where only one arm is moving at a time, rather than schedules that allow for parallel arm motion. In order to extend TAMP to produce schedules, we present ScheduleStream, the first general-purpose framework for planning & scheduling with sampling operations. ScheduleStream models temporal dynamics using hybrid durative actions, which can be started asynchronously and persist for a duration that's a function of their parameters. We propose domain-independent algorithms that solve ScheduleStream problems without any application-specific mechanisms. We apply ScheduleStream to Task and Motion Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers to expedite planning. We compare ScheduleStream algorithms to several ablations in simulation and find that they produce more efficient solutions. We demonstrate ScheduleStream on several real-world bimanual robot tasks at https://schedulestream.github.io.",
    "fetched_at": "2025-11-11T02:19:10.039456Z"
  },
  {
    "id": "2511.04760v1",
    "title": "When Data Falls Short: Grokking Below the Critical Threshold",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Vaibhav Singh",
      "Eugene Belilovsky",
      "Rahaf Aljundi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04760v1",
    "abstract": "In this paper, we investigate the phenomenon of grokking, where models exhibit delayed generalization following overfitting on training data. We focus on data-scarce regimes where the number of training samples falls below the critical threshold, making grokking unobservable, and on practical scenarios involving distribution shift. We first show that Knowledge Distillation (KD) from a model that has already grokked on a distribution (p1) can induce and accelerate grokking on a different distribution (p2), even when the available data lies below the critical threshold. This highlights the value of KD for deployed models that must adapt to new distributions under limited data. We then study training on the joint distribution (p1, p2) and demonstrate that while standard supervised training fails when either distribution has insufficient data, distilling from models grokked on the individual distributions enables generalization. Finally, we examine a continual pretraining setup, where a grokked model transitions from p1 to p2, and find that KD both accelerates generalization and mitigates catastrophic forgetting, achieving strong performance even with only 10% of the data. Together, our results provide new insights into the mechanics of grokking under knowledge transfer and underscore the central role of KD in enabling generalization in low-data and evolving distribution settings.",
    "fetched_at": "2025-11-11T02:19:10.039411Z"
  },
  {
    "id": "2511.04768v1",
    "title": "FuseFlow: A Fusion-Centric Compilation Framework for Sparse Deep   Learning on Streaming Dataflow",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AR",
      "AR",
      "cs.PL",
      "PL"
    ],
    "authors": [
      "Rubens Lacouture",
      "Nathan Zhang",
      "Ritvik Sharma",
      "Marco Siracusa",
      "Fredrik Kjolstad",
      "Kunle Olukotun",
      "Olivia Hsu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04768v1",
    "abstract": "As deep learning models scale, sparse computation and specialized dataflow hardware have emerged as powerful solutions to address efficiency. We propose FuseFlow, a compiler that converts sparse machine learning models written in PyTorch to fused sparse dataflow graphs for reconfigurable dataflow architectures (RDAs). FuseFlow is the first compiler to support general cross-expression fusion of sparse operations. In addition to fusion across kernels (expressions), FuseFlow also supports optimizations like parallelization, dataflow ordering, and sparsity blocking. It targets a cycle-accurate dataflow simulator for microarchitectural analysis of fusion strategies. We use FuseFlow for design-space exploration across four real-world machine learning applications with sparsity, showing that full fusion (entire cross-expression fusion across all computation in an end-to-end model) is not always optimal for sparse models-fusion granularity depends on the model itself. FuseFlow also provides a heuristic to identify and prune suboptimal configurations. Using Fuseflow, we achieve performance improvements, including a ~2.7x speedup over an unfused baseline for GPT-3 with BigBird block-sparse attention.",
    "fetched_at": "2025-11-11T02:19:10.039366Z"
  },
  {
    "id": "2511.04770v1",
    "title": "Machine Learning-Driven Analysis of kSZ Maps to Predict CMB Optical   Depth $$",
    "date": "2025-11-06",
    "tags": [
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Farshid Farhadi Khouzani",
      "Abinash Kumar Shaw",
      "Paul La Plante",
      "Bryar Mustafa Shareef",
      "Laxmi Gewali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04770v1",
    "abstract": "Upcoming measurements of the kinetic Sunyaev-Zel'dovich (kSZ) effect, which results from Cosmic Microwave Background (CMB) photons scattering off moving electrons, offer a powerful probe of the Epoch of Reionization (EoR). The kSZ signal contains key information about the timing, duration, and spatial structure of the EoR. A precise measurement of the CMB optical depth $\\tau$, a key parameter that characterizes the universe's integrated electron density, would significantly constrain models of early structure formation. However, the weak kSZ signal is difficult to extract from CMB observations due to significant contamination from astrophysical foregrounds. We present a machine learning approach to extract $\\tau$ from simulated kSZ maps. We train advanced machine learning models, including swin transformers, on high-resolution seminumeric simulations of the kSZ signal. To robustly quantify prediction uncertainties of $\\tau$, we employ the Laplace Approximation (LA). This approach provides an efficient and principled Gaussian approximation to the posterior distribution over the model's weights, allowing for reliable error estimation. We investigate and compare two distinct application modes: a post-hoc LA applied to a pre-trained model, and an online LA where model weights and hyperparameters are optimized jointly by maximizing the marginal likelihood. This approach provides a framework for robustly constraining $\\tau$ and its associated uncertainty, which can enhance the analysis of upcoming CMB surveys like the Simons Observatory and CMB-S4.",
    "fetched_at": "2025-11-11T02:19:10.039307Z"
  },
  {
    "id": "2511.04774v1",
    "title": "SLOFetch: Compressed-Hierarchical Instruction Prefetching for Cloud   Microservices",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AR",
      "AR"
    ],
    "authors": [
      "Liu Jiang",
      "Zerui Bao",
      "Shiqi Sheng",
      "Di Zhu"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04774v1",
    "abstract": "Large-scale networked services rely on deep soft-ware stacks and microservice orchestration, which increase instruction footprints and create frontend stalls that inflate tail latency and energy. We revisit instruction prefetching for these cloud workloads and present a design that aligns with SLO driven and self optimizing systems. Building on the Entangling Instruction Prefetcher (EIP), we introduce a Compressed Entry that captures up to eight destinations around a base using 36 bits by exploiting spatial clustering, and a Hierarchical Metadata Storage scheme that keeps only L1 resident and frequently queried entries on chip while virtualizing bulk metadata into lower levels. We further add a lightweight Online ML Controller that scores prefetch profitability using context features and a bandit adjusted threshold. On data center applications, our approach preserves EIP like speedups with smaller on chip state and improves efficiency for networked services in the ML era.",
    "fetched_at": "2025-11-11T02:19:10.039234Z"
  },
  {
    "id": "2511.04776v1",
    "title": "Quantifying the Climate Risk of Generative AI: Region-Aware Carbon   Accounting with G-TRACE and the AI Sustainability Pyramid",
    "date": "2025-11-06",
    "tags": [
      "cs.CY",
      "CY",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zahida Kausar",
      "Seemab Latif",
      "Raja Khurrum Shahzad",
      "Mehwish Fatima"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04776v1",
    "abstract": "Generative Artificial Intelligence (GenAI) represents a rapidly expanding digital infrastructure whose energy demand and associated CO2 emissions are emerging as a new category of climate risk. This study introduces G-TRACE (GenAI Transformative Carbon Estimator), a cross-modal, region-aware framework that quantifies training- and inference-related emissions across modalities and deployment geographies. Using real-world analytics and microscopic simulation, G-TRACE measures energy use and carbon intensity per output type (text, image, video) and reveals how decentralized inference amplifies small per-query energy costs into system-level impacts. Through the Ghibli-style image generation trend (2024-2025), we estimate 4,309 MWh of energy consumption and 2,068 tCO2 emissions, illustrating how viral participation inflates individual digital actions into tonne-scale consequences. Building on these findings, we propose the AI Sustainability Pyramid, a seven-level governance model linking carbon accounting metrics (L1-L7) with operational readiness, optimization, and stewardship. This framework translates quantitative emission metrics into actionable policy guidance for sustainable AI deployment. The study contributes to the quantitative assessment of emerging digital infrastructures as a novel category of climate risk, supporting adaptive governance for sustainable technology deployment. By situating GenAI within climate-risk frameworks, the work advances data-driven methods for aligning technological innovation with global decarbonization and resilience objectives.",
    "fetched_at": "2025-11-11T02:19:10.039188Z"
  },
  {
    "id": "2511.04789v1",
    "title": "Conditional Neural ODE for Longitudinal Parkinson's Disease Progression   Forecasting",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiaoda Wang",
      "Yuji Zhao",
      "Kaiqiao Han",
      "Xiao Luo",
      "Sanne van Rooij",
      "Jennifer Stevens",
      "Lifang He",
      "Liang Zhan",
      "Yizhou Sun",
      "Wei Wang",
      "Carl Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04789v1",
    "abstract": "Parkinson's disease (PD) shows heterogeneous, evolving brain-morphometry patterns. Modeling these longitudinal trajectories enables mechanistic insight, treatment development, and individualized 'digital-twin' forecasting. However, existing methods usually adopt recurrent neural networks and transformer architectures, which rely on discrete, regularly sampled data while struggling to handle irregular and sparse magnetic resonance imaging (MRI) in PD cohorts. Moreover, these methods have difficulty capturing individual heterogeneity including variations in disease onset, progression rate, and symptom severity, which is a hallmark of PD. To address these challenges, we propose CNODE (Conditional Neural ODE), a novel framework for continuous, individualized PD progression forecasting. The core of CNODE is to model morphological brain changes as continuous temporal processes using a neural ODE model. In addition, we jointly learn patient-specific initial time and progress speed to align individual trajectories into a shared progression trajectory. We validate CNODE on the Parkinson's Progression Markers Initiative (PPMI) dataset. Experimental results show that our method outperforms state-of-the-art baselines in forecasting longitudinal PD progression.",
    "fetched_at": "2025-11-11T02:19:10.039132Z"
  },
  {
    "id": "2511.04790v1",
    "title": "Causal Structure and Representation Learning with Biomedical   Applications",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Caroline Uhler",
      "Jiaqi Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04790v1",
    "abstract": "Massive data collection holds the promise of a better understanding of complex phenomena and, ultimately, better decisions. Representation learning has become a key driver of deep learning applications, as it allows learning latent spaces that capture important properties of the data without requiring any supervised annotations. Although representation learning has been hugely successful in predictive tasks, it can fail miserably in causal tasks including predicting the effect of a perturbation/intervention. This calls for a marriage between representation learning and causal inference. An exciting opportunity in this regard stems from the growing availability of multi-modal data (observational and perturbational, imaging-based and sequencing-based, at the single-cell level, tissue-level, and organism-level). We outline a statistical and computational framework for causal structure and representation learning motivated by fundamental biomedical questions: how to effectively use observational and perturbational data to perform causal discovery on observed causal variables; how to use multi-modal views of the system to learn causal variables; and how to design optimal perturbations.",
    "fetched_at": "2025-11-11T02:19:10.039056Z"
  },
  {
    "id": "2511.04791v1",
    "title": "DuetServe: Harmonizing Prefill and Decode for LLM Serving via Adaptive   GPU Multiplexing",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lei Gao",
      "Chaoyi Jiang",
      "Hossein Entezari Zarch",
      "Daniel Wong",
      "Murali Annavaram"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04791v1",
    "abstract": "Modern LLM serving systems must sustain high throughput while meeting strict latency SLOs across two distinct inference phases: compute-intensive prefill and memory-bound decode phases. Existing approaches either (1) aggregate both phases on shared GPUs, leading to interference between prefill and decode phases, which degrades time-between-tokens (TBT); or (2) disaggregate the two phases across GPUs, improving latency but wasting resources through duplicated models and KV cache transfers. We present DuetServe, a unified LLM serving framework that achieves disaggregation-level isolation within a single GPU. DuetServe operates in aggregated mode by default and dynamically activates SM-level GPU spatial multiplexing when TBT degradation is predicted. Its key idea is to decouple prefill and decode execution only when needed through fine-grained, adaptive SM partitioning that provides phase isolation only when contention threatens latency service level objectives (SLOs). DuetServe integrates (1) an attention-aware roofline model to forecast iteration latency, (2) a partitioning optimizer that selects the optimal SM split to maximize throughput under TBT constraints, and (3) an interruption-free execution engine that eliminates CPU-GPU synchronization overhead. Evaluations show that DuetServe improves total throughput by up to 1.3x while maintaining low generation latency compared to state-of-the-art frameworks.",
    "fetched_at": "2025-11-11T02:19:10.039015Z"
  },
  {
    "id": "2511.04792v1",
    "title": "Blind Strong Gravitational Lensing Inversion: Joint Inference of Source   and Lens Mass with Score-Based Models",
    "date": "2025-11-06",
    "tags": [
      "astro-ph.IM",
      "IM",
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gabriel Missael Barco",
      "Ronan Legin",
      "Connor Stone",
      "Yashar Hezaveh",
      "Laurence Perreault-Levasseur"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04792v1",
    "abstract": "Score-based models can serve as expressive, data-driven priors for scientific inverse problems. In strong gravitational lensing, they enable posterior inference of a background galaxy from its distorted, multiply-imaged observation. Previous work, however, assumes that the lens mass distribution (and thus the forward operator) is known. We relax this assumption by jointly inferring the source and a parametric lens-mass profile, using a sampler based on GibbsDDRM but operating in continuous time. The resulting reconstructions yield residuals consistent with the observational noise, and the marginal posteriors of the lens parameters recover true values without systematic bias. To our knowledge, this is the first successful demonstration of joint source-and-lens inference with a score-based prior.",
    "fetched_at": "2025-11-11T02:19:10.038962Z"
  },
  {
    "id": "2511.04798v1",
    "title": "MDM: Manhattan Distance Mapping of DNN Weights for   Parasitic-Resistance-Resilient Memristive Crossbars",
    "date": "2025-11-06",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI",
      "cs.ET",
      "ET",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matheus Farias",
      "Wanghley Martins",
      "H. T. Kung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04798v1",
    "abstract": "Manhattan Distance Mapping (MDM) is a post-training deep neural network (DNN) weight mapping technique for memristive bit-sliced compute-in-memory (CIM) crossbars that reduces parasitic resistance (PR) nonidealities.   PR limits crossbar efficiency by mapping DNN matrices into small crossbar tiles, reducing CIM-based speedup. Each crossbar executes one tile, requiring digital synchronization before the next layer. At this granularity, designers either deploy many small crossbars in parallel or reuse a few sequentially-both increasing analog-to-digital conversions, latency, I/O pressure, and chip area.   MDM alleviates PR effects by optimizing active-memristor placement. Exploiting bit-level structured sparsity, it feeds activations from the denser low-order side and reorders rows according to the Manhattan distance, relocating active cells toward regions less affected by PR and thus lowering the nonideality factor (NF).   Applied to DNN models on ImageNet-1k, MDM reduces NF by up to 46% and improves accuracy under analog distortion by an average of 3.6% in ResNets. Overall, it provides a lightweight, spatially informed method for scaling CIM DNN accelerators.",
    "fetched_at": "2025-11-11T02:19:10.038912Z"
  },
  {
    "id": "2511.04800v1",
    "title": "Explore Data Left Behind in Reinforcement Learning for Reasoning   Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Chenxi Liu",
      "Junjie Liang",
      "Yuqi Jia",
      "Bochuan Cao",
      "Yang Bai",
      "Heng Huang",
      "Xun Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04800v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as an effective approach for improving the reasoning abilities of large language models (LLMs). The Group Relative Policy Optimization (GRPO) family has demonstrated strong performance in training LLMs with RLVR. However, as models train longer and scale larger, more training prompts become residual prompts, those with zero variance rewards that provide no training signal. Consequently, fewer prompts contribute to training, reducing diversity and hindering effectiveness. To fully exploit these residual prompts, we propose the Explore Residual Prompts in Policy Optimization (ERPO) framework, which encourages exploration on residual prompts and reactivates their training signals. ERPO maintains a history tracker for each prompt and adaptively increases the sampling temperature for residual prompts that previously produced all correct responses. This encourages the model to generate more diverse reasoning traces, introducing incorrect responses that revive training signals. Empirical results on the Qwen2.5 series demonstrate that ERPO consistently surpasses strong baselines across multiple mathematical reasoning benchmarks.",
    "fetched_at": "2025-11-11T02:19:10.038865Z"
  },
  {
    "id": "2511.04803v1",
    "title": "Data Efficiency and Transfer Robustness in Biomedical Image   Segmentation: A Study of Redundancy and Forgetting with Cellpose",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "I.2.10; I.4.6",
      "6"
    ],
    "authors": [
      "Shuo Zhao",
      "Jianxu Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04803v1",
    "abstract": "Generalist biomedical image segmentation models such as Cellpose are increasingly applied across diverse imaging modalities and cell types. However, two critical challenges remain underexplored: (1) the extent of training data redundancy and (2) the impact of cross domain transfer on model retention. In this study, we conduct a systematic empirical analysis of these challenges using Cellpose as a case study. First, to assess data redundancy, we propose a simple dataset quantization (DQ) strategy for constructing compact yet diverse training subsets. Experiments on the Cyto dataset show that image segmentation performance saturates with only 10% of the data, revealing substantial redundancy and potential for training with minimal annotations. Latent space analysis using MAE embeddings and t-SNE confirms that DQ selected patches capture greater feature diversity than random sampling. Second, to examine catastrophic forgetting, we perform cross domain finetuning experiments and observe significant degradation in source domain performance, particularly when adapting from generalist to specialist domains. We demonstrate that selective DQ based replay reintroducing just 5-10% of the source data effectively restores source performance, while full replay can hinder target adaptation. Additionally, we find that training domain sequencing improves generalization and reduces forgetting in multi stage transfer. Our findings highlight the importance of data centric design in biomedical image segmentation and suggest that efficient training requires not only compact subsets but also retention aware learning strategies and informed domain ordering. The code is available at https://github.com/MMV-Lab/biomedseg-efficiency.",
    "fetched_at": "2025-11-11T02:19:10.038796Z"
  },
  {
    "id": "2511.04804v1",
    "title": "Simplex-FEM Networks (SiFEN): Learning A Triangulated Function   Approximator",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chaymae Yahyati",
      "Ismail Lamaakal",
      "Khalid El Makkaoui",
      "Ibrahim Ouahbi",
      "Yassine Maleh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04804v1",
    "abstract": "We introduce Simplex-FEM Networks (SiFEN), a learned piecewise-polynomial predictor that represents f: R^d -> R^k as a globally C^r finite-element field on a learned simplicial mesh in an optionally warped input space. Each query activates exactly one simplex and at most d+1 basis functions via barycentric coordinates, yielding explicit locality, controllable smoothness, and cache-friendly sparsity. SiFEN pairs degree-m Bernstein-Bezier polynomials with a light invertible warp and trains end-to-end with shape regularization, semi-discrete OT coverage, and differentiable edge flips. Under standard shape-regularity and bi-Lipschitz warp assumptions, SiFEN achieves the classic FEM approximation rate M^(-m/d) with M mesh vertices. Empirically, on synthetic approximation tasks, tabular regression/classification, and as a drop-in head on compact CNNs, SiFEN matches or surpasses MLPs and KANs at matched parameter budgets, improves calibration (lower ECE/Brier), and reduces inference latency due to geometric locality. These properties make SiFEN a compact, interpretable, and theoretically grounded alternative to dense MLPs and edge-spline networks.",
    "fetched_at": "2025-11-11T02:19:10.038747Z"
  },
  {
    "id": "2511.04805v1",
    "title": "PuzzleMoE: Efficient Compression of Large Mixture-of-Experts Models via   Sparse Expert Merging and Bit-packed inference",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yushu Zhao",
      "Zheng Wang",
      "Minjia Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04805v1",
    "abstract": "Mixture-of-Experts (MoE) models have shown strong potential in scaling language models efficiently by activating only a small subset of experts per input. However, their widespread deployment remains limited due to the high memory overhead associated with storing all expert parameters, particularly as the number of experts increases. To address this challenge, prior works have explored expert dropping and merging strategies, yet they often suffer from performance drop at high compression ratios. In this paper, we introduce PuzzleMoE, a training-free MoE compression method that achieves both high accuracy and efficient inference through two key innovations: First, PuzzleMoE performs sparse expert merging by identifying element-wise weight redundancy and specialization. It uses a dual-mask to capture both shared and expert-specific parameters. Second, to avoid the overhead of storing binary masks and signs, PuzzleMoE introduces a bit-packed encoding scheme that reuses underutilized exponent bits, enabling efficient MoE inference on GPUs. Extensive experiments demonstrate that PuzzleMoE can compress MoE models by up to 50% while maintaining accuracy across various tasks. Specifically, it outperforms prior MoE compression methods by up to 16.7% on MMLU at 50% compression ratio, and achieves up to 1.28\\times inference speedup.",
    "fetched_at": "2025-11-11T02:19:10.038696Z"
  },
  {
    "id": "2511.04807v1",
    "title": "Autoencoding Dynamics: Topological Limitations and Capabilities",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.DS",
      "DS"
    ],
    "authors": [
      "Matthew D. Kvalheim",
      "Eduardo D. Sontag"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04807v1",
    "abstract": "Given a \"data manifold\" $M\\subset \\mathbb{R}^n$ and \"latent space\" $\\mathbb{R}^\\ell$, an autoencoder is a pair of continuous maps consisting of an \"encoder\" $E\\colon \\mathbb{R}^n\\to \\mathbb{R}^\\ell$ and \"decoder\" $D\\colon \\mathbb{R}^\\ell\\to \\mathbb{R}^n$ such that the \"round trip\" map $D\\circ E$ is as close as possible to the identity map $\\mbox{id}_M$ on $M$. We present various topological limitations and capabilites inherent to the search for an autoencoder, and describe capabilities for autoencoding dynamical systems having $M$ as an invariant manifold.",
    "fetched_at": "2025-11-11T02:19:10.038652Z"
  },
  {
    "id": "2511.04808v1",
    "title": "Sharp Minima Can Generalize: A Loss Landscape Perspective On Data",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Raymond Fan",
      "Bryce Sandlund",
      "Lin Myat Ko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04808v1",
    "abstract": "The volume hypothesis suggests deep learning is effective because it is likely to find flat minima due to their large volumes, and flat minima generalize well. This picture does not explain the role of large datasets in generalization. Measuring minima volumes under varying amounts of training data reveals sharp minima which generalize well exist, but are unlikely to be found due to their small volumes. Increasing data changes the loss landscape, such that previously small generalizing minima become (relatively) large.",
    "fetched_at": "2025-11-11T02:19:10.038618Z"
  },
  {
    "id": "2511.04811v1",
    "title": "An Active Learning Pipeline for Biomedical Image Instance Segmentation   with Minimal Human Intervention",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "68T07, 68U10",
      "I.2.10; I.4.6; J.3",
      "3"
    ],
    "authors": [
      "Shuo Zhao",
      "Yu Zhou",
      "Jianxu Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04811v1",
    "abstract": "Biomedical image segmentation is critical for precise structure delineation and downstream analysis. Traditional methods often struggle with noisy data, while deep learning models such as U-Net have set new benchmarks in segmentation performance. nnU-Net further automates model configuration, making it adaptable across datasets without extensive tuning. However, it requires a substantial amount of annotated data for cross-validation, posing a challenge when only raw images but no labels are available. Large foundation models offer zero-shot generalizability, but may underperform on specific datasets with unique characteristics, limiting their direct use for analysis. This work addresses these bottlenecks by proposing a data-centric AI workflow that leverages active learning and pseudo-labeling to combine the strengths of traditional neural networks and large foundation models while minimizing human intervention. The pipeline starts by generating pseudo-labels from a foundation model, which are then used for nnU-Net's self-configuration. Subsequently, a representative core-set is selected for minimal manual annotation, enabling effective fine-tuning of the nnU-Net model. This approach significantly reduces the need for manual annotations while maintaining competitive performance, providing an accessible solution for biomedical researchers to apply state-of-the-art AI techniques in their segmentation tasks. The code is available at https://github.com/MMV-Lab/AL_BioMed_img_seg.",
    "fetched_at": "2025-11-11T02:19:10.038581Z"
  },
  {
    "id": "2511.04812v1",
    "title": "Unified Multimodal Diffusion Forcing for Forceful Manipulation",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zixuan Huang",
      "Huaidian Hou",
      "Dmitry Berenson"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04812v1",
    "abstract": "Given a dataset of expert trajectories, standard imitation learning approaches typically learn a direct mapping from observations (e.g., RGB images) to actions. However, such methods often overlook the rich interplay between different modalities, i.e., sensory inputs, actions, and rewards, which is crucial for modeling robot behavior and understanding task outcomes. In this work, we propose Multimodal Diffusion Forcing, a unified framework for learning from multimodal robot trajectories that extends beyond action generation. Rather than modeling a fixed distribution, MDF applies random partial masking and trains a diffusion model to reconstruct the trajectory. This training objective encourages the model to learn temporal and cross-modal dependencies, such as predicting the effects of actions on force signals or inferring states from partial observations. We evaluate MDF on contact-rich, forceful manipulation tasks in simulated and real-world environments. Our results show that MDF not only delivers versatile functionalities, but also achieves strong performance, and robustness under noisy observations. More visualizations can be found on our website https://unified-df.github.io",
    "fetched_at": "2025-11-11T02:19:10.038528Z"
  },
  {
    "id": "2511.04814v1",
    "title": "A Standardized Benchmark for Multilabel Antimicrobial Peptide   Classification",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.BM",
      "BM",
      "68T07, 62H30, 62P10",
      "I.2.6; I.2.1; I.5.1; I.5.2",
      "2"
    ],
    "authors": [
      "Sebastian Ojeda",
      "Rafael Velasquez",
      "Nicols Aparicio",
      "Juanita Puentes",
      "Paula Crdenas",
      "Nicols Andrade",
      "Gabriel Gonzlez",
      "Sergio Rincn",
      "Carolina Muoz-Camargo",
      "Pablo Arbelez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04814v1",
    "abstract": "Antimicrobial peptides have emerged as promising molecules to combat antimicrobial resistance. However, fragmented datasets, inconsistent annotations, and the lack of standardized benchmarks hinder computational approaches and slow down the discovery of new candidates. To address these challenges, we present the Expanded Standardized Collection for Antimicrobial Peptide Evaluation (ESCAPE), an experimental framework integrating over 80.000 peptides from 27 validated repositories. Our dataset separates antimicrobial peptides from negative sequences and incorporates their functional annotations into a biologically coherent multilabel hierarchy, capturing activities across antibacterial, antifungal, antiviral, and antiparasitic classes. Building on ESCAPE, we propose a transformer-based model that leverages sequence and structural information to predict multiple functional activities of peptides. Our method achieves up to a 2.56% relative average improvement in mean Average Precision over the second-best method adapted for this task, establishing a new state-of-the-art multilabel peptide classification. ESCAPE provides a comprehensive and reproducible evaluation framework to advance AI-driven antimicrobial peptide research.",
    "fetched_at": "2025-11-11T02:19:10.038483Z"
  },
  {
    "id": "2511.04825v1",
    "title": "Persistent reachability homology in machine learning applications",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.AT",
      "AT",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Luigi Caputi",
      "Nicholas Meadows",
      "Henri Riihimki"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04825v1",
    "abstract": "We explore the recently introduced persistent reachability homology (PRH) of digraph data, i.e. data in the form of directed graphs. In particular, we study the effectiveness of PRH in network classification task in a key neuroscience problem: epilepsy detection. PRH is a variation of the persistent homology of digraphs, more traditionally based on the directed flag complex (DPH). A main advantage of PRH is that it considers the condensations of the digraphs appearing in the persistent filtration and thus is computed from smaller digraphs. We compare the effectiveness of PRH to that of DPH and we show that PRH outperforms DPH in the classification task. We use the Betti curves and their integrals as topological features and implement our pipeline on support vector machine.",
    "fetched_at": "2025-11-11T02:19:10.038406Z"
  },
  {
    "id": "2511.04831v1",
    "title": "Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot   Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "NVIDIA",
      ":",
      "Mayank Mittal",
      "Pascal Roth",
      "James Tigue",
      "Antoine Richard",
      "Octi Zhang",
      "Peter Du",
      "Antonio Serrano-Muoz",
      "Xinjie Yao",
      "Ren Zurbrgg",
      "Nikita Rudin",
      "Lukasz Wawrzyniak",
      "Milad Rakhsha",
      "Alain Denzler",
      "Eric Heiden",
      "Ales Borovicka",
      "Ossama Ahmed",
      "Iretiayo Akinola",
      "Abrar Anwar",
      "Mark T. Carlson",
      "Ji Yuan Feng",
      "Animesh Garg",
      "Renato Gasoto",
      "Lionel Gulich",
      "Yijie Guo",
      "M. Gussert",
      "Alex Hansen",
      "Mihir Kulkarni",
      "Chenran Li",
      "Wei Liu",
      "Viktor Makoviychuk",
      "Grzegorz Malczyk",
      "Hammad Mazhar",
      "Masoud Moghani",
      "Adithyavairavan Murali",
      "Michael Noseworthy",
      "Alexander Poddubny",
      "Nathan Ratliff",
      "Welf Rehberg",
      "Clemens Schwarke",
      "Ritvik Singh",
      "James Latham Smith",
      "Bingjie Tang",
      "Ruchik Thaker",
      "Matthew Trepte",
      "Karl Van Wyk",
      "Fangzhou Yu",
      "Alex Millane",
      "Vikram Ramasamy",
      "Remo Steiner",
      "Sangeeta Subramanian",
      "Clemens Volk",
      "CY Chen",
      "Neel Jawale",
      "Ashwin Varghese Kuruttukulam",
      "Michael A. Lin",
      "Ajay Mandlekar",
      "Karsten Patzwaldt",
      "John Welsh",
      "Huihua Zhao",
      "Fatima Anes",
      "Jean-Francois Lafleche",
      "Nicolas Monne-Loccoz",
      "Soowan Park",
      "Rob Stepinski",
      "Dirk Van Gelder",
      "Chris Amevor",
      "Jan Carius",
      "Jumyung Chang",
      "Anka He Chen",
      "Pablo de Heras Ciechomski",
      "Gilles Daviet",
      "Mohammad Mohajerani",
      "Julia von Muralt",
      "Viktor Reutskyy",
      "Michael Sauter",
      "Simon Schirm",
      "Eric L. Shi",
      "Pierre Terdiman",
      "Kenny Vilella",
      "Tobias Widmer",
      "Gordon Yeoman",
      "Tiffany Chen",
      "Sergey Grizan",
      "Cathy Li",
      "Lotus Li",
      "Connor Smith",
      "Rafael Wiltz",
      "Kostas Alexis",
      "Yan Chang",
      "David Chu",
      "Linxi \"Jim\" Fan",
      "Farbod Farshidian",
      "Ankur Handa",
      "Spencer Huang",
      "Marco Hutter",
      "Yashraj Narang",
      "Soha Pouya",
      "Shiwei Sheng",
      "Yuke Zhu",
      "Miles Macklin",
      "Adam Moravanszky",
      "Philipp Reist",
      "Yunrong Guo",
      "David Hoeller",
      "Gavriel State"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04831v1",
    "abstract": "We present Isaac Lab, the natural successor to Isaac Gym, which extends the paradigm of GPU-native robotics simulation into the era of large-scale multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics, photorealistic rendering, and a modular, composable architecture for designing environments and training robot policies. Beyond physics and rendering, the framework integrates actuator models, multi-frequency sensor simulation, data collection pipelines, and domain randomization tools, unifying best practices for reinforcement and imitation learning at scale within a single extensible platform. We highlight its application to a diverse set of challenges, including whole-body control, cross-embodiment mobility, contact-rich and dexterous manipulation, and the integration of human demonstrations for skill acquisition. Finally, we discuss upcoming integration with the differentiable, GPU-accelerated Newton physics engine, which promises new opportunities for scalable, data-efficient, and gradient-based approaches to robot learning. We believe Isaac Lab's combination of advanced simulation capabilities, rich sensing, and data-center scale execution will help unlock the next generation of breakthroughs in robotics research.",
    "fetched_at": "2025-11-11T02:19:10.038363Z"
  },
  {
    "id": "2511.04834v1",
    "title": "Prompt-Based Safety Guidance Is Ineffective for Unlearned Text-to-Image   Diffusion Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Jiwoo Shin",
      "Byeonghu Na",
      "Mina Kang",
      "Wonhyeok Choi",
      "Il-chul Moon"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04834v1",
    "abstract": "Recent advances in text-to-image generative models have raised concerns about their potential to produce harmful content when provided with malicious input text prompts. To address this issue, two main approaches have emerged: (1) fine-tuning the model to unlearn harmful concepts and (2) training-free guidance methods that leverage negative prompts. However, we observe that combining these two orthogonal approaches often leads to marginal or even degraded defense performance. This observation indicates a critical incompatibility between two paradigms, which hinders their combined effectiveness. In this work, we address this issue by proposing a conceptually simple yet experimentally robust method: replacing the negative prompts used in training-free methods with implicit negative embeddings obtained through concept inversion. Our method requires no modification to either approach and can be easily integrated into existing pipelines. We experimentally validate its effectiveness on nudity and violence benchmarks, demonstrating consistent improvements in defense success rate while preserving the core semantics of input prompts.",
    "fetched_at": "2025-11-11T02:19:10.037961Z"
  },
  {
    "id": "2511.04838v1",
    "title": "SPECTRA: Spectral Target-Aware Graph Augmentation for Imbalanced   Molecular Property Regression",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.SP",
      "SP",
      "q-bio.MN",
      "MN"
    ],
    "authors": [
      "Brenda Nogueira",
      "Meng Jiang",
      "Nitesh V. Chawla",
      "Nuno Moniz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04838v1",
    "abstract": "In molecular property prediction, the most valuable compounds (e.g., high potency) often occupy sparse regions of the target space. Standard Graph Neural Networks (GNNs) commonly optimize for the average error, underperforming on these uncommon but critical cases, with existing oversampling methods often distorting molecular topology. In this paper, we introduce SPECTRA, a Spectral Target-Aware graph augmentation framework that generates realistic molecular graphs in the spectral domain. SPECTRA (i) reconstructs multi-attribute molecular graphs from SMILES; (ii) aligns molecule pairs via (Fused) Gromov-Wasserstein couplings to obtain node correspondences; (iii) interpolates Laplacian eigenvalues, eigenvectors and node features in a stable share-basis; and (iv) reconstructs edges to synthesize physically plausible intermediates with interpolated targets. A rarity-aware budgeting scheme, derived from a kernel density estimation of labels, concentrates augmentation where data are scarce. Coupled with a spectral GNN using edge-aware Chebyshev convolutions, SPECTRA densifies underrepresented regions without degrading global accuracy. On benchmarks, SPECTRA consistently improves error in relevant target ranges while maintaining competitive overall MAE, and yields interpretable synthetic molecules whose structure reflects the underlying spectral geometry. Our results demonstrate that spectral, geometry-aware augmentation is an effective and efficient strategy for imbalanced molecular property regression.",
    "fetched_at": "2025-11-11T02:19:10.037907Z"
  },
  {
    "id": "2511.04844v1",
    "title": "Sublinear iterations can suffice even for DDPMs",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Matthew S. Zhang",
      "Stephen Huan",
      "Jerry Huang",
      "Nicholas M. Boffi",
      "Sitan Chen",
      "Sinho Chewi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04844v1",
    "abstract": "SDE-based methods such as denoising diffusion probabilistic models (DDPMs) have shown remarkable success in real-world sample generation tasks. Prior analyses of DDPMs have been focused on the exponential Euler discretization, showing guarantees that generally depend at least linearly on the dimension or initial Fisher information. Inspired by works in log-concave sampling (Shen and Lee, 2019), we analyze an integrator -- the denoising diffusion randomized midpoint method (DDRaM) -- that leverages an additional randomized midpoint to better approximate the SDE. Using a recently-developed analytic framework called the \"shifted composition rule\", we show that this algorithm enjoys favorable discretization properties under appropriate smoothness assumptions, with sublinear $\\widetilde{O}(\\sqrt{d})$ score evaluations needed to ensure convergence. This is the first sublinear complexity bound for pure DDPM sampling -- prior works which obtained such bounds worked instead with ODE-based sampling and had to make modifications to the sampler which deviate from how they are used in practice. We also provide experimental validation of the advantages of our method, showing that it performs well in practice with pre-trained image synthesis models.",
    "fetched_at": "2025-11-11T02:19:10.037843Z"
  },
  {
    "id": "2511.04845v1",
    "title": "Investigating U.S. Consumer Demand for Food Products with Innovative   Transportation Certificates Based on Stated Preferences and Machine Learning   Approaches",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jingchen Bi",
      "Rodrigo Mesa-Arango"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04845v1",
    "abstract": "This paper utilizes a machine learning model to estimate the consumer's behavior for food products with innovative transportation certificates in the U.S. Building on previous research that examined demand for food products with supply chain traceability using stated preference analysis, transportation factors were identified as significant in consumer food purchasing choices. Consequently, a second experiment was conducted to pinpoint the specific transportation attributes valued by consumers. A machine learning model was applied, and five innovative certificates related to transportation were proposed: Transportation Mode, Internet of Things (IoT), Safety measures, Energy Source, and Must Arrive By Dates (MABDs). The preference experiment also incorporated product-specific and decision-maker factors for control purposes. The findings reveal a notable inclination toward safety and energy certificates within the transportation domain of the U.S. food supply chain. Additionally, the study examined the influence of price, product type, certificates, and decision-maker factors on purchasing choices. Ultimately, the study offers data-driven recommendations for improving food supply chain systems.",
    "fetched_at": "2025-11-11T02:19:10.037784Z"
  },
  {
    "id": "2511.04849v1",
    "title": "Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI",
      "I.2.6; I.2.7; D.2.3",
      "3"
    ],
    "authors": [
      "Quang-Dung Nguyen",
      "Tri-Dung Tran",
      "Thanh-Hieu Chu",
      "Hoang-Loc Tran",
      "Xiangwei Cheng",
      "Dirk Slama"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04849v1",
    "abstract": "The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in the automotive industry, where software now plays a pivotal role in defining vehicle functionality, enabling rapid innovation of modern vehicles. Developing SDV-specific applications demands advanced tools to streamline code generation and improve development efficiency. In recent years, general-purpose large language models (LLMs) have demonstrated transformative potential across domains. Still, restricted access to proprietary model architectures hinders their adaption to specific tasks like SDV code generation. In this study, we propose using prompts, a common and basic strategy to interact with LLMs and redirect their responses. Using only system prompts with an appropriate and efficient prompt structure designed using advanced prompt engineering techniques, LLMs can be crafted without requiring a training session or access to their base design. This research investigates the extensive experiments on different models by applying various prompting techniques, including bare models, using a benchmark specifically created to evaluate LLMs' performance in generating SDV code. The results reveal that the model with a few-shot prompting strategy outperforms the others in adjusting the LLM answers to match the expected outcomes based on quantitative metrics.",
    "fetched_at": "2025-11-11T02:19:10.037670Z"
  },
  {
    "id": "2511.04854v1",
    "title": "SigmaDock: Untwisting Molecular Docking With Fragment-Based SE(3)   Diffusion",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Alvaro Prat",
      "Leo Zhang",
      "Charlotte M. Deane",
      "Yee Whye Teh",
      "Garrett M. Morris"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04854v1",
    "abstract": "Determining the binding pose of a ligand to a protein, known as molecular docking, is a fundamental task in drug discovery. Generative approaches promise faster, improved, and more diverse pose sampling than physics-based methods, but are often hindered by chemically implausible outputs, poor generalisability, and high computational cost. To address these challenges, we introduce a novel fragmentation scheme, leveraging inductive biases from structural chemistry, to decompose ligands into rigid-body fragments. Building on this decomposition, we present SigmaDock, an SE(3) Riemannian diffusion model that generates poses by learning to reassemble these rigid bodies within the binding pocket. By operating at the level of fragments in SE(3), SigmaDock exploits well-established geometric priors while avoiding overly complex diffusion processes and unstable training dynamics. Experimentally, we show SigmaDock achieves state-of-the-art performance, reaching Top-1 success rates (RMSD<2 & PB-valid) above 79.9% on the PoseBusters set, compared to 12.7-30.8% reported by recent deep learning approaches, whilst demonstrating consistent generalisation to unseen proteins. SigmaDock is the first deep learning approach to surpass classical physics-based docking under the PB train-test split, marking a significant leap forward in the reliability and feasibility of deep learning for molecular modelling.",
    "fetched_at": "2025-11-11T02:19:10.037613Z"
  },
  {
    "id": "2511.04855v1",
    "title": "Epistemic Reject Option Prediction",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Vojtech Franc",
      "Jakub Paplham"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04855v1",
    "abstract": "In high-stakes applications, predictive models must not only produce accurate predictions but also quantify and communicate their uncertainty. Reject-option prediction addresses this by allowing the model to abstain when prediction uncertainty is high. Traditional reject-option approaches focus solely on aleatoric uncertainty, an assumption valid only when large training data makes the epistemic uncertainty negligible. However, in many practical scenarios, limited data makes this assumption unrealistic. This paper introduces the epistemic reject-option predictor, which abstains in regions of high epistemic uncertainty caused by insufficient data. Building on Bayesian learning, we redefine the optimal predictor as the one that minimizes expected regret -- the performance gap between the learned model and the Bayes-optimal predictor with full knowledge of the data distribution. The model abstains when the regret for a given input exceeds a specified rejection cost. To our knowledge, this is the first principled framework that enables learning predictors capable of identifying inputs for which the training data is insufficient to make reliable decisions.",
    "fetched_at": "2025-11-11T02:19:10.037559Z"
  },
  {
    "id": "2511.04856v1",
    "title": "Quantum Boltzmann Machines for Sample-Efficient Reinforcement Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Thore Gerlach",
      "Michael Schenk",
      "Verena Kain"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04856v1",
    "abstract": "We introduce theoretically grounded Continuous Semi-Quantum Boltzmann Machines (CSQBMs) that supports continuous-action reinforcement learning. By combining exponential-family priors over visible units with quantum Boltzmann distributions over hidden units, CSQBMs yield a hybrid quantum-classical model that reduces qubit requirements while retaining strong expressiveness. Crucially, gradients with respect to continuous variables can be computed analytically, enabling direct integration into Actor-Critic algorithms. Building on this, we propose a continuous Q-learning framework that replaces global maximization by efficient sampling from the CSQBM distribution, thereby overcoming instability issues in continuous control.",
    "fetched_at": "2025-11-11T02:19:10.037520Z"
  },
  {
    "id": "2511.04865v1",
    "title": "FoodRL: A Reinforcement Learning Ensembling Framework For In-Kind Food   Donation Forecasting",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Esha Sharma",
      "Lauren Davis",
      "Julie Ivy",
      "Min Chi"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04865v1",
    "abstract": "Food banks are crucial for alleviating food insecurity, but their effectiveness hinges on accurately forecasting highly volatile in-kind donations to ensure equitable and efficient resource distribution. Traditional forecasting models often fail to maintain consistent accuracy due to unpredictable fluctuations and concept drift driven by seasonal variations and natural disasters such as hurricanes in the Southeastern U.S. and wildfires in the West Coast. To address these challenges, we propose FoodRL, a novel reinforcement learning (RL) based metalearning framework that clusters and dynamically weights diverse forecasting models based on recent performance and contextual information. Evaluated on multi-year data from two structurally distinct U.S. food banks-one large regional West Coast food bank affected by wildfires and another state-level East Coast food bank consistently impacted by hurricanes, FoodRL consistently outperforms baseline methods, particularly during periods of disruption or decline. By delivering more reliable and adaptive forecasts, FoodRL can facilitate the redistribution of food equivalent to 1.7 million additional meals annually, demonstrating its significant potential for social impact as well as adaptive ensemble learning for humanitarian supply chains.",
    "fetched_at": "2025-11-11T02:19:10.037476Z"
  },
  {
    "id": "2511.04869v1",
    "title": "Trained on Tokens, Calibrated on Concepts: The Emergence of Semantic   Calibration in LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Preetum Nakkiran",
      "Arwen Bradley",
      "Adam Goliski",
      "Eugene Ndiaye",
      "Michael Kirchhof",
      "Sinead Williamson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04869v1",
    "abstract": "Large Language Models (LLMs) often lack meaningful confidence estimates for their outputs. While base LLMs are known to exhibit next-token calibration, it remains unclear whether they can assess confidence in the actual meaning of their responses beyond the token level. We find that, when using a certain sampling-based notion of semantic calibration, base LLMs are remarkably well-calibrated: they can meaningfully assess confidence in open-domain question-answering tasks, despite not being explicitly trained to do so. Our main theoretical contribution establishes a mechanism for why semantic calibration emerges as a byproduct of next-token prediction, leveraging a recent connection between calibration and local loss optimality. The theory relies on a general definition of \"B-calibration,\" which is a notion of calibration parameterized by a choice of equivalence classes (semantic or otherwise). This theoretical mechanism leads to a testable prediction: base LLMs will be semantically calibrated when they can easily predict their own distribution over semantic answer classes before generating a response. We state three implications of this prediction, which we validate through experiments: (1) Base LLMs are semantically calibrated across question-answering tasks, (2) RL instruction-tuning systematically breaks this calibration, and (3) chain-of-thought reasoning breaks calibration. To our knowledge, our work provides the first principled explanation of when and why semantic calibration emerges in LLMs.",
    "fetched_at": "2025-11-11T02:19:10.037427Z"
  },
  {
    "id": "2511.04873v1",
    "title": "Prototype Selection Using Topological Data Analysis",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jordan Eckert",
      "Elvan Ceyhan",
      "Henry Schenck"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04873v1",
    "abstract": "Recently, there has been an explosion in statistical learning literature to represent data using topological principles to capture structure and relationships. We propose a topological data analysis (TDA)-based framework, named Topological Prototype Selector (TPS), for selecting representative subsets (prototypes) from large datasets. We demonstrate the effectiveness of TPS on simulated data under different data intrinsic characteristics, and compare TPS against other currently used prototype selection methods in real data settings. In all simulated and real data settings, TPS significantly preserves or improves classification performance while substantially reducing data size. These contributions advance both algorithmic and geometric aspects of prototype learning and offer practical tools for parallelized, interpretable, and efficient classification.",
    "fetched_at": "2025-11-11T02:19:10.037367Z"
  },
  {
    "id": "2511.04875v2",
    "title": "Minimal and Mechanistic Conditions for Behavioral Self-Awareness in LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matthew Bozoukov",
      "Matthew Nguyen",
      "Shubkarman Singh",
      "Bart Bussmann",
      "Patrick Leask"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04875v2",
    "abstract": "Recent studies have revealed that LLMs can exhibit behavioral self-awareness: the ability to accurately describe or predict their own learned behaviors without explicit supervision. This capability raises safety concerns as it may, for example, allow models to better conceal their true abilities during evaluation. We attempt to characterize the minimal conditions under which such self-awareness emerges, and the mechanistic processes through which it manifests. Through controlled finetuning experiments on instruction-tuned LLMs with low-rank adapters (LoRA), we find: (1) that self-awareness can be reliably induced using a single rank-1 LoRA adapter; (2) that the learned self-aware behavior can be largely captured by a single steering vector in activation space, recovering nearly all of the fine-tune's behavioral effect; and (3) that self-awareness is non-universal and domain-localized, with independent representations across tasks. Together, these findings suggest that behavioral self-awareness emerges as a domain-specific, linear feature that can be easily induced and modulated.",
    "fetched_at": "2025-11-11T02:19:10.037324Z"
  },
  {
    "id": "2511.04880v1",
    "title": "DMA: Online RAG Alignment with Human Feedback",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yu Bai",
      "Yukai Miao",
      "Dawei Wang",
      "Li Chen",
      "Fei Long",
      "Rundi Zhai",
      "Dan Li",
      "Yanyu Ren",
      "Tianfeng Liu",
      "Hongtao Xie",
      "Ce Yang",
      "Xuhui Cai"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04880v1",
    "abstract": "Retrieval-augmented generation (RAG) systems often rely on static retrieval, limiting adaptation to evolving intent and content drift. We introduce Dynamic Memory Alignment (DMA), an online learning framework that systematically incorporates multi-granularity human feedback to align ranking in interactive settings. DMA organizes document-, list-, and response-level signals into a coherent learning pipeline: supervised training for pointwise and listwise rankers, policy optimization driven by response-level preferences, and knowledge distillation into a lightweight scorer for low-latency serving. Throughout this paper, memory refers to the model's working memory, which is the entire context visible to the LLM for In-Context Learning.   We adopt a dual-track evaluation protocol mirroring deployment: (i) large-scale online A/B ablations to isolate the utility of each feedback source, and (ii) few-shot offline tests on knowledge-intensive benchmarks. Online, a multi-month industrial deployment further shows substantial improvements in human engagement. Offline, DMA preserves competitive foundational retrieval while yielding notable gains on conversational QA (TriviaQA, HotpotQA). Taken together, these results position DMA as a principled approach to feedback-driven, real-time adaptation in RAG without sacrificing baseline capability.",
    "fetched_at": "2025-11-11T02:19:10.037272Z"
  },
  {
    "id": "2511.03925v1",
    "title": "Collaborative Agents for Automated Program Repair in Ruby",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nikta Akbarpour",
      "Mahdieh Sadat Benis",
      "Fatemeh Hendijani Fard",
      "Ali Ouni",
      "Mohamed Aymen Saied"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03925v1",
    "abstract": "Automated Program Repair (APR) has advanced rapidly with Large Language Models (LLMs), but most existing methods remain computationally expensive, and focused on a small set of languages. Ruby, despite its widespread use in web development and the persistent challenges faced by its developers, has received little attention in APR research. In this paper, we introduce RAMP, a novel lightweight framework that formulates program repair as a feedback-driven, iterative process for Ruby. RAMP employs a team of collaborative agents that generate targeted tests, reflect on errors, and refine candidate fixes until a correct solution is found. Unlike prior approaches, RAMP is designed to avoid reliance on large multilingual repair databases or costly fine-tuning, instead operating directly on Ruby through lightweight prompting and test-driven feedback. Evaluation on the XCodeEval benchmark shows that RAMP achieves a pass@1 of 67% on Ruby, outper-forming prior approaches. RAMP converges quickly within five iterations, and ablation studies confirm that test generation and self-reflection are key drivers of its performance. Further analysis shows that RAMP is particularly effective at repairing wrong answers, compilation errors, and runtime errors. Our approach provides new insights into multi-agent repair strategies, and establishes a foundation for extending LLM-based debugging tools to under-studied languages.",
    "fetched_at": "2025-11-11T02:19:08.306744Z"
  },
  {
    "id": "2511.03934v1",
    "title": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive   Error Feedback Agentic-AI",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Athma Narayanan",
      "Mahesh Subedar",
      "Omesh Tickoo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03934v1",
    "abstract": "We present an agentic flow consisting of multiple agents that combine specialized LLMs and hardware simulation tools to collaboratively complete the complex task of Register Transfer Level (RTL) generation without human intervention. A key feature of the proposed flow is the progressive error feedback system of agents (PEFA), a self-correcting mechanism that leverages iterative error feedback to progressively increase the complexity of the approach. The generated RTL includes checks for compilation, functional correctness, and synthesizable constructs. To validate this adaptive approach to code generation, benchmarking is performed using two opensource natural language-to-RTL datasets. We demonstrate the benefits of the proposed approach implemented on an open source agentic framework, using both open- and closed-source LLMs, effectively bridging the performance gap between them. Compared to previously published methods, our approach sets a new benchmark, providing state-of-the-art pass rates while being efficient in token counts.",
    "fetched_at": "2025-11-11T02:19:08.306692Z"
  },
  {
    "id": "2511.03945v1",
    "title": "Direct Semantic Communication Between Large Language Models via Vector   Translation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Fu-Chun Yang",
      "Jason Eshraghian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03945v1",
    "abstract": "In multi-agent settings, such as debate, reflection, or tool-calling, large language models (LLMs) pass messages as plain tokens, discarding most latent semantics. This constrains information transfer and adds unnecessary computational overhead. We form a latent bridge via vector translations, which use learned mappings that enable direct semantic exchange between representation spaces. A dual-encoder translator trained between Llama-2-7B and Mistral-7B-Instruct attains an average cosine alignment of 0.538. Injecting the translated vectors at 30 percent blending strength steers the target model's generation without destabilizing logits. Bidirectional evaluation shows a 2.01:1 transfer asymmetry, indicating that general-purpose models yield more transferable representations than instruction-tuned variants. This conservative injection preserves computational stability while demonstrating that cross-model latent communication is feasible, enabling collaborative AI systems that share meaning rather than tokens.",
    "fetched_at": "2025-11-11T02:19:08.306649Z"
  },
  {
    "id": "2511.03958v1",
    "title": "Multi-Agent Collaborative Framework For Math Problem Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.MA",
      "MA",
      "cs.CL",
      "CL",
      "cs.HC",
      "HC",
      "I.2.11; I.2.6; K.3.1",
      "1"
    ],
    "authors": [
      "Kia Karbasi",
      "Kevin Hong",
      "Mohammad Amin Samadi",
      "Gregory Pottie"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.03958v1",
    "abstract": "Automatic question generation (AQG) for mathematics education remains an elusive goal for Intelligent Tutoring Systems and educators. While pre-trained transformer-based language models have significantly advanced natural language generation, they often struggle to precisely control problem complexity and cognitive demands. In this paper, we introduce a collaborative multi-agent framework as a novel method of incorporating inference-time computation into AQG. This approach leverages multiple agents that iteratively refine generated question-answer pairs to better balance complexity and cognitive demand. We evaluate the generated questions on five meta-evaluation criteria: relevance, importance, clarity, difficulty matching, answerability, to assess the system's ability to control the required complexity and quality of the questions. Preliminary evaluations show that this collaborative multi-agent framework elevates the quality of generated educational content by fostering a more nuanced balance between cognitive challenge and clarity. These promising outcomes suggest that integrating collaborative multi-agent workflows can yield more controlled, pedagogically valuable content that can help advance automated educational content generation and adaptive learning environments.",
    "fetched_at": "2025-11-11T02:19:08.306607Z"
  },
  {
    "id": "2511.03985v1",
    "title": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning   Engineering",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhuowen Yuan",
      "Tao Liu",
      "Yang Yang",
      "Yang Wang",
      "Feng Qi",
      "Kaushik Rangadurai",
      "Bo Li",
      "Shuang Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03985v1",
    "abstract": "Recent LLM-based agents have demonstrated strong capabilities in automated ML engineering. However, they heavily rely on repeated full training runs to evaluate candidate solutions, resulting in significant computational overhead, limited scalability to large search spaces, and slow iteration cycles. To address these challenges, we introduce ArchPilot, a multi-agent system that integrates architecture generation, proxy-based evaluation, and adaptive search into a unified framework. ArchPilot consists of three specialized agents: an orchestration agent that coordinates the search process using a Monte Carlo Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and manages memory of previous candidates; a generation agent that iteratively generates, improves, and debugs candidate architectures; and an evaluation agent that executes proxy training runs, generates and optimizes proxy functions, and aggregates the proxy scores into a fidelity-aware performance metric. This multi-agent collaboration allows ArchPilot to prioritize high-potential candidates with minimal reliance on expensive full training runs, facilitating efficient ML engineering under limited budgets. Experiments on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE and ML-Master, validating the effectiveness of our multi-agent system.",
    "fetched_at": "2025-11-11T02:19:06.856944Z"
  },
  {
    "id": "2511.04133v1",
    "title": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing   Platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Miguel E. Andres",
      "Vadim Fedorov",
      "Rida Sadek",
      "Enric Spagnolo-Arrizabalaga",
      "Nadescha Trudel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04133v1",
    "abstract": "Voice AI agents are rapidly transitioning to production deployments, yet systematic methods for ensuring testing reliability remain underdeveloped. Organizations cannot objectively assess whether their testing approaches (internal tools or external platforms) actually work, creating a critical measurement gap as voice AI scales to billions of daily interactions.   We present the first systematic framework for evaluating voice AI testing quality through human-centered benchmarking. Our methodology addresses the fundamental dual challenge of testing platforms: generating realistic test conversations (simulation quality) and accurately evaluating agent responses (evaluation quality). The framework combines established psychometric techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence intervals, and permutation tests) with rigorous statistical validation to provide reproducible metrics applicable to any testing approach.   To validate the framework and demonstrate its utility, we conducted comprehensive empirical evaluation of three leading commercial platforms focused on Voice AI Testing using 21,600 human judgments across 45 simulations and ground truth validation on 60 conversations. Results reveal statistically significant performance differences with the proposed framework, with the top-performing platform, Evalion, achieving 0.92 evaluation quality measured as f1-score versus 0.73 for others, and 0.61 simulation quality using a league based scoring system (including ties) vs 0.43 for other platforms.   This framework enables researchers and organizations to empirically validate the testing capabilities of any platform, providing essential measurement foundations for confident voice AI deployment at scale. Supporting materials are made available to facilitate reproducibility and adoption.",
    "fetched_at": "2025-11-11T02:19:06.856764Z"
  },
  {
    "id": "2511.04156v1",
    "title": "Deep reinforcement learning based navigation of a jellyfish-like swimmer   in flows with obstacles",
    "date": "2025-11-06",
    "tags": [
      "physics.flu-dyn",
      "flu-dyn"
    ],
    "authors": [
      "Yihao Chen",
      "Yue Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04156v1",
    "abstract": "We develop a deep reinforcement learning framework for controlling a bio-inspired jellyfish swimmer to navigate complex fluid environments with obstacles. While existing methods often rely on kinematic and geometric states, a key challenge remains in achieving efficient obstacle avoidance under strong fluid-structure interactions and near-wall effects. We augment the agent's state representation within a soft actor-critic algorithm to include the real-time forces and torque experienced by the swimmer, providing direct mechanical feedback from vortex-wall interactions. This augmented state space enables the swimmer to perceive and interpret wall proximity and orientation through distinct hydrodynamic force signatures. We analyze how these force and torque patterns, generated by walls at different positions influence the swimmer's decision-making policy. Comparative experiments with a baseline model without force feedback demonstrate that the present one with force feedback achieves higher navigation efficiency in two-dimensional obstacle-avoidance tasks. The results show that explicit force feedback facilitates earlier, smoother maneuvers and enables the exploitation of wall effects for efficient turning behaviors. With an application to autonomous cave mapping, this work underscores the critical role of direct mechanical feedback in fluid environments and presents a physics-aware machine learning framework for advancing robust underwater exploration systems.",
    "fetched_at": "2025-11-11T02:19:06.856644Z"
  },
  {
    "id": "2511.04235v1",
    "title": "Shared Spatial Memory Through Predictive Coding",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "Zhengru Fang",
      "Yu Guo",
      "Jingjing Wang",
      "Yuang Zhang",
      "Haonan An",
      "Yinhai Wang",
      "Yuguang Fang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04235v1",
    "abstract": "Sharing and reconstructing a consistent spatial memory is a critical challenge in multi-agent systems, where partial observability and limited bandwidth often lead to catastrophic failures in coordination. We introduce a multi-agent predictive coding framework that formulate coordination as the minimization of mutual uncertainty among agents. Instantiated as an information bottleneck objective, it prompts agents to learn not only who and what to communicate but also when. At the foundation of this framework lies a grid-cell-like metric as internal spatial coding for self-localization, emerging spontaneously from self-supervised motion prediction. Building upon this internal spatial code, agents gradually develop a bandwidth-efficient communication mechanism and specialized neural populations that encode partners' locations: an artificial analogue of hippocampal social place cells (SPCs). These social representations are further enacted by a hierarchical reinforcement learning policy that actively explores to reduce joint uncertainty. On the Memory-Maze benchmark, our approach shows exceptional resilience to bandwidth constraints: success degrades gracefully from 73.5% to 64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically principled and biologically plausible basis for how complex social representations emerge from a unified predictive drive, leading to social collective intelligence.",
    "fetched_at": "2025-11-11T02:19:06.856602Z"
  },
  {
    "id": "2511.04375v1",
    "title": "Studying the Effect of Explicit Interaction Representations on Learning   Scene-level Distributions of Human Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Anna Mszros",
      "Javier Alonso-Mora",
      "Jens Kober"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04375v1",
    "abstract": "Effectively capturing the joint distribution of all agents in a scene is relevant for predicting the true evolution of the scene and in turn providing more accurate information to the decision processes of autonomous vehicles. While new models have been developed for this purpose in recent years, it remains unclear how to best represent the joint distributions particularly from the perspective of the interactions between agents. Thus far there is no clear consensus on how best to represent interactions between agents; whether they should be learned implicitly from data by neural networks, or explicitly modeled using the spatial and temporal relations that are more grounded in human decision-making. This paper aims to study various means of describing interactions within the same network structure and their effect on the final learned joint distributions. Our findings show that more often than not, simply allowing a network to establish interactive connections between agents based on data has a detrimental effect on performance. Instead, having well defined interactions (such as which agent of an agent pair passes first at an intersection) can often bring about a clear boost in performance.",
    "fetched_at": "2025-11-11T02:19:06.856392Z"
  },
  {
    "id": "2511.04515v1",
    "title": "Robust mean-field control under common noise uncertainty",
    "date": "2025-11-06",
    "tags": [
      "math.OC",
      "OC",
      "math.PR",
      "PR",
      "q-fin.MF",
      "MF"
    ],
    "authors": [
      "Mathieu Laurire",
      "Ariel Neufeld",
      "Kyunghyun Park"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04515v1",
    "abstract": "We propose and analyze a framework for discrete-time robust mean-field control problems under common noise uncertainty. In this framework, the mean-field interaction describes the collective behavior of infinitely many cooperative agents' state and action, while the common noise -- a random disturbance affecting all agents' state dynamics -- is uncertain. A social planner optimizes over open-loop controls on an infinite horizon to maximize the representative agent's worst-case expected reward, where worst-case corresponds to the most adverse probability measure among all candidates inducing the unknown true law of the common noise process. We refer to this optimization as a robust mean-field control problem under common noise uncertainty. We first show that this problem arises as the asymptotic limit of a cooperative $N$-agent robust optimization problem, commonly known as propagation of chaos. We then prove the existence of an optimal open-loop control by linking the robust mean field control problem to a lifted robust Markov decision problem on the space of probability measures and by establishing the dynamic programming principle and Bellman--Isaac fixed point theorem for the lifted robust Markov decision problem. Finally, we complement our theoretical results with numerical experiments motivated by distribution planning and systemic risk in finance, highlighting the advantages of accounting for common noise uncertainty.",
    "fetched_at": "2025-11-11T02:19:06.856293Z"
  },
  {
    "id": "2511.04590v1",
    "title": "Complexity as Advantage: A Regret-Based Perspective on Emergent   Structure",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Oshri Naparstek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04590v1",
    "abstract": "We introduce Complexity as Advantage (CAA), a framework that defines the complexity of a system relative to a family of observers. Instead of measuring complexity as an intrinsic property, we evaluate how much predictive regret a system induces for different observers attempting to model it. A system is complex when it is easy for some observers and hard for others, creating an information advantage. We show that this formulation unifies several notions of emergent behavior, including multiscale entropy, predictive information, and observer-dependent structure. The framework suggests that \"interesting\" systems are those positioned to create differentiated regret across observers, providing a quantitative grounding for why complexity can be functionally valuable. We demonstrate the idea through simple dynamical models and discuss implications for learning, evolution, and artificial agents.",
    "fetched_at": "2025-11-11T02:19:06.856241Z"
  },
  {
    "id": "2511.04598v1",
    "title": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free   Autonomous Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hampus strm",
      "Elin Anna Topp",
      "Jacek Malec"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04598v1",
    "abstract": "In this paper we study how transforming regular reinforcement learning environments into goal-conditioned environments can let agents learn to solve tasks autonomously and reward-free. We show that an agent can learn to solve tasks by selecting its own goals in an environment-agnostic way, at training times comparable to externally guided reinforcement learning. Our method is independent of the underlying off-policy learning algorithm. Since our method is environment-agnostic, the agent does not value any goals higher than others, leading to instability in performance for individual goals. However, in our experiments, we show that the average goal success rate improves and stabilizes. An agent trained with this method can be instructed to seek any observations made in the environment, enabling generic training of agents prior to specific use cases.",
    "fetched_at": "2025-11-11T02:19:06.856205Z"
  },
  {
    "id": "2511.04824v1",
    "title": "Agentic Refactoring: An Empirical Study of AI Coding Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "D.2.7",
      "7"
    ],
    "authors": [
      "Kosei Horikawa",
      "Hao Li",
      "Yutaro Kashiwa",
      "Bram Adams",
      "Hajimu Iida",
      "Ahmed E. Hassan"
    ],
    "institution": "OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2511.04824v1",
    "abstract": "Agentic coding tools, such as OpenAI Codex, Claude Code, and Cursor, are transforming the software engineering landscape. These AI-powered systems function as autonomous teammates capable of planning and executing complex development tasks. Agents have become active participants in refactoring, a cornerstone of sustainable software development aimed at improving internal code quality without altering observable behavior. Despite their increasing adoption, there is a critical lack of empirical understanding regarding how agentic refactoring is utilized in practice, how it compares to human-driven refactoring, and what impact it has on code quality. To address this empirical gap, we present a large-scale study of AI agent-generated refactorings in real-world open-source Java projects, analyzing 15,451 refactoring instances across 12,256 pull requests and 14,988 commits derived from the AIDev dataset. Our empirical analysis shows that refactoring is a common and intentional activity in this development paradigm, with agents explicitly targeting refactoring in 26.1% of commits. Analysis of refactoring types reveals that agentic efforts are dominated by low-level, consistency-oriented edits, such as Change Variable Type (11.8%), Rename Parameter (10.4%), and Rename Variable (8.5%), reflecting a preference for localized improvements over the high-level design changes common in human refactoring. Additionally, the motivations behind agentic refactoring focus overwhelmingly on internal quality concerns, with maintainability (52.5%) and readability (28.1%). Furthermore, quantitative evaluation of code quality metrics shows that agentic refactoring yields small but statistically significant improvements in structural metrics, particularly for medium-level changes, reducing class size and complexity (e.g., Class LOC median $\\Delta$ = -15.25).",
    "fetched_at": "2025-11-11T02:19:06.856109Z"
  },
  {
    "id": "2511.04032v1",
    "title": "Detecting Silent Failures in Multi-Agentic AI Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Divya Pathak",
      "Harshit Kumar",
      "Anuska Roy",
      "Felix George",
      "Mudit Verma",
      "Pratibha Moogi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04032v1",
    "abstract": "Multi-Agentic AI systems, powered by large language models (LLMs), are inherently non-deterministic and prone to silent failures such as drift, cycles, and missing details in outputs, which are difficult to detect. We introduce the task of anomaly detection in agentic trajectories to identify these failures and present a dataset curation pipeline that captures user behavior, agent non-determinism, and LLM variation. Using this pipeline, we curate and label two benchmark datasets comprising \\textbf{4,275 and 894} trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection methods on these datasets, we show that supervised (XGBoost) and semi-supervised (SVDD) approaches perform comparably, achieving accuracies up to 98% and 96%, respectively. This work provides the first systematic study of anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks, and insights to guide future research.",
    "fetched_at": "2025-11-11T02:19:05.034815Z"
  },
  {
    "id": "2511.04064v1",
    "title": "Benchmarking and Studying the LLM-based Agent System in End-to-End   Software Development",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Zhengran Zeng",
      "Yixin Li",
      "Rui Xie",
      "Wei Ye",
      "Shikun Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04064v1",
    "abstract": "The development of LLM-based autonomous agents for end-to-end software development represents a significant paradigm shift in software engineering. However, the scientific evaluation of these systems is hampered by significant challenges, including overly simplistic benchmarks and the difficulty of conducting fair comparisons between different agent architectures due to confounding implementation variables. To address these limitations, we first construct a challenging and dynamically curated E2EDevBench to simulate realistic development scenarios. Second, we propose a hybrid evaluation framework that combines test-case-based functional assessment with fine-grained, LLM-based requirement verification. Using this framework, we conduct a controlled empirical study on three representative agent architectures implemented upon a unified foundation to isolate the impact of workflow design. Our findings reveal that state-of-the-art agents can fulfill approximately 50\\% of requirements on \\bench{}, but their success is critically dependent on the architectural strategy for task decomposition and collaboration. Furthermore, our analysis indicates that the primary bottleneck is the omission of requirements and inadequate self-verification. This work provides the community with a more realistic benchmark, a comprehensive evaluation framework, and crucial insights into the current capabilities and core challenges of software development agents, guiding future research toward enhancing requirement comprehension and planning.",
    "fetched_at": "2025-11-11T02:19:05.034764Z"
  },
  {
    "id": "2511.04076v2",
    "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via   Large Language Model Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hao Li",
      "Haotian Chen",
      "Ruoyuan Gong",
      "Juanjuan Wang",
      "Hao Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04076v2",
    "abstract": "Redistricting plays a central role in shaping how votes are translated into political power. While existing computational methods primarily aim to generate large ensembles of legally valid districting plans, they often neglect the strategic dynamics involved in the selection process. This oversight creates opportunities for partisan actors to cherry-pick maps that, while technically compliant, are politically advantageous. Simply satisfying formal constraints does not ensure fairness when the selection process itself can be manipulated. We propose \\textbf{Agentmandering}, a framework that reimagines redistricting as a turn-based negotiation between two agents representing opposing political interests. Drawing inspiration from game-theoretic ideas, particularly the \\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction into the redistricting process via large language model (LLM) agents. Agents alternate between selecting and freezing districts from a small set of candidate maps, gradually partitioning the state through constrained and interpretable choices. Evaluation on post-2020 U.S. Census data across all states shows that Agentmandering significantly reduces partisan bias and unfairness, while achieving 2 to 3 orders of magnitude lower variance than standard baselines. These results demonstrate both fairness and stability, especially in swing-state scenarios. Our code is available at https://github.com/Lihaogx/AgentMandering.",
    "fetched_at": "2025-11-11T02:19:05.034709Z"
  },
  {
    "id": "2511.04153v1",
    "title": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated   Text-to-SQL Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Fahim Ahmed",
      "Md Mubtasim Ahasan",
      "Jahir Sadik Monon",
      "Muntasir Wahed",
      "M Ashraful Amin",
      "A K M Mahbubur Rahman",
      "Amin Ahsan Ali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04153v1",
    "abstract": "Text-to-SQL systems provide a natural language interface that can enable even laymen to access information stored in databases. However, existing Large Language Models (LLM) struggle with SQL generation from natural instructions due to large schema sizes and complex reasoning. Prior work often focuses on complex, somewhat impractical pipelines using flagship models, while smaller, efficient models remain overlooked. In this work, we explore three multi-agent LLM pipelines, with systematic performance benchmarking across a range of small to large open-source models: (1) Multi-agent discussion pipeline, where agents iteratively critique and refine SQL queries, and a judge synthesizes the final answer; (2) Planner-Coder pipeline, where a thinking model planner generates stepwise SQL generation plans and a coder synthesizes queries; and (3) Coder-Aggregator pipeline, where multiple coders independently generate SQL queries, and a reasoning agent selects the best query. Experiments on the Bird-Bench Mini-Dev set reveal that Multi-Agent discussion can improve small model performance, with up to 10.6% increase in Execution Accuracy for Qwen2.5-7b-Instruct seen after three rounds of discussion. Among the pipelines, the LLM Reasoner-Coder pipeline yields the best results, with DeepSeek-R1-32B and QwQ-32B planners boosting Gemma 3 27B IT accuracy from 52.4% to the highest score of 56.4%. Codes are available at https://github.com/treeDweller98/bappa-sql.",
    "fetched_at": "2025-11-11T02:19:05.034653Z"
  },
  {
    "id": "2511.04184v1",
    "title": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity   in LLM as a Communicator (LAAC) Framework in Multiple Application Domains",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mohammed Musthafa Rafi",
      "Adarsh Krishnamurthy",
      "Aditya Balu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04184v1",
    "abstract": "The proliferation of AI-generated content has created an absurd communication theater where senders use LLMs to inflate simple ideas into verbose content, recipients use LLMs to compress them back into summaries, and as a consequence neither party engage with authentic content. LAAC (LLM as a Communicator) proposes a paradigm shift - positioning LLMs as intelligent communication intermediaries that capture the sender's intent through structured dialogue and facilitate genuine knowledge exchange with recipients. Rather than perpetuating cycles of AI-generated inflation and compression, LAAC enables authentic communication across diverse contexts including academic papers, proposals, professional emails, and cross-platform content generation. However, deploying LLMs as trusted communication intermediaries raises critical questions about information fidelity, consistency, and reliability. This position paper systematically evaluates the trustworthiness requirements for LAAC's deployment across multiple communication domains. We investigate three fundamental dimensions: (1) Information Capture Fidelity - accuracy of intent extraction during sender interviews across different communication types, (2) Reproducibility - consistency of structured knowledge across multiple interaction instances, and (3) Query Response Integrity - reliability of recipient-facing responses without hallucination, source conflation, or fabrication. Through controlled experiments spanning multiple LAAC use cases, we assess these trust dimensions using LAAC's multi-agent architecture. Preliminary findings reveal measurable trust gaps that must be addressed before LAAC can be reliably deployed in high-stakes communication scenarios.",
    "fetched_at": "2025-11-11T02:19:05.034552Z"
  },
  {
    "id": "2511.04720v1",
    "title": "Learning to reason about rare diseases through retrieval-augmented   agents",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ha Young Kim",
      "Jun Li",
      "Ana Beatriz Solana",
      "Carolin M. Pirkl",
      "Benedikt Wiestler",
      "Julia A. Schnabel",
      "Cosmin I. Bercea"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04720v1",
    "abstract": "Rare diseases represent the long tail of medical imaging, where AI models often fail due to the scarcity of representative training data. In clinical workflows, radiologists frequently consult case reports and literature when confronted with unfamiliar findings. Following this line of reasoning, we introduce RADAR, Retrieval Augmented Diagnostic Reasoning Agents, an agentic system for rare disease detection in brain MRI. Our approach uses AI agents with access to external medical knowledge by embedding both case reports and literature using sentence transformers and indexing them with FAISS to enable efficient similarity search. The agent retrieves clinically relevant evidence to guide diagnostic decision making on unseen diseases, without the need of additional training. Designed as a model-agnostic reasoning module, RADAR can be seamlessly integrated with diverse large language models, consistently improving their rare pathology recognition and interpretability. On the NOVA dataset comprising 280 distinct rare diseases, RADAR achieves up to a 10.2% performance gain, with the strongest improvements observed for open source models such as DeepSeek. Beyond accuracy, the retrieved examples provide interpretable, literature grounded explanations, highlighting retrieval-augmented reasoning as a powerful paradigm for low-prevalence conditions in medical imaging.",
    "fetched_at": "2025-11-11T02:19:05.034459Z"
  },
  {
    "id": "2511.04307v1",
    "title": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jian Mu",
      "Chaoyun Zhang",
      "Chiming Ni",
      "Lu Wang",
      "Bo Qiao",
      "Kartik Mathur",
      "Qianhui Wu",
      "Yuhang Xie",
      "Xiaojun Ma",
      "Mengyu Zhou",
      "Si Qin",
      "Liqun Li",
      "Yu Kang",
      "Minghua Ma",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04307v1",
    "abstract": "We introduce GUI-360$^\\circ$, a large-scale, comprehensive dataset and benchmark suite designed to advance computer-using agents (CUAs). CUAs present unique challenges and is constrained by three persistent gaps: a scarcity of real-world CUA tasks, the lack of automated collection-and-annotation pipelines for multi-modal trajectories, and the absence of a unified benchmark that jointly evaluates GUI grounding, screen parsing, and action prediction.   GUI-360$^\\circ$ addresses these gaps with an LLM-augmented, largely automated pipeline for query sourcing, environment-template construction, task instantiation, batched execution, and LLM-driven quality filtering. The released corpus contains over 1.2M executed action steps across thousands of trajectories in popular Windows office applications, and includes full-resolution screenshots, accessibility metadata when available, instantiated goals, intermediate reasoning traces, and both successful and failed action trajectories. The dataset supports three canonical tasks, GUI grounding, screen parsing, and action prediction, and a hybrid GUI+API action space that reflects modern agent designs. Benchmarking state-of-the-art vision--language models on GUI-360$^\\circ$ reveals substantial out-of-the-box shortcomings in grounding and action prediction; supervised fine-tuning and reinforcement learning yield significant gains but do not close the gap to human-level reliability. We release GUI-360$^\\circ$ and accompanying code to facilitate reproducible research and accelerate progress on robust desktop CUAs.   The full dataset has been made public on https://huggingface.co/datasets/vyokky/GUI-360.",
    "fetched_at": "2025-11-11T02:19:05.034341Z"
  },
  {
    "id": "2511.04393v1",
    "title": "Post-Training LLMs as Better Decision-Making Agents: A   Regret-Minimization Approach",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chanwoo Park",
      "Ziyang Chen",
      "Asuman Ozdaglar",
      "Kaiqing Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04393v1",
    "abstract": "Large language models (LLMs) are increasingly deployed as \"agents\" for decision-making (DM) in interactive and dynamic environments. Yet, since they were not originally designed for DM, recent studies show that LLMs can struggle even in basic online DM problems, failing to achieve low regret or an effective exploration-exploitation tradeoff. To address this, we introduce Iterative Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure that repeatedly distills low-regret decision trajectories back into the base model. At each iteration, the model rolls out multiple decision trajectories, selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior methods that (a) distill action sequences from known DM algorithms or (b) rely on manually crafted chain-of-thought templates, our approach leverages the regret metric to elicit the model's own DM ability and reasoning rationales. This reliance on model-generated reasoning avoids rigid output engineering and provides more flexible, natural-language training signals. Empirical results show that Iterative RMFT improves LLMs' DM performance across diverse models - from Transformers with numerical input/output, to open-weight LLMs, and advanced closed-weight models like GPT-4o mini. Its flexibility in output and reasoning formats enables generalization across tasks with varying horizons, action spaces, reward processes, and natural-language contexts. Finally, we provide theoretical insight showing that a single-layer Transformer under this paradigm can act as a no-regret learner in a simplified setting. Overall, Iterative RMFT offers a principled and general post-training framework for enhancing LLMs' decision-making capabilities.",
    "fetched_at": "2025-11-11T02:19:05.034174Z"
  },
  {
    "id": "2511.04427v1",
    "title": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on   Software Development",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hao He",
      "Courtney Miller",
      "Shyam Agarwal",
      "Christian Kstner",
      "Bogdan Vasilescu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04427v1",
    "abstract": "Large language models (LLMs) have demonstrated the promise to revolutionize the field of software engineering. Among other things, LLM agents are rapidly gaining momentum in their application to software development, with practitioners claiming a multifold productivity increase after adoption. Yet, empirical evidence is lacking around these claims. In this paper, we estimate the causal effect of adopting a widely popular LLM agent assistant, namely Cursor, on development velocity and software quality. The estimation is enabled by a state-of-the-art difference-in-differences design comparing Cursor-adopting GitHub projects with a matched control group of similar GitHub projects that do not use Cursor. We find that the adoption of Cursor leads to a significant, large, but transient increase in project-level development velocity, along with a significant and persistent increase in static analysis warnings and code complexity. Further panel generalized method of moments estimation reveals that the increase in static analysis warnings and code complexity acts as a major factor causing long-term velocity slowdown. Our study carries implications for software engineering practitioners, LLM agent assistant designers, and researchers.",
    "fetched_at": "2025-11-11T02:19:05.034079Z"
  },
  {
    "id": "2511.04464v1",
    "title": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Carnot Braun",
      "Rafael O. Jarczewski",
      "Gabriel U. Talasso",
      "Leandro A. Villas",
      "Allan M. de Souza"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04464v1",
    "abstract": "Traditional vehicle routing systems efficiently optimize singular metrics like time or distance, and when considering multiple metrics, they need more processes to optimize . However, they lack the capability to interpret and integrate the complex, semantic, and dynamic contexts of human drivers, such as multi-step tasks, situational constraints, or urgent needs. This paper introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a hybrid agentic assistant designed to augment classical pathfinding algorithms with contextual reasoning. Our approach employs a Large Language Model (LLM) agent that operates on a candidate set of routes generated by a multi-objective (time, CO2) Dijkstra algorithm. The agent evaluates these options against user-provided tasks, preferences, and avoidance rules by leveraging a pre-processed geospatial cache of urban Points of Interest (POIs). In a benchmark of realistic urban scenarios, PAVe successfully used complex user intent into appropriate route modifications, achieving over 88% accuracy in its initial route selections with a local model. We conclude that combining classical routing algorithms with an LLM-based semantic reasoning layer is a robust and effective approach for creating personalized, adaptive, and scalable solutions for urban mobility optimization.",
    "fetched_at": "2025-11-11T02:19:05.033971Z"
  },
  {
    "id": "2511.04481v1",
    "title": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy   Consumption through Empirical and Theoretical Analysis",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lars Krupp",
      "Daniel Geiler",
      "Vishal Banwari",
      "Paul Lukowicz",
      "Jakob Karolus"
    ],
    "institution": "Google, OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2511.04481v1",
    "abstract": "Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful agentic systems pushing the boundaries of Large Language Models (LLM). They can autonomously interact with the internet at the user's behest, such as navigating websites, filling search masks, and comparing price lists. Though web agent research is thriving, induced sustainability issues remain largely unexplored. To highlight the urgency of this issue, we provide an initial exploration of the energy and $CO_2$ cost associated with web agents from both a theoretical -via estimation- and an empirical perspective -by benchmarking. Our results show how different philosophies in web agent creation can severely impact the associated expended energy, and that more energy consumed does not necessarily equate to better results. We highlight a lack of transparency regarding disclosing model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. Our work contributes towards a change in thinking of how we evaluate web agents, advocating for dedicated metrics measuring energy consumption in benchmarks.",
    "fetched_at": "2025-11-11T02:19:05.033833Z"
  },
  {
    "id": "2511.04502v1",
    "title": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific   RAG",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Joshua Gao",
      "Quoc Huy Pham",
      "Subin Varghese",
      "Silwal Saurav",
      "Vedhus Hoskere"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04502v1",
    "abstract": "Retrieval-Augmented Generation (RAG) is a critical technique for grounding Large Language Models (LLMs) in factual evidence, yet evaluating RAG systems in specialized, safety-critical domains remains a significant challenge. Existing evaluation frameworks often rely on heuristic-based metrics that fail to capture domain-specific nuances and other works utilize LLM-as-a-Judge approaches that lack validated alignment with human judgment. This paper introduces RAGalyst, an automated, human-aligned agentic framework designed for the rigorous evaluation of domain-specific RAG systems. RAGalyst features an agentic pipeline that generates high-quality, synthetic question-answering (QA) datasets from source documents, incorporating an agentic filtering step to ensure data fidelity. The framework refines two key LLM-as-a-Judge metrics-Answer Correctness and Answerability-using prompt optimization to achieve a strong correlation with human annotations. Applying this framework to evaluate various RAG components across three distinct domains (military operations, cybersecurity, and bridge engineering), we find that performance is highly context-dependent. No single embedding model, LLM, or hyperparameter configuration proves universally optimal. Additionally, we provide an analysis on the most common low Answer Correctness reasons in RAG. These findings highlight the necessity of a systematic evaluation framework like RAGalyst, which empowers practitioners to uncover domain-specific trade-offs and make informed design choices for building reliable and effective RAG systems. RAGalyst is available on our Github.",
    "fetched_at": "2025-11-11T02:19:05.033720Z"
  },
  {
    "id": "2511.04646v1",
    "title": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for   Embodied LLM-Based Multi-Agent Collaboration",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Narjes Nourzad",
      "Hanqing Yang",
      "Shiyu Chen",
      "Carlee Joe-Wong"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04646v1",
    "abstract": "Cooperative multi-agent planning requires agents to make joint decisions with partial information and limited communication. Coordination at the trajectory level often fails, as small deviations in timing or movement cascade into conflicts. Symbolic planning mitigates this challenge by raising the level of abstraction and providing a minimal vocabulary of actions that enable synchronization and collective progress. We present DR. WELL, a decentralized neurosymbolic framework for cooperative multi-agent planning. Cooperation unfolds through a two-phase negotiation protocol: agents first propose candidate roles with reasoning and then commit to a joint allocation under consensus and environment constraints. After commitment, each agent independently generates and executes a symbolic plan for its role without revealing detailed trajectories. Plans are grounded in execution outcomes via a shared world model that encodes the current state and is updated as agents act. By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids brittle step-level alignment and enables higher-level operations that are reusable, synchronizable, and interpretable. Experiments on cooperative block-push tasks show that agents adapt across episodes, with the dynamic world model capturing reusable patterns and improving task completion rates and efficiency. Experiments on cooperative block-push tasks show that our dynamic world model improves task completion and efficiency through negotiation and self-refinement, trading a time overhead for evolving, more efficient collaboration strategies.",
    "fetched_at": "2025-11-11T02:19:05.033602Z"
  },
  {
    "id": "2511.04769v1",
    "title": "ReGen: Generative Robot Simulation via Inverse Design",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Phat Nguyen",
      "Tsun-Hsuan Wang",
      "Zhang-Wei Hong",
      "Erfan Aasi",
      "Andrew Silva",
      "Guy Rosman",
      "Sertac Karaman",
      "Daniela Rus"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04769v1",
    "abstract": "Simulation plays a key role in scaling robot learning and validating policies, but constructing simulations remains a labor-intensive process. This paper introduces ReGen, a generative simulation framework that automates simulation design via inverse design. Given a robot's behavior -- such as a motion trajectory or an objective function -- and its textual description, ReGen infers plausible scenarios and environments that could have caused the behavior. ReGen leverages large language models to synthesize scenarios by expanding a directed graph that encodes cause-and-effect relationships, relevant entities, and their properties. This structured graph is then translated into a symbolic program, which configures and executes a robot simulation environment. Our framework supports (i) augmenting simulations based on ego-agent behaviors, (ii) controllable, counterfactual scenario generation, (iii) reasoning about agent cognition and mental states, and (iv) reasoning with distinct sensing modalities, such as braking due to faulty GPS signals. We demonstrate ReGen in autonomous driving and robot manipulation tasks, generating more diverse, complex simulated environments compared to existing simulations with high success rates, and enabling controllable generation for corner cases. This approach enhances the validation of robot policies and supports data or simulation augmentation, advancing scalable robot learning for improved generalization and robustness. We provide code and example videos at: https://regen-sim.github.io/",
    "fetched_at": "2025-11-11T02:19:05.033496Z"
  },
  {
    "id": "2511.04847v1",
    "title": "Grounded Test-Time Adaptation for LLM Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Arthur Chen",
      "Zuxin Liu",
      "Jianguo Zhang",
      "Akshara Prabhakar",
      "Zhiwei Liu",
      "Shelby Heinecke",
      "Silvio Savarese",
      "Victor Zhong",
      "Caiming Xiong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04847v1",
    "abstract": "Large language model (LLM)-based agents struggle to generalize to novel and complex environments, such as unseen websites or new sets of functions, due to a fundamental mismatch between their pre-training and test-time conditions. This challenge stems from two distinct failure modes: a syntactic misunderstanding of environment-specific components like observation formats, and a semantic misunderstanding of state-transition dynamics, which are only revealed at test time. To address these issues, we propose two distinct and complementary strategies for adapting LLM agents by leveraging environment-specific information available during deployment. First, an online distributional adaptation method parameterizes environmental nuances by learning a lightweight adaptation vector that biases the model's output distribution, enabling rapid alignment with an environment response format. Second, a deployment-time dynamics grounding method employs a persona-driven exploration phase to systematically probe and learn the environment's causal dynamics before task execution, equipping the agent with a nonparametric world model. We evaluate these strategies across diverse agentic benchmarks, including function calling and web navigation. Our empirical results show the effectiveness of both strategies across all benchmarks with minimal computational cost. We find that dynamics grounding is particularly effective in complex environments where unpredictable dynamics pose a major obstacle, demonstrating a robust path toward more generalizable and capable LLM-based agents. For example, on the WebArena multi-site split, this method increases the agent's success rate from 2% to 23%.",
    "fetched_at": "2025-11-11T02:19:05.033363Z"
  },
  {
    "id": "2511.03924v1",
    "title": "On Predicting Sociodemographics from Mobility Signals",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ekin Uurel",
      "Cynthia Chen",
      "Brian H. Y. Lee",
      "Filipe Rodrigues"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03924v1",
    "abstract": "Inferring sociodemographic attributes from mobility data could help transportation planners better leverage passively collected datasets, but this task remains difficult due to weak and inconsistent relationships between mobility patterns and sociodemographic traits, as well as limited generalization across contexts. We address these challenges from three angles. First, to improve predictive accuracy while retaining interpretability, we introduce a behaviorally grounded set of higher-order mobility descriptors based on directed mobility graphs. These features capture structured patterns in trip sequences, travel modes, and social co-travel, and significantly improve prediction of age, gender, income, and household structure over baselines features. Second, we introduce metrics and visual diagnostic tools that encourage evenness between model confidence and accuracy, enabling planners to quantify uncertainty. Third, to improve generalization and sample efficiency, we develop a multitask learning framework that jointly predicts multiple sociodemographic attributes from a shared representation. This approach outperforms single-task models, particularly when training data are limited or when applying models across different time periods (i.e., when the test set distribution differs from the training set).",
    "fetched_at": "2025-11-10T02:23:10.844947Z"
  },
  {
    "id": "2511.03928v1",
    "title": "SynQuE: Estimating Synthetic Dataset Quality Without Annotations",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Arthur Chen",
      "Victor Zhong"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03928v1",
    "abstract": "We introduce and formalize the Synthetic Dataset Quality Estimation (SynQuE) problem: ranking synthetic datasets by their expected real-world task performance using only limited unannotated real data. This addresses a critical and open challenge where data is scarce due to collection costs or privacy constraints. We establish the first comprehensive benchmarks for this problem by introducing and evaluating proxy metrics that choose synthetic data for training to maximize task performance on real data. We introduce the first proxy metrics for SynQuE by adapting distribution and diversity-based distance measures to our context via embedding models. To address the shortcomings of these metrics on complex planning tasks, we propose LENS, a novel proxy that leverages large language model reasoning. Our results show that SynQuE proxies correlate with real task performance across diverse tasks, including sentiment analysis, Text2SQL, web navigation, and image classification, with LENS consistently outperforming others on complex tasks by capturing nuanced characteristics. For instance, on text-to-SQL parsing, training on the top-3 synthetic datasets selected via SynQuE proxies can raise accuracy from 30.4% to 38.4 (+8.1)% on average compared to selecting data indiscriminately. This work establishes SynQuE as a practical framework for synthetic data selection under real-data scarcity and motivates future research on foundation model-based data characterization and fine-grained data selection.",
    "fetched_at": "2025-11-10T02:23:10.844840Z"
  },
  {
    "id": "2511.03929v2",
    "title": "NVIDIA Nemotron Nano V2 VL",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "NVIDIA",
      ":",
      "Amala Sanjay Deshmukh",
      "Kateryna Chumachenko",
      "Tuomas Rintamaki",
      "Matthieu Le",
      "Tyler Poon",
      "Danial Mohseni Taheri",
      "Ilia Karmanov",
      "Guilin Liu",
      "Jarno Seppanen",
      "Guo Chen",
      "Karan Sapra",
      "Zhiding Yu",
      "Adi Renduchintala",
      "Charles Wang",
      "Peter Jin",
      "Arushi Goel",
      "Mike Ranzinger",
      "Lukas Voegtle",
      "Philipp Fischer",
      "Timo Roman",
      "Wei Ping",
      "Boxin Wang",
      "Zhuolin Yang",
      "Nayeon Lee",
      "Shaokun Zhang",
      "Fuxiao Liu",
      "Zhiqi Li",
      "Di Zhang",
      "Greg Heinrich",
      "Hongxu Yin",
      "Song Han",
      "Pavlo Molchanov",
      "Parth Mannan",
      "Yao Xu",
      "Jane Polak Scowcroft",
      "Tom Balough",
      "Subhashree Radhakrishnan",
      "Paris Zhang",
      "Sean Cha",
      "Ratnesh Kumar",
      "Zaid Pervaiz Bhat",
      "Jian Zhang",
      "Darragh Hanley",
      "Pritam Biswas",
      "Jesse Oliver",
      "Kevin Vasques",
      "Roger Waleffe",
      "Duncan Riach",
      "Oluwatobi Olabiyi",
      "Ameya Sunil Mahabaleshwarkar",
      "Bilal Kartal",
      "Pritam Gundecha",
      "Khanh Nguyen",
      "Alexandre Milesi",
      "Eugene Khvedchenia",
      "Ran Zilberstein",
      "Ofri Masad",
      "Natan Bagrov",
      "Nave Assaf",
      "Tomer Asida",
      "Daniel Afrimi",
      "Amit Zuker",
      "Netanel Haber",
      "Zhiyu Cheng",
      "Jingyu Xin",
      "Di Wu",
      "Nik Spirin",
      "Maryam Moosaei",
      "Roman Ageev",
      "Vanshil Atul Shah",
      "Yuting Wu",
      "Daniel Korzekwa",
      "Unnikrishnan Kizhakkemadam Sreekumar",
      "Wanli Jiang",
      "Padmavathy Subramanian",
      "Alejandra Rico",
      "Sandip Bhaskar",
      "Saeid Motiian",
      "Kedi Wu",
      "Annie Surla",
      "Chia-Chih Chen",
      "Hayden Wolff",
      "Matthew Feinberg",
      "Melissa Corpuz",
      "Marek Wawrzos",
      "Eileen Long",
      "Aastha Jhunjhunwala",
      "Paul Hendricks",
      "Farzan Memarian",
      "Benika Hall",
      "Xin-Yu Wang",
      "David Mosallanezhad",
      "Soumye Singhal",
      "Luis Vega",
      "Katherine Cheung",
      "Krzysztof Pawelec",
      "Michael Evans",
      "Katherine Luna",
      "Jie Lou",
      "Erick Galinkin",
      "Akshay Hazare",
      "Kaustubh Purandare",
      "Ann Guan",
      "Anna Warno",
      "Chen Cui",
      "Yoshi Suhara",
      "Shibani Likhite",
      "Seph Mard",
      "Meredith Price",
      "Laya Sleiman",
      "Saori Kaji",
      "Udi Karpas",
      "Kari Briski",
      "Joey Conway",
      "Michael Lightstone",
      "Jan Kautz",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Jonathen Cohen",
      "Oleksii Kuchaiev",
      "Andrew Tao",
      "Bryan Catanzaro"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03929v2",
    "abstract": "We introduce Nemotron Nano V2 VL, the latest model of the Nemotron vision-language series designed for strong real-world document understanding, long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers significant improvements over our previous model, Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major enhancements in model architecture, datasets, and training recipes. Nemotron Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and innovative token reduction techniques to achieve higher inference throughput in long document and video scenarios. We are releasing model checkpoints in BF16, FP8, and FP4 formats and sharing large parts of our datasets, recipes and training code.",
    "fetched_at": "2025-11-10T02:23:10.844782Z"
  },
  {
    "id": "2511.03938v1",
    "title": "LogHD: Robust Compression of Hyperdimensional Classifiers via   Logarithmic Class-Axis Reduction",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sanggeon Yun",
      "Hyunwoo Oh",
      "Ryozo Masukawa",
      "Pietro Mercati",
      "Nathaniel D. Bastian",
      "Mohsen Imani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03938v1",
    "abstract": "Hyperdimensional computing (HDC) suits memory, energy, and reliability-constrained systems, yet the standard \"one prototype per class\" design requires $O(CD)$ memory (with $C$ classes and dimensionality $D$). Prior compaction reduces $D$ (feature axis), improving storage/compute but weakening robustness. We introduce LogHD, a logarithmic class-axis reduction that replaces the $C$ per-class prototypes with $n\\!\\approx\\!\\lceil\\log_k C\\rceil$ bundle hypervectors (alphabet size $k$) and decodes in an $n$-dimensional activation space, cutting memory to $O(D\\log_k C)$ while preserving $D$. LogHD uses a capacity-aware codebook and profile-based decoding, and composes with feature-axis sparsification. Across datasets and injected bit flips, LogHD attains competitive accuracy with smaller models and higher resilience at matched memory. Under equal memory, it sustains target accuracy at roughly $2.5$-$3.0\\times$ higher bit-flip rates than feature-axis compression; an ASIC instantiation delivers $498\\times$ energy efficiency and $62.6\\times$ speedup over an AMD Ryzen 9 9950X and $24.3\\times$/$6.58\\times$ over an NVIDIA RTX 4090, and is $4.06\\times$ more energy-efficient and $2.19\\times$ faster than a feature-axis HDC ASIC baseline.",
    "fetched_at": "2025-11-10T02:23:10.844289Z"
  },
  {
    "id": "2511.03939v1",
    "title": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency   Alignment Methods",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Raghav Sharma",
      "Manan Mehta",
      "Sai Tiger Raina"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03939v1",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is the standard for aligning Large Language Models (LLMs), yet recent progress has moved beyond canonical text-based methods. This survey synthesizes the new frontier of alignment research by addressing critical gaps in multi-modal alignment, cultural fairness, and low-latency optimization. To systematically explore these domains, we first review foundational algo- rithms, including PPO, DPO, and GRPO, before presenting a detailed analysis of the latest innovations. By providing a comparative synthesis of these techniques and outlining open challenges, this work serves as an essential roadmap for researchers building more robust, efficient, and equitable AI systems.",
    "fetched_at": "2025-11-10T02:23:10.844235Z"
  },
  {
    "id": "2511.03942v1",
    "title": "MIDI-LLM: Adapting Large Language Models for Text-to-MIDI Music   Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.SD",
      "SD",
      "cs.CL",
      "CL",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Shih-Lun Wu",
      "Yoon Kim",
      "Cheng-Zhi Anna Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03942v1",
    "abstract": "We present MIDI-LLM, an LLM for generating multitrack MIDI music from free-form text prompts. Our approach expands a text LLM's vocabulary to include MIDI tokens, and uses a two-stage training recipe to endow text-to-MIDI abilities. By preserving the original LLM's parameter structure, we can directly leverage the vLLM library for accelerated inference. Experiments show that MIDI-LLM achieves higher quality, better text control, and faster inference compared to the recent Text2midi model. Live demo at https://midi-llm-demo.vercel.app.",
    "fetched_at": "2025-11-10T02:23:10.844193Z"
  },
  {
    "id": "2511.03948v1",
    "title": "Extracting Causal Relations in Deep Knowledge Tracing",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "I.2.6; K.3.1",
      "1"
    ],
    "authors": [
      "Kevin Hong",
      "Kia Karbasi",
      "Gregory Pottie"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03948v1",
    "abstract": "A longstanding goal in computational educational research is to develop explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which leverages a Recurrent Neural Network (RNN) to predict student knowledge and performance on exercises, has been proposed as a major advancement over traditional KT methods. Several studies suggest that its performance gains stem from its ability to model bidirectional relationships between different knowledge components (KCs) within a course, enabling the inference of a student's understanding of one KC from their performance on others. In this paper, we challenge this prevailing explanation and demonstrate that DKT's strength lies in its implicit ability to model prerequisite relationships as a causal structure, rather than bidirectional relationships. By pruning exercise relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal subsets of the Assistments dataset, we show that DKT's predictive capabilities align strongly with these causal structures. Furthermore, we propose an alternative method for extracting exercise relation DAGs using DKT's learned representations and provide empirical evidence supporting our claim. Our findings suggest that DKT's effectiveness is largely driven by its capacity to approximate causal dependencies between KCs rather than simple relational mappings.",
    "fetched_at": "2025-11-10T02:23:10.844112Z"
  },
  {
    "id": "2511.03950v1",
    "title": "Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh   Joint Optimization",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhejia Cai",
      "Puhua Jiang",
      "Shiwei Mao",
      "Hongkun Cao",
      "Ruqi Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03950v1",
    "abstract": "Reconstructing real-world objects from multi-view images is essential for applications in 3D editing, AR/VR, and digital content creation. Existing methods typically prioritize either geometric accuracy (Multi-View Stereo) or photorealistic rendering (Novel View Synthesis), often decoupling geometry and appearance optimization, which hinders downstream editing tasks. This paper advocates an unified treatment on geometry and appearance optimization for seamless Gaussian-mesh joint optimization. More specifically, we propose a novel framework that simultaneously optimizes mesh geometry (vertex positions and faces) and vertex colors via Gaussian-guided mesh differentiable rendering, leveraging photometric consistency from input images and geometric regularization from normal and depth maps. The obtained high-quality 3D reconstruction can be further exploit in down-stream editing tasks, such as relighting and shape deformation. The code will be publicly available upon acceptance.",
    "fetched_at": "2025-11-10T02:23:10.844064Z"
  },
  {
    "id": "2511.03952v1",
    "title": "High-dimensional limit theorems for SGD: Momentum and Adaptive   Step-sizes",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aukosh Jagannath",
      "Taj Jones-McCormick",
      "Varnan Sarangian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03952v1",
    "abstract": "We develop a high-dimensional scaling limit for Stochastic Gradient Descent with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework to rigourously compare online SGD with some of its popular variants. We show that the scaling limits of SGD-M coincide with those of online SGD after an appropriate time rescaling and a specific choice of step-size. However, if the step-size is kept the same between the two algorithms, SGD-M will amplify high-dimensional effects, potentially degrading performance relative to online SGD. We demonstrate our framework on two popular learning problems: Spiked Tensor PCA and Single Index Models. In both cases, we also examine online SGD with an adaptive step-size based on normalized gradients. In the high-dimensional regime, this algorithm yields multiple benefits: its dynamics admit fixed points closer to the population minimum and widens the range of admissible step-sizes for which the iterates converge to such solutions. These examples provide a rigorous account, aligning with empirical motivation, of how early preconditioners can stabilize and improve dynamics in settings where online SGD fails.",
    "fetched_at": "2025-11-10T02:23:10.844008Z"
  },
  {
    "id": "2511.03953v1",
    "title": "Conditional Score Learning for Quickest Change Detection in Markov   Transition Kernels",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Wuxia Chen",
      "Taposh Banerjee",
      "Vahid Tarokh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03953v1",
    "abstract": "We address the problem of quickest change detection in Markov processes with unknown transition kernels. The key idea is to learn the conditional score $\\nabla_{\\mathbf{y}} \\log p(\\mathbf{y}|\\mathbf{x})$ directly from sample pairs $( \\mathbf{x},\\mathbf{y})$, where both $\\mathbf{x}$ and $\\mathbf{y}$ are high-dimensional data generated by the same transition kernel. In this way, we avoid explicit likelihood evaluation and provide a practical way to learn the transition dynamics. Based on this estimation, we develop a score-based CUSUM procedure that uses conditional Hyvarinen score differences to detect changes in the kernel. To ensure bounded increments, we propose a truncated version of the statistic. With Hoeffding's inequality for uniformly ergodic Markov processes, we prove exponential lower bounds on the mean time to false alarm. We also prove asymptotic upper bounds on detection delay. These results give both theoretical guarantees and practical feasibility for score-based detection in high-dimensional Markov models.",
    "fetched_at": "2025-11-10T02:23:10.843964Z"
  },
  {
    "id": "2511.03963v1",
    "title": "Robust inference using density-powered Stein operators",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shinto Eguchi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03963v1",
    "abstract": "We introduce a density-power weighted variant for the Stein operator, called the $\\gamma$-Stein operator. This is a novel class of operators derived from the $\\gamma$-divergence, designed to build robust inference methods for unnormalized probability models. The operator's construction (weighting by the model density raised to a positive power $\\gamma$ inherently down-weights the influence of outliers, providing a principled mechanism for robustness. Applying this operator yields a robust generalization of score matching that retains the crucial property of being independent of the model's normalizing constant. We extend this framework to develop two key applications: the $\\gamma$-kernelized Stein discrepancy for robust goodness-of-fit testing, and $\\gamma$-Stein variational gradient descent for robust Bayesian posterior approximation. Empirical results on contaminated Gaussian and quartic potential models show our methods significantly outperform standard baselines in both robustness and statistical efficiency.",
    "fetched_at": "2025-11-10T02:23:10.843862Z"
  },
  {
    "id": "2511.03966v1",
    "title": "PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in   Cognitive Diagnosis",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mingliang Hou",
      "Yinuo Wang",
      "Teng Guo",
      "Zitao Liu",
      "Wenzhou Dou",
      "Jiaqi Zheng",
      "Renqiang Luo",
      "Mi Tian",
      "Weiqi Luo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03966v1",
    "abstract": "The need to remove specific student data from cognitive diagnosis (CD) models has become a pressing requirement, driven by users' growing assertion of their \"right to be forgotten\". However, existing CD models are largely designed without privacy considerations and lack effective data unlearning mechanisms. Directly applying general purpose unlearning algorithms is suboptimal, as they struggle to balance unlearning completeness, model utility, and efficiency when confronted with the unique heterogeneous structure of CD models. To address this, our paper presents the first systematic study of the data unlearning problem for CD models, proposing a novel and efficient algorithm: hierarchical importanceguided forgetting (HIF). Our key insight is that parameter importance in CD models exhibits distinct layer wise characteristics. HIF leverages this via an innovative smoothing mechanism that combines individual and layer, level importance, enabling a more precise distinction of parameters associated with the data to be unlearned. Experiments on three real world datasets show that HIF significantly outperforms baselines on key metrics, offering the first effective solution for CD models to respond to user data removal requests and for deploying high-performance, privacy preserving AI systems",
    "fetched_at": "2025-11-10T02:23:10.843824Z"
  },
  {
    "id": "2511.03972v1",
    "title": "Non-Asymptotic Optimization and Generalization Bounds for Stochastic   Gauss-Newton in Overparameterized Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Semih Cayci"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03972v1",
    "abstract": "An important question in deep learning is how higher-order optimization methods affect generalization. In this work, we analyze a stochastic Gauss-Newton (SGN) method with Levenberg-Marquardt damping and mini-batch sampling for training overparameterized deep neural networks with smooth activations in a regression setting. Our theoretical contributions are twofold. First, we establish finite-time convergence bounds via a variable-metric analysis in parameter space, with explicit dependencies on the batch size, network width and depth. Second, we derive non-asymptotic generalization bounds for SGN using uniform stability in the overparameterized regime, characterizing the impact of curvature, batch size, and overparameterization on generalization performance. Our theoretical results identify a favorable generalization regime for SGN in which a larger minimum eigenvalue of the Gauss-Newton matrix along the optimization path yields tighter stability bounds.",
    "fetched_at": "2025-11-10T02:23:10.843747Z"
  },
  {
    "id": "2511.03976v1",
    "title": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation   Prediction",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.GN",
      "GN"
    ],
    "authors": [
      "Xu Zou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03976v1",
    "abstract": "Since its emergence, SARS-CoV-2 has demonstrated a rapid and unpredictable evolutionary trajectory, characterized by the continual emergence of immune-evasive variants. This poses persistent challenges to public health and vaccine development.   While large-scale generative pre-trained transformers (GPTs) have revolutionized the modeling of sequential data, their direct applications to noisy viral genomic sequences are limited. In this paper, we introduce PETRA(Pretrained Evolutionary TRAnsformer), a novel transformer approach based on evolutionary trajectories derived from phylogenetic trees rather than raw RNA sequences. This method effectively mitigates sequencing noise and captures the hierarchical structure of viral evolution.   With a weighted training framework to address substantial geographical and temporal imbalances in global sequence data, PETRA excels in predicting future SARS-CoV-2 mutations, achieving a weighted recall@1 of 9.45% for nucleotide mutations and 17.10\\% for spike amino-acid mutations, compared to 0.49% and 6.64% respectively for the best baseline. PETRA also demonstrates its ability to aid in the real-time mutation prediction of major clades like 24F(XEC) and 25A(LP.8.1). The code is open sourced on https://github.com/xz-keg/PETra",
    "fetched_at": "2025-11-10T02:23:10.843707Z"
  },
  {
    "id": "2511.03980v1",
    "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit   Cultural Framing",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bram Bult",
      "Ayla Rigouts Terryn"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03980v1",
    "abstract": "Large Language Models (LLMs) are rapidly being adopted by users across the globe, who interact with them in a diverse range of languages. At the same time, there are well-documented imbalances in the training data and optimisation objectives of this technology, raising doubts as to whether LLMs can represent the cultural diversity of their broad user base. In this study, we look at LLMs and cultural values and examine how prompt language and cultural framing influence model responses and their alignment with human values in different countries. We probe 10 LLMs with 63 items from the Hofstede Values Survey Module and World Values Survey, translated into 11 languages, and formulated as prompts with and without different explicit cultural perspectives. Our study confirms that both prompt language and cultural perspective produce variation in LLM outputs, but with an important caveat: While targeted prompting can, to a certain extent, steer LLM responses in the direction of the predominant values of the corresponding countries, it does not overcome the models' systematic bias toward the values associated with a restricted set of countries in our dataset: the Netherlands, Germany, the US, and Japan. All tested models, regardless of their origin, exhibit remarkably similar patterns: They produce fairly neutral responses on most topics, with selective progressive stances on issues such as social tolerance. Alignment with cultural values of human respondents is improved more with an explicit cultural perspective than with a targeted prompt language. Unexpectedly, combining both approaches is no more effective than cultural framing with an English prompt. These findings reveal that LLMs occupy an uncomfortable middle ground: They are responsive enough to changes in prompts to produce variation, but too firmly anchored to specific cultural defaults to adequately represent cultural diversity.",
    "fetched_at": "2025-11-10T02:23:10.843665Z"
  },
  {
    "id": "2511.03981v1",
    "title": "Structural Priors and Modular Adapters in the Composable Fine-Tuning   Algorithm of Large-Scale Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuxiao Wang",
      "Di Wu",
      "Feng Liu",
      "Zhimin Qiu",
      "Chenrui Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03981v1",
    "abstract": "This paper proposes a composable fine-tuning method that integrates graph structural priors with modular adapters to address the high computational cost and structural instability faced by large-scale pre-trained models in multi-task adaptation. The method introduces a relation matrix to model dependencies among tasks, explicitly encoding correlations between nodes and paths into graph structural priors, which provide unified structural constraints for adapter weight allocation and path selection. Modular adapters are embedded into different layers through low-rank mapping and a pluggable mechanism, enabling efficient cross-task composition and reuse under prior guidance. This mechanism not only improves parameter efficiency and training stability but also alleviates path conflicts and redundant computation in multi-task scenarios. Furthermore, experiments on hyperparameter sensitivity, environmental sensitivity, and data sensitivity are conducted to systematically analyze key factors such as routing temperature, gating thresholds, and relation matrix regularization strength, verifying the consistency and superior performance of the method under structural constraints. The results demonstrate that the proposed framework significantly enhances task prediction accuracy, adapter weight allocation precision, and overall computational efficiency while maintaining model lightweight design, highlighting the synergistic advantages of graph priors and modular mechanisms in composable fine-tuning.",
    "fetched_at": "2025-11-10T02:23:10.843617Z"
  },
  {
    "id": "2511.03983v1",
    "title": "TwIST: Rigging the Lottery in Transformers with Independent Subnetwork   Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Michael Menezes",
      "Barbara Su",
      "Xinze Feng",
      "Yehya Farhat",
      "Hamza Shili",
      "Anastasios Kyrillidis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03983v1",
    "abstract": "We introduce TwIST, a distributed training framework for efficient large language model (LLM) sparsification. TwIST trains multiple subnetworks in parallel, periodically aggregates their parameters, and resamples new subnetworks during training. This process identifies high-quality subnetworks (\"golden tickets\") without requiring post-training procedures such as calibration or Hessian-based recovery. As a result, TwIST enables zero-cost pruning at deployment time while achieving perplexity competitive with state-of-the-art post-training sparsification methods. The benefits are most pronounced under aggressive sparsity (e.g., 50%+), where TwIST significantly outperforms baseline methods; for example, reaching 23.14 PPL compared to 31.64 for the closest prior approach. Unlike unstructured pruning, TwIST produces structured, dense matrices that offer practical inference speedups and memory reductions on commodity hardware (e.g., CPUs) that do not support efficient sparse computation. TwIST provides an efficient training-time path to deployable sparse LLMs without additional fine-tuning or recovery overhead.",
    "fetched_at": "2025-11-10T02:23:10.843563Z"
  },
  {
    "id": "2511.03986v1",
    "title": "Use of Continuous Glucose Monitoring with Machine Learning to Identify   Metabolic Subphenotypes and Inform Precision Lifestyle Changes",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Ahmed A. Metwally",
      "Heyjun Park",
      "Yue Wu",
      "Tracey McLaughlin",
      "Michael P. Snyder"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03986v1",
    "abstract": "The classification of diabetes and prediabetes by static glucose thresholds obscures the pathophysiological dysglycemia heterogeneity, primarily driven by insulin resistance (IR), beta-cell dysfunction, and incretin deficiency. This review demonstrates that continuous glucose monitoring and wearable technologies enable a paradigm shift towards non-invasive, dynamic metabolic phenotyping. We show evidence that machine learning models can leverage high-resolution glucose data from at-home, CGM-enabled oral glucose tolerance tests to accurately predict gold-standard measures of muscle IR and beta-cell function. This personalized characterization extends to real-world nutrition, where an individual's unique postprandial glycemic response (PPGR) to standardized meals, such as the relative glucose spike to potatoes versus grapes, could serve as a biomarker for their metabolic subtype. Moreover, integrating wearable data reveals that habitual diet, sleep, and physical activity patterns, particularly their timing, are uniquely associated with specific metabolic dysfunctions, informing precision lifestyle interventions. The efficacy of dietary mitigators in attenuating PPGR is also shown to be phenotype-dependent. Collectively, this evidence demonstrates that CGM can deconstruct the complexity of early dysglycemia into distinct, actionable subphenotypes. This approach moves beyond simple glycemic control, paving the way for targeted nutritional, behavioral, and pharmacological strategies tailored to an individual's core metabolic defects, thereby paving the way for a new era of precision diabetes prevention.",
    "fetched_at": "2025-11-10T02:23:10.843443Z"
  },
  {
    "id": "2511.03993v1",
    "title": "Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible   Intelligence in Anomaly Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Berk Iskar",
      "Michael Taynnan Barros"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03993v1",
    "abstract": "Network anomaly detection systems encounter several challenges with traditional detectors trained offline. They become susceptible to concept drift and new threats such as zero-day or polymorphic attacks. To address this limitation, we propose a Ca$^{2+}$-modulated learning framework that draws inspiration from astrocytic Ca$^{2+}$ signaling in the brain, where rapid, context-sensitive adaptation enables robust information processing. Our approach couples a multicellular astrocyte dynamics simulator with a deep neural network (DNN). The simulator models astrocytic Ca$^{2+}$ dynamics through three key mechanisms: IP$_3$-mediated Ca$^{2+}$ release, SERCA pump uptake, and conductance-aware diffusion through gap junctions between cells. Evaluation of our proposed network on CTU-13 (Neris) network traffic data demonstrates the effectiveness of our biologically plausible approach. The Ca$^{2+}$-gated model outperforms a matched baseline DNN, achieving up to $\\sim$98\\% accuracy with reduced false positives and negatives across multiple train/test splits. Importantly, this improved performance comes with negligible runtime overhead once Ca$^{2+}$ trajectories are precomputed. While demonstrated here for cybersecurity applications, this Ca$^{2+}$-modulated learning framework offers a generic solution for streaming detection tasks that require rapid, biologically grounded adaptation to evolving data patterns.",
    "fetched_at": "2025-11-10T02:23:10.843387Z"
  },
  {
    "id": "2511.03995v1",
    "title": "Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shiyin Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03995v1",
    "abstract": "Software fuzzing has become a cornerstone in automated vulnerability discovery, yet existing mutation strategies often lack semantic awareness, leading to redundant test cases and slow exploration of deep program states. In this work, I present a hybrid fuzzing framework that integrates static and dynamic analysis with Large Language Model (LLM)-guided input mutation and semantic feedback. Static analysis extracts control-flow and data-flow information, which is transformed into structured prompts for the LLM to generate syntactically valid and semantically diverse inputs. During execution, I augment traditional coverage-based feedback with semantic feedback signals-derived from program state changes, exception types, and output semantics-allowing the fuzzer to prioritize inputs that trigger novel program behaviors beyond mere code coverage. I implement our approach atop AFL++, combining program instrumentation with embedding-based semantic similarity metrics to guide seed selection. Evaluation on real-world open-source targets, including libpng, tcpdump, and sqlite, demonstrates that our method achieves faster time-to-first-bug, higher semantic diversity, and a competitive number of unique bugs compared to state-of-the-art fuzzers. This work highlights the potential of combining LLM reasoning with semantic-aware feedback to accelerate and deepen vulnerability discovery.",
    "fetched_at": "2025-11-10T02:23:10.843344Z"
  },
  {
    "id": "2511.04000v1",
    "title": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via   Synthetic Model Generations",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Kyaw Hpone Myint",
      "Zhe Wu",
      "Alexandre G. R. Day",
      "Giri Iyengar"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.04000v1",
    "abstract": "Decision trees are widely used in high-stakes fields like finance and healthcare due to their interpretability. This work introduces an efficient, scalable method for generating synthetic pre-training data to enable meta-learning of decision trees. Our approach samples near-optimal decision trees synthetically, creating large-scale, realistic datasets. Using the MetaTree transformer architecture, we demonstrate that this method achieves performance comparable to pre-training on real-world data or with computationally expensive optimal decision trees. This strategy significantly reduces computational costs, enhances data generation flexibility, and paves the way for scalable and efficient meta-learning of interpretable decision tree models.",
    "fetched_at": "2025-11-10T02:23:10.843303Z"
  },
  {
    "id": "2511.04001v1",
    "title": "Accelerating scientific discovery with the common task framework",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "J. Nathan Kutz",
      "Peter Battaglia",
      "Michael Brenner",
      "Kevin Carlberg",
      "Aric Hagberg",
      "Shirley Ho",
      "Stephan Hoyer",
      "Henning Lange",
      "Hod Lipson",
      "Michael W. Mahoney",
      "Frank Noe",
      "Max Welling",
      "Laure Zanna",
      "Francis Zhu",
      "Steven L. Brunton"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04001v1",
    "abstract": "Machine learning (ML) and artificial intelligence (AI) algorithms are transforming and empowering the characterization and control of dynamic systems in the engineering, physical, and biological sciences. These emerging modeling paradigms require comparative metrics to evaluate a diverse set of scientific objectives, including forecasting, state reconstruction, generalization, and control, while also considering limited data scenarios and noisy measurements. We introduce a common task framework (CTF) for science and engineering, which features a growing collection of challenge data sets with a diverse set of practical and common objectives. The CTF is a critically enabling technology that has contributed to the rapid advance of ML/AI algorithms in traditional applications such as speech recognition, language processing, and computer vision. There is a critical need for the objective metrics of a CTF to compare the diverse algorithms being rapidly developed and deployed in practice today across science and engineering.",
    "fetched_at": "2025-11-10T02:23:10.843253Z"
  },
  {
    "id": "2511.04002v1",
    "title": "Memory- and Latency-Constrained Inference of Large Language Models via   Adaptive Split Computing",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mingyu Sung",
      "Vikas Palakonda",
      "Suhwan Im",
      "Sunghwan Moon",
      "Il-Min Kim",
      "Sangseok Yun",
      "Jae-Mo Kang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04002v1",
    "abstract": "Large language models (LLMs) have achieved near-human performance across diverse reasoning tasks, yet their deployment on resource-constrained Internet-of-Things (IoT) devices remains impractical due to massive parameter footprints and memory-intensive autoregressive decoding. While split computing offers a promising solution by partitioning model execution between edge devices and cloud servers, existing approaches fail to address the unique challenges of autoregressive inference, particularly the iterative token generation process and expanding key-value (KV) cache requirements. This work introduces the first autoregressive-aware split computing framework designed explicitly for LLM deployment on edge devices. Our approach makes three key contributions. First, we develop one-point split compression (OPSC), a mixed-precision quantization scheme that prevents out-of-memory failures by strategically partitioning models into front-end and back-end segments with different precision levels. Second, we propose a two-stage intermediate compression pipeline that combines threshold splitting (TS) and token-wise adaptive bit quantization (TAB-Q) to preserve accuracy-critical activations while dramatically reducing communication overhead. Third, we formulate a unified optimization framework that jointly selects optimal split points, quantization settings, and sequence lengths to satisfy strict memory and latency constraints. Extensive evaluations across diverse LLMs and hardware platforms demonstrate superior performance compared to state-of-the-art quantization methods, including SmoothQuant, OmniQuant, and Atom. The framework achieves a 1.49 inference speedup and significant communication overhead reduction while maintaining or improving model accuracy.",
    "fetched_at": "2025-11-10T02:23:10.843169Z"
  },
  {
    "id": "2511.04020v1",
    "title": "Abductive Inference in Retrieval-Augmented Language Models: Generating   and Validating Missing Premises",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shiyin Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04020v1",
    "abstract": "Large Language Models (LLMs) enhanced with retrieval -- commonly referred to as Retrieval-Augmented Generation (RAG) -- have demonstrated strong performance in knowledge-intensive tasks. However, RAG pipelines often fail when retrieved evidence is incomplete, leaving gaps in the reasoning process. In such cases, \\emph{abductive inference} -- the process of generating plausible missing premises to explain observations -- offers a principled approach to bridge these gaps. In this paper, we propose a framework that integrates abductive inference into retrieval-augmented LLMs. Our method detects insufficient evidence, generates candidate missing premises, and validates them through consistency and plausibility checks. Experimental results on abductive reasoning and multi-hop QA benchmarks show that our approach improves both answer accuracy and reasoning faithfulness. This work highlights abductive inference as a promising direction for enhancing the robustness and explainability of RAG systems.",
    "fetched_at": "2025-11-10T02:23:10.843104Z"
  },
  {
    "id": "2511.04035v1",
    "title": "WST: Weakly Supervised Transducer for Automatic Speech Recognition",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Dongji Gao",
      "Chenda Liao",
      "Changliang Liu",
      "Matthew Wiesner",
      "Leibny Paola Garcia",
      "Daniel Povey",
      "Sanjeev Khudanpur",
      "Jian Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04035v1",
    "abstract": "The Recurrent Neural Network-Transducer (RNN-T) is widely adopted in end-to-end (E2E) automatic speech recognition (ASR) tasks but depends heavily on large-scale, high-quality annotated data, which are often costly and difficult to obtain. To mitigate this reliance, we propose a Weakly Supervised Transducer (WST), which integrates a flexible training graph designed to robustly handle errors in the transcripts without requiring additional confidence estimation or auxiliary pre-trained models. Empirical evaluations on synthetic and industrial datasets reveal that WST effectively maintains performance even with transcription error rates of up to 70%, consistently outperforming existing Connectionist Temporal Classification (CTC)-based weakly supervised approaches, such as Bypass Temporal Classification (BTC) and Omni-Temporal Classification (OTC). These results demonstrate the practical utility and robustness of WST in realistic ASR settings. The implementation will be publicly available.",
    "fetched_at": "2025-11-10T02:23:10.843015Z"
  },
  {
    "id": "2511.04040v1",
    "title": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch   Dynamic Selection with Reconstructive Pre-Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NE",
      "NE",
      "q-bio.BM",
      "BM"
    ],
    "authors": [
      "Xiaoling Luo",
      "Peng Chen",
      "Chengliang Liu",
      "Xiaopeng Jin",
      "Jie Wen",
      "Yumeng Liu",
      "Junsong Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04040v1",
    "abstract": "Multimodal protein features play a crucial role in protein function prediction. However, these features encompass a wide range of information, ranging from structural data and sequence features to protein attributes and interaction networks, making it challenging to decipher their complex interconnections. In this work, we propose a multimodal protein function prediction method (DSRPGO) by utilizing dynamic selection and reconstructive pre-training mechanisms. To acquire complex protein information, we introduce reconstructive pre-training to mine more fine-grained information with low semantic levels. Moreover, we put forward the Bidirectional Interaction Module (BInM) to facilitate interactive learning among multimodal features. Additionally, to address the difficulty of hierarchical multi-label classification in this task, a Dynamic Selection Module (DSM) is designed to select the feature representation that is most conducive to current protein function prediction. Our proposed DSRPGO model improves significantly in BPO, MFO, and CCO on human datasets, thereby outperforming other benchmark models.",
    "fetched_at": "2025-11-10T02:23:10.842956Z"
  },
  {
    "id": "2511.04042v1",
    "title": "An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster   Search and Rescue",
    "date": "2025-11-06",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kailun Ji",
      "Xiaoyu Hu",
      "Xinyu Zhang",
      "Jun Chen"
    ],
    "institution": "School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China",
    "link": "http://arxiv.org/pdf/2511.04042v1",
    "abstract": "Large-scale disaster Search And Rescue (SAR) operations are persistently challenged by complex terrain and disrupted communications. While Unmanned Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area search and supply delivery, yet their effective coordination places a significant cognitive burden on human operators. The core human-machine collaboration bottleneck lies in the ``intention-to-action gap'', which is an error-prone process of translating a high-level rescue objective into a low-level swarm command under high intensity and pressure. To bridge this gap, this study proposes a novel LLM-CRF system that leverages Large Language Models (LLMs) to model and augment human-swarm teaming cognition. The proposed framework initially captures the operator's intention through natural and multi-modal interactions with the device via voice or graphical annotations. It then employs the LLM as a cognitive engine to perform intention comprehension, hierarchical task decomposition, and mission planning for the UAV swarm. This closed-loop framework enables the swarm to act as a proactive partner, providing active feedback in real-time while reducing the need for manual monitoring and control, which considerably advances the efficacy of the SAR task. We evaluate the proposed framework in a simulated SAR scenario. Experimental results demonstrate that, compared to traditional order and command-based interfaces, the proposed LLM-driven approach reduced task completion time by approximately $64.2\\%$ and improved task success rate by $7\\%$. It also leads to a considerable reduction in subjective cognitive workload, with NASA-TLX scores dropping by $42.9\\%$. This work establishes the potential of LLMs to create more intuitive and effective human-swarm collaborations in high-stakes scenarios.",
    "fetched_at": "2025-11-10T02:23:10.842895Z"
  },
  {
    "id": "2511.04048v1",
    "title": "Explorability in Pushdown Automata",
    "date": "2025-11-06",
    "tags": [
      "cs.FL",
      "FL",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ayaan Bedi",
      "Karoliina Lehtinen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04048v1",
    "abstract": "We study explorability, a measure of nondeterminism in pushdown automata, which generalises history-determinism. An automaton is k-explorable if, while reading the input, it suffices to follow k concurrent runs, built step-by-step based only on the input seen so far, to construct an accepting one, if it exists. We show that the class of explorable PDAs lies strictly between history-deterministic and fully nondeterministic PDAs in terms of both expressiveness and succinctness. In fact increasing explorability induces an infinite hierarchy: each level k defines a strictly more expressive class than level k-1, yet the entire class remains less expressive than general nondeterministic PDAs. We then introduce a parameterized notion of explorability, where the number of runs may depend on input length, and show that exponential explorability precisely captures the context-free languages. Finally, we prove that explorable PDAs can be doubly exponentially more succinct than history-deterministic ones, and that the succinctness gap between deterministic and 2-explorable PDAs is not recursively enumerable. These results position explorability as a robust and operationally meaningful measure of nondeterminism for pushdown systems.",
    "fetched_at": "2025-11-10T02:23:10.842856Z"
  },
  {
    "id": "2511.04053v1",
    "title": "Interpreting Multi-Attribute Confounding through Numerical Attributes in   Large Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hirohane Takagi",
      "Gouki Minegishi",
      "Shota Kizawa",
      "Issey Sukeda",
      "Hitomi Yanaka"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04053v1",
    "abstract": "Although behavioral studies have documented numerical reasoning errors in large language models (LLMs), the underlying representational mechanisms remain unclear. We hypothesize that numerical attributes occupy shared latent subspaces and investigate two questions:(1) How do LLMs internally integrate multiple numerical attributes of a single entity? (2)How does irrelevant numerical context perturb these representations and their downstream outputs? To address these questions, we combine linear probing with partial correlation analysis and prompt-based vulnerability tests across models of varying sizes. Our results show that LLMs encode real-world numerical correlations but tend to systematically amplify them. Moreover, irrelevant context induces consistent shifts in magnitude representations, with downstream effects that vary by model size. These findings reveal a vulnerability in LLM decision-making and lay the groundwork for fairer, representation-aware control under multi-attribute entanglement.",
    "fetched_at": "2025-11-10T02:23:10.842800Z"
  },
  {
    "id": "2511.04063v1",
    "title": "DartQuant: Efficient Rotational Distribution Calibration for LLM   Quantization",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yuantian Shao",
      "Yuanteng Chen",
      "Peisong Wang",
      "Jianlin Yu",
      "Jing Lin",
      "Yiwu Yao",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04063v1",
    "abstract": "Quantization plays a crucial role in accelerating the inference of large-scale models, and rotational matrices have been shown to effectively improve quantization performance by smoothing outliers. However, end-to-end fine-tuning of rotational optimization algorithms incurs high computational costs and is prone to overfitting. To address this challenge, we propose an efficient distribution-aware rotational calibration method, DartQuant, which reduces the complexity of rotational optimization by constraining the distribution of the activations after rotation. This approach also effectively reduces reliance on task-specific losses, thereby mitigating the risk of overfitting. Additionally, we introduce the QR-Orth optimization scheme, which replaces expensive alternating optimization with a more efficient solution. In a variety of model quantization experiments, DartQuant demonstrates superior performance. Compared to existing methods, it achieves 47$\\times$ acceleration and 10$\\times$ memory savings for rotational optimization on a 70B model. Furthermore, it is the first to successfully complete rotational calibration for a 70B model on a single 3090 GPU, making quantization of large language models feasible in resource-constrained environments. Code is available at https://github.com/CAS-CLab/DartQuant.git.",
    "fetched_at": "2025-11-10T02:23:10.842749Z"
  },
  {
    "id": "2511.04070v1",
    "title": "T-FIX: Text-Based Explanations with Features Interpretable to eXperts",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shreya Havaldar",
      "Helen Jin",
      "Chaehyeon Kim",
      "Anton Xue",
      "Weiqiu You",
      "Marco Gatti",
      "Bhuvnesh Jain",
      "Helen Qu",
      "Daniel A Hashimoto",
      "Amin Madani",
      "Rajat Deo",
      "Sameed Ahmed M. Khatana",
      "Gary E. Weissman",
      "Lyle Ungar",
      "Eric Wong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04070v1",
    "abstract": "As LLMs are deployed in knowledge-intensive settings (e.g., surgery, astronomy, therapy), users expect not just answers, but also meaningful explanations for those answers. In these settings, users are often domain experts (e.g., doctors, astrophysicists, psychologists) who require explanations that reflect expert-level reasoning. However, current evaluation schemes primarily emphasize plausibility or internal faithfulness of the explanation, which fail to capture whether the content of the explanation truly aligns with expert intuition. We formalize expert alignment as a criterion for evaluating explanations with T-FIX, a benchmark spanning seven knowledge-intensive domains. In collaboration with domain experts, we develop novel metrics to measure the alignment of LLM explanations with expert judgment.",
    "fetched_at": "2025-11-10T02:23:10.842685Z"
  },
  {
    "id": "2511.04069v1",
    "title": "Pediatric Appendicitis Detection from Ultrasound Images",
    "date": "2025-11-06",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04069v1",
    "abstract": "Pediatric appendicitis remains one of the most common causes of acute abdominal pain in children, and its diagnosis continues to challenge clinicians due to overlapping symptoms and variable imaging quality. This study aims to develop and evaluate a deep learning model based on a pretrained ResNet architecture for automated detection of appendicitis from ultrasound images. We used the Regensburg Pediatric Appendicitis Dataset, which includes ultrasound scans, laboratory data, and clinical scores from pediatric patients admitted with abdominal pain to Children Hospital. Hedwig in Regensburg, Germany. Each subject had 1 to 15 ultrasound views covering the right lower quadrant, appendix, lymph nodes, and related structures. For the image based classification task, ResNet was fine tuned to distinguish appendicitis from non-appendicitis cases. Images were preprocessed by normalization, resizing, and augmentation to enhance generalization. The proposed ResNet model achieved an overall accuracy of 93.44, precision of 91.53, and recall of 89.8, demonstrating strong performance in identifying appendicitis across heterogeneous ultrasound views. The model effectively learned discriminative spatial features, overcoming challenges posed by low contrast, speckle noise, and anatomical variability in pediatric imaging.",
    "fetched_at": "2025-11-10T02:23:10.842602Z"
  },
  {
    "id": "2511.04071v1",
    "title": "Left Atrial Segmentation with nnU-Net Using MRI",
    "date": "2025-11-06",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fatemeh Hosseinabadi",
      "Seyedhassan Sharifi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04071v1",
    "abstract": "Accurate segmentation of the left atrium (LA) from cardiac MRI is critical for guiding atrial fibrillation (AF) ablation and constructing biophysical cardiac models. Manual delineation is time-consuming, observer-dependent, and impractical for large-scale or time-sensitive clinical workflows. Deep learning methods, particularly convolutional architectures, have recently demonstrated superior performance in medical image segmentation tasks. In this study, we applied the nnU-Net framework, an automated, self-configuring deep learning segmentation architecture, to the Left Atrial Segmentation Challenge 2013 dataset. The dataset consists of thirty MRI scans with corresponding expert-annotated masks. The nnU-Net model automatically adapted its preprocessing, network configuration, and training pipeline to the characteristics of the MRI data. Model performance was quantitatively evaluated using the Dice similarity coefficient (DSC), and qualitative results were compared against expert segmentations. The proposed nnUNet model achieved a mean Dice score of 93.5, demonstrating high overlap with expert annotations and outperforming several traditional segmentation approaches reported in previous studies. The network exhibited robust generalization across variations in left atrial shape, contrast, and image quality, accurately delineating both the atrial body and proximal pulmonary veins.",
    "fetched_at": "2025-11-10T02:23:10.842556Z"
  },
  {
    "id": "2511.04072v1",
    "title": "Plan of Knowledge: Retrieval-Augmented Large Language Models for   Temporal Knowledge Graph Question Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xinying Qian",
      "Ying Zhang",
      "Yu Zhao",
      "Baohang Zhou",
      "Xuhui Sui",
      "Xiaojie Yuan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04072v1",
    "abstract": "Temporal Knowledge Graph Question Answering (TKGQA) aims to answer time-sensitive questions by leveraging factual information from Temporal Knowledge Graphs (TKGs). While previous studies have employed pre-trained TKG embeddings or graph neural networks to inject temporal knowledge, they fail to fully understand the complex semantic information of time constraints. Recently, Large Language Models (LLMs) have shown remarkable progress, benefiting from their strong semantic understanding and reasoning generalization capabilities. However, their temporal reasoning ability remains limited. LLMs frequently suffer from hallucination and a lack of knowledge. To address these limitations, we propose the Plan of Knowledge framework with a contrastive temporal retriever, which is named PoK. Specifically, the proposed Plan of Knowledge module decomposes a complex temporal question into a sequence of sub-objectives from the pre-defined tools, serving as intermediate guidance for reasoning exploration. In parallel, we construct a Temporal Knowledge Store (TKS) with a contrastive retrieval framework, enabling the model to selectively retrieve semantically and temporally aligned facts from TKGs. By combining structured planning with temporal knowledge retrieval, PoK effectively enhances the interpretability and factual consistency of temporal reasoning. Extensive experiments on four benchmark TKGQA datasets demonstrate that PoK significantly improves the retrieval precision and reasoning accuracy of LLMs, surpassing the performance of the state-of-the-art TKGQA methods by 56.0% at most.",
    "fetched_at": "2025-11-10T02:23:10.842513Z"
  },
  {
    "id": "2511.04073v1",
    "title": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with   Multiple Filters",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.DB",
      "DB",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Ananya Sutradhar",
      "Suryansh Gupta",
      "Ravishankar Krishnaswamy",
      "Haiyang Xu",
      "Aseem Rastogi",
      "Gopal Srinivasa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04073v1",
    "abstract": "Filtered Approximate Nearest Neighbor (ANN) search retrieves the closest vectors for a query vector from a dataset. It enforces that a specified set of discrete labels $S$ for the query must be included in the labels of each retrieved vector. Existing graph-based methods typically incorporate filter awareness by assigning fixed penalties or prioritizing nodes based on filter satisfaction. However, since these methods use fixed, data in- dependent penalties, they often fail to generalize across datasets with diverse label and vector distributions. In this work, we propose a principled alternative that learns the optimal trade-off between vector distance and filter match directly from the data, rather than relying on fixed penalties. We formulate this as a constrained linear optimization problem, deriving weights that better reflect the underlying filter distribution and more effectively address the filtered ANN search problem. These learned weights guide both the search process and index construction, leading to graph structures that more effectively capture the underlying filter distribution and filter semantics. Our experiments demonstrate that adapting the distance function to the data significantly im- proves accuracy by 5-10% over fixed-penalty methods, providing a more flexible and generalizable framework for the filtered ANN search problem.",
    "fetched_at": "2025-11-10T02:23:10.842451Z"
  },
  {
    "id": "2511.04077v1",
    "title": "The truth is no diaper: Human and AI-generated associations to emotional   words",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "pela Vintar",
      "Jan Jona Javorek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04077v1",
    "abstract": "Human word associations are a well-known method of gaining insight into the internal mental lexicon, but the responses spontaneously offered by human participants to word cues are not always predictable as they may be influenced by personal experience, emotions or individual cognitive styles. The ability to form associative links between seemingly unrelated concepts can be the driving mechanisms of creativity. We perform a comparison of the associative behaviour of humans compared to large language models. More specifically, we explore associations to emotionally loaded words and try to determine whether large language models generate associations in a similar way to humans. We find that the overlap between humans and LLMs is moderate, but also that the associations of LLMs tend to amplify the underlying emotional load of the stimulus, and that they tend to be more predictable and less creative than human ones.",
    "fetched_at": "2025-11-10T02:23:10.842339Z"
  },
  {
    "id": "2511.04079v1",
    "title": "Improving the Performance of Radiology Report De-identification with   Large-Scale Training and Benchmarking Against Cloud Vendor Methods",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Eva Prakash",
      "Maayane Attias",
      "Pierre Chambon",
      "Justin Xu",
      "Steven Truong",
      "Jean-Benoit Delbrouck",
      "Tessa Cook",
      "Curtis Langlotz"
    ],
    "institution": "Stanford",
    "link": "http://arxiv.org/pdf/2511.04079v1",
    "abstract": "Objective: To enhance automated de-identification of radiology reports by scaling transformer-based models through extensive training datasets and benchmarking performance against commercial cloud vendor systems for protected health information (PHI) detection. Materials and Methods: In this retrospective study, we built upon a state-of-the-art, transformer-based, PHI de-identification pipeline by fine-tuning on two large annotated radiology corpora from Stanford University, encompassing chest X-ray, chest CT, abdomen/pelvis CT, and brain MR reports and introducing an additional PHI category (AGE) into the architecture. Model performance was evaluated on test sets from Stanford and the University of Pennsylvania (Penn) for token-level PHI detection. We further assessed (1) the stability of synthetic PHI generation using a \"hide-in-plain-sight\" method and (2) performance against commercial systems. Precision, recall, and F1 scores were computed across all PHI categories. Results: Our model achieved overall F1 scores of 0.973 on the Penn dataset and 0.996 on the Stanford dataset, outperforming or maintaining the previous state-of-the-art model performance. Synthetic PHI evaluation showed consistent detectability (overall F1: 0.959 [0.958-0.960]) across 50 independently de-identified Penn datasets. Our model outperformed all vendor systems on synthetic Penn reports (overall F1: 0.960 vs. 0.632-0.754). Discussion: Large-scale, multimodal training improved cross-institutional generalization and robustness. Synthetic PHI generation preserved data utility while ensuring privacy. Conclusion: A transformer-based de-identification model trained on diverse radiology datasets outperforms prior academic and commercial systems in PHI detection and establishes a new benchmark for secure clinical text processing.",
    "fetched_at": "2025-11-10T02:23:10.842300Z"
  },
  {
    "id": "2511.04086v1",
    "title": "DeNoise: Learning Robust Graph Representations for Unsupervised   Graph-Level Anomaly Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qingfeng Chen",
      "Haojin Zeng",
      "Jingyi Jie",
      "Shichao Zhang",
      "Debo Cheng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04086v1",
    "abstract": "With the rapid growth of graph-structured data in critical domains, unsupervised graph-level anomaly detection (UGAD) has become a pivotal task. UGAD seeks to identify entire graphs that deviate from normal behavioral patterns. However, most Graph Neural Network (GNN) approaches implicitly assume that the training set is clean, containing only normal graphs, which is rarely true in practice. Even modest contamination by anomalous graphs can distort learned representations and sharply degrade performance. To address this challenge, we propose DeNoise, a robust UGAD framework explicitly designed for contaminated training data. It jointly optimizes a graph-level encoder, an attribute decoder, and a structure decoder via an adversarial objective to learn noise-resistant embeddings. Further, DeNoise introduces an encoder anchor-alignment denoising mechanism that fuses high-information node embeddings from normal graphs into all graph embeddings, improving representation quality while suppressing anomaly interference. A contrastive learning component then compacts normal graph embeddings and repels anomalous ones in the latent space. Extensive experiments on eight real-world datasets demonstrate that DeNoise consistently learns reliable graph-level representations under varying noise intensities and significantly outperforms state-of-the-art UGAD baselines.",
    "fetched_at": "2025-11-10T02:23:10.842233Z"
  },
  {
    "id": "2511.04090v1",
    "title": "Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for   Latin American Contexts",
    "date": "2025-11-06",
    "tags": [
      "cs.SI",
      "SI",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Brigitte A. Mora-Reyes",
      "Jennifer A. Drewyor",
      "Abel A. Reyes-Angulo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04090v1",
    "abstract": "Artificial intelligence (AI) systems often reflect biases from economically advanced regions, marginalizing contexts in economically developing regions like Latin America due to imbalanced datasets. This paper examines AI representations of diverse Latin American contexts, revealing disparities between data from economically advanced and developing regions. We highlight how the dominance of English over Spanish, Portuguese, and indigenous languages such as Quechua and Nahuatl perpetuates biases, framing Latin American perspectives through a Western lens. To address this, we introduce a culturally aware dataset rooted in Latin American history and socio-political contexts, challenging Eurocentric models. We evaluate six language models on questions testing cultural context awareness, using a novel Cultural Expressiveness metric, statistical tests, and linguistic analyses. Our findings show that some models better capture Latin American perspectives, while others exhibit significant sentiment misalignment (p < 0.001). Fine-tuning Mistral-7B with our dataset improves its cultural expressiveness by 42.9%, advancing equitable AI development. We advocate for equitable AI by prioritizing datasets that reflect Latin American history, indigenous knowledge, and diverse languages, while emphasizing community-centered approaches to amplify marginalized voices.",
    "fetched_at": "2025-11-10T02:23:10.842179Z"
  },
  {
    "id": "2511.04092v1",
    "title": "An Automated Theorem Generator with Theoretical Foundation Based on   Rectangular Standard Contradiction",
    "date": "2025-11-06",
    "tags": [
      "cs.LO",
      "LO",
      "cs.AI",
      "AI",
      "math.LO"
    ],
    "authors": [
      "Yang Xu",
      "Peiyao Liu",
      "Shuwei Chen",
      "Jun Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04092v1",
    "abstract": "Currently, there is a lack of rigorous theoretical system for systematically generating non-trivial and logically valid theorems. Addressing this critical gap, this paper conducts research to propose a novel automated theorem generation theory and tool. Based on the concept of standard contradiction which possesses unique deductive advantages, this paper defines and proves, for the first time, a new logical structure known as rectangular standard contradiction. Centered on this structure, a complete Automated Theorem Generation (ATG) theory is put forward. Theoretical proofs clarify two core properties of rectangular standard contradiction: first, it is a standard contradiction (necessarily unsatisfiable); second, it exhibits non-redundancy (the remaining clause set becomes satisfiable after removing any clause). Leveraging these properties, this paper proves that partitioning a rectangular standard contradiction into a premise subset $A$ and negation of its complement $H$, a valid theorem $A \\vdash \\neg H$ can be formed, and all such theorems are logically equivalent. To implement this theory, an efficient template-based ATG algorithm is designed, and a Rectangular Automated Theorem Generator is developed. This research enables machines to transition from \"verifiers\" to \"discoverers\", opening up new avenues for fundamental research in the fields of logic and artificial intelligence.",
    "fetched_at": "2025-11-10T02:23:10.842132Z"
  },
  {
    "id": "2511.04093v1",
    "title": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question   Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuanning Cui",
      "Zequn Sun",
      "Wei Hu",
      "Zhangjie Fu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04093v1",
    "abstract": "Large language models (LLMs) excel at reasoning but struggle with knowledge-intensive questions due to limited context and parametric knowledge. However, existing methods that rely on finetuned LLMs or GNN retrievers are limited by dataset-specific tuning and scalability on large or unseen graphs. We propose the LLM-KGFR collaborative framework, where an LLM works with a structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR encodes relations using LLM-generated descriptions and initializes entities based on their roles in the question, enabling zero-shot generalization to unseen KGs. To handle large graphs efficiently, it employs Asymmetric Progressive Propagation (APP)- a stepwise expansion that selectively limits high-degree nodes while retaining informative paths. Through node-, edge-, and path-level interfaces, the LLM iteratively requests candidate answers, supporting facts, and reasoning paths, forming a controllable reasoning loop. Experiments demonstrate that LLM-KGFR achieves strong performance while maintaining scalability and generalization, providing a practical solution for KG-augmented reasoning.",
    "fetched_at": "2025-11-10T02:23:10.842081Z"
  },
  {
    "id": "2511.04094v1",
    "title": "KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and   Governance in Korea",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hyungjong Na",
      "Wonho Song",
      "Seungyong Han",
      "Donghyeon Jo",
      "Sejin Myung",
      "Hyungjoon Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04094v1",
    "abstract": "This study introduces the Korean Tax Avoidance Panel (KoTaP), a long-term panel dataset of non-financial firms listed on KOSPI and KOSDAQ between 2011 and 2024. After excluding financial firms, firms with non-December fiscal year ends, capital impairment, and negative pre-tax income, the final dataset consists of 12,653 firm-year observations from 1,754 firms. KoTaP is designed to treat corporate tax avoidance as a predictor variable and link it to multiple domains, including earnings management (accrual- and activity-based), profitability (ROA, ROE, CFO, LOSS), stability (LEV, CUR, SIZE, PPE, AGE, INVREC), growth (GRW, MB, TQ), and governance (BIG4, FORN, OWN). Tax avoidance itself is measured using complementary indicators cash effective tax rate (CETR), GAAP effective tax rate (GETR), and book-tax difference measures (TSTA, TSDA) with adjustments to ensure interpretability. A key strength of KoTaP is its balanced panel structure with standardized variables and its consistency with international literature on the distribution and correlation of core indicators. At the same time, it reflects distinctive institutional features of Korean firms, such as concentrated ownership, high foreign shareholding, and elevated liquidity ratios, providing both international comparability and contextual uniqueness. KoTaP enables applications in benchmarking econometric and deep learning models, external validity checks, and explainable AI analyses. It further supports policy evaluation, audit planning, and investment analysis, making it a critical open resource for accounting, finance, and interdisciplinary research.",
    "fetched_at": "2025-11-10T02:23:10.842033Z"
  },
  {
    "id": "2511.04103v1",
    "title": "A Characterization of List Language Identification in the Limit",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Moses Charikar",
      "Chirag Pabbaraju",
      "Ambuj Tewari"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04103v1",
    "abstract": "We study the problem of language identification in the limit, where given a sequence of examples from a target language, the goal of the learner is to output a sequence of guesses for the target language such that all the guesses beyond some finite time are correct. Classical results of Gold showed that language identification in the limit is impossible for essentially any interesting collection of languages. Later, Angluin gave a precise characterization of language collections for which this task is possible. Motivated by recent positive results for the related problem of language generation, we revisit the classic language identification problem in the setting where the learner is given the additional power of producing a list of $k$ guesses at each time step. The goal is to ensure that beyond some finite time, one of the guesses is correct at each time step.   We give an exact characterization of collections of languages that can be $k$-list identified in the limit, based on a recursive version of Angluin's characterization (for language identification with a list of size $1$). This further leads to a conceptually appealing characterization: A language collection can be $k$-list identified in the limit if and only if the collection can be decomposed into $k$ collections of languages, each of which can be identified in the limit (with a list of size $1$). We also use our characterization to establish rates for list identification in the statistical setting where the input is drawn as an i.i.d. stream from a distribution supported on some language in the collection. Our results show that if a collection is $k$-list identifiable in the limit, then the collection can be $k$-list identified at an exponential rate, and this is best possible. On the other hand, if a collection is not $k$-list identifiable in the limit, then it cannot be $k$-list identified at any rate that goes to zero.",
    "fetched_at": "2025-11-10T02:23:10.841968Z"
  },
  {
    "id": "2511.04106v1",
    "title": "Sub-exponential Growth in Online Word Usage: A Piecewise Power-Law Model",
    "date": "2025-11-06",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Hayafumi Watanabe"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04106v1",
    "abstract": "The diffusion of ideas and language in society has conventionally been described by S-shaped models, such as the logistic curve. However, the role of sub-exponential growth -a slower than exponential pattern known in epidemiology- has been largely overlooked in broader social phenomena. Here, we present a piecewise power-law model to characterize complex growth curves with a few parameters. We systematically analyzed a large-scale dataset of approximately one billion Japanese blog articles linked to Wikipedia vocabulary, and observed consistent patterns in web search trend data (English, Spanish, and Japanese). Our analysis of the 2,965 selected items reveals that about 55% (1,625 items) were found to have no abrupt jumps and were well captured by one or two segments. For single-segment curves, we found that (i) the mode of the shape parameter alpha was near 0.5, indicating prevalent sub-exponential growth; (ii) the ultimate diffusion scale is primarily determined by the growth rate R, with minor contributions from alpha or the duration T; and (iii) alpha showed a tendency to vary with the nature of the topic, being smaller for niche/local topics and larger for widely shared ones. Furthermore, a micro-behavioral model distinguishing outward contact with strangers from inward interaction within their community suggests that alpha can be interpreted as an index of the preference for outward-oriented communication. These findings suggest that sub-exponential growth is a common pattern of social diffusion, and our model provides a practical framework for consistently describing, comparing, and interpreting complex and diverse growth curves.",
    "fetched_at": "2025-11-10T02:23:10.841916Z"
  },
  {
    "id": "2511.04108v1",
    "title": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How   Batch Prompting Suppresses Overthinking in Reasoning Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Wenmo Qiu",
      "Saurabh Srivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04108v1",
    "abstract": "Recent work has explored batch prompting as a strategy to amortize inference cost in large language models (LLMs). In this paper, we show that batching offers an additional, underappreciated benefit: it regularizes model behavior during multi-step reasoning for Large Reasoning Models (LRMs). We conduct a comprehensive study across 13 diverse benchmarks and observe that batching improves accuracy while substantially reducing reasoning token usage, often by 3x-5x. Through detailed behavioral analysis, we find that batching suppresses overthinking, reduces hedging language (e.g., repetitive self-corrections), and encourages more decisive answers. Surprisingly, we also observe emergent collective effects in batched inference: models often generalize patterns from earlier examples to solve harder ones in the same batch. These findings position batching not just as a throughput optimization, but as a powerful inference-time regularizer for more efficient and reliable LLM reasoning.",
    "fetched_at": "2025-11-10T02:23:10.841871Z"
  },
  {
    "id": "2511.04114v1",
    "title": "Automated and Explainable Denial of Service Analysis for AI-Driven   Intrusion Detection Systems",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Paul Badu Yakubu",
      "Lesther Santana",
      "Mohamed Rahouti",
      "Yufeng Xin",
      "Abdellah Chehri",
      "Mohammed Aledhari"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04114v1",
    "abstract": "With the increasing frequency and sophistication of Distributed Denial of Service (DDoS) attacks, it has become critical to develop more efficient and interpretable detection methods. Traditional detection systems often struggle with scalability and transparency, hindering real-time response and understanding of attack vectors. This paper presents an automated framework for detecting and interpreting DDoS attacks using machine learning (ML). The proposed method leverages the Tree-based Pipeline Optimization Tool (TPOT) to automate the selection and optimization of ML models and features, reducing the need for manual experimentation. SHapley Additive exPlanations (SHAP) is incorporated to enhance model interpretability, providing detailed insights into the contribution of individual features to the detection process. By combining TPOT's automated pipeline selection with SHAP interpretability, this approach improves the accuracy and transparency of DDoS detection. Experimental results demonstrate that key features such as mean backward packet length and minimum forward packet header length are critical in detecting DDoS attacks, offering a scalable and explainable cybersecurity solution.",
    "fetched_at": "2025-11-10T02:23:10.841828Z"
  },
  {
    "id": "2511.04120v1",
    "title": "RIDE: Difficulty Evolving Perturbation with Item Response Theory for   Mathematical Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xinyuan Li",
      "Murong Xu",
      "Wenbiao Tao",
      "Hanlun Zhu",
      "Yike Zhao",
      "Jipeng Zhang",
      "Yunshi Lan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04120v1",
    "abstract": "Large language models (LLMs) achieve high performance on mathematical reasoning, but these results can be inflated by training data leakage or superficial pattern matching rather than genuine reasoning. To this end, an adversarial perturbation-based evaluation is needed to measure true mathematical reasoning ability. Current rule-based perturbation methods often generate ill-posed questions and impede the systematic evaluation of question difficulty and the evolution of benchmarks. To bridge this gap, we propose RIDE, a novel adversarial question-rewriting framework that leverages Item Response Theory (IRT) to rigorously measure question difficulty and to generate intrinsically more challenging, well-posed variations of mathematical problems. We employ 35 LLMs to simulate students and build a difficulty ranker from their responses. This ranker provides a reward signal during reinforcement learning and guides a question-rewriting model to reformulate existing questions across difficulty levels. Applying RIDE to competition-level mathematical benchmarks yields perturbed versions that degrade advanced LLM performance, with experiments showing an average 21.73% drop across 26 models, thereby exposing limited robustness in mathematical reasoning and confirming the validity of our evaluation approach.",
    "fetched_at": "2025-11-10T02:23:10.841755Z"
  },
  {
    "id": "2511.04124v1",
    "title": "Decomposable Neuro Symbolic Regression",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Giorgio Morales",
      "John W. Sheppard"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04124v1",
    "abstract": "Symbolic regression (SR) models complex systems by discovering mathematical expressions that capture underlying relationships in observed data. However, most SR methods prioritize minimizing prediction error over identifying the governing equations, often producing overly complex or inaccurate expressions. To address this, we present a decomposable SR method that generates interpretable multivariate expressions leveraging transformer models, genetic algorithms (GAs), and genetic programming (GP). In particular, our explainable SR method distills a trained ``opaque'' regression model into mathematical expressions that serve as explanations of its computed function. Our method employs a Multi-Set Transformer to generate multiple univariate symbolic skeletons that characterize how each variable influences the opaque model's response. We then evaluate the generated skeletons' performance using a GA-based approach to select a subset of high-quality candidates before incrementally merging them via a GP-based cascade procedure that preserves their original skeleton structure. The final multivariate skeletons undergo coefficient optimization via a GA. We evaluated our method on problems with controlled and varying degrees of noise, demonstrating lower or comparable interpolation and extrapolation errors compared to two GP-based methods, three neural SR methods, and a hybrid approach. Unlike them, our approach consistently learned expressions that matched the original mathematical structure.",
    "fetched_at": "2025-11-10T02:23:10.841696Z"
  },
  {
    "id": "2511.04126v1",
    "title": "Automated Tennis Player and Ball Tracking with Court Keypoints Detection   (Hawk Eye System)",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Venkata Manikanta Desu",
      "Syed Fawaz Ali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04126v1",
    "abstract": "This study presents a complete pipeline for automated tennis match analysis. Our framework integrates multiple deep learning models to detect and track players and the tennis ball in real time, while also identifying court keypoints for spatial reference. Using YOLOv8 for player detection, a custom-trained YOLOv5 model for ball tracking, and a ResNet50-based architecture for court keypoint detection, our system provides detailed analytics including player movement patterns, ball speed, shot accuracy, and player reaction times. The experimental results demonstrate robust performance in varying court conditions and match scenarios. The model outputs an annotated video along with detailed performance metrics, enabling coaches, broadcasters, and players to gain actionable insights into the dynamics of the game.",
    "fetched_at": "2025-11-10T02:23:10.841653Z"
  },
  {
    "id": "2511.04128v1",
    "title": "DMSORT: An efficient parallel maritime multi-object tracking   architecture for unmanned vessel platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shengyu Tang",
      "Zeyuan Lu",
      "Jiazhi Dong",
      "Changdong Yu",
      "Xiaoyu Wang",
      "Yaohui Lyu",
      "Weihao Xia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04128v1",
    "abstract": "Accurate perception of the marine environment through robust multi-object tracking (MOT) is essential for ensuring safe vessel navigation and effective maritime surveillance. However, the complicated maritime environment often causes camera motion and subsequent visual degradation, posing significant challenges to MOT. To address this challenge, we propose an efficient Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the framework is a parallel tracker with affine compensation, which incorporates an object detection and re-identification (ReID) branch, along with a dedicated branch for dynamic camera motion estimation. Specifically, a Reversible Columnar Detection Network (RCDN) is integrated into the detection module to leverage multi-level visual features for robust object detection. Furthermore, a lightweight Transformer-based appearance extractor (Li-TAE) is designed to capture global contextual information and generate robust appearance features. Another branch decouples platform-induced and target-intrinsic motion by constructing a projective transformation, applying platform-motion compensation within the Kalman filter, and thereby stabilizing true object trajectories. Finally, a clustering-optimized feature fusion module effectively combines motion and appearance cues to ensure identity consistency under noise, occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT attains the fastest runtime among existing ReID-based MOT frameworks while maintaining high identity consistency and robustness to jitter and occlusion. Code is available at: https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.",
    "fetched_at": "2025-11-10T02:23:10.841614Z"
  },
  {
    "id": "2511.04132v1",
    "title": "Exploring the Feasibility of End-to-End Large Language Model as a   Compiler",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hongbin Zhang",
      "Shihao Gao",
      "Yang Liu",
      "Mingjie Xing",
      "Yanjun Wu",
      "Chen Zhao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04132v1",
    "abstract": "In recent years, end-to-end Large Language Model (LLM) technology has shown substantial advantages across various domains. As critical system software and infrastructure, compilers are responsible for transforming source code into target code. While LLMs have been leveraged to assist in compiler development and maintenance, their potential as an end-to-end compiler remains largely unexplored. This paper explores the feasibility of LLM as a Compiler (LaaC) and its future directions. We designed the CompilerEval dataset and framework specifically to evaluate the capabilities of mainstream LLMs in source code comprehension and assembly code generation. In the evaluation, we analyzed various errors, explored multiple methods to improve LLM-generated code, and evaluated cross-platform compilation capabilities. Experimental results demonstrate that LLMs exhibit basic capabilities as compilers but currently achieve low compilation success rates. By optimizing prompts, scaling up the model, and incorporating reasoning methods, the quality of assembly code generated by LLMs can be significantly enhanced. Based on these findings, we maintain an optimistic outlook for LaaC and propose practical architectural designs and future research directions. We believe that with targeted training, knowledge-rich prompts, and specialized infrastructure, LaaC has the potential to generate high-quality assembly code and drive a paradigm shift in the field of compilation.",
    "fetched_at": "2025-11-10T02:23:10.841546Z"
  },
  {
    "id": "2511.04137v1",
    "title": "Learning from Online Videos at Inference Time for Computer-Use Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yujian Liu",
      "Ze Wang",
      "Hao Chen",
      "Ximeng Sun",
      "Xiaodong Yu",
      "Jialian Wu",
      "Jiang Liu",
      "Emad Barsoum",
      "Zicheng Liu",
      "Shiyu Chang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04137v1",
    "abstract": "Computer-use agents can operate computers and automate laborious tasks, but despite recent rapid progress, they still lag behind human users, especially when tasks require domain-specific procedural knowledge about particular applications, platforms, and multi-step workflows. Humans can bridge this gap by watching video tutorials: we search, skim, and selectively imitate short segments that match our current subgoal. In this paper, we study how to enable computer-use agents to learn from online videos at inference time effectively. We propose a framework that retrieves and filters tutorial videos, converts them into structured demonstration trajectories, and dynamically selects trajectories as in-context guidance during execution. Particularly, using a VLM, we infer UI actions, segment videos into short subsequences of actions, and assign each subsequence a textual objective. At inference time, a two-stage selection mechanism dynamically chooses a single trajectory to add in context at each step, focusing the agent on the most helpful local guidance for its next decision. Experiments on two widely used benchmarks show that our framework consistently outperforms strong base agents and variants that use only textual tutorials or transcripts. Analyses highlight the importance of trajectory segmentation and selection, action filtering, and visual information, suggesting that abundant online videos can be systematically distilled into actionable guidance that improves computer-use agents at inference time. Our code is available at https://github.com/UCSB-NLP-Chang/video_demo.",
    "fetched_at": "2025-11-10T02:23:10.841432Z"
  },
  {
    "id": "2511.04139v1",
    "title": "CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource   Cantonese",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Dazhong Chen",
      "Yi-Cheng Lin",
      "Yuchen Huang",
      "Ziwei Gong",
      "Di Jiang",
      "Zeying Xie",
      "Yi R.",
      "Fung"
    ],
    "institution": "May",
    "link": "http://arxiv.org/pdf/2511.04139v1",
    "abstract": "Automatic speech recognition (ASR) is critical for language accessibility, yet low-resource Cantonese remains challenging due to limited annotated data, six lexical tones, tone sandhi, and accent variation. Existing ASR models, such as Whisper, often suffer from high word error rates. Large audio-language models (LALMs), in contrast, can leverage broader contextual reasoning but still require explicit tonal and prosodic acoustic cues. We introduce CantoASR, a collaborative ASR-LALM error correction framework that integrates forced alignment for acoustic feature extraction, a LoRA-finetuned Whisper for improved tone discrimination, and an instruction-tuned Qwen-Audio for prosody-aware correction. Evaluations on spontaneous Cantonese data show substantial CER gains over Whisper-Large-V3. These findings suggest that integrating acoustic cues with LALM reasoning provides a scalable strategy for low-resource tonal and dialectal ASR.",
    "fetched_at": "2025-11-10T02:23:10.841354Z"
  },
  {
    "id": "2511.04144v1",
    "title": "Scaffolding Metacognition in Programming Education: Understanding   Student-AI Interactions and Design Implications",
    "date": "2025-11-06",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Boxuan Ma",
      "Huiyong Li",
      "Gen Li",
      "Li Chen",
      "Cheng Tang",
      "Yinjie Xie",
      "Chenghao Gu",
      "Atsushi Shimada",
      "Shin'ichi Konomi"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04144v1",
    "abstract": "Generative AI tools such as ChatGPT now provide novice programmers with unprecedented access to instant, personalized support. While this holds clear promise, their influence on students' metacognitive processes remains underexplored. Existing work has largely focused on correctness and usability, with limited attention to whether and how students' use of AI assistants supports or bypasses key metacognitive processes. This study addresses that gap by analyzing student-AI interactions through a metacognitive lens in university-level programming courses. We examined more than 10,000 dialogue logs collected over three years, complemented by surveys of students and educators. Our analysis focused on how prompts and responses aligned with metacognitive phases and strategies. Synthesizing these findings across data sources, we distill design considerations for AI-powered coding assistants that aim to support rather than supplant metacognitive engagement. Our findings provide guidance for developing educational AI tools that strengthen students' learning processes in programming education.",
    "fetched_at": "2025-11-10T02:23:10.841301Z"
  },
  {
    "id": "2511.04147v1",
    "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe   Reinforcement Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jiaming Zhang",
      "Yujie Yang",
      "Haoning Wang",
      "Liping Zhang",
      "Shengbo Eben Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04147v1",
    "abstract": "Safe reinforcement learning (safe RL) aims to respect safety requirements while optimizing long-term performance. In many practical applications, however, the problem involves an infinite number of constraints, known as semi-infinite safe RL (SI-safe RL). Such constraints typically appear when safety conditions must be enforced across an entire continuous parameter space, such as ensuring adequate resource distribution at every spatial location. In this paper, we propose exchange policy optimization (EPO), an algorithmic framework that achieves optimal policy performance and deterministic bounded safety. EPO works by iteratively solving safe RL subproblems with finite constraint sets and adaptively adjusting the active set through constraint expansion and deletion. At each iteration, constraints with violations exceeding the predefined tolerance are added to refine the policy, while those with zero Lagrange multipliers are removed after the policy update. This exchange rule prevents uncontrolled growth of the working set and supports effective policy training. Our theoretical analysis demonstrates that, under mild assumptions, strategies trained via EPO achieve performance comparable to optimal solutions with global constraint violations strictly remaining within a prescribed bound.",
    "fetched_at": "2025-11-10T02:23:10.841235Z"
  },
  {
    "id": "2511.04155v1",
    "title": "Learning to Land Anywhere: Transferable Generative Models for Aircraft   Trajectories",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "I.2.6; I.5.1",
      "1"
    ],
    "authors": [
      "Olav Finne Praesteng Larsen",
      "Massimiliano Ruocco",
      "Michail Spitieris",
      "Abdulmajid Murad",
      "Martina Ragosta"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04155v1",
    "abstract": "Access to trajectory data is a key requirement for developing and validating Air Traffic Management (ATM) solutions, yet many secondary and regional airports face severe data scarcity. This limits the applicability of machine learning methods and the ability to perform large-scale simulations or \"what-if\" analyses. In this paper, we investigate whether generative models trained on data-rich airports can be efficiently adapted to data-scarce airports using transfer learning. We adapt state-of-the-art diffusion- and flow-matching-based architectures to the aviation domain and evaluate their transferability between Zurich (source) and Dublin (target) landing trajectory datasets. Models are pretrained on Zurich and fine-tuned on Dublin with varying amounts of local data, ranging from 0% to 100%. Results show that diffusion-based models achieve competitive performance with as little as 5% of the Dublin data and reach baseline-level performance around 20%, consistently outperforming models trained from scratch across metrics and visual inspections. Latent flow matching and latent diffusion models also benefit from pretraining, though with more variable gains, while flow matching models show weaker generalization. Despite challenges in capturing rare trajectory patterns, these findings demonstrate the potential of transfer learning to substantially reduce data requirements for trajectory generation in ATM, enabling realistic synthetic data generation even in environments with limited historical records.",
    "fetched_at": "2025-11-10T02:23:10.841118Z"
  },
  {
    "id": "2511.04157v1",
    "title": "Are We Aligned? A Preliminary Investigation of the Alignment of   Responsible AI Values between LLMs and Human Judgment",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Asma Yamani",
      "Malak Baslyman",
      "Moataz Ahmed"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04157v1",
    "abstract": "Large Language Models (LLMs) are increasingly employed in software engineering tasks such as requirements elicitation, design, and evaluation, raising critical questions regarding their alignment with human judgments on responsible AI values. This study investigates how closely LLMs' value preferences align with those of two human groups: a US-representative sample and AI practitioners. We evaluate 23 LLMs across four tasks: (T1) selecting key responsible AI values, (T2) rating their importance in specific contexts, (T3) resolving trade-offs between competing values, and (T4) prioritizing software requirements that embody those values. The results show that LLMs generally align more closely with AI practitioners than with the US-representative sample, emphasizing fairness, privacy, transparency, safety, and accountability. However, inconsistencies appear between the values that LLMs claim to uphold (Tasks 1-3) and the way they prioritize requirements (Task 4), revealing gaps in faithfulness between stated and applied behavior. These findings highlight the practical risk of relying on LLMs in requirements engineering without human oversight and motivate the need for systematic approaches to benchmark, interpret, and monitor value alignment in AI-assisted software development.",
    "fetched_at": "2025-11-10T02:23:10.841063Z"
  },
  {
    "id": "2511.04158v1",
    "title": "Deep Learning Approach for Clinical Risk Identification Using   Transformer Modeling of Heterogeneous EHR Data",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anzhuo Xie",
      "Wei-Chen Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04158v1",
    "abstract": "This study proposes a Transformer-based longitudinal modeling method to address challenges in clinical risk classification with heterogeneous Electronic Health Record (EHR) data, including irregular temporal patterns, large modality differences, and complex semantic structures. The method takes multi-source medical features as input and employs a feature embedding layer to achieve a unified representation of structured and unstructured data. A learnable temporal encoding mechanism is introduced to capture dynamic evolution under uneven sampling intervals. The core model adopts a multi-head self-attention structure to perform global dependency modeling on longitudinal sequences, enabling the aggregation of long-term trends and short-term fluctuations across different temporal scales. To enhance semantic representation, a semantic-weighted pooling module is designed to assign adaptive importance to key medical events, improving the discriminative ability of risk-related features. Finally, a linear mapping layer generates individual-level risk scores. Experimental results show that the proposed model outperforms traditional machine learning and temporal deep learning models in accuracy, recall, precision, and F1-Score, achieving stable and precise risk identification in multi-source heterogeneous EHR environments and providing an efficient and reliable framework for clinical intelligent decision-making.",
    "fetched_at": "2025-11-10T02:23:10.841017Z"
  },
  {
    "id": "2511.04160v2",
    "title": "On Joint Regularization and Calibration in Deep Ensembles",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Laurits Fredsgaard",
      "Mikkel N. Schmidt"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04160v2",
    "abstract": "Deep ensembles are a powerful tool in machine learning, improving both model performance and uncertainty calibration. While ensembles are typically formed by training and tuning models individually, evidence suggests that jointly tuning the ensemble can lead to better performance. This paper investigates the impact of jointly tuning weight decay, temperature scaling, and early stopping on both predictive performance and uncertainty quantification. Additionally, we propose a partially overlapping holdout strategy as a practical compromise between enabling joint evaluation and maximizing the use of data for training. Our results demonstrate that jointly tuning the ensemble generally matches or improves performance, with significant variation in effect size across different tasks and metrics. We highlight the trade-offs between individual and joint optimization in deep ensemble training, with the overlapping holdout strategy offering an attractive practical solution. We believe our findings provide valuable insights and guidance for practitioners looking to optimize deep ensemble models. Code is available at: https://github.com/lauritsf/ensemble-optimality-gap",
    "fetched_at": "2025-11-10T02:23:10.840971Z"
  },
  {
    "id": "2511.04161v1",
    "title": "Seeing Straight: Document Orientation Detection for Efficient OCR",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Suranjan Goswami",
      "Abhinav Ravi",
      "Raja Kolla",
      "Ali Faraz",
      "Shaharukh Khan",
      "Akash",
      "Chandra Khatri",
      "Shubham Agarwal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04161v1",
    "abstract": "Despite significant advances in document understanding, determining the correct orientation of scanned or photographed documents remains a critical pre-processing step in the real world settings. Accurate rotation correction is essential for enhancing the performance of downstream tasks such as Optical Character Recognition (OCR) where misalignment commonly arises due to user errors, particularly incorrect base orientations of the camera during capture. In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from rotation-transformed structured and free-form English OCR datasets, and (ii) ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource languages. We also present a fast, robust and lightweight rotation classification pipeline built on the vision encoder of Phi-3.5-Vision model with dynamic image cropping, fine-tuned specifically for 4-class rotation task in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy on identifying the rotations respectively on both the datasets. Beyond classification, we demonstrate the critical role of our module in boosting OCR performance: closed-source (up to 14%) and open-weights models (up to 4x) in the simulated real-world setting.",
    "fetched_at": "2025-11-10T02:23:10.840930Z"
  },
  {
    "id": "2511.04162v1",
    "title": "ScaleDL: Towards Scalable and Efficient Runtime Prediction for   Distributed Deep Learning Workloads",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiaokai Wang",
      "Shaoyuan Huang",
      "Yuting Li",
      "Xiaofei Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04162v1",
    "abstract": "Deep neural networks (DNNs) form the cornerstone of modern AI services, supporting a wide range of applications, including autonomous driving, chatbots, and recommendation systems. As models increase in size and complexity, DNN workloads like training and inference tasks impose unprecedented demands on distributed computing resources, making the accurate prediction of runtime essential for optimizing development and resource allocation. Traditional methods rely on additive computational unit models, limiting their accuracy and generalizability. In contrast, graph-enhanced modeling improves performance but significantly increases data collection costs. Therefore, there is a critical need for a method that strikes a balance between accuracy, generalizability, and the costs of data collection. To address these challenges, we propose ScaleDL, a novel runtime prediction framework that combines nonlinear layer-wise modeling with graph neural network (GNN)-based cross-layer interaction mechanism, enabling accurate DNN runtime prediction and hierarchical generalizability across different network architectures. Additionally, we employ the D-optimal method to reduce data collection costs. Experiments on the workloads of five popular DNN models prove that ScaleDL enhances runtime prediction accuracy and generalizability, achieving 6$\\times$ lower MRE and 5$\\times$ lower RMSE compared to baseline models.",
    "fetched_at": "2025-11-10T02:23:10.840867Z"
  },
  {
    "id": "2511.04171v1",
    "title": "Systematic Evaluation of Preprocessing Techniques for Accurate Image   Registration in Digital Pathology",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fatemehzahra Darzi",
      "Rodrigo Escobar Diaz Guerrero",
      "Thomas Bocklitz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04171v1",
    "abstract": "Image registration refers to the process of spatially aligning two or more images by mapping them into a common coordinate system, so that corresponding anatomical or tissue structures are matched across images. In digital pathology, registration enables direct comparison and integration of information from different stains or imaging modalities, sup-porting applications such as biomarker analysis and tissue reconstruction. Accurate registration of images from different modalities is an essential step in digital pathology. In this study, we investigated how various color transformation techniques affect image registration between hematoxylin and eosin (H&E) stained images and non-linear multimodal images. We used a dataset of 20 tissue sample pairs, with each pair undergoing several preprocessing steps, including different color transformation (CycleGAN, Macenko, Reinhard, Vahadane), inversion, contrast adjustment, intensity normalization, and denoising. All images were registered using the VALIS registration method, which first applies rigid registration and then performs non-rigid registration in two steps on both low and high-resolution images. Registration performance was evaluated using the relative Target Registration Error (rTRE). We reported the median of median rTRE values (MMrTRE) and the average of median rTRE values (AMrTRE) for each method. In addition, we performed a custom point-based evaluation using ten manually selected key points. Registration was done separately for two scenarios, using either the original or inverted multimodal images. In both scenarios, CycleGAN color transformation achieved the lowest registration errors, while the other methods showed higher errors. These findings show that applying color transformation before registration improves alignment between images from different modalities and supports more reliable analysis in digital pathology.",
    "fetched_at": "2025-11-10T02:23:10.840816Z"
  },
  {
    "id": "2511.04172v1",
    "title": "Transforming Mentorship: An AI Powered Chatbot Approach to University   Guidance",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mashrur Rahman",
      "Mantaqa abedin",
      "Monowar Zamil Abir",
      "Faizul Islam Ansari",
      "Adib Reza",
      "Farig Yousuf Sadeque",
      "Niloy Farhan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04172v1",
    "abstract": "University students face immense challenges during their undergraduate lives, often being deprived of personalized on-demand guidance that mentors fail to provide at scale. Digital tools exist, but there is a serious lack of customized coaching for newcomers. This paper presents an AI-powered chatbot that will serve as a mentor for the students of BRAC University. The main component is a data ingestion pipeline that efficiently processes and updates information from diverse sources, such as CSV files and university webpages. The chatbot retrieves information through a hybrid approach, combining BM25 lexical ranking with ChromaDB semantic retrieval, and uses a Large Language Model, LLaMA-3.3-70B, to generate conversational responses. The generated text was found to be semantically highly relevant, with a BERTScore of 0.831 and a METEOR score of 0.809. The data pipeline was also very efficient, taking 106.82 seconds for updates, compared to 368.62 seconds for new data. This chatbot will be able to help students by responding to their queries, helping them to get a better understanding of university life, and assisting them to plan better routines for their semester in the open-credit university.",
    "fetched_at": "2025-11-10T02:23:10.840752Z"
  },
  {
    "id": "2511.04177v1",
    "title": "When Empowerment Disempowers",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Claire Yang",
      "Maya Cakmak",
      "Max Kleiman-Weiner"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04177v1",
    "abstract": "Empowerment, a measure of an agent's ability to control its environment, has been proposed as a universal goal-agnostic objective for motivating assistive behavior in AI agents. While multi-human settings like homes and hospitals are promising for AI assistance, prior work on empowerment-based assistance assumes that the agent assists one human in isolation. We introduce an open source multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we empirically show that assistive RL agents optimizing for one human's empowerment can significantly reduce another human's environmental influence and rewards - a phenomenon we formalize as disempowerment. We characterize when disempowerment occurs in these environments and show that joint empowerment mitigates disempowerment at the cost of the user's reward. Our work reveals a broader challenge for the AI alignment community: goal-agnostic objectives that seem aligned in single-agent settings can become misaligned in multi-agent contexts.",
    "fetched_at": "2025-11-10T02:23:10.840694Z"
  },
  {
    "id": "2511.04179v1",
    "title": "Explaining Software Vulnerabilities with Large Language Models",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oshando Johnson",
      "Alexandra Fomina",
      "Ranjith Krishnamurthy",
      "Vaibhav Chaudhari",
      "Rohith Kumar Shanmuganathan",
      "Eric Bodden"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04179v1",
    "abstract": "The prevalence of security vulnerabilities has prompted companies to adopt static application security testing (SAST) tools for vulnerability detection. Nevertheless, these tools frequently exhibit usability limitations, as their generic warning messages do not sufficiently communicate important information to developers, resulting in misunderstandings or oversight of critical findings. In light of recent developments in Large Language Models (LLMs) and their text generation capabilities, our work investigates a hybrid approach that uses LLMs to tackle the SAST explainability challenges. In this paper, we present SAFE, an Integrated Development Environment (IDE) plugin that leverages GPT-4o to explain the causes, impacts, and mitigation strategies of vulnerabilities detected by SAST tools. Our expert user study findings indicate that the explanations generated by SAFE can significantly assist beginner to intermediate developers in understanding and addressing security vulnerabilities, thereby improving the overall usability of SAST tools.",
    "fetched_at": "2025-11-10T02:23:10.840648Z"
  },
  {
    "id": "2511.04183v1",
    "title": "A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing",
    "date": "2025-11-06",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Leszek Sliwko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04183v1",
    "abstract": "This paper presents a reinforced genetic approach to a defined d-resource system optimization problem. The classical evolution schema was ineffective due to a very strict feasibility function in the studied problem. Hence, the presented strategy has introduced several modifications and adaptations to standard genetic routines, e.g.: a migration operator which is an analogy to the biological random genetic drift.",
    "fetched_at": "2025-11-10T02:23:10.840596Z"
  },
  {
    "id": "2511.04192v1",
    "title": "AStF: Motion Style Transfer via Adaptive Statistics Fusor",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hanmo Chen",
      "Chenghao Xu",
      "Jiexi Yan",
      "Cheng Deng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04192v1",
    "abstract": "Human motion style transfer allows characters to appear less rigidity and more realism with specific style. Traditional arbitrary image style transfer typically process mean and variance which is proved effective. Meanwhile, similar methods have been adapted for motion style transfer. However, due to the fundamental differences between images and motion, relying on mean and variance is insufficient to fully capture the complex dynamic patterns and spatiotemporal coherence properties of motion data. Building upon this, our key insight is to bring two more coefficient, skewness and kurtosis, into the analysis of motion style. Specifically, we propose a novel Adaptive Statistics Fusor (AStF) which consists of Style Disentanglement Module (SDM) and High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in conjunction with a Motion Consistency Regularization (MCR) discriminator. Experimental results show that, by providing a more comprehensive model of the spatiotemporal statistical patterns inherent in dynamic styles, our proposed AStF shows proficiency superiority in motion style transfers over state-of-the-arts. Our code and model are available at https://github.com/CHMimilanlan/AStF.",
    "fetched_at": "2025-11-10T02:23:10.840514Z"
  },
  {
    "id": "2511.04195v1",
    "title": "Computational Turing Test Reveals Systematic Differences Between Human   and AI Language",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.MA",
      "MA",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Nicol Pagan",
      "Petter Trnberg",
      "Christopher A. Bail",
      "Anik Hannk",
      "Christopher Barrie"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04195v1",
    "abstract": "Large language models (LLMs) are increasingly used in the social sciences to simulate human behavior, based on the assumption that they can generate realistic, human-like text. Yet this assumption remains largely untested. Existing validation efforts rely heavily on human-judgment-based evaluations -- testing whether humans can distinguish AI from human output -- despite evidence that such judgments are blunt and unreliable. As a result, the field lacks robust tools for assessing the realism of LLM-generated text or for calibrating models to real-world data. This paper makes two contributions. First, we introduce a computational Turing test: a validation framework that integrates aggregate metrics (BERT-based detectability and semantic similarity) with interpretable linguistic features (stylistic markers and topical patterns) to assess how closely LLMs approximate human language within a given dataset. Second, we systematically compare nine open-weight LLMs across five calibration strategies -- including fine-tuning, stylistic prompting, and context retrieval -- benchmarking their ability to reproduce user interactions on X (formerly Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the literature. Even after calibration, LLM outputs remain clearly distinguishable from human text, particularly in affective tone and emotional expression. Instruction-tuned models underperform their base counterparts, and scaling up model size does not enhance human-likeness. Crucially, we identify a trade-off: optimizing for human-likeness often comes at the cost of semantic fidelity, and vice versa. These results provide a much-needed scalable framework for validation and calibration in LLM simulations -- and offer a cautionary note about their current limitations in capturing human communication.",
    "fetched_at": "2025-11-10T02:23:10.840463Z"
  },
  {
    "id": "2511.04205v1",
    "title": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for   the Member of the Polish National Board of Appeal",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Micha Karp",
      "Anna Kubaszewska",
      "Magdalena Krl",
      "Robert Krl",
      "Aleksander Smywiski-Pohl",
      "Mateusz Szymaski",
      "Witold Wydmaski"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04205v1",
    "abstract": "This study provides an empirical assessment of whether current large language models (LLMs) can pass the official qualifying examination for membership in Poland's National Appeal Chamber (Krajowa Izba Odwo{\\l}awcza). The authors examine two related ideas: using LLM as actual exam candidates and applying the 'LLM-as-a-judge' approach, in which model-generated answers are automatically evaluated by other models. The paper describes the structure of the exam, which includes a multiple-choice knowledge test on public procurement law and a written judgment, and presents the hybrid information recovery and extraction pipeline built to support the models. Several LLMs (including GPT-4.1, Claude 4 Sonnet and Bielik-11B-v2.6) were tested in closed-book and various Retrieval-Augmented Generation settings. The results show that although the models achieved satisfactory scores in the knowledge test, none met the passing threshold in the practical written part, and the evaluations of the 'LLM-as-a-judge' often diverged from the judgments of the official examining committee. The authors highlight key limitations: susceptibility to hallucinations, incorrect citation of legal provisions, weaknesses in logical argumentation, and the need for close collaboration between legal experts and technical teams. The findings indicate that, despite rapid technological progress, current LLMs cannot yet replace human judges or independent examiners in Polish public procurement adjudication.",
    "fetched_at": "2025-11-10T02:23:10.840404Z"
  },
  {
    "id": "2511.04214v1",
    "title": "Block Rotation is All You Need for MXFP4 Quantization",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yuantian Shao",
      "Peisong Wang",
      "Yuanteng Chen",
      "Chang Xu",
      "Zhihui Wei",
      "Jian Cheng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04214v1",
    "abstract": "Large language models (LLMs) have achieved remarkable success, but their rapidly growing scale imposes prohibitive costs in memory, computation, and energy. Post-training quantization (PTQ) is a promising solution for efficient deployment, yet achieving accurate W4A4 quantization remains an open challenge. While most existing methods are designed for INT4 formats, the emergence of MXFP4 -- a new FP4 format with various hardware support (NVIDIA, AMD, Intel)-- raises questions about the applicability of current techniques. In this work, we establish a comprehensive benchmark of PTQ methods under the MXFP4 format. Through systematic evaluation, we find that methods like GPTQ consistently deliver strong performance, whereas rotation-based approaches, which are almost used by all state-of-the-art approaches, suffer from severe incompatibility with MXFP4. We further provide the first in-depth analysis of this conflict, tracing its root to a fundamental mismatch between MXFP4's PoT (power-of-two) block scaling and the redistribution of outlier energy via global rotation. Building on this insight, we propose a simple yet effective block rotation strategy that adapts rotation-based methods to MXFP4, leading to substantial accuracy improvements across diverse LLMs. Our findings not only offer clear guidance for practitioners but also set a foundation for advancing PTQ research under emerging low-precision formats.",
    "fetched_at": "2025-11-10T02:23:10.840343Z"
  },
  {
    "id": "2511.04215v1",
    "title": "Black-Box Guardrail Reverse-engineering Attack",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Hongwei Yao",
      "Yun Xia",
      "Shuo Shao",
      "Haoran Shi",
      "Tong Qiao",
      "Cong Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04215v1",
    "abstract": "Large language models (LLMs) increasingly employ guardrails to enforce ethical, legal, and application-specific constraints on their outputs. While effective at mitigating harmful responses, these guardrails introduce a new class of vulnerabilities by exposing observable decision patterns. In this work, we present the first study of black-box LLM guardrail reverse-engineering attacks. We propose Guardrail Reverse-engineering Attack (GRA), a reinforcement learning-based framework that leverages genetic algorithm-driven data augmentation to approximate the decision-making policy of victim guardrails. By iteratively collecting input-output pairs, prioritizing divergence cases, and applying targeted mutations and crossovers, our method incrementally converges toward a high-fidelity surrogate of the victim guardrail. We evaluate GRA on three widely deployed commercial systems, namely ChatGPT, DeepSeek, and Qwen3, and demonstrate that it achieves an rule matching rate exceeding 0.92 while requiring less than $85 in API costs. These findings underscore the practical feasibility of guardrail extraction and highlight significant security risks for current LLM safety mechanisms. Our findings expose critical vulnerabilities in current guardrail designs and highlight the urgent need for more robust defense mechanisms in LLM deployment.",
    "fetched_at": "2025-11-10T02:23:10.840287Z"
  },
  {
    "id": "2511.04217v1",
    "title": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hikari Otsuka",
      "Daiki Chijiwa",
      "Yasuyuki Okoshi",
      "Daichi Fujiki",
      "Susumu Takeuchi",
      "Masato Motomura"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04217v1",
    "abstract": "The strong lottery ticket hypothesis (SLTH) conjectures that high-performing subnetworks, called strong lottery tickets (SLTs), are hidden in randomly initialized neural networks. Although recent theoretical studies have established the SLTH across various neural architectures, the SLTH for transformer architectures still lacks theoretical understanding. In particular, the current theory of the SLTH does not yet account for the multi-head attention (MHA) mechanism, a core component of transformers. To address this gap, we introduce a theoretical analysis of the existence of SLTs within MHAs. We prove that, if a randomly initialized MHA of $H$ heads and input dimension $d$ has the hidden dimension $O(d\\log(Hd^{3/2}))$ for the key and value, it contains an SLT that approximates an arbitrary MHA with the same input dimension with high probability. Furthermore, by leveraging this theory for MHAs, we extend the SLTH to transformers without normalization layers. We empirically validate our theoretical findings, demonstrating that the approximation error between the SLT within a source model (MHA and transformer) and an approximate target counterpart decreases exponentially by increasing the hidden dimension of the source model.",
    "fetched_at": "2025-11-10T02:23:10.840232Z"
  },
  {
    "id": "2511.04220v1",
    "title": "Opus: A Quantitative Framework for Workflow Evaluation",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Alan Seroul",
      "Tho Fagnoni",
      "Ins Adnani",
      "Dana O. Mohamed",
      "Phillip Kingston"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04220v1",
    "abstract": "This paper introduces the Opus Workflow Evaluation Framework, a probabilistic-normative formulation for quantifying Workflow quality and efficiency. It integrates notions of correctness, reliability, and cost into a coherent mathematical model that enables direct comparison, scoring, and optimization of Workflows. The framework combines the Opus Workflow Reward, a probabilistic function estimating expected performance through success likelihood, resource usage, and output gain, with the Opus Workflow Normative Penalties, a set of measurable functions capturing structural and informational quality across Cohesion, Coupling, Observability, and Information Hygiene. It supports automated Workflow assessment, ranking, and optimization within modern automation systems such as Opus and can be integrated into Reinforcement Learning loops to guide Workflow discovery and refinement. In this paper, we introduce the Opus Workflow Reward model that formalizes Workflow success as a probabilistic expectation over costs and outcomes. We define measurable Opus Workflow Normative Penalties capturing structural, semantic, and signal-related properties of Workflows. Finally, we propose a unified optimization formulation for identifying and ranking optimal Workflows under joint Reward-Penalty trade-offs.",
    "fetched_at": "2025-11-10T02:23:10.840176Z"
  },
  {
    "id": "2511.04228v1",
    "title": "REMIND: Input Loss Landscapes Reveal Residual Memorization in   Post-Unlearning LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "I.2.7; I.2.6; K.4.1",
      "1"
    ],
    "authors": [
      "Liran Cohen",
      "Yaniv Nemcovesky",
      "Avi Mendelson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04228v1",
    "abstract": "Machine unlearning aims to remove the influence of specific training data from a model without requiring full retraining. This capability is crucial for ensuring privacy, safety, and regulatory compliance. Therefore, verifying whether a model has truly forgotten target data is essential for maintaining reliability and trustworthiness. However, existing evaluation methods often assess forgetting at the level of individual inputs. This approach may overlook residual influence present in semantically similar examples. Such influence can compromise privacy and lead to indirect information leakage. We propose REMIND (Residual Memorization In Neighborhood Dynamics), a novel evaluation method aiming to detect the subtle remaining influence of unlearned data and classify whether the data has been effectively forgotten. REMIND analyzes the model's loss over small input variations and reveals patterns unnoticed by single-point evaluations. We show that unlearned data yield flatter, less steep loss landscapes, while retained or unrelated data exhibit sharper, more volatile patterns. REMIND requires only query-based access, outperforms existing methods under similar constraints, and demonstrates robustness across different models, datasets, and paraphrased inputs, making it practical for real-world deployment. By providing a more sensitive and interpretable measure of unlearning effectiveness, REMIND provides a reliable framework to assess unlearning in language models. As a result, REMIND offers a novel perspective on memorization and unlearning.",
    "fetched_at": "2025-11-10T02:23:10.840121Z"
  },
  {
    "id": "2511.04234v1",
    "title": "Reusing Pre-Training Data at Test Time is a Compute Multiplier",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alex Fang",
      "Thomas Voice",
      "Ruoming Pang",
      "Ludwig Schmidt",
      "Tom Gunter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04234v1",
    "abstract": "Large language models learn from their vast pre-training corpora, gaining the ability to solve an ever increasing variety of tasks; yet although researchers work to improve these datasets, there is little effort to understand how efficient the pre-training apparatus is at extracting ideas and knowledge from the data. In this work, we use retrieval augmented generation along with test-time compute as a way to quantify how much dataset value was left behind by the process of pre-training, and how this changes across scale. We demonstrate that pre-training then retrieving from standard and largely open-sourced datasets results in significant accuracy gains in MMLU, Math-500, and SimpleQA, which persist through decontamination. For MMLU we observe that retrieval acts as a ~5x compute multiplier versus pre-training alone. We show that these results can be further improved by leveraging additional compute at test time to parse the retrieved context, demonstrating a 10 percentage point improvement on MMLU for the public LLaMA 3.1 8B model. Overall, our results suggest that today's pre-training methods do not make full use of the information in existing pre-training datasets, leaving significant room for progress.",
    "fetched_at": "2025-11-10T02:23:10.840072Z"
  },
  {
    "id": "2511.04237v1",
    "title": "Denoised Recommendation Model with Collaborative Signal Decoupling",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zefeng Li",
      "Ning Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04237v1",
    "abstract": "Although the collaborative filtering (CF) algorithm has achieved remarkable performance in recommendation systems, it suffers from suboptimal recommendation performance due to noise in the user-item interaction matrix. Numerous noise-removal studies have improved recommendation models, but most existing approaches conduct denoising on a single graph. This may cause attenuation of collaborative signals: removing edges between two nodes can interrupt paths between other nodes, weakening path-dependent collaborative information. To address these limitations, this study proposes a novel GNN-based CF model called DRCSD for denoising unstable interactions. DRCSD includes two core modules: a collaborative signal decoupling module (decomposes signals into distinct orders by structural characteristics) and an order-wise denoising module (performs targeted denoising on each order). Additionally, the information aggregation mechanism of traditional GNN-based CF models is modified to avoid cross-order signal interference until the final pooling operation. Extensive experiments on three public real-world datasets show that DRCSD has superior robustness against unstable interactions and achieves statistically significant performance improvements in recommendation accuracy metrics compared to state-of-the-art baseline models.",
    "fetched_at": "2025-11-10T02:23:10.839961Z"
  },
  {
    "id": "2511.04239v1",
    "title": "seqme: a Python library for evaluating biological sequence design",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T01"
    ],
    "authors": [
      "Rasmus Mller-Larsen",
      "Adam Izdebski",
      "Jan Olszewski",
      "Pankhil Gawade",
      "Michal Kmicikiewicz",
      "Wojciech Zarzecki",
      "Ewa Szczurek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04239v1",
    "abstract": "Recent advances in computational methods for designing biological sequences have sparked the development of metrics to evaluate these methods performance in terms of the fidelity of the designed sequences to a target distribution and their attainment of desired properties. However, a single software library implementing these metrics was lacking. In this work we introduce seqme, a modular and highly extendable open-source Python library, containing model-agnostic metrics for evaluating computational methods for biological sequence design. seqme considers three groups of metrics: sequence-based, embedding-based, and property-based, and is applicable to a wide range of biological sequences: small molecules, DNA, ncRNA, mRNA, peptides and proteins. The library offers a number of embedding and property models for biological sequences, as well as diagnostics and visualization functions to inspect the results. seqme can be used to evaluate both one-shot and iterative computational design methods.",
    "fetched_at": "2025-11-10T02:23:10.839919Z"
  },
  {
    "id": "2511.04243v1",
    "title": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum   Machine Learning Ansatzes",
    "date": "2025-11-06",
    "tags": [
      "quant-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Valter Uotila",
      "Vin Mehtola",
      "Ilmo Salmenper",
      "Bo Zhao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04243v1",
    "abstract": "Leveraging data symmetries has been a key driver of performance gains in geometric deep learning and geometric and equivariant quantum machine learning. While symmetrization appears to be a promising method, its practical overhead, such as additional gates, reduced expressibility, and other factors, is not well understood in quantum machine learning. In this work, we develop an automated pipeline to measure various characteristics of quantum machine learning ansatzes with respect to symmetries that can appear in the learning task. We define the degree of symmetry in the learning problem as the size of the subgroup it admits. Subgroups define partial symmetries, which have not been extensively studied in previous research, which has focused on symmetries defined by whole groups. Symmetrizing the 19 common ansatzes with respect to these varying-sized subgroup representations, we compute three classes of metrics that describe how the common ansatz structures behave under varying amounts of symmetries. The first metric is based on the norm of the difference between the original and symmetrized generators, while the second metric counts depth, size, and other characteristics from the symmetrized circuits. The third class of metrics includes expressibility and entangling capability. The results demonstrate varying gate overhead across the studied ansatzes and confirm that increased symmetry reduces expressibility of the circuits. In most cases, increased symmetry increases entanglement capability. These results help select sufficiently expressible and computationally efficient ansatze patterns for geometric quantum machine learning applications.",
    "fetched_at": "2025-11-10T02:23:10.839862Z"
  },
  {
    "id": "2511.04244v1",
    "title": "Guided by Stars: Interpretable Concept Learning Over Time Series via   Temporal Logic Semantics",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Irene Ferfoglia",
      "Simone Silvetti",
      "Gaia Saveri",
      "Laura Nenzi",
      "Luca Bortolussi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04244v1",
    "abstract": "Time series classification is a task of paramount importance, as this kind of data often arises in safety-critical applications. However, it is typically tackled with black-box deep learning methods, making it hard for humans to understand the rationale behind their output. To take on this challenge, we propose a novel approach, STELLE (Signal Temporal logic Embedding for Logically-grounded Learning and Explanation), a neuro-symbolic framework that unifies classification and explanation through direct embedding of trajectories into a space of temporal logic concepts. By introducing a novel STL-inspired kernel that maps raw time series to their alignment with predefined STL formulae, our model jointly optimises accuracy and interpretability, as each prediction is accompanied by the most relevant logical concepts that characterise it. This yields (i) local explanations as human-readable STL conditions justifying individual predictions, and (ii) global explanations as class-characterising formulae. Experiments demonstrate that STELLE achieves competitive accuracy while providing logically faithful explanations, validated on diverse real-world benchmarks.",
    "fetched_at": "2025-11-10T02:23:10.839798Z"
  },
  {
    "id": "2511.04247v2",
    "title": "On the Brittleness of CLIP Text Encoders",
    "date": "2025-11-06",
    "tags": [
      "cs.MM",
      "MM",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Allie Tran",
      "Luca Rossetto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04247v2",
    "abstract": "Multimodal co-embedding models, especially CLIP, have advanced the state of the art in zero-shot classification and multimedia information retrieval in recent years by aligning images and text in a shared representation space. However, such modals trained on a contrastive alignment can lack stability towards small input perturbations. Especially when dealing with manually expressed queries, minor variations in the query can cause large differences in the ranking of the best-matching results. In this paper, we present a systematic analysis of the effect of multiple classes of non-semantic query perturbations in an multimedia information retrieval scenario. We evaluate a diverse set of lexical, syntactic, and semantic perturbations across multiple CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video collection. Across models, we find that syntactic and semantic perturbations drive the largest instabilities, while brittleness is concentrated in trivial surface edits such as punctuation and case. Our results highlight robustness as a critical dimension for evaluating vision-language models beyond benchmark accuracy.",
    "fetched_at": "2025-11-10T02:23:10.839743Z"
  },
  {
    "id": "2511.04248v1",
    "title": "Efficient Topic Extraction via Graph-Based Labeling: A Lightweight   Alternative to Deep Models",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Salma Mekaoui",
      "Hiba Sofyan",
      "Imane Amaaz",
      "Imane Benchrif",
      "Arsalane Zarghili",
      "Ilham Chaker",
      "Nikola S. Nikolov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04248v1",
    "abstract": "Extracting topics from text has become an essential task, especially with the rapid growth of unstructured textual data. Most existing works rely on highly computational methods to address this challenge. In this paper, we argue that probabilistic and statistical approaches, such as topic modeling (TM), can offer effective alternatives that require fewer computational resources. TM is a statistical method that automatically discovers topics in large collections of unlabeled text; however, it produces topics as distributions of representative words, which often lack clear interpretability. Our objective is to perform topic labeling by assigning meaningful labels to these sets of words. To achieve this without relying on computationally expensive models, we propose a graph-based approach that not only enriches topic words with semantically related terms but also explores the relationships among them. By analyzing these connections within the graph, we derive suitable labels that accurately capture each topic's meaning. We present a comparative study between our proposed method and several benchmarks, including ChatGPT-3.5, across two different datasets. Our method achieved consistently better results than traditional benchmarks in terms of BERTScore and cosine similarity and produced results comparable to ChatGPT-3.5, while remaining computationally efficient. Finally, we discuss future directions for topic labeling and highlight potential research avenues for enhancing interpretability and automation.",
    "fetched_at": "2025-11-10T02:23:10.839703Z"
  },
  {
    "id": "2511.04255v1",
    "title": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Marawan Elbatel",
      "Anbang Wang",
      "Keyuan Liu",
      "Kaouther Mouheb",
      "Enrique Almar-Munoz",
      "Lizhuo Lin",
      "Yanqi Yang",
      "Karim Lekadir",
      "Xiaomeng Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04255v1",
    "abstract": "This paper does not introduce a novel architecture; instead, it revisits a fundamental yet overlooked baseline: adapting human-centric foundation models for anatomical landmark detection in medical imaging. While landmark detection has traditionally relied on domain-specific models, the emergence of large-scale pre-trained vision models presents new opportunities. In this study, we investigate the adaptation of Sapiens, a human-centric foundation model designed for pose estimation, to medical imaging through multi-dataset pretraining, establishing a new state of the art across multiple datasets. Our proposed model, MedSapiens, demonstrates that human-centric foundation models, inherently optimized for spatial pose localization, provide strong priors for anatomical landmark detection, yet this potential has remained largely untapped. We benchmark MedSapiens against existing state-of-the-art models, achieving up to 5.26% improvement over generalist models and up to 21.81% improvement over specialist models in the average success detection rate (SDR). To further assess MedSapiens adaptability to novel downstream tasks with few annotations, we evaluate its performance in limited-data settings, achieving 2.69% improvement over the few-shot state of the art in SDR. Code and model weights are available at https://github.com/xmed-lab/MedSapiens .",
    "fetched_at": "2025-11-10T02:23:10.839643Z"
  },
  {
    "id": "2511.04256v1",
    "title": "SSPO: Subsentence-level Policy Optimization",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kun Yang",
      "Zikang chen",
      "Yanmeng Wang",
      "Zhigen Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04256v1",
    "abstract": "As a significant part of post-training of the Large Language Models (LLMs), Reinforcement Learning from Verifiable Reward (RLVR) has greatly improved LLMs' reasoning skills. However, some RLVR algorithms, such as GRPO (Group Relative Policy Optimization) and GSPO (Group Sequence Policy Optimization), are observed to suffer from unstable policy updates and low usage of sampling data, respectively. The importance ratio of GRPO is calculated at the token level, which focuses more on optimizing a single token. This will be easily affected by outliers, leading to model training collapse. GSPO proposed the calculation of the response level importance ratio, which solves the problem of high variance and training noise accumulation in the calculation of the GRPO importance ratio. However, since all the response tokens share a common importance ratio, extreme values can easily raise or lower the overall mean, leading to the entire response being mistakenly discarded, resulting in a decrease in the utilization of sampled data. This paper introduces SSPO, which applies sentence-level importance ratio, taking the balance between GRPO and GSPO. SSPO not only avoids training collapse and high variance, but also prevents the whole response tokens from being abandoned by the clipping mechanism. Furthermore, we apply sentence entropy to PPO-CLIP to steadily adjust the clipping bounds, encouraging high-entropy tokens to explore and narrow the clipping range of low-entropy tokens. In particular, SSPO achieves an average score of 46.57 across five datasets, surpassing GRPO (43.01) and GSPO (44.42), and wins state-of-the-art performance on three datasets. These results highlight SSPO's effectiveness in leveraging generated data by taking the essence of GSPO but rejecting its shortcomings.",
    "fetched_at": "2025-11-10T02:23:10.839572Z"
  },
  {
    "id": "2511.04260v1",
    "title": "Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human   Face Imagery",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Claudio Giusti",
      "Luca Guarnera",
      "Sebastiano Battiato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04260v1",
    "abstract": "The growing sophistication of synthetic image and deepfake generation models has turned source attribution and authenticity verification into a critical challenge for modern computer vision systems. Recent studies suggest that diffusion pipelines unintentionally imprint persistent statistical traces, known as signal leaks, within their outputs, particularly in latent representations. Building on this observation, we propose Proto-LeakNet, a signal-leak-aware and interpretable attribution framework that integrates closed-set classification with a density-based open-set evaluation on the learned embeddings, enabling analysis of unseen generators without retraining. Operating in the latent domain of diffusion models, our method re-simulates partial forward diffusion to expose residual generator-specific cues. A temporal attention encoder aggregates multi-step latent features, while a feature-weighted prototype head structures the embedding space and enables transparent attribution. Trained solely on closed data and achieving a Macro AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under post-processing, surpassing state-of-the-art methods, and achieves strong separability between known and unseen generators. These results demonstrate that modeling signal-leak bias in latent space enables reliable and interpretable AI-image and deepfake forensics. The code for the whole work will be available upon submission.",
    "fetched_at": "2025-11-10T02:23:10.839520Z"
  },
  {
    "id": "2511.04275v1",
    "title": "Online Conformal Inference with Retrospective Adjustment for Faster   Adaptation to Distribution Shift",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jungbin Jun",
      "Ilsang Ohn"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04275v1",
    "abstract": "Conformal prediction has emerged as a powerful framework for constructing distribution-free prediction sets with guaranteed coverage assuming only the exchangeability assumption. However, this assumption is often violated in online environments where data distributions evolve over time. Several recent approaches have been proposed to address this limitation, but, typically, they slowly adapt to distribution shifts because they update predictions only in a forward manner, that is, they generate a prediction for a newly observed data point while previously computed predictions are not updated. In this paper, we propose a novel online conformal inference method with retrospective adjustment, which is designed to achieve faster adaptation to distributional shifts. Our method leverages regression approaches with efficient leave-one-out update formulas to retroactively adjust past predictions when new data arrive, thereby aligning the entire set of predictions with the most recent data distribution. Through extensive numerical studies performed on both synthetic and real-world data sets, we show that the proposed approach achieves faster coverage recalibration and improved statistical efficiency compared to existing online conformal prediction methods.",
    "fetched_at": "2025-11-10T02:23:10.839472Z"
  },
  {
    "id": "2511.04285v1",
    "title": "RLoop: An Self-Improving Framework for Reinforcement Learning with   Iterative Policy Initialization",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zeng Zhiyuan",
      "Jiashuo Liu",
      "Zhangyue Yin",
      "Ge Zhang",
      "Wenhao Huang",
      "Xipeng Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04285v1",
    "abstract": "While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for training large reasoning models, its training dynamics harbor a critical challenge: RL overfitting, where models gain training rewards but lose generalization. Our analysis reveals this is driven by policy over-specialization and catastrophic forgetting of diverse solutions generated during training. Standard optimization discards this valuable inter-step policy diversity. To address this, we introduce RLoop, a self-improving framework built on iterative policy initialization. RLoop transforms the standard training process into a virtuous cycle: it first uses RL to explore the solution space from a given policy, then filters the successful trajectories to create an expert dataset. This dataset is used via Rejection-sampling Fine-Tuning (RFT) to refine the initial policy, creating a superior starting point for the next iteration. This loop of exploration and exploitation via iterative re-initialization effectively converts transient policy variations into robust performance gains. Our experiments show RLoop mitigates forgetting and substantially improves generalization, boosting average accuracy by 9% and pass@32 by over 15% compared to vanilla RL.",
    "fetched_at": "2025-11-10T02:23:10.839431Z"
  },
  {
    "id": "2511.04286v1",
    "title": "Efficient Reinforcement Learning from Human Feedback via Bayesian   Preference Inference",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Matteo Cercola",
      "Valeria Capretti",
      "Simone Formentin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04286v1",
    "abstract": "Learning from human preferences is a cornerstone of aligning machine learning models with subjective human judgments. Yet, collecting such preference data is often costly and time-consuming, motivating the need for more efficient learning paradigms. Two established approaches offer complementary advantages: RLHF scales effectively to high-dimensional tasks such as LLM fine-tuning, while PBO achieves greater sample efficiency through active querying. We propose a hybrid framework that unifies RLHF's scalability with PBO's query efficiency by integrating an acquisition-driven module into the RLHF pipeline, thereby enabling active and sample-efficient preference gathering. We validate the proposed approach on two representative domains: (i) high-dimensional preference optimization and (ii) LLM fine-tuning. Experimental results demonstrate consistent improvements in both sample efficiency and overall performance across these tasks.",
    "fetched_at": "2025-11-10T02:23:10.839372Z"
  },
  {
    "id": "2511.04291v1",
    "title": "Robustness of Minimum-Volume Nonnegative Matrix Factorization under an   Expanded Sufficiently Scattered Condition",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "eess.SP",
      "SP",
      "math.NA"
    ],
    "authors": [
      "Giovanni Barbarino",
      "Nicolas Gillis",
      "Subhayan Saha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04291v1",
    "abstract": "Minimum-volume nonnegative matrix factorization (min-vol NMF) has been used successfully in many applications, such as hyperspectral imaging, chemical kinetics, spectroscopy, topic modeling, and audio source separation. However, its robustness to noise has been a long-standing open problem. In this paper, we prove that min-vol NMF identifies the groundtruth factors in the presence of noise under a condition referred to as the expanded sufficiently scattered condition which requires the data points to be sufficiently well scattered in the latent simplex generated by the basis vectors.",
    "fetched_at": "2025-11-10T02:23:10.839330Z"
  },
  {
    "id": "2511.04304v1",
    "title": "Deep learning-based object detection of offshore platforms on Sentinel-1   Imagery and the impact of synthetic training data",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Robin Spanier",
      "Thorsten Hoeser",
      "Claudia Kuenzer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04304v1",
    "abstract": "The recent and ongoing expansion of marine infrastructure, including offshore wind farms, oil and gas platforms, artificial islands, and aquaculture facilities, highlights the need for effective monitoring systems. The development of robust models for offshore infrastructure detection relies on comprehensive, balanced datasets, but falls short when samples are scarce, particularly for underrepresented object classes, shapes, and sizes. By training deep learning-based YOLOv10 object detection models with a combination of synthetic and real Sentinel-1 satellite imagery acquired in the fourth quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of Guinea, and Coast of Brazil), this study investigates the use of synthetic training data to enhance model performance. We evaluated this approach by applying the model to detect offshore platforms in three unseen regions (Gulf of Mexico, North Sea, Persian Gulf) and thereby assess geographic transferability. This region-holdout evaluation demonstrated that the model generalises beyond the training areas. In total, 3,529 offshore platforms were detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and 1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which improved to 0.90 upon incorporating synthetic data. We analysed how synthetic data enhances the representation of unbalanced classes and overall model performance, taking a first step toward globally transferable detection of offshore infrastructure. This study underscores the importance of balanced datasets and highlights synthetic data generation as an effective strategy to address common challenges in remote sensing, demonstrating the potential of deep learning for scalable, global offshore infrastructure monitoring.",
    "fetched_at": "2025-11-10T02:23:10.839289Z"
  },
  {
    "id": "2511.04309v1",
    "title": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems",
    "date": "2025-11-06",
    "tags": [
      "math.NA",
      "NA",
      "cs.LG",
      "LG",
      "cs.NA"
    ],
    "authors": [
      "Michael Ludkovski",
      "Changgen Xie",
      "Zimu Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04309v1",
    "abstract": "We consider numerical resolution of principal-agent (PA) problems in continuous time. We formulate a generic PA model with continuous and lump payments and a multi-dimensional strategy of the agent. To tackle the resulting Hamilton-Jacobi-Bellman equation with an implicit Hamiltonian we develop a novel deep learning method: the Deep Principal-Agent Actor Critic (DeepPAAC) Actor-Critic algorithm. DeepPAAC is able to handle multi-dimensional states and controls, as well as constraints. We investigate the role of the neural network architecture, training designs, loss functions, etc. on the convergence of the solver, presenting five different case studies.",
    "fetched_at": "2025-11-10T02:23:10.839144Z"
  },
  {
    "id": "2511.04312v1",
    "title": "Probing the Probes: Methods and Metrics for Concept Alignment",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jacob Lysns-Larsen",
      "Marte Eggen",
      "Inga Strmke"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04312v1",
    "abstract": "In explainable AI, Concept Activation Vectors (CAVs) are typically obtained by training linear classifier probes to detect human-understandable concepts as directions in the activation space of deep neural networks. It is widely assumed that a high probe accuracy indicates a CAV faithfully representing its target concept. However, we show that the probe's classification accuracy alone is an unreliable measure of concept alignment, i.e., the degree to which a CAV captures the intended concept. In fact, we argue that probes are more likely to capture spurious correlations than they are to represent only the intended concept. As part of our analysis, we demonstrate that deliberately misaligned probes constructed to exploit spurious correlations, achieve an accuracy close to that of standard probes. To address this severe problem, we introduce a novel concept localization method based on spatial linear attribution, and provide a comprehensive comparison of it to existing feature visualization techniques for detecting and mitigating concept misalignment. We further propose three classes of metrics for quantitatively assessing concept alignment: hard accuracy, segmentation scores, and augmentation robustness. Our analysis shows that probes with translation invariance and spatial alignment consistently increase concept alignment. These findings highlight the need for alignment-based evaluation metrics rather than probe accuracy, and the importance of tailoring probes to both the model architecture and the nature of the target concept.",
    "fetched_at": "2025-11-10T02:23:10.839105Z"
  },
  {
    "id": "2511.04316v1",
    "title": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Tim Beyer",
      "Jonas Dornbusch",
      "Jakob Steimle",
      "Moritz Ladenburger",
      "Leo Schwinn",
      "Stephan Gnnemann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04316v1",
    "abstract": "The rapid expansion of research on Large Language Model (LLM) safety and robustness has produced a fragmented and oftentimes buggy ecosystem of implementations, datasets, and evaluation methods. This fragmentation makes reproducibility and comparability across studies challenging, hindering meaningful progress. To address these issues, we introduce AdversariaLLM, a toolbox for conducting LLM jailbreak robustness research. Its design centers on reproducibility, correctness, and extensibility. The framework implements twelve adversarial attack algorithms, integrates seven benchmark datasets spanning harmfulness, over-refusal, and utility evaluation, and provides access to a wide range of open-weight LLMs via Hugging Face. The implementation includes advanced features for comparability and reproducibility such as compute-resource tracking, deterministic results, and distributional evaluation techniques. \\name also integrates judging through the companion package JudgeZoo, which can also be used independently. Together, these components aim to establish a robust foundation for transparent, comparable, and reproducible research in LLM safety.",
    "fetched_at": "2025-11-10T02:23:10.839059Z"
  },
  {
    "id": "2511.04321v1",
    "title": "AIM: Software and Hardware Co-design for Architecture-level IR-drop   Mitigation in High-performance PIM",
    "date": "2025-11-06",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuanpeng Zhang",
      "Xing Hu",
      "Xi Chen",
      "Zhihang Yuan",
      "Cong Li",
      "Jingchen Zhu",
      "Zhao Wang",
      "Chenguang Zhang",
      "Xin Si",
      "Wei Gao",
      "Qiang Wu",
      "Runsheng Wang",
      "Guangyu Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04321v1",
    "abstract": "SRAM Processing-in-Memory (PIM) has emerged as the most promising implementation for high-performance PIM, delivering superior computing density, energy efficiency, and computational precision. However, the pursuit of higher performance necessitates more complex circuit designs and increased operating frequencies, which exacerbate IR-drop issues. Severe IR-drop can significantly degrade chip performance and even threaten reliability. Conventional circuit-level IR-drop mitigation methods, such as back-end optimizations, are resource-intensive and often compromise power, performance, and area (PPA). To address these challenges, we propose AIM, comprehensive software and hardware co-design for architecture-level IR-drop mitigation in high-performance PIM. Initially, leveraging the bit-serial and in-situ dataflow processing properties of PIM, we introduce Rtog and HR, which establish a direct correlation between PIM workloads and IR-drop. Building on this foundation, we propose LHR and WDS, enabling extensive exploration of architecture-level IR-drop mitigation while maintaining computational accuracy through software optimization. Subsequently, we develop IR-Booster, a dynamic adjustment mechanism that integrates software-level HR information with hardware-based IR-drop monitoring to adapt the V-f pairs of the PIM macro, achieving enhanced energy efficiency and performance. Finally, we propose the HR-aware task mapping method, bridging software and hardware designs to achieve optimal improvement. Post-layout simulation results on a 7nm 256-TOPS PIM chip demonstrate that AIM achieves up to 69.2% IR-drop mitigation, resulting in 2.29x energy efficiency improvement and 1.152x speedup.",
    "fetched_at": "2025-11-10T02:23:10.839004Z"
  },
  {
    "id": "2511.04328v1",
    "title": "RxSafeBench: Identifying Medication Safety Issues of Large Language   Models in Simulated Consultation",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiahao Zhao",
      "Luxin Xu",
      "Minghuan Tan",
      "Lichao Zhang",
      "Ahmadreza Argha",
      "Hamid Alinejad-Rokny",
      "Min Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04328v1",
    "abstract": "Numerous medical systems powered by Large Language Models (LLMs) have achieved remarkable progress in diverse healthcare tasks. However, research on their medication safety remains limited due to the lack of real world datasets, constrained by privacy and accessibility issues. Moreover, evaluation of LLMs in realistic clinical consultation settings, particularly regarding medication safety, is still underexplored. To address these gaps, we propose a framework that simulates and evaluates clinical consultations to systematically assess the medication safety capabilities of LLMs. Within this framework, we generate inquiry diagnosis dialogues with embedded medication risks and construct a dedicated medication safety database, RxRisk DB, containing 6,725 contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs. A two-stage filtering strategy ensures clinical realism and professional quality, resulting in the benchmark RxSafeBench with 2,443 high-quality consultation scenarios. We evaluate leading open-source and proprietary LLMs using structured multiple choice questions that test their ability to recommend safe medications under simulated patient contexts. Results show that current LLMs struggle to integrate contraindication and interaction knowledge, especially when risks are implied rather than explicit. Our findings highlight key challenges in ensuring medication safety in LLM-based systems and provide insights into improving reliability through better prompting and task-specific tuning. RxSafeBench offers the first comprehensive benchmark for evaluating medication safety in LLMs, advancing safer and more trustworthy AI-driven clinical decision support.",
    "fetched_at": "2025-11-10T02:23:10.838918Z"
  },
  {
    "id": "2511.04332v1",
    "title": "Differentially Private In-Context Learning with Nearest Neighbor Search",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Antti Koskela",
      "Tejas Kulkarni",
      "Laith Zumot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04332v1",
    "abstract": "Differentially private in-context learning (DP-ICL) has recently become an active research topic due to the inherent privacy risks of in-context learning. However, existing approaches overlook a critical component of modern large language model (LLM) pipelines: the similarity search used to retrieve relevant context data. In this work, we introduce a DP framework for in-context learning that integrates nearest neighbor search of relevant examples in a privacy-aware manner. Our method outperforms existing baselines by a substantial margin across all evaluated benchmarks, achieving more favorable privacy-utility trade-offs. To achieve this, we employ nearest neighbor retrieval from a database of context data, combined with a privacy filter that tracks the cumulative privacy cost of selected samples to ensure adherence to a central differential privacy budget. Experimental results on text classification and document question answering show a clear advantage of the proposed method over existing baselines.",
    "fetched_at": "2025-11-10T02:23:10.838855Z"
  },
  {
    "id": "2511.04333v1",
    "title": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in   Intensive Care",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Federico Pirola",
      "Fabio Stella",
      "Marco Grzegorczyk"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04333v1",
    "abstract": "Dynamic Bayesian networks (DBNs) are increasingly used in healthcare due to their ability to model complex temporal relationships in patient data while maintaining interpretability, an essential feature for clinical decision-making. However, existing approaches to handling missing data in longitudinal clinical datasets are largely derived from static Bayesian networks literature, failing to properly account for the temporal nature of the data. This gap limits the ability to quantify uncertainty over time, which is particularly critical in settings such as intensive care, where understanding the temporal dynamics is fundamental for model trustworthiness and applicability across diverse patient groups. Despite the potential of DBNs, a full Bayesian framework that integrates missing data handling remains underdeveloped. In this work, we propose a novel Gibbs sampling-based method for learning DBNs from incomplete data. Our method treats each missing value as an unknown parameter following a Gaussian distribution. At each iteration, the unobserved values are sampled from their full conditional distributions, allowing for principled imputation and uncertainty estimation. We evaluate our method on both simulated datasets and real-world intensive care data from critically ill patients. Compared to standard model-agnostic techniques such as MICE, our Bayesian approach demonstrates superior reconstruction accuracy and convergence properties. These results highlight the clinical relevance of incorporating full Bayesian inference in temporal models, providing more reliable imputations and offering deeper insight into model behavior. Our approach supports safer and more informed clinical decision-making, particularly in settings where missing data are frequent and potentially impactful.",
    "fetched_at": "2025-11-10T02:23:10.838798Z"
  },
  {
    "id": "2511.04334v1",
    "title": "Submanifold Sparse Convolutional Networks for Automated 3D Segmentation   of Kidneys and Kidney Tumours in Computed Tomography",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sal Alonso-Monsalve",
      "Leigh H. Whitehead",
      "Adam Aurisano",
      "Lorena Escudero Sanchez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04334v1",
    "abstract": "The accurate delineation of tumours in radiological images like Computed Tomography is a very specialised and time-consuming task, and currently a bottleneck preventing quantitative analyses to be performed routinely in the clinical setting. For this reason, developing methods for the automated segmentation of tumours in medical imaging is of the utmost importance and has driven significant efforts in recent years. However, challenges regarding the impracticality of 3D scans, given the large amount of voxels to be analysed, usually requires the downsampling of such images or using patches thereof when applying traditional convolutional neural networks. To overcome this problem, in this paper we propose a new methodology that uses, divided into two stages, voxel sparsification and submanifold sparse convolutional networks. This method allows segmentations to be performed with high-resolution inputs and a native 3D model architecture, obtaining state-of-the-art accuracies while significantly reducing the computational resources needed in terms of GPU memory and time. We studied the deployment of this methodology in the context of Computed Tomography images of renal cancer patients from the KiTS23 challenge, and our method achieved results competitive with the challenge winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7% for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also offers significant computational improvements, achieving up to a 60% reduction in inference time and up to a 75\\% reduction in VRAM usage compared to an equivalent dense architecture, across both CPU and various GPU cards tested.",
    "fetched_at": "2025-11-10T02:23:10.838742Z"
  },
  {
    "id": "2511.04341v2",
    "title": "Monitor-Generate-Verify (MGV): Formalising Metacognitive Theory for   Language Model Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nick Oh",
      "Fernand Gobet"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04341v2",
    "abstract": "Test-time reasoning architectures such as those following the Generate-Verify paradigm -- where a model iteratively refines or verifies its own generated outputs -- prioritise generation and verification but exclude the monitoring processes that determine when and how reasoning should begin. This omission may contribute to the prefix dominance trap, in which models commit early to suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy loss. We address this architectural gap by formalising Flavell's and Nelson and Narens' metacognitive theories into computational specifications, proposing the Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify paradigm by adding explicit monitoring that captures metacognitive experiences (from difficulty assessments to confidence judgements) before generation begins and refines future monitoring through verification feedback. Though we present no empirical validation, this work provides the first systematic computational translation of foundational metacognitive theories, offering a principled vocabulary for understanding reasoning system failures and suggesting specific architectural interventions for future test-time reasoning designs.",
    "fetched_at": "2025-11-10T02:23:10.838689Z"
  },
  {
    "id": "2511.04355v1",
    "title": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation   Benchmarks",
    "date": "2025-11-06",
    "tags": [
      "cs.SE",
      "SE",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Amir Molzam Sharifloo",
      "Maedeh Heydari",
      "Parsa Kazerooni",
      "Daniel Maninger",
      "Mira Mezini"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04355v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable success in code generation, and the race to improve their performance has become a central focus of AI research. Benchmarks and leaderboards are increasingly popular, offering quantitative rankings of LLMs. However, they provide limited insight into the tasks that LLMs consistently fail to solve - information that is crucial for understanding current limitations and guiding the development of more capable models. To address this gap, we examined code generation tasks across four popular benchmarks, identifying those that major LLMs are most likely to fail. To understand the causes of these failures, we investigated whether the static complexity of solution code contributes to them, followed by a systematic inspection of 114 tasks that LLMs consistently struggled with. Our analysis revealed four recurring patterns of weaknesses in LLMs, as well as common complications within benchmark tasks that most often lead to failure.",
    "fetched_at": "2025-11-10T02:23:10.838648Z"
  },
  {
    "id": "2511.04361v1",
    "title": "Causal Regime Detection in Energy Markets With Augmented Time Series   Structural Causal Models",
    "date": "2025-11-06",
    "tags": [
      "q-fin.CP",
      "CP",
      "cs.LG",
      "LG",
      "stat.OT",
      "OT"
    ],
    "authors": [
      "Dennis Thumm"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04361v1",
    "abstract": "Energy markets exhibit complex causal relationships between weather patterns, generation technologies, and price formation, with regime changes occurring continuously rather than at discrete break points. Current approaches model electricity prices without explicit causal interpretation or counterfactual reasoning capabilities. We introduce Augmented Time Series Causal Models (ATSCM) for energy markets, extending counterfactual reasoning frameworks to multivariate temporal data with learned causal structure. Our approach models energy systems through interpretable factors (weather, generation mix, demand patterns), rich grid dynamics, and observable market variables. We integrate neural causal discovery to learn time-varying causal graphs without requiring ground truth DAGs. Applied to real-world electricity price data, ATSCM enables novel counterfactual queries such as \"What would prices be under different renewable generation scenarios?\".",
    "fetched_at": "2025-11-10T02:23:10.838599Z"
  },
  {
    "id": "2511.04376v1",
    "title": "MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion   Transformers",
    "date": "2025-11-06",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Ali Boudaghi",
      "Hadi Zare"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04376v1",
    "abstract": "Music editing has emerged as an important and practical area of artificial intelligence, with applications ranging from video game and film music production to personalizing existing tracks according to user preferences. However, existing models face significant limitations, such as being restricted to editing synthesized music generated by their own models, requiring highly precise prompts, or necessitating task-specific retraining, thus lacking true zero-shot capability. Leveraging recent advances in rectified flow and diffusion transformers, we introduce MusRec, the first zero-shot text-to-music editing model capable of performing diverse editing tasks on real-world music efficiently and effectively. Experimental results demonstrate that our approach outperforms existing methods in preserving musical content, structural consistency, and editing fidelity, establishing a strong foundation for controllable music editing in real-world scenarios.",
    "fetched_at": "2025-11-10T02:23:10.838560Z"
  },
  {
    "id": "2511.04384v1",
    "title": "Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal   VQA",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Itbaan Safwan",
      "Muhammad Annas Shaikh",
      "Muhammad Haaris",
      "Ramail Khan",
      "Muhammad Atif Tahir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04384v1",
    "abstract": "We present a multi-task framework for the MediaEval Medico 2025 challenge, leveraging a LoRA-tuned Florence-2 model for simultaneous visual question answering (VQA), explanation generation, and visual grounding. The proposed system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer learning, (2) a synthetically enriched explanation dataset offering structured medical reasoning, and (3) text-to-region pairs linking visual features with segmentation masks. This multi-task setup enables the model to jointly learn visual grounding, reasoning, and interpretation, producing responses that are both accurate and interpretable. Extensive evaluation demonstrates that our approach substantially improves over single-task baselines in both answer accuracy and visual localization, highlighting the effectiveness of grounded multi-task learning for medical VQA applications.",
    "fetched_at": "2025-11-10T02:23:10.838519Z"
  },
  {
    "id": "2511.04401v1",
    "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group   Robustness",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Subeen Park",
      "Joowang Kim",
      "Hakyung Lee",
      "Sunjae Yoo",
      "Kyungwoo Song"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04401v1",
    "abstract": "Deep learning models achieve strong performance across various domains but often rely on spurious correlations, making them vulnerable to distribution shifts. This issue is particularly severe in subpopulation shift scenarios, where models struggle in underrepresented groups. While existing methods have made progress in mitigating this issue, their performance gains are still constrained. They lack a rigorous theoretical framework connecting the embedding space representations with worst-group error. To address this limitation, we propose Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER), a novel approach that directly regularizes feature representations to suppress spurious cues. We show theoretically that worst-group error is influenced by how strongly the classifier relies on spurious versus core directions, identified from differences in group-wise mean embeddings across domains and classes. By imposing theoretical constraints at the embedding level, SCER encourages models to focus on core features while reducing sensitivity to spurious patterns. Through systematic evaluation on multiple vision and language, we show that SCER outperforms prior state-of-the-art studies in worst-group accuracy. Our code is available at \\href{https://github.com/MLAI-Yonsei/SCER}{https://github.com/MLAI-Yonsei/SCER}.",
    "fetched_at": "2025-11-10T02:23:10.838414Z"
  },
  {
    "id": "2511.04403v1",
    "title": "Online Bayesian Experimental Design for Partially Observed Dynamical   Systems",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.CO",
      "CO"
    ],
    "authors": [
      "Sara Prez-Vieites",
      "Sahel Iqbal",
      "Simo Srkk",
      "Dominik Baumann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04403v1",
    "abstract": "Bayesian experimental design (BED) provides a principled framework for optimizing data collection, but existing approaches do not apply to crucial real-world settings such as dynamical systems with partial observability, where only noisy and incomplete observations are available. These systems are naturally modeled as state-space models (SSMs), where latent states mediate the link between parameters and data, making the likelihood -- and thus information-theoretic objectives like the expected information gain (EIG) -- intractable. In addition, the dynamical nature of the system requires online algorithms that update posterior distributions and select designs sequentially in a computationally efficient manner. We address these challenges by deriving new estimators of the EIG and its gradient that explicitly marginalize latent states, enabling scalable stochastic optimization in nonlinear SSMs. Our approach leverages nested particle filters (NPFs) for efficient online inference with convergence guarantees. Applications to realistic models, such as the susceptible-infected-recovered (SIR) and a moving source location task, show that our framework successfully handles both partial observability and online computation.",
    "fetched_at": "2025-11-10T02:23:10.838358Z"
  },
  {
    "id": "2511.04406v1",
    "title": "Dynamic Jointly Batch Selection for Data Efficient Machine Translation   Fine-Tuning",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mohammad Amin Ghanizadeh",
      "Mohammad Javad Dousti"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04406v1",
    "abstract": "Data quality and its effective selection are fundamental to improving the performance of machine translation models, serving as cornerstones for achieving robust and reliable translation systems. This paper presents a data selection methodology specifically designed for fine-tuning machine translation systems, which leverages the synergy between a learner model and a pre-trained reference model to enhance overall training effectiveness. By defining a learnability score, our approach systematically evaluates the utility of data points for training, ensuring that only the most relevant and impactful examples contribute to the fine-tuning process. Furthermore, our method employs a batch selection strategy which considers interdependencies among data points, optimizing the efficiency of the training process while maintaining a focus on data relevance. Experiments on English to Persian and several other language pairs using an mBART model fine-tuned on the CCMatrix dataset demonstrate that our method can achieve up to a fivefold improvement in data efficiency compared to an iid baseline. Experimental results indicate that our approach improves computational efficiency by 24 when utilizing cached embeddings, as it requires fewer training data points. Additionally, it enhances generalization, resulting in superior translation performance compared to random selection method.",
    "fetched_at": "2025-11-10T02:23:10.838305Z"
  },
  {
    "id": "2511.04418v1",
    "title": "The Illusion of Certainty: Uncertainty quantification for LLMs fails   under ambiguity",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tim Tomov",
      "Dominik Fuchsgruber",
      "Tom Wollschlger",
      "Stephan Gnnemann"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04418v1",
    "abstract": "Accurate uncertainty quantification (UQ) in Large Language Models (LLMs) is critical for trustworthy deployment. While real-world language is inherently ambiguous, reflecting aleatoric uncertainty, existing UQ methods are typically benchmarked against tasks with no ambiguity. In this work, we demonstrate that while current uncertainty estimators perform well under the restrictive assumption of no ambiguity, they degrade to close-to-random performance on ambiguous data. To this end, we introduce MAQA* and AmbigQA*, the first ambiguous question-answering (QA) datasets equipped with ground-truth answer distributions estimated from factual co-occurrence. We find this performance deterioration to be consistent across different estimation paradigms: using the predictive distribution itself, internal representations throughout the model, and an ensemble of models. We show that this phenomenon can be theoretically explained, revealing that predictive-distribution and ensemble-based estimators are fundamentally limited under ambiguity. Overall, our study reveals a key shortcoming of current UQ methods for LLMs and motivates a rethinking of current modeling paradigms.",
    "fetched_at": "2025-11-10T02:23:10.838263Z"
  },
  {
    "id": "2511.04422v1",
    "title": "On the Equivalence of Regression and Classification",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "68T05, 68T10, 68Q32",
      "I.2.6; I.5.1; I.5.2",
      "2"
    ],
    "authors": [
      "Jayadeva",
      "Naman Dwivedi",
      "Hari Krishnan",
      "N. M. Anoop Krishnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04422v1",
    "abstract": "A formal link between regression and classification has been tenuous. Even though the margin maximization term $\\|w\\|$ is used in support vector regression, it has at best been justified as a regularizer. We show that a regression problem with $M$ samples lying on a hyperplane has a one-to-one equivalence with a linearly separable classification task with $2M$ samples. We show that margin maximization on the equivalent classification task leads to a different regression formulation than traditionally used. Using the equivalence, we demonstrate a ``regressability'' measure, that can be used to estimate the difficulty of regressing a dataset, without needing to first learn a model for it. We use the equivalence to train neural networks to learn a linearizing map, that transforms input variables into a space where a linear regressor is adequate.",
    "fetched_at": "2025-11-10T02:23:10.838215Z"
  },
  {
    "id": "2511.04432v1",
    "title": "If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning   Task for LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Lars Bungum",
      "Charles Yijia Huang",
      "Abeer Kashar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04432v1",
    "abstract": "In this study, we experiment with the ability of LLMs to do temporal reasoning. Using a Norwegian book from 1940 containing trivia questions, we prompt the LLMs to answer the questions as if it were 1940. We also pose the questions in both English and Norwegian. Correct answers are often presented as sentences, and grading is done by means of LLM-as-judge, with sampled checks by a native speaker. Prompting in English consistently gave better results than in Norwegian, an unexpected result. In contrast, using larger LLMs improved results. We tested the DeepSeek-R1, Gemma3, Qwen3, and Llama3.1 model families, and also the largest available LLM especially crafted for Norwegian.",
    "fetched_at": "2025-11-10T02:23:10.838116Z"
  },
  {
    "id": "2511.04437v1",
    "title": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Patrik Valbek",
      "Michaela Horvthov",
      "Martin Klauo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04437v1",
    "abstract": "This paper presents a deep Koopman-based Economic Model Predictive Control (EMPC) for efficient operation of a laboratory-scale pasteurization unit (PU). The method uses Koopman operator theory to transform the complex, nonlinear system dynamics into a linear representation, enabling the application of convex optimization while representing the complex PU accurately. The deep Koopman model utilizes neural networks to learn the linear dynamics from experimental data, achieving a 45% improvement in open-loop prediction accuracy over conventional N4SID subspace identification. Both analyzed models were employed in the EMPC formulation that includes interpretable economic costs, such as energy consumption, material losses due to inadequate pasteurization, and actuator wear. The feasibility of EMPC is ensured using slack variables. The deep Koopman EMPC and N4SID EMPC are numerically validated on a nonlinear model of multivariable PU under external disturbance. The disturbances include feed pump fail-to-close scenario and the introduction of a cold batch to be pastuerized. These results demonstrate that the deep Koopmand EMPC achieves a 32% reduction in total economic cost compared to the N4SID baseline. This improvement is mainly due to the reductions in material losses and energy consumption. Furthermore, the steady-state operation via Koopman-based EMPC requires 10.2% less electrical energy. The results highlight the practical advantages of integrating deep Koopman representations with economic optimization to achieve resource-efficient control of thermal-intensive plants.",
    "fetched_at": "2025-11-10T02:23:10.838072Z"
  },
  {
    "id": "2511.04439v1",
    "title": "The Peril of Preference: Why GRPO fails on Ordinal Rewards",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anisha Garg",
      "Ganesh Venkatesh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04439v1",
    "abstract": "Group-relative Policy Optimization's (GRPO) simplicity makes it highly desirable for adapting LLMs to become experts at specific tasks. But this simplicity also makes it ill-specified as we seek to enhance RL training with richer, non-binary feedback. When using ordinal rewards to give partial credit, GRPO's simplicity starts to hurt, as its group-average baseline often assigns a positive advantage to failed trajectories and reinforces incorrect behavior.   We introduce Correctness Relative Policy Optimization (CoRPO), a new formulation that solves this flaw. CoRPO uses an adaptive baseline that enforces a minimum quality threshold, ensuring failed solutions are never positively reinforced. Once the policy consistently meets this threshold, the baseline automatically transitions to a relative preference mode, pushing the model to find optimal solutions rather than just \"acceptable\" ones. We empirically validate CoRPO on a code verification task, where it demonstrates more stable convergence and better out-of-domain generalization.   This work represents a critical step in our broader research program to enable LLMs to learn genuinely new capabilities through reinforcement learning. We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback - progressing from binary to ordinal rewards in this work, and onward to denser, per-step supervision.",
    "fetched_at": "2025-11-10T02:23:10.838022Z"
  },
  {
    "id": "2511.04445v1",
    "title": "ForecastGAN: A Decomposition-Based Adversarial Framework for   Multi-Horizon Time Series Forecasting",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Syeda Sitara Wishal Fatima",
      "Afshin Rahimi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04445v1",
    "abstract": "Time series forecasting is essential across domains from finance to supply chain management. This paper introduces ForecastGAN, a novel decomposition based adversarial framework addressing limitations in existing approaches for multi-horizon predictions. Although transformer models excel in long-term forecasting, they often underperform in short-term scenarios and typically ignore categorical features. ForecastGAN operates through three integrated modules: a Decomposition Module that extracts seasonality and trend components; a Model Selection Module that identifies optimal neural network configurations based on forecasting horizon; and an Adversarial Training Module that enhances prediction robustness through Conditional Generative Adversarial Network training. Unlike conventional approaches, ForecastGAN effectively integrates both numerical and categorical features. We validate our framework on eleven benchmark multivariate time series datasets that span various forecasting horizons. The results show that ForecastGAN consistently outperforms state-of-the-art transformer models for short-term forecasting while remaining competitive for long-term horizons. This research establishes a more generalizable approach to time series forecasting that adapts to specific contexts while maintaining strong performance across diverse data characteristics without extensive hyperparameter tuning.",
    "fetched_at": "2025-11-10T02:23:10.837980Z"
  },
  {
    "id": "2511.04451v1",
    "title": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear   System with Input Delay",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Patrik Valbek",
      "Marek Wadinger",
      "Michal Kvasnica",
      "Martin Klauo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04451v1",
    "abstract": "Nonlinear dynamical systems with input delays pose significant challenges for prediction, estimation, and control due to their inherent complexity and the impact of delays on system behavior. Traditional linear control techniques often fail in these contexts, necessitating innovative approaches. This paper introduces a novel approach to approximate the Koopman operator using an LSTM-enhanced Deep Koopman model, enabling linear representations of nonlinear systems with time delays. By incorporating Long Short-Term Memory (LSTM) layers, the proposed framework captures historical dependencies and efficiently encodes time-delayed system dynamics into a latent space. Unlike traditional extended Dynamic Mode Decomposition (eDMD) approaches that rely on predefined dictionaries, the LSTM-enhanced Deep Koopman model is dictionary-free, which mitigates the problems with the underlying dynamics being known and incorporated into the dictionary. Quantitative comparisons with extended eDMD on a simulated system demonstrate highly significant performance gains in prediction accuracy in cases where the true nonlinear dynamics are unknown and achieve comparable results to eDMD with known dynamics of a system.",
    "fetched_at": "2025-11-10T02:23:10.837936Z"
  },
  {
    "id": "2511.04454v1",
    "title": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits",
    "date": "2025-11-06",
    "tags": [
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "q-bio.NC",
      "NC",
      "90C25, 90C59, 90C90"
    ],
    "authors": [
      "Hao Zhu",
      "Jasper Hoffmann",
      "Baohe Zhang",
      "Joschka Boedecker"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04454v1",
    "abstract": "We consider the problem of fitting a reinforcement learning (RL) model to some given behavioral data under a multi-armed bandit environment. These models have received much attention in recent years for characterizing human and animal decision making behavior. We provide a generic mathematical optimization problem formulation for the fitting problem of a wide range of RL models that appear frequently in scientific research applications, followed by a detailed theoretical analysis of its convexity properties. Based on the theoretical results, we introduce a novel solution method for the fitting problem of RL models based on convex relaxation and optimization. Our method is then evaluated in several simulated bandit environments to compare with some benchmark methods that appear in the literature. Numerical results indicate that our method achieves comparable performance to the state-of-the-art, while significantly reducing computation time. We also provide an open-source Python package for our proposed method to empower researchers to apply it in the analysis of their datasets directly, without prior knowledge of convex optimization.",
    "fetched_at": "2025-11-10T02:23:10.837886Z"
  },
  {
    "id": "2511.04456v1",
    "title": "Federated Stochastic Minimax Optimization under Heavy-Tailed Noises",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinwen Zhang",
      "Hongchang Gao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04456v1",
    "abstract": "Heavy-tailed noise has attracted growing attention in nonconvex stochastic optimization, as numerous empirical studies suggest it offers a more realistic assumption than standard bounded variance assumption. In this work, we investigate nonconvex-PL minimax optimization under heavy-tailed gradient noise in federated learning. We propose two novel algorithms: Fed-NSGDA-M, which integrates normalized gradients, and FedMuon-DA, which leverages the Muon optimizer for local updates. Both algorithms are designed to effectively address heavy-tailed noise in federated minimax optimization, under a milder condition. We theoretically establish that both algorithms achieve a convergence rate of $O({1}/{(TNp)^{\\frac{s-1}{2s}}})$. To the best of our knowledge, these are the first federated minimax optimization algorithms with rigorous theoretical guarantees under heavy-tailed noise. Extensive experiments further validate their effectiveness.",
    "fetched_at": "2025-11-10T02:23:10.837836Z"
  },
  {
    "id": "2511.04461v1",
    "title": "Data-driven uncertainty-aware seakeeping prediction of the Delft 372   catamaran using ensemble Hankel dynamic mode decomposition",
    "date": "2025-11-06",
    "tags": [
      "eess.SY",
      "SY",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Giorgio Palma",
      "Andrea Serani",
      "Matteo Diez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04461v1",
    "abstract": "In this study, we present and validate an ensemble-based Hankel Dynamic Mode Decomposition with control (HDMDc) for uncertainty-aware seakeeping predictions of a high-speed catamaran, namely the Delft 372 model. Experimental measurements (time histories) of wave elevation at the longitudinal center of gravity, heave, pitch, notional flight-deck velocity, notional bridge acceleration, and total resistance were collected from irregular wave basin tests on a 1:33.3 scale replica of the Delft 372 model under sea state 5 conditions at Fr = 0.425, and organized into training, validation, and test sets. The HDMDc algorithm constructs an equation-free linear reduced-order model of the seakeeping vessel by augmenting states and inputs with their time-lagged copies to capture nonlinear and memory effects. Two ensembling strategies, namely Bayesian HDMDc (BHDMDc), which samples hyperparameters considered stochastic variables with prior distribution to produce posterior mean forecasts with confidence intervals, and Frequentist HDMDc (FHDMDc), which aggregates multiple model obtained over data subsets, are compared in providing seakeeping prediction and uncertainty quantification. The FHDMDc approach is found to improve the accuracy of the predictions compared to the deterministic counterpart, also providing robust uncertainty estimation; whereas the application of BHDMDc to the present test case is not found beneficial in comparison to the deterministic model. FHDMDc-derived probability density functions for the motions closely match both experimental data and URANS results, demonstrating reliable and computationally efficient seakeeping prediction for design and operational support.",
    "fetched_at": "2025-11-10T02:23:10.837783Z"
  },
  {
    "id": "2511.04465v1",
    "title": "Fraud-Proof Revenue Division on Subscription Platforms",
    "date": "2025-11-06",
    "tags": [
      "cs.GT",
      "GT",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "econ.TH",
      "TH"
    ],
    "authors": [
      "Abheek Ghosh",
      "Tzeh Yuan Neoh",
      "Nicholas Teh",
      "Giannis Tyrovolas"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04465v1",
    "abstract": "We study a model of subscription-based platforms where users pay a fixed fee for unlimited access to content, and creators receive a share of the revenue. Existing approaches to detecting fraud predominantly rely on machine learning methods, engaging in an ongoing arms race with bad actors. We explore revenue division mechanisms that inherently disincentivize manipulation. We formalize three types of manipulation-resistance axioms and examine which existing rules satisfy these. We show that a mechanism widely used by streaming platforms, not only fails to prevent fraud, but also makes detecting manipulation computationally intractable. We also introduce a novel rule, ScaledUserProp, that satisfies all three manipulation-resistance axioms. Finally, experiments with both real-world and synthetic streaming data support ScaledUserProp as a fairer alternative compared to existing rules.",
    "fetched_at": "2025-11-10T02:23:10.837681Z"
  },
  {
    "id": "2511.04469v1",
    "title": "Towards Causal Market Simulators",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "q-fin.CP",
      "CP",
      "stat.OT",
      "OT"
    ],
    "authors": [
      "Dennis Thumm",
      "Luis Ontaneda Mijares"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04469v1",
    "abstract": "Market generators using deep generative models have shown promise for synthetic financial data generation, but existing approaches lack causal reasoning capabilities essential for counterfactual analysis and risk assessment. We propose a Time-series Neural Causal Model VAE (TNCM-VAE) that combines variational autoencoders with structural causal models to generate counterfactual financial time series while preserving both temporal dependencies and causal relationships. Our approach enforces causal constraints through directed acyclic graphs in the decoder architecture and employs the causal Wasserstein distance for training. We validate our method on synthetic autoregressive models inspired by the Ornstein-Uhlenbeck process, demonstrating superior performance in counterfactual probability estimation with L1 distances as low as 0.03-0.10 compared to ground truth. The model enables financial stress testing, scenario analysis, and enhanced backtesting by generating plausible counterfactual market trajectories that respect underlying causal mechanisms.",
    "fetched_at": "2025-11-10T02:23:10.837635Z"
  },
  {
    "id": "2511.04473v1",
    "title": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge   Graph Augmented LLMs",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Alberto Cattaneo",
      "Carlo Luschi",
      "Daniel Justus"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04473v1",
    "abstract": "Retrieval of information from graph-structured knowledge bases represents a promising direction for improving the factuality of LLMs. While various solutions have been proposed, a comparison of methods is difficult due to the lack of challenging QA datasets with ground-truth targets for graph retrieval. We present SynthKGQA, a framework for generating high-quality synthetic Knowledge Graph Question Answering datasets from any Knowledge Graph, providing the full set of ground-truth facts in the KG to reason over each question. We show how, in addition to enabling more informative benchmarking of KG retrievers, the data produced with SynthKGQA also allows us to train better models. We apply SynthKGQA to Wikidata to generate GTSQA, a new dataset designed to test zero-shot generalization abilities of KG retrievers with respect to unseen graph structures and relation types, and benchmark popular solutions for KG-augmented LLMs on it.",
    "fetched_at": "2025-11-10T02:23:10.837594Z"
  },
  {
    "id": "2511.04476v1",
    "title": "Probabilistic Textual Time Series Depression Detection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Fabian Schmidt",
      "Seyedehmoniba Ravan",
      "Vladimir Vlassov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04476v1",
    "abstract": "Accurate and interpretable predictions of depression severity are essential for clinical decision support, yet existing models often lack uncertainty estimates and temporal modeling. We propose PTTSD, a Probabilistic Textual Time Series Depression Detection framework that predicts PHQ-8 scores from utterance-level clinical interviews while modeling uncertainty over time. PTTSD includes sequence-to-sequence and sequence-to-one variants, both combining bidirectional LSTMs, self-attention, and residual connections with Gaussian or Student-t output heads trained via negative log-likelihood. Evaluated on E-DAIC and DAIC-WOZ, PTTSD achieves state-of-the-art performance among text-only systems (e.g., MAE = 3.85 on E-DAIC, 3.55 on DAIC) and produces well-calibrated prediction intervals. Ablations confirm the value of attention and probabilistic modeling, while comparisons with MentalBERT establish generality. A three-part calibration analysis and qualitative case studies further highlight the interpretability and clinical relevance of uncertainty-aware forecasting.",
    "fetched_at": "2025-11-10T02:23:10.837551Z"
  },
  {
    "id": "2511.04478v1",
    "title": "Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop   Refinement of LLM Judges",
    "date": "2025-11-06",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hyo Jin Do",
      "Zahra Ashktorab",
      "Jasmina Gajcin",
      "Erik Miehling",
      "Martn Santilln Cooper",
      "Qian Pan",
      "Elizabeth M. Daly",
      "Werner Geyer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04478v1",
    "abstract": "The LLM-as-a-judge paradigm enables flexible, user-defined evaluation, but its effectiveness is often limited by the scarcity of diverse, representative data for refining criteria. We present a tool that integrates synthetic data generation into the LLM-as-a-judge workflow, empowering users to create tailored and challenging test cases with configurable domains, personas, lengths, and desired outcomes, including borderline cases. The tool also supports AI-assisted inline editing of existing test cases. To enhance transparency and interpretability, it reveals the prompts and explanations behind each generation. In a user study (N=24), 83% of participants preferred the tool over manually creating or selecting test cases, as it allowed them to rapidly generate diverse synthetic data without additional workload. The generated synthetic data proved as effective as hand-crafted data for both refining evaluation criteria and aligning with human preferences. These findings highlight synthetic data as a promising alternative, particularly in contexts where efficiency and scalability are critical.",
    "fetched_at": "2025-11-10T02:23:10.837508Z"
  },
  {
    "id": "2511.04479v2",
    "title": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding   in Thai",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Surapon Nonesung",
      "Teetouch Jaknamon",
      "Sirinya Chaiophat",
      "Natapong Nitarach",
      "Chanakan Wittayasakpan",
      "Warit Sirichotedumrong",
      "Adisai Na-Thalang",
      "Kunat Pipatanakul"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04479v2",
    "abstract": "We present ThaiOCRBench, the first comprehensive benchmark for evaluating vision-language models (VLMs) on Thai text-rich visual understanding tasks. Despite recent progress in multimodal modeling, existing benchmarks predominantly focus on high-resource languages, leaving Thai underrepresented, especially in tasks requiring document structure understanding. ThaiOCRBench addresses this gap by offering a diverse, human-annotated dataset comprising 2,808 samples across 13 task categories. We evaluate a wide range of state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and open-source systems. Results show a significant performance gap, with proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source counterparts. Notably, fine-grained text recognition and handwritten content extraction exhibit the steepest performance drops among open-source models. Through detailed error analysis, we identify key challenges such as language bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a standardized framework for assessing VLMs in low-resource, script-complex settings, and provides actionable insights for improving Thai-language document understanding.",
    "fetched_at": "2025-11-10T02:23:10.837447Z"
  },
  {
    "id": "2511.04484v1",
    "title": "Online Algorithms for Repeated Optimal Stopping: Achieving Both   Competitive Ratio and Regret Bounds",
    "date": "2025-11-06",
    "tags": [
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tsubasa Harada",
      "Yasushi Kawase",
      "Hanna Sumita"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04484v1",
    "abstract": "We study the repeated optimal stopping problem, which generalizes the classical optimal stopping problem with an unknown distribution to a setting where the same problem is solved repeatedly over $T$ rounds. In this framework, we aim to design algorithms that guarantee a competitive ratio in each round while also achieving sublinear regret across all rounds.   Our primary contribution is a general algorithmic framework that achieves these objectives simultaneously for a wide array of repeated optimal stopping problems. The core idea is to dynamically select an algorithm for each round, choosing between two candidates: (1) an empirically optimal algorithm derived from the history of observations, and (2) a sample-based algorithm with a proven competitive ratio guarantee. Based on this approach, we design an algorithm that performs no worse than the baseline sample-based algorithm in every round, while ensuring that the total regret is bounded by $\\tilde{O}(\\sqrt{T})$.   We demonstrate the broad applicability of our framework to canonical problems, including the prophet inequality, the secretary problem, and their variants under adversarial, random, and i.i.d. input models. For example, for the repeated prophet inequality problem, our method achieves a $1/2$-competitive ratio from the second round on and an $\\tilde{O}(\\sqrt{T})$ regret. Furthermore, we establish a regret lower bound of $\\Omega(\\sqrt{T})$ even in the i.i.d. model, confirming that our algorithm's performance is almost optimal with respect to the number of rounds.",
    "fetched_at": "2025-11-10T02:23:10.837332Z"
  },
  {
    "id": "2511.04485v1",
    "title": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank   Training",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Ipsita Ghosh",
      "Ethan Nguyen",
      "Christian Kmmerle"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04485v1",
    "abstract": "Parameter-efficient training, based on low-rank optimization, has become a highly successful tool for fine-tuning large deep-learning models. However, these methods fail at low-rank pre-training tasks where maintaining the low-rank structure and the objective remains a challenging task. We propose the Quadratic Reweighted Rank Regularizer dubbed Q3R, which leads to a novel low-rank inducing training strategy inspired by the iteratively reweighted least squares (IRLS) framework. Q3R is based on a quadratic regularizer term which majorizes a smoothed log determinant serving as rank surrogate objective. Unlike other low-rank training techniques, Q3R is able to train weight matrices with prescribed, low target ranks of models that achieve comparable predictive performance as dense models, with small computational overhead, while remaining fully compatible with existing architectures. For example, we demonstrated one experiment where we are able to truncate $60\\%$ and $80\\%$ of the parameters of a ViT-Tiny model with $~1.3\\%$ and $~4\\%$ accuracy drop in CIFAR-10 performance respectively. The efficacy of Q3R is confirmed on Transformers across both image and language tasks, including for low-rank fine-tuning.",
    "fetched_at": "2025-11-10T02:23:10.837282Z"
  },
  {
    "id": "2511.04491v1",
    "title": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within   Structured Tables",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nikhil Abhyankar",
      "Purvi Chaurasia",
      "Sanchit Kabra",
      "Ananya Srivastava",
      "Vivek Gupta",
      "Chandan K. Reddy"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04491v1",
    "abstract": "Existing tabular reasoning benchmarks mostly test models on small, uniform tables, underrepresenting the complexity of real-world data and giving an incomplete view of Large Language Models' (LLMs) reasoning abilities. Real tables are long, heterogeneous, and domain-specific, mixing structured fields with free text and requiring multi-hop reasoning across thousands of tokens. To address this gap, we introduce RUST-BENCH, a benchmark of 7966 questions from 2031 real-world tables spanning two domains: i) RB-Science (NSF grant records) and ii) RB-Sports (NBA statistics). Unlike prior work, RUST-BENCH evaluates LLMs jointly across scale, heterogeneity, domain specificity, and reasoning complexity. Experiments with open-source and proprietary models show that LLMs struggle with heterogeneous schemas and complex multi-hop inference, revealing persistent weaknesses in current architectures and prompting strategies. RUST-BENCH establishes a challenging new testbed for advancing tabular reasoning research.",
    "fetched_at": "2025-11-10T02:23:10.837233Z"
  },
  {
    "id": "2511.04494v1",
    "title": "Distribution-Aware Tensor Decomposition for Compression of Convolutional   Neural Networks",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Alper Kalle",
      "Theo Rudkiewicz",
      "Mohamed-Oumar Ouerfelli",
      "Mohamed Tamaazousti"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2511.04494v1",
    "abstract": "Neural networks are widely used for image-related tasks but typically demand considerable computing power. Once a network has been trained, however, its memory- and compute-footprint can be reduced by compression. In this work, we focus on compression through tensorization and low-rank representations. Whereas classical approaches search for a low-rank approximation by minimizing an isotropic norm such as the Frobenius norm in weight-space, we use data-informed norms that measure the error in function space. Concretely, we minimize the change in the layer's output distribution, which can be expressed as $\\lVert (W - \\widetilde{W}) \\Sigma^{1/2}\\rVert_F$ where $\\Sigma^{1/2}$ is the square root of the covariance matrix of the layer's input and $W$, $\\widetilde{W}$ are the original and compressed weights. We propose new alternating least square algorithms for the two most common tensor decompositions (Tucker-2 and CPD) that directly optimize the new norm. Unlike conventional compression pipelines, which almost always require post-compression fine-tuning, our data-informed approach often achieves competitive accuracy without any fine-tuning. We further show that the same covariance-based norm can be transferred from one dataset to another with only a minor accuracy drop, enabling compression even when the original training dataset is unavailable. Experiments on several CNN architectures (ResNet-18/50, and GoogLeNet) and datasets (ImageNet, FGVC-Aircraft, Cifar10, and Cifar100) confirm the advantages of the proposed method.",
    "fetched_at": "2025-11-10T02:23:10.837171Z"
  },
  {
    "id": "2511.04495v1",
    "title": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code   Generation",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Cuong Huynh",
      "Jie Cao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04495v1",
    "abstract": "This paper describes the OUNLP system submitted to the TSAR-2025 Shared Task (Alva-Manchego et al., 2025), designed for readability-controlled text simplification using LLM-prompting-based generation. Based on the analysis of prompt-based text simplification methods, we discovered an interesting finding that text simplification performance is highly related to the gap between the source CEFR (Arase et al., 2022) level and the target CEFR level. Inspired by this finding, we propose two multi-round simplification methods and generate them via GPT-4o: rule-based simplification (MRS-Rule) and jointly rule-based LLM simplification (MRS-Joint). Our submitted systems ranked 7 out of 20 teams. Later improvements with MRS-Joint show that taking the LLM simplified candidates as the starting point could further boost the multi-round simplification performance.",
    "fetched_at": "2025-11-10T02:23:10.837120Z"
  },
  {
    "id": "2511.04499v1",
    "title": "Decoding Emergent Big Five Traits in Large Language Models:   Temperature-Dependent Expression and Architectural Clustering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Christos-Nikolaos Zacharopoulos",
      "Revekka Kyriakoglou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04499v1",
    "abstract": "As Large Language Models (LLMs) become integral to human-centered applications, understanding their personality-like behaviors is increasingly important for responsible development and deployment. This paper systematically evaluates six LLMs, applying the Big Five Inventory-2 (BFI-2) framework, to assess trait expressions under varying sampling temperatures. We find significant differences across four of the five personality dimensions, with Neuroticism and Extraversion susceptible to temperature adjustments. Further, hierarchical clustering reveals distinct model clusters, suggesting that architectural features may predispose certain models toward stable trait profiles. Taken together, these results offer new insights into the emergence of personality-like patterns in LLMs and provide a new perspective on model tuning, selection, and the ethical governance of AI systems. We share the data and code for this analysis here: https://osf.io/bsvzc/?view_only=6672219bede24b4e875097426dc3fac1",
    "fetched_at": "2025-11-10T02:23:10.837082Z"
  },
  {
    "id": "2511.04500v1",
    "title": "Large language models replicate and predict human cooperation across   experiments in game theory",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.GT",
      "GT",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Andrea Cera Palatsi",
      "Samuel Martin-Gutierrez",
      "Ana S. Cardenal",
      "Max Pellert"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04500v1",
    "abstract": "Large language models (LLMs) are increasingly used both to make decisions in domains such as health, education and law, and to simulate human behavior. Yet how closely LLMs mirror actual human decision-making remains poorly understood. This gap is critical: misalignment could produce harmful outcomes in practical applications, while failure to replicate human behavior renders LLMs ineffective for social simulations. Here, we address this gap by developing a digital twin of game-theoretic experiments and introducing a systematic prompting and probing framework for machine-behavioral evaluation. Testing three open-source models (Llama, Mistral and Qwen), we find that Llama reproduces human cooperation patterns with high fidelity, capturing human deviations from rational choice theory, while Qwen aligns closely with Nash equilibrium predictions. Notably, we achieved population-level behavioral replication without persona-based prompting, simplifying the simulation process. Extending beyond the original human-tested games, we generate and preregister testable hypotheses for novel game configurations outside the original parameter grid. Our findings demonstrate that appropriately calibrated LLMs can replicate aggregate human behavioral patterns and enable systematic exploration of unexplored experimental spaces, offering a complementary approach to traditional research in the social and behavioral sciences that generates new empirical predictions about human social decision-making.",
    "fetched_at": "2025-11-10T02:23:10.837041Z"
  },
  {
    "id": "2511.04505v1",
    "title": "Alternative Fairness and Accuracy Optimization in Criminal Justice",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Shaolong Wu",
      "James Blume",
      "Geshi Yeung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04505v1",
    "abstract": "Algorithmic fairness has grown rapidly as a research area, yet key concepts remain unsettled, especially in criminal justice. We review group, individual, and process fairness and map the conditions under which they conflict. We then develop a simple modification to standard group fairness. Rather than exact parity across protected groups, we minimize a weighted error loss while keeping differences in false negative rates within a small tolerance. This makes solutions easier to find, can raise predictive accuracy, and surfaces the ethical choice of error costs. We situate this proposal within three classes of critique: biased and incomplete data, latent affirmative action, and the explosion of subgroup constraints. Finally, we offer a practical framework for deployment in public decision systems built on three pillars: need-based decisions, Transparency and accountability, and narrowly tailored definitions and solutions. Together, these elements link technical design to legitimacy and provide actionable guidance for agencies that use risk assessment and related tools.",
    "fetched_at": "2025-11-10T02:23:10.836933Z"
  },
  {
    "id": "2511.04506v1",
    "title": "Modeling Clinical Uncertainty in Radiology Reports: from Explicit   Uncertainty Markers to Implicit Reasoning Pathways",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Paloma Rabaey",
      "Jong Hak Moon",
      "Jung-Oh Lee",
      "Min Gwan Kim",
      "Hangyul Yoon",
      "Thomas Demeester",
      "Edward Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04506v1",
    "abstract": "Radiology reports are invaluable for clinical decision-making and hold great potential for automated analysis when structured into machine-readable formats. These reports often contain uncertainty, which we categorize into two distinct types: (i) Explicit uncertainty reflects doubt about the presence or absence of findings, conveyed through hedging phrases. These vary in meaning depending on the context, making rule-based systems insufficient to quantify the level of uncertainty for specific findings; (ii) Implicit uncertainty arises when radiologists omit parts of their reasoning, recording only key findings or diagnoses. Here, it is often unclear whether omitted findings are truly absent or simply unmentioned for brevity. We address these challenges with a two-part framework. We quantify explicit uncertainty by creating an expert-validated, LLM-based reference ranking of common hedging phrases, and mapping each finding to a probability value based on this reference. In addition, we model implicit uncertainty through an expansion framework that systematically adds characteristic sub-findings derived from expert-defined diagnostic pathways for 14 common diagnoses. Using these methods, we release Lunguage++, an expanded, uncertainty-aware version of the Lunguage benchmark of fine-grained structured radiology reports. This enriched resource enables uncertainty-aware image classification, faithful diagnostic reasoning, and new investigations into the clinical impact of diagnostic uncertainty.",
    "fetched_at": "2025-11-10T02:23:10.836888Z"
  },
  {
    "id": "2511.04514v1",
    "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image   Classifiers",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "C. Hepburn",
      "T. Zielke",
      "A. P. Raulf"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04514v1",
    "abstract": "The phenomenon of linear mode connectivity (LMC) links several aspects of deep learning, including training stability under noisy stochastic gradients, the smoothness and generalization of local minima (basins), the similarity and functional diversity of sampled models, and architectural effects on data processing. In this work, we experimentally study LMC under data shifts and identify conditions that mitigate their impact. We interpret data shifts as an additional source of stochastic gradient noise, which can be reduced through small learning rates and large batch sizes. These parameters influence whether models converge to the same local minimum or to regions of the loss landscape with varying smoothness and generalization. Although models sampled via LMC tend to make similar errors more frequently than those converging to different basins, the benefit of LMC lies in balancing training efficiency against the gains achieved from larger, more diverse ensembles. Code and supplementary materials will be made publicly available at https://github.com/DLR-KI/LMC in due course.",
    "fetched_at": "2025-11-10T02:23:10.836827Z"
  },
  {
    "id": "2511.04518v1",
    "title": "Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom   Parity",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA",
      "stat.ML",
      "ML",
      "68T05, 62J07, 65M20, 65M60",
      "I.2.6; G.1.2; G.1.8",
      "8"
    ],
    "authors": [
      "Obed Amo",
      "Samit Ghosh",
      "Markus Lange-Hegermann",
      "Bogdan Rai",
      "Michael Pokojovy"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04518v1",
    "abstract": "We present a new benchmarking study comparing a boundary-constrained Ehrenpreis--Palamodov Gaussian Process (B-EPGP) surrogate with a classical finite element method combined with Crank--Nicolson time stepping (CN-FEM) for solving the two-dimensional wave equation with homogeneous Dirichlet boundary conditions. The B-EPGP construction leverages exponential-polynomial bases derived from the characteristic variety to enforce the PDE and boundary conditions exactly and employs penalized least squares to estimate the coefficients. To ensure fairness across paradigms, we introduce a degrees-of-freedom (DoF) matching protocol. Under matched DoF, B-EPGP consistently attains lower space-time $L^2$-error and maximum-in-time $L^{2}$-error in space than CN-FEM, improving accuracy by roughly two orders of magnitude.",
    "fetched_at": "2025-11-10T02:23:10.836767Z"
  },
  {
    "id": "2511.04522v1",
    "title": "End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air   Separation Unit",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Daniel Mayfrank",
      "Kayra Dernek",
      "Laura Lang",
      "Alexander Mitsos",
      "Manuel Dahmen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04522v1",
    "abstract": "With our recently proposed method based on reinforcement learning (Mayfrank et al. (2024), Comput. Chem. Eng. 190), Koopman surrogate models can be trained for optimal performance in specific (economic) nonlinear model predictive control ((e)NMPC) applications. So far, our method has exclusively been demonstrated on a small-scale case study. Herein, we show that our method scales well to a more challenging demand response case study built on a large-scale model of a single-product (nitrogen) air separation unit. Across all numerical experiments, we assume observability of only a few realistically measurable plant variables. Compared to a purely system identification-based Koopman eNMPC, which generates small economic savings but frequently violates constraints, our method delivers similar economic performance while avoiding constraint violations.",
    "fetched_at": "2025-11-10T02:23:10.836716Z"
  },
  {
    "id": "2511.04527v1",
    "title": "Are language models aware of the road not taken? Token-level uncertainty   and hidden state dynamics",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amir Zur",
      "Atticus Geiger",
      "Ekdeep Singh Lubana",
      "Eric Bigelow"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04527v1",
    "abstract": "When a language model generates text, the selection of individual tokens might lead it down very different reasoning paths, making uncertainty difficult to quantify. In this work, we consider whether reasoning language models represent the alternate paths that they could take during generation. To test this hypothesis, we use hidden activations to control and predict a language model's uncertainty during chain-of-thought reasoning. In our experiments, we find a clear correlation between how uncertain a model is at different tokens, and how easily the model can be steered by controlling its activations. This suggests that activation interventions are most effective when there are alternate paths available to the model -- in other words, when it has not yet committed to a particular final answer. We also find that hidden activations can predict a model's future outcome distribution, demonstrating that models implicitly represent the space of possible paths.",
    "fetched_at": "2025-11-10T02:23:10.836665Z"
  },
  {
    "id": "2511.04528v1",
    "title": "IntelliProof: An Argumentation Network-based Conversational Helper for   Organized Reflection",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kaveh Eskandari Miandoab",
      "Katharine Kowalyshyn",
      "Kabir Pamnani",
      "Anesu Gavhera",
      "Vasanth Sarathy",
      "Matthias Scheutz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04528v1",
    "abstract": "We present IntelliProof, an interactive system for analyzing argumentative essays through LLMs. IntelliProof structures an essay as an argumentation graph, where claims are represented as nodes, supporting evidence is attached as node properties, and edges encode supporting or attacking relations. Unlike existing automated essay scoring systems, IntelliProof emphasizes the user experience: each relation is initially classified and scored by an LLM, then visualized for enhanced understanding. The system provides justifications for classifications and produces quantitative measures for essay coherence. It enables rapid exploration of argumentative quality while retaining human oversight. In addition, IntelliProof provides a set of tools for a better understanding of an argumentative essay and its corresponding graph in natural language, bridging the gap between the structural semantics of argumentative essays and the user's understanding of a given text. A live demo and the system are available here to try: \\textbf{https://intelliproof.vercel.app}",
    "fetched_at": "2025-11-10T02:23:10.836619Z"
  },
  {
    "id": "2511.04534v1",
    "title": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to   Cloud Microphysics",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "physics.ao-ph",
      "ao-ph",
      "physics.comp-ph",
      "comp-ph",
      "I.6.5; I.2.6; G.3; J.2",
      "2"
    ],
    "authors": [
      "Jonas E. Katona",
      "Emily K. de Jong",
      "Nipun Gunawardena"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04534v1",
    "abstract": "Reduced-order models (ROMs) can efficiently simulate high-dimensional physical systems, but lack robust uncertainty quantification methods. Existing approaches are frequently architecture- or training-specific, which limits flexibility and generalization. We introduce a post hoc, model-agnostic framework for predictive uncertainty quantification in latent space ROMs that requires no modification to the underlying architecture or training procedure. Using conformal prediction, our approach estimates statistical prediction intervals for multiple components of the ROM pipeline: latent dynamics, reconstruction, and end-to-end predictions. We demonstrate the method on a latent space dynamical model for cloud microphysics, where it accurately predicts the evolution of droplet-size distributions and quantifies uncertainty across the ROM pipeline.",
    "fetched_at": "2025-11-10T02:23:10.836568Z"
  },
  {
    "id": "2511.04538v1",
    "title": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities   Reporting",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Cyril Vallez",
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Ljiljana Dolamic"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04538v1",
    "abstract": "As the role of Large Language Models (LLM)-based coding assistants in software development becomes more critical, so does the role of the bugs they generate in the overall cybersecurity landscape. While a number of LLM code security benchmarks have been proposed alongside approaches to improve the security of generated code, it remains unclear to what extent they have impacted widely used coding LLMs. Here, we show that even the latest open-weight models are vulnerable in the earliest reported vulnerability scenarios in a realistic use setting, suggesting that the safety-functionality trade-off has until now prevented effective patching of vulnerabilities. To help address this issue, we introduce a new severity metric that reflects the risk posed by an LLM-generated vulnerability, accounting for vulnerability severity, generation chance, and the formulation of the prompt that induces vulnerable code generation - Prompt Exposure (PE). To encourage the mitigation of the most serious and prevalent vulnerabilities, we use PE to define the Model Exposure (ME) score, which indicates the severity and prevalence of vulnerabilities a model generates.",
    "fetched_at": "2025-11-10T02:23:10.836525Z"
  },
  {
    "id": "2511.04539v1",
    "title": "Unified Generative Latent Representation for Functional Brain Graphs",
    "date": "2025-11-06",
    "tags": [
      "q-bio.NC",
      "NC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Subati Abulikemu",
      "Tiago Azevedo",
      "Michail Mamalakis",
      "John Suckling"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04539v1",
    "abstract": "Functional brain graphs are often characterized with separate graph-theoretic or spectral descriptors, overlooking how these properties covary and partially overlap across brains and conditions. We anticipate that dense, weighted functional connectivity graphs occupy a low-dimensional latent geometry along which both topological and spectral structures display graded variations. Here, we estimated this unified graph representation and enabled generation of dense functional brain graphs through a graph transformer autoencoder with latent diffusion, with spectral geometry providing an inductive bias to guide learning. This geometry-aware latent representation, although unsupervised, meaningfully separated working-memory states and decoded visual stimuli, with performance further enhanced by incorporating neural dynamics. From the diffusion modeled distribution, we were able to sample biologically plausible and structurally grounded synthetic dense graphs.",
    "fetched_at": "2025-11-10T02:23:10.836478Z"
  },
  {
    "id": "2511.04541v1",
    "title": "LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems",
    "date": "2025-11-06",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Baptiste Bonin",
      "Maxime Heuillet",
      "Audrey Durand"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04541v1",
    "abstract": "Modeling user preferences across domains remains a key challenge in slate recommendation (i.e. recommending an ordered sequence of items) research. We investigate how Large Language Models (LLM) can effectively act as world models of user preferences through pairwise reasoning over slates. We conduct an empirical study involving several LLMs on three tasks spanning different datasets. Our results reveal relationships between task performance and properties of the preference function captured by LLMs, hinting towards areas for improvement and highlighting the potential of LLMs as world models in recommender systems.",
    "fetched_at": "2025-11-10T02:23:10.836429Z"
  },
  {
    "id": "2511.04550v1",
    "title": "Confidential Computing for Cloud Security: Exploring Hardware based   Encryption Using Trusted Execution Environments",
    "date": "2025-11-06",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Dhruv Deepak Agarwal",
      "Aswani Kumar Cherukuri"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04550v1",
    "abstract": "The growth of cloud computing has revolutionized data processing and storage capacities to another levels of scalability and flexibility. But in the process, it has created a huge challenge of security, especially in terms of safeguarding sensitive data. Classical security practices, including encryption at rest and during transit, fail to protect data in use and expose it to various possible breaches. In response to this problem , Confidential Computing has been a tool ,seeking to secure data in processing by usage of hardware-based Trusted Execution Environments (TEEs). TEEs, including Intel's Software Guard Extensions (SGX) and ARM's TrustZone, offers protected contexts within the processor, where data is kept confidential ,intact and secure , even with malicious software or compromised operating systems. In this research, we have explored the architecture and security features of TEEs like Intel SGX and ARM TrustZone, and their effectiveness in improving cloud data security. From a thorough literature survey ,we have analyzed the deployment strategies, performance indicators, and practical uses of these TEEs for the same purpose. In addition, we have discussed the issues regarding deployment, possible weaknesses, scalability issues, and integration issues. Our results focuses on the central position of TEEs in strengthening and advancing cloud security infrastructures, pointing towards their ability to create a secure foundation for Confidential Computing.",
    "fetched_at": "2025-11-10T02:23:10.836391Z"
  },
  {
    "id": "2511.04556v1",
    "title": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse   Sensing Approach",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CE",
      "CE"
    ],
    "authors": [
      "Zihang Ding",
      "Kun Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04556v1",
    "abstract": "Urban surface water flooding, triggered by intense rainfall overwhelming drainage systems, is increasingly frequent and widespread. While flood prediction and monitoring in high spatial-temporal resolution are desired, practical constraints in time, budget, and technology hinder its full implementation. How to monitor urban drainage networks and predict flow conditions under constrained resource is a major challenge. This study presents a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to optimize sensor placement and reconstruct peak flowrates in a stormwater system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case study. We utilized a SWMM model to generate a training dataset of peak flowrate profiles across the stormwater network. Furthermore, we applied DSS - leveraging singular value decomposition for dimensionality reduction and QR factorization for sensor allocation - to identify the optimal monitoring nodes based on the simulated training dataset. We then validated the representativeness of these identified monitoring nodes by comparing the DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three optimally placed sensors among 77 nodes achieved satisfactory reconstruction performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to 75th percentiles). In addition, the model showed good robustness to uncertainty in measurements. Its robustness to sensor failures is location-dependent and improves with the number of sensors deployed. The framework balances computational efficiency and physical interpretability, enabling high-accuracy flow reconstruction with minimal sensors. This DSS framework can be further integrated with predictive models to realize flood early warning and real-time control under limited sensing and monitoring resource.",
    "fetched_at": "2025-11-10T02:23:10.836348Z"
  },
  {
    "id": "2511.04557v1",
    "title": "Integrating Temporal and Structural Context in Graph Transformers for   Relational Deep Learning",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Divyansha Lachi",
      "Mahmoud Mohammadi",
      "Joe Meyer",
      "Vinam Arora",
      "Tom Palczewski",
      "Eva L. Dyer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04557v1",
    "abstract": "In domains such as healthcare, finance, and e-commerce, the temporal dynamics of relational data emerge from complex interactions-such as those between patients and providers, or users and products across diverse categories. To be broadly useful, models operating on these data must integrate long-range spatial and temporal dependencies across diverse types of entities, while also supporting multiple predictive tasks. However, existing graph models for relational data primarily focus on spatial structure, treating temporal information merely as a filtering constraint to exclude future events rather than a modeling signal, and are typically designed for single-task prediction. To address these gaps, we introduce a temporal subgraph sampler that enhances global context by retrieving nodes beyond the immediate neighborhood to capture temporally relevant relationships. In addition, we propose the Relational Graph Perceiver (RGP), a graph transformer architecture for relational deep learning that leverages a cross-attention-based latent bottleneck to efficiently integrate information from both structural and temporal contexts. This latent bottleneck integrates signals from different node and edge types into a common latent space, enabling the model to build global context across the entire relational system. RGP also incorporates a flexible cross-attention decoder that supports joint learning across tasks with disjoint label spaces within a single model. Experiments on RelBench, SALT, and CTU show that RGP delivers state-of-the-art performance, offering a general and scalable solution for relational deep learning with support for diverse predictive tasks.",
    "fetched_at": "2025-11-10T02:23:10.836300Z"
  },
  {
    "id": "2511.04560v1",
    "title": "BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented   Generation Strategies for Bangla Biomedical Question Answering",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Sadia Sultana",
      "Saiyma Sittul Muna",
      "Mosammat Zannatul Samarukh",
      "Ajwad Abrar",
      "Tareque Mohmud Chowdhury"
    ],
    "institution": "OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2511.04560v1",
    "abstract": "Developing accurate biomedical Question Answering (QA) systems in low-resource languages remains a major challenge, limiting equitable access to reliable medical knowledge. This paper introduces BanglaMedQA and BanglaMMedBench, the first large-scale Bangla biomedical Multiple Choice Question (MCQ) datasets designed to evaluate reasoning and retrieval in medical artificial intelligence (AI). The study applies and benchmarks several Retrieval-Augmented Generation (RAG) strategies, including Traditional, Zero-Shot Fallback, Agentic, Iterative Feedback, and Aggregate RAG, combining textbook-based and web retrieval with generative reasoning to improve factual accuracy. A key novelty lies in integrating a Bangla medical textbook corpus through Optical Character Recognition (OCR) and implementing an Agentic RAG pipeline that dynamically selects between retrieval and reasoning strategies. Experimental results show that the Agentic RAG achieved the highest accuracy 89.54% with openai/gpt-oss-120b, outperforming other configurations and demonstrating superior rationale quality. These findings highlight the potential of RAG-based methods to enhance the reliability and accessibility of Bangla medical QA, establishing a foundation for future research in multilingual medical artificial intelligence.",
    "fetched_at": "2025-11-10T02:23:10.836242Z"
  },
  {
    "id": "2511.04564v1",
    "title": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in   Scientific AI",
    "date": "2025-11-06",
    "tags": [
      "physics.comp-ph",
      "comp-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yoh-ichi Mototake",
      "Makoto Sasaki"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04564v1",
    "abstract": "Physics-informed machine learning (PIML) integrates partial differential equations (PDEs) into machine learning models to solve inverse problems, such as estimating coefficient functions (e.g., the Hamiltonian function) that characterize physical systems. This framework enables data-driven understanding and prediction of complex physical phenomena. While coefficient functions in PIML are typically estimated on the basis of predictive performance, physics as a discipline does not rely solely on prediction accuracy to evaluate models. For example, Kepler's heliocentric model was favored owing to small discrepancies in planetary motion, despite its similar predictive accuracy to the geocentric model. This highlights the inherent uncertainties in data-driven model inference and the scientific importance of selecting physically meaningful solutions. In this paper, we propose a framework to quantify and analyze such uncertainties in the estimation of coefficient functions in PIML. We apply our framework to reduced model of magnetohydrodynamics and our framework shows that there are uncertainties, and unique identification is possible with geometric constraints. Finally, we confirm that we can estimate the reduced model uniquely by incorporating these constraints.",
    "fetched_at": "2025-11-10T02:23:10.836190Z"
  },
  {
    "id": "2511.04567v1",
    "title": "Machine Learning for Electron-Scale Turbulence Modeling in W7-X",
    "date": "2025-11-06",
    "tags": [
      "physics.plasm-ph",
      "plasm-ph",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Ionut-Gabriel Farcas",
      "Don Lawrence Carl Agapito Fernando",
      "Alejandro Banon Navarro",
      "Gabriele Merlo",
      "Frank Jenko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04567v1",
    "abstract": "Constructing reduced models for turbulent transport is essential for accelerating profile predictions and enabling many-query tasks such as uncertainty quantification, parameter scans, and design optimization. This paper presents machine-learning-driven reduced models for Electron Temperature Gradient (ETG) turbulence in the Wendelstein 7-X (W7-X) stellarator. Each model predicts the ETG heat flux as a function of three plasma parameters: the normalized electron temperature radial gradient ($\\omega_{T_e}$), the ratio of normalized electron temperature and density radial gradients ($\\eta_e$), and the electron-to-ion temperature ratio ($\\tau$). We first construct models across seven radial locations using regression and an active machine-learning-based procedure. This process initializes models using low-cardinality sparse-grid training data and then iteratively refines their training sets by selecting the most informative points from a pre-existing simulation database. We evaluate the prediction capabilities of our models using out-of-sample datasets with over $393$ points per location, and $95\\%$ prediction intervals are estimated via bootstrapping to assess prediction uncertainty. We then investigate the construction of generalized reduced models, including a generic, position-independent model, and assess their heat flux prediction capabilities at three additional locations. Our models demonstrate robust performance and predictive accuracy comparable to the original reference simulations, even when applied beyond the training domain.",
    "fetched_at": "2025-11-10T02:23:10.836147Z"
  },
  {
    "id": "2511.04568v1",
    "title": "Riesz Regression As Direct Density Ratio Estimation",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "econ.EM",
      "EM",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Masahiro Kato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04568v1",
    "abstract": "Riesz regression has garnered attention as a tool in debiased machine learning for causal and structural parameter estimation (Chernozhukov et al., 2021). This study shows that Riesz regression is closely related to direct density-ratio estimation (DRE) in important cases, including average treat- ment effect (ATE) estimation. Specifically, the idea and objective in Riesz regression coincide with the one in least-squares importance fitting (LSIF, Kanamori et al., 2009) in direct density-ratio estimation. While Riesz regression is general in the sense that it can be applied to Riesz representer estimation in a wide class of problems, the equivalence with DRE allows us to directly import exist- ing results in specific cases, including convergence-rate analyses, the selection of loss functions via Bregman-divergence minimization, and regularization techniques for flexible models, such as neural networks. Conversely, insights about the Riesz representer in debiased machine learning broaden the applications of direct density-ratio estimation methods. This paper consolidates our prior results in Kato (2025a) and Kato (2025b).",
    "fetched_at": "2025-11-10T02:23:10.836087Z"
  },
  {
    "id": "2511.04570v1",
    "title": "Thinking with Video: Video Generation as a Promising Multimodal   Reasoning Paradigm",
    "date": "2025-11-06",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jingqi Tong",
      "Yurong Mou",
      "Hangcheng Li",
      "Mingzhe Li",
      "Yongzhuo Yang",
      "Ming Zhang",
      "Qiguang Chen",
      "Tianyi Liang",
      "Xiaomeng Hu",
      "Yining Zheng",
      "Xinchi Chen",
      "Jun Zhao",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04570v1",
    "abstract": "\"Thinking with Text\" and \"Thinking with Images\" paradigm significantly improve the reasoning ability of large language models (LLMs) and Vision Language Models (VLMs). However, these paradigms have inherent limitations. (1) Images capture only single moments and fail to represent dynamic processes or continuous changes, and (2) The separation of text and vision as distinct modalities, hindering unified multimodal understanding and generation. To overcome these limitations, we introduce \"Thinking with Video\", a new paradigm that leverages video generation models, such as Sora-2, to bridge visual and textual reasoning in a unified temporal framework. To support this exploration, we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks, Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU. Furthermore, we systematically analyse the source of these abilities. We also find that self-consistency and in-context learning can improve Sora-2's performance. In summary, our findings demonstrate that the video generation model is the potential unified multimodal understanding and generation model, positions \"thinking with video\" as a unified multimodal reasoning paradigm.",
    "fetched_at": "2025-11-10T02:23:10.836046Z"
  },
  {
    "id": "2511.04573v1",
    "title": "ARETE: an R package for Automated REtrieval from TExt with large   language models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Vasco V. Branco",
      "Jand Benedek",
      "Lidia Pivovarova",
      "Lus Correia",
      "Pedro Cardoso"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04573v1",
    "abstract": "1. A hard stop for the implementation of rigorous conservation initiatives is our lack of key species data, especially occurrence data. Furthermore, researchers have to contend with an accelerated speed at which new information must be collected and processed due to anthropogenic activity. Publications ranging from scientific papers to gray literature contain this crucial information but their data are often not machine-readable, requiring extensive human work to be retrieved. 2. We present the ARETE R package, an open-source software aiming to automate data extraction of species occurrences powered by large language models, namely using the chatGPT Application Programming Interface. This R package integrates all steps of the data extraction and validation process, from Optical Character Recognition to detection of outliers and output in tabular format. Furthermore, we validate ARETE through systematic comparison between what is modelled and the work of human annotators. 3. We demonstrate the usefulness of the approach by comparing range maps produced using GBIF data and with those automatically extracted for 100 species of spiders. Newly extracted data allowed to expand the known Extent of Occurrence by a mean three orders of magnitude, revealing new areas where the species were found in the past, which mayhave important implications for spatial conservation planning and extinction risk assessments. 4. ARETE allows faster access to hitherto untapped occurrence data, a potential game changer in projects requiring such data. Researchers will be able to better prioritize resources, manually verifying selected species while maintaining automated extraction for the majority. This workflow also allows predicting available bibliographic data during project planning.",
    "fetched_at": "2025-11-10T02:23:10.835961Z"
  },
  {
    "id": "2511.04576v2",
    "title": "Physics-Informed Neural Networks and Neural Operators for Parametric   PDEs: A Human-AI Collaborative Analysis",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "68T01"
    ],
    "authors": [
      "Zhuo Zhang",
      "Xiong Xiong",
      "Sen Zhang",
      "Yuan Zhao",
      "Xi Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04576v2",
    "abstract": "PDEs arise ubiquitously in science and engineering, where solutions depend on parameters (physical properties, boundary conditions, geometry). Traditional numerical methods require re-solving the PDE for each parameter, making parameter space exploration prohibitively expensive. Recent machine learning advances, particularly physics-informed neural networks (PINNs) and neural operators, have revolutionized parametric PDE solving by learning solution operators that generalize across parameter spaces. We critically analyze two main paradigms: (1) PINNs, which embed physical laws as soft constraints and excel at inverse problems with sparse data, and (2) neural operators (e.g., DeepONet, Fourier Neural Operator), which learn mappings between infinite-dimensional function spaces and achieve unprecedented generalization. Through comparisons across fluid dynamics, solid mechanics, heat transfer, and electromagnetics, we show neural operators can achieve computational speedups of $10^3$ to $10^5$ times faster than traditional solvers for multi-query scenarios, while maintaining comparable accuracy. We provide practical guidance for method selection, discuss theoretical foundations (universal approximation, convergence), and identify critical open challenges: high-dimensional parameters, complex geometries, and out-of-distribution generalization. This work establishes a unified framework for understanding parametric PDE solvers via operator learning, offering a comprehensive, incrementally updated resource for this rapidly evolving field",
    "fetched_at": "2025-11-10T02:23:10.835900Z"
  },
  {
    "id": "2511.04583v1",
    "title": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration   from a Baseline Paper",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Atsuyuki Miyai",
      "Mashiro Toyooka",
      "Takashi Otonari",
      "Zaiying Zhao",
      "Kiyoharu Aizawa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04583v1",
    "abstract": "Understanding the current capabilities and risks of AI Scientist systems is essential for ensuring trustworthy and sustainable AI-driven scientific progress while preserving the integrity of the academic ecosystem. To this end, we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system that mimics the core research workflow of a novice student researcher: Given the baseline paper from the human mentor, it analyzes its limitations, formulates novel hypotheses for improvement, validates them through rigorous experimentation, and writes a paper with the results. Unlike previous approaches that assume full automation or operate on small-scale code, Jr. AI Scientist follows a well-defined research workflow and leverages modern coding agents to handle complex, multi-file implementations, leading to scientifically valuable contributions. For evaluation, we conducted automated assessments using AI Reviewers, author-led evaluations, and submissions to Agents4Science, a venue dedicated to AI-driven scientific contributions. The findings demonstrate that Jr. AI Scientist generates papers receiving higher review scores than existing fully automated systems. Nevertheless, we identify important limitations from both the author evaluation and the Agents4Science reviews, indicating the potential risks of directly applying current AI Scientist systems and key challenges for future research. Finally, we comprehensively report various risks identified during development. We hope these insights will deepen understanding of current progress and risks in AI Scientist development.",
    "fetched_at": "2025-11-10T02:23:10.835823Z"
  },
  {
    "id": "2511.04638v1",
    "title": "Addressing divergent representations from causal interventions on neural   networks",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Satchel Grant",
      "Simon Jerome Han",
      "Alexa Tartaglini",
      "Christopher Potts"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04638v1",
    "abstract": "A common approach to mechanistic interpretability is to causally manipulate model representations via targeted interventions in order to understand what those representations encode. Here we ask whether such interventions create out-of-distribution (divergent) representations, and whether this raises concerns about how faithful their resulting explanations are to the target model in its natural state. First, we demonstrate empirically that common causal intervention techniques often do shift internal representations away from the natural distribution of the target model. Then, we provide a theoretical analysis of two classes of such divergences: `harmless' divergences that occur in the null-space of the weights and from covariance within behavioral decision boundaries, and `pernicious' divergences that activate hidden network pathways and cause dormant behavioral changes. Finally, in an effort to mitigate the pernicious cases, we modify the Counterfactual Latent (CL) loss from Grant (2025) that regularizes interventions to remain closer to the natural distributions, reducing the likelihood of harmful divergences while preserving the interpretive power of interventions. Together, these results highlight a path towards more reliable interpretability methods.",
    "fetched_at": "2025-11-10T02:23:10.835379Z"
  },
  {
    "id": "2511.04647v1",
    "title": "Optimal Inference Schedules for Masked Diffusion Models",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sitan Chen",
      "Kevin Cong",
      "Jerry Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.04647v1",
    "abstract": "A major bottleneck of standard auto-regressive large language models is that their inference process is inherently sequential, resulting in very long and costly inference times. To circumvent this, practitioners proposed a class of language models called diffusion language models, of which the masked diffusion model (MDM) is the most successful. The MDM is able to sample tokens out-of-order and, ostensibly, many tokens at once and in parallel. However, there is very limited rigorous understanding of how much parallel sampling these models can perform without noticeable degradation in their sampling performance. Prior work of Li and Cai obtained some preliminary bounds, but these are not tight for many natural classes of distributions. In this work, we give a new, exact characterization of the expected divergence between the true distribution and the sampled distribution, for any distribution and any unmasking schedule for the sampler, showing an elegant connection to the theory of univariate function approximation.   By leveraging this connection, we then attain a number of novel lower and upper bounds for this problem. While the connection to function approximation in principle gives the optimal unmasking schedule for any distribution, we show that it is in general impossible to compete with it without strong a priori knowledge of the distribution, even in seemingly benign settings. However, we also demonstrate new upper bounds and new sampling schedules in terms of well-studied information-theoretic properties of the base distribution, namely, its total correlation and dual total correlation, which show that in some natural settings, one can sample in $O(log n)$ steps without any visible loss in performance, where $n$ is the total sequence length.",
    "fetched_at": "2025-11-10T02:23:10.835181Z"
  },
  {
    "id": "2511.04076v1",
    "title": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via   Large Language Model Agents",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hao Li",
      "Haotian Chen",
      "Ruoyuan Gong",
      "Juanjuan Wang",
      "Hao Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04076v1",
    "abstract": "Redistricting plays a central role in shaping how votes are translated into political power. While existing computational methods primarily aim to generate large ensembles of legally valid districting plans, they often neglect the strategic dynamics involved in the selection process. This oversight creates opportunities for partisan actors to cherry-pick maps that, while technically compliant, are politically advantageous. Simply satisfying formal constraints does not ensure fairness when the selection process itself can be manipulated. We propose \\textbf{Agentmandering}, a framework that reimagines redistricting as a turn-based negotiation between two agents representing opposing political interests. Drawing inspiration from game-theoretic ideas, particularly the \\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction into the redistricting process via large language model (LLM) agents. Agents alternate between selecting and freezing districts from a small set of candidate maps, gradually partitioning the state through constrained and interpretable choices. Evaluation on post-2020 U.S. Census data across all states shows that Agentmandering significantly reduces partisan bias and unfairness, while achieving 2 to 3 orders of magnitude lower variance than standard baselines. These results demonstrate both fairness and stability, especially in swing-state scenarios. Our code is available at https://github.com/Lihaogx/AgentMandering.",
    "fetched_at": "2025-11-10T02:23:01.290906Z"
  },
  {
    "id": "2511.03929v1",
    "title": "NVIDIA Nemotron Nano V2 VL",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "NVIDIA",
      ":",
      "Amala Sanjay Deshmukh",
      "Kateryna Chumachenko",
      "Tuomas Rintamaki",
      "Matthieu Le",
      "Tyler Poon",
      "Danial Mohseni Taheri",
      "Ilia Karmanov",
      "Guilin Liu",
      "Jarno Seppanen",
      "Guo Chen",
      "Karan Sapra",
      "Zhiding Yu",
      "Adi Renduchintala",
      "Charles Wang",
      "Peter Jin",
      "Arushi Goel",
      "Mike Ranzinger",
      "Lukas Voegtle",
      "Philipp Fischer",
      "Timo Roman",
      "Wei Ping",
      "Boxin Wang",
      "Zhuolin Yang",
      "Nayeon Lee",
      "Shaokun Zhang",
      "Fuxiao Liu",
      "Zhiqi Li",
      "Di Zhang",
      "Greg Heinrich",
      "Hongxu",
      "Yin",
      "Song Han",
      "Pavlo Molchanov",
      "Parth Mannan",
      "Yao Xu",
      "Jane Polak Scowcroft",
      "Tom Balough",
      "Subhashree Radhakrishnan",
      "Paris Zhang",
      "Sean Cha",
      "Ratnesh Kumar",
      "Zaid Pervaiz Bhat",
      "Jian Zhang",
      "Darragh Hanley",
      "Pritam Biswas",
      "Jesse Oliver",
      "Kevin Vasques",
      "Roger Waleffe",
      "Duncan Riach",
      "Oluwatobi Olabiyi",
      "Ameya Sunil Mahabaleshwarkar",
      "Bilal Kartal",
      "Pritam Gundecha",
      "Khanh Nguyen",
      "Alexandre Milesi",
      "Eugene Khvedchenia",
      "Ran Zilberstein",
      "Ofri Masad",
      "Natan Bagrov",
      "Nave Assaf",
      "Tomer Asida",
      "Daniel Afrimi",
      "Amit Zuker",
      "Netanel Haber",
      "Zhiyu Cheng",
      "Jingyu",
      "Xin",
      "Di",
      "Wu",
      "Nik Spirin",
      "Maryam Moosaei",
      "Roman Ageev",
      "Vanshil Atul Shah",
      "Yuting Wu",
      "Daniel Korzekwa",
      "Unnikrishnan Kizhakkemadam Sreekumar",
      "Wanli Jiang",
      "Padmavathy Subramanian",
      "Alejandra Rico",
      "Sandip Bhaskar",
      "Saeid Motiian",
      "Kedi Wu",
      "Annie Surla",
      "Chia-Chih Chen",
      "Hayden Wolff",
      "Matthew Feinberg",
      "Melissa Corpuz",
      "Marek Wawrzos",
      "Eileen Long",
      "Aastha Jhunjhunwala",
      "Paul Hendricks",
      "Farzan Memarian",
      "Benika Hall",
      "Xin-Yu Wang",
      "David Mosallanezhad",
      "Soumye Singhal",
      "Luis Vega",
      "Katherine Cheung",
      "Krzysztof Pawelec",
      "Michael Evans",
      "Katherine Luna",
      "Jie Lou",
      "Erick Galinkin",
      "Akshay Hazare",
      "Kaustubh Purandare",
      "Ann Guan",
      "Anna Warno",
      "Chen Cui",
      "Yoshi Suhara",
      "Shibani Likhite",
      "Seph Mard",
      "Meredith Price",
      "Laya Sleiman",
      "Saori Kaji",
      "Udi Karpas",
      "Kari Briski",
      "Joey Conway",
      "Michael Lightstone",
      "Jan Kautz",
      "Mohammad Shoeybi",
      "Mostofa Patwary",
      "Jonathen Cohen",
      "Oleksii Kuchaiev",
      "Andrew Tao",
      "Bryan Catanzaro"
    ],
    "institution": "Allan, Danny, Justin",
    "link": "http://arxiv.org/pdf/2511.03929v1",
    "abstract": "We introduce Nemotron Nano V2 VL, the latest model of the Nemotron vision-language series designed for strong real-world document understanding, long video comprehension, and reasoning tasks. Nemotron Nano V2 VL delivers significant improvements over our previous model, Llama-3.1-Nemotron-Nano-VL-8B, across all vision and text domains through major enhancements in model architecture, datasets, and training recipes. Nemotron Nano V2 VL builds on Nemotron Nano V2, a hybrid Mamba-Transformer LLM, and innovative token reduction techniques to achieve higher inference throughput in long document and video scenarios. We are releasing model checkpoints in BF16, FP8, and FP4 formats and sharing large parts of our datasets, recipes and training code.",
    "fetched_at": "2025-11-09T02:21:28.189058Z"
  },
  {
    "id": "2511.04160v1",
    "title": "On Joint Regularization and Calibration in Deep Ensembles",
    "date": "2025-11-06",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Laurits Fredsgaard",
      "Mikkel N. Schmidt"
    ],
    "institution": "Department of Applied Mathematics and Computer Science, Technical University of Denmark",
    "link": "http://arxiv.org/pdf/2511.04160v1",
    "abstract": "Deep ensembles are a powerful tool in machine learning, improving both model performance and uncertainty calibration. While ensembles are typically formed by training and tuning models individually, evidence suggests that jointly tuning the ensemble can lead to better performance. This paper investigates the impact of jointly tuning weight decay, temperature scaling, and early stopping on both predictive performance and uncertainty quantification. Additionally, we propose a partially overlapping holdout strategy as a practical compromise between enabling joint evaluation and maximizing the use of data for training. Our results demonstrate that jointly tuning the ensemble generally matches or improves performance, with significant variation in effect size across different tasks and metrics. We highlight the trade-offs between individual and joint optimization in deep ensemble training, with the overlapping holdout strategy offering an attractive practical solution. We believe our findings provide valuable insights and guidance for practitioners looking to optimize deep ensemble models. Code is available at: https://github.com/lauritsf/ensemble-optimality-gap",
    "fetched_at": "2025-11-09T02:21:28.185383Z"
  },
  {
    "id": "2511.04247v1",
    "title": "On the Brittleness of CLIP Text Encoders",
    "date": "2025-11-06",
    "tags": [
      "cs.MM",
      "MM",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Allie Tran",
      "Luca Rossetto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04247v1",
    "abstract": "Multimodal co-embedding models, especially CLIP, have advanced the state of the art in zero-shot classification and multimedia information retrieval in recent years by aligning images and text in a shared representation space. However, such modals trained on a contrastive alignment can lack stability towards small input perturbations. Especially when dealing with manually expressed queries, minor variations in the query can cause large differences in the ranking of the best-matching results. In this paper, we present a systematic analysis of the effect of multiple classes of non-semantic query perturbations in an multimedia information retrieval scenario. We evaluate a diverse set of lexical, syntactic, and semantic perturbations across multiple CLIP variants using the TRECVID Ad-Hoc Video Search queries and the V3C1 video collection. Across models, we find that syntactic and semantic perturbations drive the largest instabilities, while brittleness is concentrated in trivial surface edits such as punctuation and case. Our results highlight robustness as a critical dimension for evaluating vision-language models beyond benchmark accuracy.",
    "fetched_at": "2025-11-09T02:21:28.184193Z"
  },
  {
    "id": "2511.04341v1",
    "title": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for   Language Model Reasoning",
    "date": "2025-11-06",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nick Oh",
      "Fernand Gobet"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.04341v1",
    "abstract": "Test-time reasoning architectures such as those following the Generate-Verify paradigm -- where a model iteratively refines or verifies its own generated outputs -- prioritise generation and verification but exclude the monitoring processes that determine when and how reasoning should begin. This omission may contribute to the prefix dominance trap, in which models commit early to suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy loss. We address this architectural gap by formalising Flavell's and Nelson and Narens' metacognitive theories into computational specifications, proposing the Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify paradigm by adding explicit monitoring that captures metacognitive experiences (from difficulty assessments to confidence judgements) before generation begins and refines future monitoring through verification feedback. Though we present no empirical validation, this work provides the first systematic computational translation of foundational metacognitive theories, offering a principled vocabulary for understanding reasoning system failures and suggesting specific architectural interventions for future test-time reasoning designs.",
    "fetched_at": "2025-11-09T02:21:28.183188Z"
  },
  {
    "id": "2511.04479v1",
    "title": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding   in Thai",
    "date": "2025-11-06",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Surapon Nonesung",
      "Teetouch Jaknamon",
      "Sirinya Chaiophat",
      "Natapong Nitarach",
      "Chanakan Wittayasakpan",
      "Warit Sirichotedumrong",
      "Adisai Na-Thalang",
      "Kunat Pipatanakul"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04479v1",
    "abstract": "We present ThaiOCRBench, the first comprehensive benchmark for evaluating vision-language models (VLMs) on Thai text-rich visual understanding tasks. Despite recent progress in multimodal modeling, existing benchmarks predominantly focus on high-resource languages, leaving Thai underrepresented, especially in tasks requiring document structure understanding. ThaiOCRBench addresses this gap by offering a diverse, human-annotated dataset comprising 2,808 samples across 13 task categories. We evaluate a wide range of state-of-the-art VLMs in a zero-shot setting, spanning both proprietary and open-source systems. Results show a significant performance gap, with proprietary models (e.g., Gemini 2.5 Pro) outperforming open-source counterparts. Notably, fine-grained text recognition and handwritten content extraction exhibit the steepest performance drops among open-source models. Through detailed error analysis, we identify key challenges such as language bias, structural mismatch, and hallucinated content. ThaiOCRBench provides a standardized framework for assessing VLMs in low-resource, script-complex settings, and provides actionable insights for improving Thai-language document understanding.",
    "fetched_at": "2025-11-09T02:21:28.181996Z"
  },
  {
    "id": "2511.04576v1",
    "title": "Physics-Informed Neural Networks and Neural Operators for Parametric   PDEs: A Human-AI Collaborative Analysis",
    "date": "2025-11-06",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "68T01"
    ],
    "authors": [
      "Zhuo Zhang",
      "Xiong Xiong",
      "Sen Zhang",
      "Yuan Zhao",
      "Xi Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.04576v1",
    "abstract": "PDEs arise ubiquitously in science and engineering, where solutions depend on parameters (physical properties, boundary conditions, geometry). Traditional numerical methods require re-solving the PDE for each parameter, making parameter space exploration prohibitively expensive. Recent machine learning advances, particularly physics-informed neural networks (PINNs) and neural operators, have revolutionized parametric PDE solving by learning solution operators that generalize across parameter spaces. We critically analyze two main paradigms: (1) PINNs, which embed physical laws as soft constraints and excel at inverse problems with sparse data, and (2) neural operators (e.g., DeepONet, Fourier Neural Operator), which learn mappings between infinite-dimensional function spaces and achieve unprecedented generalization. Through comparisons across fluid dynamics, solid mechanics, heat transfer, and electromagnetics, we show neural operators can achieve computational speedups of $10^3$ to $10^5$ times faster than traditional solvers for multi-query scenarios, while maintaining comparable accuracy. We provide practical guidance for method selection, discuss theoretical foundations (universal approximation, convergence), and identify critical open challenges: high-dimensional parameters, complex geometries, and out-of-distribution generalization. This work establishes a unified framework for understanding parametric PDE solvers via operator learning, offering a comprehensive, incrementally updated resource for this rapidly evolving field",
    "fetched_at": "2025-11-09T02:21:28.180516Z"
  },
  {
    "id": "2511.03363v1",
    "title": "A Modular, Data-Free Pipeline for Multi-Label Intention Recognition in   Transportation Agentic AI Applications",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiaocai Zhang",
      "Hur Lim",
      "Ke Wang",
      "Zhe Xiao",
      "Jing Wang",
      "Kelvin Lee",
      "Xiuju Fu",
      "Zheng Qin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03363v1",
    "abstract": "In this study, a modular, data-free pipeline for multi-label intention recognition is proposed for agentic AI applications in transportation. Unlike traditional intent recognition systems that depend on large, annotated corpora and often struggle with fine-grained, multi-label discrimination, our approach eliminates the need for costly data collection while enhancing the accuracy of multi-label intention understanding. Specifically, the overall pipeline, named DMTC, consists of three steps: 1) using prompt engineering to guide large language models (LLMs) to generate diverse synthetic queries in different transport scenarios; 2) encoding each textual query with a Sentence-T5 model to obtain compact semantic embeddings; 3) training a lightweight classifier using a novel online focal-contrastive (OFC) loss that emphasizes hard samples and maximizes inter-class separability. The applicability of the proposed pipeline is demonstrated in an agentic AI application in the maritime transportation context. Extensive experiments show that DMTC achieves a Hamming loss of 5.35% and an AUC of 95.92%, outperforming state-of-the-art multi-label classifiers and recent end-to-end SOTA LLM-based baselines. Further analysis reveals that Sentence-T5 embeddings improve subset accuracy by at least 3.29% over alternative encoders, and integrating the OFC loss yields an additional 0.98% gain compared to standard contrastive objectives. In conclusion, our system seamlessly routes user queries to task-specific modules (e.g., ETA information, traffic risk evaluation, and other typical scenarios in the transportation domain), laying the groundwork for fully autonomous, intention-aware agents without costly manual labelling.",
    "fetched_at": "2025-11-11T02:19:08.307915Z"
  },
  {
    "id": "2511.03370v1",
    "title": "EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models   for Edge-Deployable Credit Negotiation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yunbo Long",
      "Yuhan Liu",
      "Alexandra Brintrup"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03370v1",
    "abstract": "The deployment of large language models (LLMs) in automated negotiation has set a high performance benchmark, but their computational cost and data privacy requirements render them unsuitable for many privacy-sensitive, on-device applications such as mobile assistants, embodied AI agents or private client interactions. While small language models (SLMs) offer a practical alternative, they suffer from a significant performance gap compared to LLMs in playing emotionally charged complex personas, especially for credit negotiation. This paper introduces EQ-Negotiator, a novel framework that bridges this capability gap using emotional personas. Its core is a reasoning system that integrates game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional states online, without pre-training. This allows EQ-Negotiator to equip SLMs with the strategic intelligence to counter manipulation while de-escalating conflict and upholding ethical standards. Through extensive agent-to-agent simulations across diverse credit negotiation scenarios, including adversarial debtor strategies like cheating, threatening, and playing the victim, we show that a 7B parameter language model with EQ-Negotiator achieves better debt recovery and negotiation efficiency than baseline LLMs more than 10 times its size. This work advances persona modeling from descriptive character profiles to dynamic emotional architectures that operate within privacy constraints. Besides, this paper establishes that strategic emotional intelligence, not raw model scale, is the critical factor for success in automated negotiation, paving the way for effective, ethical, and privacy-preserving AI negotiators that can operate on the edge.",
    "fetched_at": "2025-11-11T02:19:08.307835Z"
  },
  {
    "id": "2511.03434v1",
    "title": "Inter-Agent Trust Models: A Comparative Study of Brief, Claim, Proof,   Stake, Reputation and Constraint in Agentic Web Protocol Design-A2A, AP2,   ERC-8004, and Beyond",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA",
      "cs.NI",
      "NI",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Botao 'Amber' Hu",
      "Helena Rong"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2511.03434v1",
    "abstract": "As the \"agentic web\" takes shape-billions of AI agents (often LLM-powered) autonomously transacting and collaborating-trust shifts from human oversight to protocol design. In 2025, several inter-agent protocols crystallized this shift, including Google's Agent-to-Agent (A2A), Agent Payments Protocol (AP2), and Ethereum's ERC-8004 \"Trustless Agents,\" yet their underlying trust assumptions remain under-examined. This paper presents a comparative study of trust models in inter-agent protocol design: Brief (self- or third-party verifiable claims), Claim (self-proclaimed capabilities and identity, e.g. AgentCard), Proof (cryptographic verification, including zero-knowledge proofs and trusted execution environment attestations), Stake (bonded collateral with slashing and insurance), Reputation (crowd feedback and graph-based trust signals), and Constraint (sandboxing and capability bounding). For each, we analyze assumptions, attack surfaces, and design trade-offs, with particular emphasis on LLM-specific fragilities-prompt injection, sycophancy/nudge-susceptibility, hallucination, deception, and misalignment-that render purely reputational or claim-only approaches brittle. Our findings indicate no single mechanism suffices. We argue for trustless-by-default architectures anchored in Proof and Stake to gate high-impact actions, augmented by Brief for identity and discovery and Reputation overlays for flexibility and social signals. We comparatively evaluate A2A, AP2, ERC-8004 and related historical variations in academic research under metrics spanning security, privacy, latency/cost, and social robustness (Sybil/collusion/whitewashing resistance). We conclude with hybrid trust model recommendations that mitigate reputation gaming and misinformed LLM behavior, and we distill actionable design guidelines for safer, interoperable, and scalable agent economies.",
    "fetched_at": "2025-11-11T02:19:08.307710Z"
  },
  {
    "id": "2511.03475v1",
    "title": "RAGBoost: Efficient Retrieval-Augmented Generation with   Accuracy-Preserving Context Reuse",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yinsicheng Jiang",
      "Yeqi Huang",
      "Liang Cheng",
      "Cheng Deng",
      "Xuan Sun",
      "Luo Mai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03475v1",
    "abstract": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with retrieved context but often suffers from downgraded prefill performance as modern applications demand longer and more complex inputs. Existing caching techniques either preserve accuracy with low cache reuse or improve reuse at the cost of degraded reasoning quality. We present RAGBoost, an efficient RAG system that achieves high cache reuse without sacrificing accuracy through accuracy-preserving context reuse. RAGBoost detects overlapping retrieved items across concurrent sessions and multi-turn interactions, using efficient context indexing, ordering, and de-duplication to maximize reuse, while lightweight contextual hints maintain reasoning fidelity. It integrates seamlessly with existing LLM inference engines and improves their prefill performance by 1.5-3X over state-of-the-art methods, while preserving or even enhancing reasoning accuracy across diverse RAG and agentic AI workloads. Our code is released at: https://github.com/Edinburgh-AgenticAI/RAGBoost.",
    "fetched_at": "2025-11-11T02:19:08.307660Z"
  },
  {
    "id": "2511.03497v1",
    "title": "ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied   AI Applications",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Lei Fu",
      "Sahar Salimpour",
      "Leonardo Militano",
      "Harry Edelman",
      "Jorge Pea Queralta",
      "Giovanni Toffetti"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.03497v1",
    "abstract": "Agentic AI systems and Physical or Embodied AI systems have been two key research verticals at the forefront of Artificial Intelligence and Robotics, with Model Context Protocol (MCP) increasingly becoming a key component and enabler of agentic applications. However, the literature at the intersection of these verticals, i.e., Agentic Embodied AI, remains scarce. This paper introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for analyzing, visualizing and processing robot data with natural language through LLMs and VLMs. We describe specific tooling built with robotics domain knowledge, with our initial release focused on mobile robotics and supporting natively the analysis of trajectories, laser scan data, transforms, or time series data. This is in addition to providing an interface to standard ROS 2 CLI tools (\"ros2 bag list\" or \"ros2 bag info\"), as well as the ability to filter bags with a subset of topics or trimmed in time. Coupled with the MCP server, we provide a lightweight UI that allows the benchmarking of the tooling with different LLMs, both proprietary (Anthropic, OpenAI) and open-source (through Groq). Our experimental results include the analysis of tool calling capabilities of eight different state-of-the-art LLM/VLM models, both proprietary and open-source, large and small. Our experiments indicate that there is a large divide in tool calling capabilities, with Kimi K2 and Claude Sonnet 4 demonstrating clearly superior performance. We also conclude that there are multiple factors affecting the success rates, from the tool description schema to the number of arguments, as well as the number of tools available to the models. The code is available with a permissive license at https://github.com/binabik-ai/mcp-rosbags.",
    "fetched_at": "2025-11-11T02:19:08.307608Z"
  },
  {
    "id": "2511.03517v1",
    "title": "U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Wencheng Ye",
      "Yan Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03517v1",
    "abstract": "Large language models (LLMs) have shown strong capabilities in software engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle well-defined problems using conventional methods, often overlooking alternative or innovative solutions beyond their predefined frameworks. This limitation is evident in open-world software environments, where emerging challenges transcend established paradigms.   We propose U2F (Unknown Unknowns to Functional solutions), a cognitive-inspired, uncertainty-embracing multi-agent framework that systematically surfaces \"Unknown Unknowns\" - novel solution pathways absent from initial formulations but holding innovative potential. U2F consists of two key components: (1) a Discovery-Exploration-Integration agent system for uncovering and synthesizing potential solutions, and (2) cognitive enhancement mechanisms across three dimensions: cross-domain analogical reasoning, reverse thinking, and external validation, which strategically reframe and extend conventional solution boundaries.   Applied to 218 real-world software enabler stories curated from authentic engineering tasks, U2F achieved notable improvements: human experts reported a 14 percent increase in overall novelty, 51 percent improvement in semantic novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based evaluator. These results highlight the potential of embracing uncertainty as a catalyst for innovation in software engineering.",
    "fetched_at": "2025-11-11T02:19:08.307478Z"
  },
  {
    "id": "2511.03542v1",
    "title": "SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across   Medical Specialties",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Roberta Di Marino",
      "Giovanni Dioguardi",
      "Antonio Romano",
      "Giuseppe Riccio",
      "Mariano Barone",
      "Marco Postiglione",
      "Flora Amato",
      "Vincenzo Moscato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03542v1",
    "abstract": "Medical question answering systems face deployment challenges including hallucinations, bias, computational demands, privacy concerns, and the need for specialized expertise across diverse domains. Here, we present SOLVE-Med, a multi-agent architecture combining domain-specialized small language models for complex medical queries. The system employs a Router Agent for dynamic specialist selection, ten specialized models (1B parameters each) fine-tuned on specific medical domains, and an Orchestrator Agent that synthesizes responses. Evaluated on Italian medical forum data across ten specialties, SOLVE-Med achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697, outperforming standalone models up to 14B parameters while enabling local deployment. Our code is publicly available on GitHub: https://github.com/PRAISELab-PicusLab/SOLVE-Med.",
    "fetched_at": "2025-11-11T02:19:08.307436Z"
  },
  {
    "id": "2511.03628v1",
    "title": "LiveTradeBench: Seeking Real-World Alpha with Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Haofei Yu",
      "Fenghai Li",
      "Jiaxuan You"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03628v1",
    "abstract": "Large language models (LLMs) achieve strong performance across benchmarks--from knowledge quizzes and math reasoning to web-agent tasks--but these tests occur in static settings, lacking real dynamics and uncertainty. Consequently, they evaluate isolated reasoning or problem-solving rather than decision-making under uncertainty. To address this, we introduce LiveTradeBench, a live trading environment for evaluating LLM agents in realistic and evolving markets. LiveTradeBench follows three design principles: (i) Live data streaming of market prices and news, eliminating dependence on offline backtesting and preventing information leakage while capturing real-time uncertainty; (ii) a portfolio-management abstraction that extends control from single-asset actions to multi-asset allocation, integrating risk management and cross-asset reasoning; and (iii) multi-market evaluation across structurally distinct environments--U.S. stocks and Polymarket prediction markets--differing in volatility, liquidity, and information flow. At each step, an agent observes prices, news, and its portfolio, then outputs percentage allocations that balance risk and return. Using LiveTradeBench, we run 50-day live evaluations of 21 LLMs across families. Results show that (1) high LMArena scores do not imply superior trading outcomes; (2) models display distinct portfolio styles reflecting risk appetite and reasoning dynamics; and (3) some LLMs effectively leverage live signals to adapt decisions. These findings expose a gap between static evaluation and real-world competence, motivating benchmarks that test sequential decision making and consistency under live uncertainty.",
    "fetched_at": "2025-11-11T02:19:08.307313Z"
  },
  {
    "id": "2511.03844v1",
    "title": "ASAP: an Agentic Solution to Auto-optimize Performance of Large-Scale   LLM Training",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Yuran Ding",
      "Xinwei Chen",
      "Xiaofan Zhang",
      "Zongwei Zhou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03844v1",
    "abstract": "Optimizing large-language model (LLM) training on distributed domain-specific accelerator systems presents significant challenges due to its complex optimization space. Existing optimization methods, however, rely on time-consuming manual tuning or resource-intensive black-box searches, which struggle to keep pace with the rapidly evolving LLM domain, leading to slow development and underutilized resources. To address this, we introduce ASAP, an Agentic Solution to Auto-optimize Performance of Large-Scale LLM Training. It is a multi-agent system, featuring Coordinator, Analyzer, and Proposal agents, which integrates LLM reasoning with insights from performance profiling tools, roofline analysis, and a knowledge base of best practices and successful past optimizations from human experts. Our proposed design can automate the diagnosis of performance bottlenecks and recommend optimized sharding configurations with reasoning, thus effectively improving the efficiency of distributed LLM training. Experiments have shown that the ASAP-generated sharding configurations can contribute up to 28% training step time reduction and 1.43 times throughput improvement. When combined with additional optimization from human experts, throughput can be further increased to 2.58 times. The proposed ASAP promises to provide a scalable and explainable methodology for AI-assisted performance engineering in large-scale LLM training.",
    "fetched_at": "2025-11-11T02:19:08.306993Z"
  },
  {
    "id": "2511.03845v1",
    "title": "To See or To Read: User Behavior Reasoning in Multimodal LLMs",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianning Dong",
      "Luyi Ma",
      "Varun Vasudevan",
      "Jason Cho",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03845v1",
    "abstract": "Multimodal Large Language Models (MLLMs) are reshaping how modern agentic systems reason over sequential user-behavior data. However, whether textual or image representations of user behavior data are more effective for maximizing MLLM performance remains underexplored. We present \\texttt{BehaviorLens}, a systematic benchmarking framework for assessing modality trade-offs in user-behavior reasoning across six MLLMs by representing transaction data as (1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a real-world purchase-sequence dataset, we find that when data is represented as images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared with an equivalent textual representation without any additional computational cost.",
    "fetched_at": "2025-11-11T02:19:08.306943Z"
  },
  {
    "id": "2511.03852v1",
    "title": "GAIA: Geothermal Analytics and Intelligent Agent",
    "date": "2025-11-05",
    "tags": [
      "physics.geo-ph",
      "geo-ph"
    ],
    "authors": [
      "Randy Harsuko",
      "Zhengfa Bi",
      "Nori Nakata"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03852v1",
    "abstract": "Geothermal field development typically involves complex processes that require multi-disciplinary expertise in each process. Thus, decision-making often demands the integration of geological, geophysical, reservoir engineering, and operational data under tight time constraints. We present Geothermal Analytics and Intelligent Agent, or GAIA, an AI-based system for automation and assistance in geothermal field development. GAIA consists of three core components: GAIA Agent, GAIA Chat, and GAIA Digital Twin, or DT, which together constitute an agentic retrieval-augmented generation (RAG) workflow. Specifically, GAIA Agent, powered by a pre-trained large language model (LLM), designs and manages task pipelines by autonomously querying knowledge bases and orchestrating multi-step analyses. GAIA DT encapsulates classical and surrogate physics models, which, combined with built-in domain-specific subroutines and visualization tools, enable predictive modeling of geothermal systems. Lastly, GAIA Chat serves as a web-based interface for users, featuring a ChatGPT-like layout with additional functionalities such as interactive visualizations, parameter controls, and in-context document retrieval. To ensure GAIA's specialized capability for handling complex geothermal-related tasks, we curate a benchmark test set comprising various geothermal-related use cases, and we rigorously and continuously evaluate the system's performance. We envision GAIA as a pioneering step toward intelligent geothermal field development, capable of assisting human experts in decision-making, accelerating project workflows, and ultimately enabling automation of the development process.",
    "fetched_at": "2025-11-11T02:19:08.306893Z"
  },
  {
    "id": "2511.03878v1",
    "title": "KnowThyself: An Agentic Assistant for LLM Interpretability",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA",
      "I.2.7; I.2.0",
      "0"
    ],
    "authors": [
      "Suraj Prasai",
      "Mengnan Du",
      "Ying Zhang",
      "Fan Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03878v1",
    "abstract": "We develop KnowThyself, an agentic assistant that advances large language model (LLM) interpretability. Existing tools provide useful insights but remain fragmented and code-intensive. KnowThyself consolidates these capabilities into a chat-based interface, where users can upload models, pose natural language questions, and obtain interactive visualizations with guided explanations. At its core, an orchestrator LLM first reformulates user queries, an agent router further directs them to specialized modules, and the outputs are finally contextualized into coherent explanations. This design lowers technical barriers and provides an extensible platform for LLM inspection. By embedding the whole process into a conversational workflow, KnowThyself offers a robust foundation for accessible LLM interpretability.",
    "fetched_at": "2025-11-11T02:19:08.306831Z"
  },
  {
    "id": "2511.03908v1",
    "title": "Context informs pragmatic interpretation in vision-language models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alvin Wei Ming Tan",
      "Ben Prystawski",
      "Veronica Boyce",
      "Michael C. Frank"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03908v1",
    "abstract": "Iterated reference games - in which players repeatedly pick out novel referents using language - present a test case for agents' ability to perform context-sensitive pragmatic reasoning in multi-turn linguistic environments. We tested humans and vision-language models on trials from iterated reference games, varying the given context in terms of amount, order, and relevance. Without relevant context, models were above chance but substantially worse than humans. However, with relevant context, model performance increased dramatically over trials. Few-shot reference games with abstract referents remain a difficult task for machine learning models.",
    "fetched_at": "2025-11-11T02:19:08.306785Z"
  },
  {
    "id": "2511.03094v1",
    "title": "ALAS: Transactional and Dynamic Multi-Agent LLM Planning",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Longling Geng",
      "Edward Y. Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03094v1",
    "abstract": "Large language models enable flexible multi-agent planning but remain fragile in practice: verification is often circular, state changes are not tracked for repair, and small faults trigger costly global recomputation. We present ALAS, a stateful, disruption-aware framework that separates planning from non-circular validation, records a versioned execution log for grounded checks and restore points, and performs localized repair that preserves work in progress. The validator operates independently of the planning LLM with fresh, bounded context, avoiding self-check loops and mid-context attrition. The repair protocol edits only the minimal affected region under explicit policies (retry, catch, timeout, backoff, idempotency keys, compensation, loop guards) defined in a canonical workflow IR that maps to Amazon States Language and Argo Workflows. On job-shop scheduling suites (DMU, TA) across five classical benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent baselines, achieving 83.7% success, reducing token usage by 60%, and running 1.82times faster under comparable settings. A minimal reliability study shows that the validator detects injected structural faults with low overhead, and that localized repair contains runtime perturbations with a bounded edit radius and less makespan degradation than global recompute. Results indicate that the combination of validator isolation, versioned execution logs, and localized repair provides measurable efficiency, feasibility, and scalability for multi-agent LLM planning. Code and seeds will be released.",
    "fetched_at": "2025-11-11T02:19:06.857950Z"
  },
  {
    "id": "2511.03100v1",
    "title": "Scaling Multi-Agent Environment Co-Design with Diffusion Models",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Hao Xiang Li",
      "Michael Amir",
      "Amanda Prorok"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03100v1",
    "abstract": "The agent-environment co-design paradigm jointly optimises agent policies and environment configurations in search of improved system performance. With application domains ranging from warehouse logistics to windfarm management, co-design promises to fundamentally change how we deploy multi-agent systems. However, current co-design methods struggle to scale. They collapse under high-dimensional environment design spaces and suffer from sample inefficiency when addressing moving targets inherent to joint optimisation. We address these challenges by developing Diffusion Co-Design (DiCoDe), a scalable and sample-efficient co-design framework pushing co-design towards practically relevant settings. DiCoDe incorporates two core innovations. First, we introduce Projected Universal Guidance (PUG), a sampling technique that enables DiCoDe to explore a distribution of reward-maximising environments while satisfying hard constraints such as spatial separation between obstacles. Second, we devise a critic distillation mechanism to share knowledge from the reinforcement learning critic, ensuring that the guided diffusion model adapts to evolving agent policies using a dense and up-to-date learning signal. Together, these improvements lead to superior environment-policy pairs when validated on challenging multi-agent environment co-design benchmarks including warehouse automation, multi-agent pathfinding and wind farm optimisation. Our method consistently exceeds the state-of-the-art, achieving, for example, 39% higher rewards in the warehouse setting with 66% fewer simulation samples. This sets a new standard in agent-environment co-design, and is a stepping stone towards reaping the rewards of co-design in real world domains.",
    "fetched_at": "2025-11-11T02:19:06.857907Z"
  },
  {
    "id": "2511.03138v3",
    "title": "DeepKnown-Guard: A Proprietary Model-Based Safety Response Framework for   AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qi Li",
      "Jianjun Xu",
      "Pingtao Wei",
      "Jiu Li",
      "Peiqiang Zhao",
      "Jiwei Shi",
      "Xuan Zhang",
      "Yanhui Yang",
      "Xiaodong Hui",
      "Peng Xu",
      "Wenqin Shao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03138v3",
    "abstract": "With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response framework designed to systematically safeguard LLMs at both the input and output levels. At the input level, the framework employs a supervised fine-tuning-based safety classification model. Through a fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused Attention), it performs precise risk identification and differentiated handling of user queries, significantly enhancing risk coverage and business scenario adaptability, and achieving a risk recall rate of 99.3%. At the output level, the framework integrates Retrieval-Augmented Generation (RAG) with a specifically fine-tuned interpretation model, ensuring all responses are grounded in a real-time, trustworthy knowledge base. This approach eliminates information fabrication and enables result traceability. Experimental results demonstrate that our proposed safety control model achieves a significantly higher safety score on public safety evaluation benchmarks compared to the baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk test set, the framework's components attained a perfect 100% safety score, validating their exceptional protective capabilities in complex risk scenarios. This research provides an effective engineering pathway for building high-security, high-trust LLM applications.",
    "fetched_at": "2025-11-11T02:19:06.857846Z"
  },
  {
    "id": "2511.03153v1",
    "title": "RefAgent: A Multi-agent LLM-based Framework for Automatic Software   Refactoring",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Khouloud Oueslati",
      "Maxime Lamothe",
      "Foutse Khomh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03153v1",
    "abstract": "Large Language Models (LLMs) have substantially influenced various software engineering tasks. Indeed, in the case of software refactoring, traditional LLMs have shown the ability to reduce development time and enhance code quality. However, these LLMs often rely on static, detailed instructions for specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving contexts and autonomously make decisions by interacting with software tools and executing workflows. In this paper, we explore the potential of LLM-based agents in supporting refactoring activities. Specifically, we introduce RefAgent, a multi-agent LLM-based framework for end-to-end software refactoring. RefAgent consists of specialized agents responsible for planning, executing, testing, and iteratively refining refactorings using self-reflection and tool-calling capabilities. We evaluate RefAgent on eight open-source Java projects, comparing its effectiveness against a single-agent approach, a search-based refactoring tool, and historical developer refactorings. Our assessment focuses on: (1) the impact of generated refactorings on software quality, (2) the ability to identify refactoring opportunities, and (3) the contribution of each LLM agent through an ablation study. Our results show that RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a median of 52.5%, and improves key quality attributes (e.g., reusability) by a median of 8.6%. Additionally, it closely aligns with developer refactorings and the search-based tool in identifying refactoring opportunities, attaining a median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent approaches, RefAgent improves the median unit test pass rate by 64.7% and the median compilation success rate by 40.1%. These findings highlight the promise of multi-agent architectures in advancing automated software refactoring.",
    "fetched_at": "2025-11-11T02:19:06.857775Z"
  },
  {
    "id": "2511.03187v2",
    "title": "Periodic Skill Discovery",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Jonghae Park",
      "Daesol Cho",
      "Jusuk Lee",
      "Dongseok Shim",
      "Inkyu Jang",
      "H. Jin Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03187v2",
    "abstract": "Unsupervised skill discovery in reinforcement learning (RL) aims to learn diverse behaviors without relying on external rewards. However, current methods often overlook the periodic nature of learned skills, focusing instead on increasing the mutual dependence between states and skills or maximizing the distance traveled in latent space. Considering that many robotic tasks - particularly those involving locomotion - require periodic behaviors across varying timescales, the ability to discover diverse periodic skills is essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a framework that discovers periodic behaviors in an unsupervised manner. The key idea of PSD is to train an encoder that maps states to a circular latent space, thereby naturally encoding periodicity in the latent representation. By capturing temporal distance, PSD can effectively learn skills with diverse periods in complex robotic tasks, even with pixel-based observations. We further show that these learned skills achieve high performance on downstream tasks such as hurdling. Moreover, integrating PSD with an existing skill discovery method offers more diverse behaviors, thus broadening the agent's repertoire. Our code and demos are available at https://jonghaepark.github.io/psd/",
    "fetched_at": "2025-11-11T02:19:06.857725Z"
  },
  {
    "id": "2511.03217v1",
    "title": "Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language   Models, and Search-Based Retrieval Agents Improves Interpretable Claim   Verification",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "cs.IR",
      "IR",
      "68T50",
      "I.2.7; H.3.3",
      "3"
    ],
    "authors": [
      "Shaghayegh Kolli",
      "Richard Rosenbaum",
      "Timo Cavelius",
      "Lasse Strothe",
      "Andrii Lata",
      "Jana Diesner"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03217v1",
    "abstract": "Large language models (LLMs) excel in generating fluent utterances but can lack reliable grounding in verified information. At the same time, knowledge-graph-based fact-checkers deliver precise and interpretable evidence, yet suffer from limited coverage or latency. By integrating LLMs with knowledge graphs and real-time search agents, we introduce a hybrid fact-checking approach that leverages the individual strengths of each component. Our system comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid one-hop lookups in DBpedia, 2) an LM-based classification guided by a task-specific labeling prompt, producing outputs with internal rule-based logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient. Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the Supported/Refuted split without task-specific fine-tuning. To address Not enough information cases, we conduct a targeted reannotation study showing that our approach frequently uncovers valid evidence for claims originally labeled as Not Enough Information (NEI), as confirmed by both expert annotators and LLM reviewers. With this paper, we present a modular, opensource fact-checking pipeline with fallback strategies and generalization across datasets.",
    "fetched_at": "2025-11-11T02:19:06.857673Z"
  },
  {
    "id": "2511.03305v1",
    "title": "DRL-Based Robust Multi-Timescale Anti-Jamming Approaches under State   Uncertainty",
    "date": "2025-11-05",
    "tags": [
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Haoqin Zhao",
      "Zan Li",
      "Jiangbo Si",
      "Rui Huang",
      "Hang Hu",
      "Tony Q. S. Quek",
      "Naofal Al-Dhahir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03305v1",
    "abstract": "Owing to the openness of wireless channels, wireless communication systems are highly susceptible to malicious jamming. Most existing anti-jamming methods rely on the assumption of accurate sensing and optimize parameters on a single timescale. However, such methods overlook two practical issues: mismatched execution latencies across heterogeneous actions and measurement errors caused by sensor imperfections. Especially for deep reinforcement learning (DRL)-based methods, the inherent sensitivity of neural networks implies that even minor perturbations in the input can mislead the agent into choosing suboptimal actions, with potentially severe consequences. To ensure reliable wireless transmission, we establish a multi-timescale decision model that incorporates state uncertainty. Subsequently, we propose two robust schemes that sustain performance under bounded sensing errors. First, a Projected Gradient Descent-assisted Double Deep Q-Network (PGD-DDQN) algorithm is designed, which derives worst-case perturbations under a norm-bounded error model and applies PGD during training for robust optimization. Second, a Nonlinear Q-Compression DDQN (NQC-DDQN) algorithm introduces a nonlinear compression mechanism that adaptively contracts Q-value ranges to eliminate action aliasing. Simulation results indicate that, compared with the perfect-sensing baseline, the proposed algorithms show only minor degradation in anti-jamming performance while maintaining robustness under various perturbations, thereby validating their practicality in imperfect sensing conditions.",
    "fetched_at": "2025-11-11T02:19:06.857615Z"
  },
  {
    "id": "2511.03348v2",
    "title": "Learning Communication Skills in Multi-task Multi-agent Deep   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.MA",
      "MA",
      "68T05"
    ],
    "authors": [
      "Changxi Zhu",
      "Mehdi Dastani",
      "Shihan Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03348v2",
    "abstract": "In multi-agent deep reinforcement learning (MADRL), agents can communicate with one another to perform a task in a coordinated manner. When multiple tasks are involved, agents can also leverage knowledge from one task to improve learning in other tasks. In this paper, we propose Multi-task Communication Skills (MCS), a MADRL with communication method that learns and performs multiple tasks simultaneously, with agents interacting through learnable communication protocols. MCS employs a Transformer encoder to encode task-specific observations into a shared message space, capturing shared communication skills among agents. To enhance coordination among agents, we introduce a prediction network that correlates messages with the actions of sender agents in each task. We adapt three multi-agent benchmark environments to multi-task settings, where the number of agents as well as the observation and action spaces vary across tasks. Experimental results demonstrate that MCS achieves better performance than multi-task MADRL baselines without communication, as well as single-task MADRL baselines with and without communication.",
    "fetched_at": "2025-11-11T02:19:06.857555Z"
  },
  {
    "id": "2511.03404v1",
    "title": "Towards Realistic Project-Level Code Generation via Multi-Agent   Collaboration and Semantic Architecture Modeling",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Qianhui Zhao",
      "Li Zhang",
      "Fang Liu",
      "Junhang Cheng",
      "Chengru Wu",
      "Junchen Ai",
      "Qiaoyuanhe Meng",
      "Lichen Zhang",
      "Xiaoli Lian",
      "Shubin Song",
      "Yuanping Guo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03404v1",
    "abstract": "In recent years, Large Language Models (LLMs) have achieved remarkable progress in automated code generation. In real-world software engineering, the growing demand for rapid iteration and continuous delivery underscores the importance of project-level code generation, where LLMs are expected to generate complete software projects directly from complex user requirements. Although existing studies have made initial explorations, they still face key limitations, including unrealistic datasets and unreliable evaluation metrics that fail to reflect real-world complexity, the semantic gap between human-written requirements and machine-interpretable structures, and difficulties in managing hierarchical dependencies and maintaining quality throughout the generation process. To address these limitations, we first introduce CodeProjectEval, a project-level code generation dataset built from 18 real-world repositories with 12.7 files and 2,388.6 lines of code per task on average, supplemented with documentation and executable test cases for automatic evaluation. We further propose ProjectGen, a multi-agent framework that decomposes projects into architecture design, skeleton generation, and code filling stages with iterative refinement and memory-based context management. Within this framework, we introduce the Semantic Software Architecture Tree (SSAT), a structured and semantically rich representation that effectively bridges user requirements and source code implementation. Experiments show that ProjectGen achieves state-of-the-art performance, passing 52/124 test cases on the small-scale project-level code generation dataset DevBench, a 57% improvement over the baseline approaches, and 310 test cases on CodeProjectEval, representing an improvement of roughly tenfold compared to the baselines.",
    "fetched_at": "2025-11-11T02:19:06.857512Z"
  },
  {
    "id": "2511.03506v2",
    "title": "HaluMem: Evaluating Hallucinations in Memory Systems of Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ding Chen",
      "Simin Niu",
      "Kehang Li",
      "Peng Liu",
      "Xiangping Zheng",
      "Bo Tang",
      "Xinchi Li",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03506v2",
    "abstract": "Memory systems are key components that enable AI systems such as LLMs and AI agents to achieve long-term learning and sustained interaction. However, during memory storage and retrieval, these systems frequently exhibit memory hallucinations, including fabrication, errors, conflicts, and omissions. Existing evaluations of memory hallucinations are primarily end-to-end question answering, which makes it difficult to localize the operational stage within the memory system where hallucinations arise. To address this, we introduce the Hallucination in Memory Benchmark (HaluMem), the first operation level hallucination evaluation benchmark tailored to memory systems. HaluMem defines three evaluation tasks (memory extraction, memory updating, and memory question answering) to comprehensively reveal hallucination behaviors across different operational stages of interaction. To support evaluation, we construct user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and HaluMem-Long. Both include about 15k memory points and 3.5k multi-type questions. The average dialogue length per user reaches 1.5k and 2.6k turns, with context lengths exceeding 1M tokens, enabling evaluation of hallucinations across different context scales and task complexities. Empirical studies based on HaluMem show that existing memory systems tend to generate and accumulate hallucinations during the extraction and updating stages, which subsequently propagate errors to the question answering stage. Future research should focus on developing interpretable and constrained memory operation mechanisms that systematically suppress hallucinations and improve memory reliability.",
    "fetched_at": "2025-11-11T02:19:06.857438Z"
  },
  {
    "id": "2511.03586v1",
    "title": "PerfDojo: Automated ML Library Generation for Heterogeneous   Architectures",
    "date": "2025-11-05",
    "tags": [
      "cs.PF",
      "PF",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Andrei Ivanov",
      "Siyuan Shen",
      "Gioele Gottardo",
      "Marcin Chrapek",
      "Afif Boudaoud",
      "Timo Schneider",
      "Luca Benini",
      "Torsten Hoefler"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03586v1",
    "abstract": "The increasing complexity of machine learning models and the proliferation of diverse hardware architectures (CPUs, GPUs, accelerators) make achieving optimal performance a significant challenge. Heterogeneity in instruction sets, specialized kernel requirements for different data types and model features (e.g., sparsity, quantization), and architecture-specific optimizations complicate performance tuning. Manual optimization is resource-intensive, while existing automatic approaches often rely on complex hardware-specific heuristics and uninterpretable intermediate representations, hindering performance portability. We introduce PerfLLM, a novel automatic optimization methodology leveraging Large Language Models (LLMs) and Reinforcement Learning (RL). Central to this is PerfDojo, an environment framing optimization as an RL game using a human-readable, mathematically-inspired code representation that guarantees semantic validity through transformations. This allows effective optimization without prior hardware knowledge, facilitating both human analysis and RL agent training. We demonstrate PerfLLM's ability to achieve significant performance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.",
    "fetched_at": "2025-11-11T02:19:06.857370Z"
  },
  {
    "id": "2511.03591v1",
    "title": "Manifold-constrained Hamilton-Jacobi Reachability Learning for   Decentralized Multi-Agent Motion Planning",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Qingyi Chen",
      "Ruiqi Ni",
      "Jun Kim",
      "Ahmed H. Qureshi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03591v1",
    "abstract": "Safe multi-agent motion planning (MAMP) under task-induced constraints is a critical challenge in robotics. Many real-world scenarios require robots to navigate dynamic environments while adhering to manifold constraints imposed by tasks. For example, service robots must carry cups upright while avoiding collisions with humans or other robots. Despite recent advances in decentralized MAMP for high-dimensional systems, incorporating manifold constraints remains difficult. To address this, we propose a manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for decentralized MAMP. Our method solves HJR problems under manifold constraints to capture task-aware safety conditions, which are then integrated into a decentralized trajectory optimization planner. This enables robots to generate motion plans that are both safe and task-feasible without requiring assumptions about other agents' policies. Our approach generalizes across diverse manifold-constrained tasks and scales effectively to high-dimensional multi-agent manipulation problems. Experiments show that our method outperforms existing constrained motion planners and operates at speeds suitable for real-world applications. Video demonstrations are available at https://youtu.be/RYcEHMnPTH8 .",
    "fetched_at": "2025-11-11T02:19:06.857303Z"
  },
  {
    "id": "2511.03616v1",
    "title": "Going Beyond Expert Performance via Deep Implicit Imitation   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03616v1",
    "abstract": "Imitation learning traditionally requires complete state-action demonstrations from optimal or near-optimal experts. These requirements severely limit practical applicability, as many real-world scenarios provide only state observations without corresponding actions and expert performance is often suboptimal. In this paper we introduce a deep implicit imitation reinforcement learning framework that addresses both limitations by combining deep reinforcement learning with implicit imitation learning from observation-only datasets. Our main algorithm, Deep Implicit Imitation Q-Network (DIIQN), employs an action inference mechanism that reconstructs expert actions through online exploration and integrates a dynamic confidence mechanism that adaptively balances expert-guided and self-directed learning. This enables the agent to leverage expert guidance for accelerated training while maintaining capacity to surpass suboptimal expert performance. We further extend our framework with a Heterogeneous Actions DIIQN (HA-DIIQN) algorithm to tackle scenarios where expert and agent possess different action sets, a challenge previously unaddressed in the implicit imitation learning literature. HA-DIIQN introduces an infeasibility detection mechanism and a bridging procedure identifying alternative pathways connecting agent capabilities to expert guidance when direct action replication is impossible. Our experimental results demonstrate that DIIQN achieves up to 130% higher episodic returns compared to standard DQN, while consistently outperforming existing implicit imitation methods that cannot exceed expert performance. In heterogeneous action settings, HA-DIIQN learns up to 64% faster than baselines, leveraging expert datasets unusable by conventional approaches. Extensive parameter sensitivity analysis reveals the framework's robustness across varying dataset sizes and hyperparameter configurations.",
    "fetched_at": "2025-11-11T02:19:06.857254Z"
  },
  {
    "id": "2511.03690v1",
    "title": "The OpenHands Software Agent SDK: A Composable and Extensible Foundation   for Production Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xingyao Wang",
      "Simon Rosenberg",
      "Juan Michelini",
      "Calvin Smith",
      "Hoang Tran",
      "Engel Nyst",
      "Rohit Malhotra",
      "Xuhui Zhou",
      "Valerie Chen",
      "Robert Brennan",
      "Graham Neubig"
    ],
    "institution": "Google, OpenAI",
    "link": "http://arxiv.org/pdf/2511.03690v1",
    "abstract": "Agents are now used widely in the process of software development, but building production-ready software engineering agents is a complex task. Deploying software agents effectively requires flexibility in implementation and experimentation, reliable and secure execution, and interfaces for users to interact with agents. In this paper, we present the OpenHands Software Agent SDK, a toolkit for implementing software development agents that satisfy these desiderata. This toolkit is a complete architectural redesign of the agent components of the popular OpenHands framework for software development agents, which has 64k+ GitHub stars. To achieve flexibility, we design a simple interface for implementing agents that requires only a few lines of code in the default case, but is easily extensible to more complex, full-featured agents with features such as custom tools, memory management, and more. For security and reliability, it delivers seamless local-to-remote execution portability, integrated REST/WebSocket services. For interaction with human users, it can connect directly to a variety of interfaces, such as visual workspaces (VS Code, VNC, browser), command-line interfaces, and APIs. Compared with existing SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and built-in security analysis. Empirical results on SWE-Bench Verified and GAIA benchmarks demonstrate strong performance. Put together, these elements allow the OpenHands Software Agent SDK to provide a practical foundation for prototyping, unlocking new classes of custom applications, and reliably deploying agents at scale.",
    "fetched_at": "2025-11-11T02:19:06.857209Z"
  },
  {
    "id": "2511.03697v1",
    "title": "AnaFlow: Agentic LLM-based Workflow for Reasoning-Driven Explainable and   Sample-Efficient Analog Circuit Sizing",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.AR",
      "AR"
    ],
    "authors": [
      "Mohsen Ahmadzadeh",
      "Kaichang Chen",
      "Georges Gielen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03697v1",
    "abstract": "Analog/mixed-signal circuits are key for interfacing electronics with the physical world. Their design, however, remains a largely handcrafted process, resulting in long and error-prone design cycles. While the recent rise of AI-based reinforcement learning and generative AI has created new techniques to automate this task, the need for many time-consuming simulations is a critical bottleneck hindering the overall efficiency. Furthermore, the lack of explainability of the resulting design solutions hampers widespread adoption of the tools. To address these issues, a novel agentic AI framework for sample-efficient and explainable analog circuit sizing is presented. It employs a multi-agent workflow where specialized Large Language Model (LLM)-based agents collaborate to interpret the circuit topology, to understand the design goals, and to iteratively refine the circuit's design parameters towards the target goals with human-interpretable reasoning. The adaptive simulation strategy creates an intelligent control that yields a high sample efficiency. The AnaFlow framework is demonstrated for two circuits of varying complexity and is able to complete the sizing task fully automatically, differently from pure Bayesian optimization and reinforcement learning approaches. The system learns from its optimization history to avoid past mistakes and to accelerate convergence. The inherent explainability makes this a powerful tool for analog design space exploration and a new paradigm in analog EDA, where AI agents serve as transparent design assistants.",
    "fetched_at": "2025-11-11T02:19:06.857136Z"
  },
  {
    "id": "2511.03724v2",
    "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via   Self-Play and Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Richard Dewey",
      "Janos Botyanszki",
      "Ciamac C. Moallemi",
      "Andrew T. Zheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03724v2",
    "abstract": "AI researchers have long focused on poker-like games as a testbed for environments characterized by multi-player dynamics, imperfect information, and reasoning under uncertainty. While recent breakthroughs have matched elite human play at no-limit Texas hold'em, the multi-player dynamics are subdued: most hands converge quickly with only two players engaged through multiple rounds of bidding. In this paper, we present Solly, the first AI agent to achieve elite human play in reduced-format Liar's Poker, a game characterized by extensive multi-player engagement. We trained Solly using self-play with a model-free, actor-critic, deep reinforcement learning algorithm. Solly played at an elite human level as measured by win rate (won over 50% of hands) and equity (money won) in heads-up and multi-player Liar's Poker. Solly also outperformed large language models (LLMs), including those with reasoning abilities, on the same metrics. Solly developed novel bidding strategies, randomized play effectively, and was not easily exploitable by world-class human players.",
    "fetched_at": "2025-11-11T02:19:06.857086Z"
  },
  {
    "id": "2511.03773v2",
    "title": "Scaling Agent Learning via Experience Synthesis",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Kai Zhang",
      "Bo Liu",
      "Qi Qi",
      "Yifan Wu",
      "Tarun Kalluri",
      "Sara Cao",
      "Yuanhao Xiong",
      "Haibo Tong",
      "Huaxiu Yao",
      "Hengduo Li",
      "Jiacheng Zhu",
      "Xian Li",
      "Dawn Song",
      "Bo Li",
      "Jason Weston",
      "Dat Huynh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03773v2",
    "abstract": "While reinforcement learning (RL) can empower autonomous agents by enabling self-improvement through interaction, its practical adoption remains challenging due to costly rollouts, limited task diversity, unreliable reward signals, and infrastructure complexity, all of which obstruct the collection of scalable experience data. To address these challenges, we introduce DreamGym, the first unified framework designed to synthesize diverse experiences with scalability in mind to enable effective online RL training for autonomous agents. Rather than relying on expensive real-environment rollouts, DreamGym distills environment dynamics into a reasoning-based experience model that derives consistent state transitions and feedback signals through step-by-step reasoning, enabling scalable agent rollout collection for RL. To improve the stability and quality of transitions, DreamGym leverages an experience replay buffer initialized with offline real-world data and continuously enriched with fresh interactions to actively support agent training. To improve knowledge acquisition, DreamGym adaptively generates new tasks that challenge the current agent policy, enabling more effective online curriculum learning. Experiments across diverse environments and agent backbones demonstrate that DreamGym substantially improves RL training, both in fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in RL-ready but costly settings, it matches GRPO and PPO performance using only synthetic interactions. When transferring a policy trained purely on synthetic experiences to real-environment RL, DreamGym yields significant additional performance gains while requiring far fewer real-world interactions, providing a scalable warm-start strategy for general-purpose RL.",
    "fetched_at": "2025-11-11T02:19:06.857040Z"
  },
  {
    "id": "2511.03891v2",
    "title": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using   Class-Based Input Image Composition",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB"
    ],
    "authors": [
      "Hlali Azzeddine",
      "Majid Ben Yakhlef",
      "Soulaiman El Hazzat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03891v2",
    "abstract": "Small, imbalanced datasets and poor input image quality can lead to high false predictions rates with deep learning models. This paper introduces Class-Based Image Composition, an approach that allows us to reformulate training inputs through a fusion of multiple images of the same class into combined visual composites, named Composite Input Images (CoImg). That enhances the intra-class variance and improves the valuable information density per training sample and increases the ability of the model to distinguish between subtle disease patterns. Our method was evaluated on the Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et al., 2024), which contains 2,064 high-resolution optical coherence tomography (OCT) scans of the human retina, representing seven distinct diseases with a significant class imbalance. We constructed a perfectly class-balanced version of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout composite image. To assess the effectiveness of this new representation, we conducted a comparative analysis between the original dataset and its variant using a VGG16 model. A fair comparison was ensured by utilizing the identical model architecture and hyperparameters for all experiments. The proposed approach markedly improved diagnostic results.The enhanced Dataset achieved near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared to a baseline model trained on raw dataset. The false prediction rate was also significantly lower, this demonstrates that the method can producehigh-quality predictions even for weak datasets affected by class imbalance or small sample size.",
    "fetched_at": "2025-11-10T02:23:10.845495Z"
  },
  {
    "id": "2511.03892v1",
    "title": "A general technique for approximating high-dimensional empirical kernel   matrices",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chiraag Kaushik",
      "Justin Romberg",
      "Vidya Muthukumar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03892v1",
    "abstract": "We present simple, user-friendly bounds for the expected operator norm of a random kernel matrix under general conditions on the kernel function $k(\\cdot,\\cdot)$. Our approach uses decoupling results for U-statistics and the non-commutative Khintchine inequality to obtain upper and lower bounds depending only on scalar statistics of the kernel function and a ``correlation kernel'' matrix corresponding to $k(\\cdot,\\cdot)$. We then apply our method to provide new, tighter approximations for inner-product kernel matrices on general high-dimensional data, where the sample size and data dimension are polynomially related. Our method obtains simplified proofs of existing results that rely on the moment method and combinatorial arguments while also providing novel approximation results for the case of anisotropic Gaussian data. Finally, using similar techniques to our approximation result, we show a tighter lower bound on the bias of kernel regression with anisotropic Gaussian data.",
    "fetched_at": "2025-11-10T02:23:10.845444Z"
  },
  {
    "id": "2511.03898v1",
    "title": "Secure Code Generation at Scale with Reflexion",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Arup Datta",
      "Ahmed Aljohani",
      "Hyunsook Do"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03898v1",
    "abstract": "Large language models (LLMs) are now widely used to draft and refactor code, but code that works is not necessarily secure. We evaluate secure code generation using the Instruct Prime, which eliminated compliance-required prompts and cue contamination, and evaluate five instruction-tuned code LLMs using a zero-shot baseline and a three-round reflexion prompting approach. Security is measured using the Insecure Code Detector (ICD), and results are reported by measuring Repair, Regression, and NetGain metrics, considering the programming language and CWE family. Our findings show that insecurity remains common at the first round: roughly 25-33% of programs are insecure at a zero-shot baseline (t0 ). Weak cryptography/config-dependent bugs are the hardest to avoid while templated ones like XSS, code injection, and hard-coded secrets are handled more reliably. Python yields the highest secure rates; C and C# are the lowest, with Java, JS, PHP, and C++ in the middle. Reflexion prompting improves security for all models, improving average accuracy from 70.74% at t0 to 79.43% at t3 , with the largest gains in the first round followed by diminishing returns. The trends with Repair, Regression, and NetGain metrics show that applying one to two rounds produces most of the benefits. A replication package is available at https://doi.org/10.5281/zenodo.17065846.",
    "fetched_at": "2025-11-10T02:23:10.845400Z"
  },
  {
    "id": "2511.03900v1",
    "title": "GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Manh Nguyen",
      "Sunil Gupta",
      "Dai Do",
      "Hung Le"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03900v1",
    "abstract": "Hallucination mitigation remains a persistent challenge for large language models (LLMs), even as model scales grow. Existing approaches often rely on external knowledge sources, such as structured databases or knowledge graphs, accessed through prompting or retrieval. However, prompt-based grounding is fragile and domain-sensitive, while symbolic knowledge integration incurs heavy retrieval and formatting costs. Motivated by knowledge graphs, we introduce Graph-Retrieved Adaptive Decoding (GRAD), a decoding-time method that grounds generation in corpus-derived evidence without retraining. GRAD constructs a sparse token transition graph by accumulating next-token logits across a small retrieved corpus in a single forward pass. During decoding, graph-retrieved logits are max-normalized and adaptively fused with model logits to favor high-evidence continuations while preserving fluency. Across three models and a range of question-answering benchmarks spanning intrinsic, extrinsic hallucination, and factuality tasks, GRAD consistently surpasses baselines, achieving up to 9.7$\\%$ higher intrinsic accuracy, 8.6$\\%$ lower hallucination rates, and 6.9$\\%$ greater correctness compared to greedy decoding, while attaining the highest truth--informativeness product score among all methods. GRAD offers a lightweight, plug-and-play alternative to contrastive decoding and knowledge graph augmentation, demonstrating that statistical evidence from corpus-level token transitions can effectively steer generation toward more truthful and verifiable outputs.",
    "fetched_at": "2025-11-10T02:23:10.845350Z"
  },
  {
    "id": "2511.03907v1",
    "title": "SnappyMeal: Design and Longitudinal Evaluation of a Multimodal AI Food   Logging Application",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "I.2.1; J.3",
      "3"
    ],
    "authors": [
      "Liam Bakar",
      "Zachary Englhardt",
      "Vidya Srinivas",
      "Girish Narayanswamy",
      "Dilini Nissanka",
      "Shwetak Patel",
      "Vikram Iyer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03907v1",
    "abstract": "Food logging, both self-directed and prescribed, plays a critical role in uncovering correlations between diet, medical, fitness, and health outcomes. Through conversations with nutritional experts and individuals who practice dietary tracking, we find current logging methods, such as handwritten and app-based journaling, are inflexible and result in low adherence and potentially inaccurate nutritional summaries. These findings, corroborated by prior literature, emphasize the urgent need for improved food logging methods. In response, we propose SnappyMeal, an AI-powered dietary tracking system that leverages multimodal inputs to enable users to more flexibly log their food intake. SnappyMeal introduces goal-dependent follow-up questions to intelligently seek missing context from the user and information retrieval from user grocery receipts and nutritional databases to improve accuracy. We evaluate SnappyMeal through publicly available nutrition benchmarks and a multi-user, 3-week, in-the-wild deployment capturing over 500 logged food instances. Users strongly praised the multiple available input methods and reported a strong perceived accuracy. These insights suggest that multimodal AI systems can be leveraged to significantly improve dietary tracking flexibility and context-awareness, laying the groundwork for a new class of intelligent self-tracking applications.",
    "fetched_at": "2025-11-10T02:23:10.845300Z"
  },
  {
    "id": "2511.03909v1",
    "title": "Vectorized Computation of Euler Characteristic Functions and Transforms",
    "date": "2025-11-05",
    "tags": [
      "cs.CG",
      "CG",
      "cs.LG",
      "LG",
      "math.AT",
      "AT",
      "55N31, 55-08"
    ],
    "authors": [
      "Jessi Cisewski-Kehe",
      "Brittany Terese Fasy",
      "Alexander McCleary",
      "Eli Quist",
      "Jack Ruder"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03909v1",
    "abstract": "The weighted Euler characteristic transform (WECT) and Euler characteristic function (ECF) have proven to be useful tools in a variety of applications. However, current methods for computing these functions are neither optimized for speed nor do they scale to higher-dimensional settings. In this work, we present a vectorized framework for computing such topological transforms using tensor operations, which is highly optimized for GPU architectures and works in full generality across geometric simplicial complexes (or cubical complexes) of arbitrary dimension. Experimentally, the framework demonstrates significant speedups (up to $180 \\times$) over existing methods when computing the WECT and ECF across a variety of image datasets. Computation of these transforms is implemented in a publicly available Python package called pyECT.",
    "fetched_at": "2025-11-10T02:23:10.845195Z"
  },
  {
    "id": "2511.03911v1",
    "title": "DecoHD: Decomposed Hyperdimensional Classification under Extreme Memory   Budgets",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sanggeon Yun",
      "Hyunwoo Oh",
      "Ryozo Masukawa",
      "Mohsen Imani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03911v1",
    "abstract": "Decomposition is a proven way to shrink deep networks without changing I/O. We bring this idea to hyperdimensional computing (HDC), where footprint cuts usually shrink the feature axis and erode concentration and robustness. Prior HDC decompositions decode via fixed atomic hypervectors, which are ill-suited for compressing learned class prototypes. We introduce DecoHD, which learns directly in a decomposed HDC parameterization: a small, shared set of per-layer channels with multiplicative binding across layers and bundling at the end, yielding a large representational space from compact factors. DecoHD compresses along the class axis via a lightweight bundling head while preserving native bind-bundle-score; training is end-to-end, and inference remains pure HDC, aligning with in/near-memory accelerators. In evaluation, DecoHD attains extreme memory savings with only minor accuracy degradation under tight deployment budgets. On average it stays within about 0.1-0.15% of a strong non-reduced HDC baseline (worst case 5.7%), is more robust to random bit-flip noise, reaches its accuracy plateau with up to ~97% fewer trainable parameters, and -- in hardware -- delivers roughly 277x/35x energy/speed gains over a CPU (AMD Ryzen 9 9950X), 13.5x/3.7x over a GPU (NVIDIA RTX 4090), and 2.0x/2.4x over a baseline HDC ASIC.",
    "fetched_at": "2025-11-10T02:23:10.845145Z"
  },
  {
    "id": "2511.03912v1",
    "title": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic   Weight Averaging-Gaussian for Oracle-Free Medical Imaging",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nand Kumar Yadav",
      "Rodrigue Rizk",
      "William CW Chen",
      "KC Santosh"
    ],
    "institution": "AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA",
    "link": "http://arxiv.org/pdf/2511.03912v1",
    "abstract": "Unknown anomaly detection in medical imaging remains a fundamental challenge due to the scarcity of labeled anomalies and the high cost of expert supervision. We introduce an unsupervised, oracle-free framework that incrementally expands a trusted set of normal samples without any anomaly labels. Starting from a small, verified seed of normal images, our method alternates between lightweight adapter updates and uncertainty-gated sample admission. A frozen pretrained vision backbone is augmented with tiny convolutional adapters, ensuring rapid domain adaptation with negligible computational overhead. Extracted embeddings are stored in a compact coreset enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during incremental expansion is enforced by dual probabilistic gates, a sample is admitted into the normal memory only if its distance to the existing coreset lies within a calibrated z-score threshold, and its SWAG-based epistemic uncertainty remains below a seed-calibrated bound. This mechanism prevents drift and false inclusions without relying on generative reconstruction or replay buffers. Empirically, our system steadily refines the notion of normality as unlabeled data arrive, producing substantial gains over baselines. On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5, ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These results highlight the effectiveness and efficiency of the proposed framework for real-world, label-scarce medical imaging applications.",
    "fetched_at": "2025-11-10T02:23:10.845096Z"
  },
  {
    "id": "2511.03913v1",
    "title": "Evolutionary Optimization Trumps Adam Optimization on Embedding Space   Exploration",
    "date": "2025-11-05",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Domcio Pereira Neto",
      "Joo Correia",
      "Penousal Machado"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03913v1",
    "abstract": "Deep generative models, especially diffusion architectures, have transformed image generation; however, they are challenging to control and optimize for specific goals without expensive retraining. Embedding Space Exploration, especially with Evolutionary Algorithms (EAs), has been shown to be a promising method for optimizing image generation, particularly within Diffusion Models. Therefore, in this work, we study the performance of an evolutionary optimization method, namely Separable Covariance Matrix Adaptation Evolution Strategy (sep-CMA-ES), against the widely adopted Adaptive Moment Estimation (Adam), applied to Stable Diffusion XL Turbo's prompt embedding vector. The evaluation of images combines the LAION Aesthetic Predictor V2 with CLIPScore into a weighted fitness function, allowing flexible trade-offs between visual appeal and adherence to prompts. Experiments on a subset of the Parti Prompts (P2) dataset showcase that sep-CMA-ES consistently yields superior improvements in aesthetic and alignment metrics in comparison to Adam. Results indicate that the evolutionary method provides efficient, gradient-free optimization for diffusion models, enhancing controllability without the need for fine-tuning. This study emphasizes the potential of evolutionary methods for embedding space exploration of deep generative models and outlines future research directions.",
    "fetched_at": "2025-11-10T02:23:10.845057Z"
  },
  {
    "id": "2511.03915v1",
    "title": "The Human Flourishing Geographic Index: A County-Level Dataset for the   United States, 2013--2023",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Stefano M. Iacus",
      "Devika Jain",
      "Andrea Nasuto",
      "Giuseppe Porro",
      "Marcello Carammia",
      "Andrea Vezzulli"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03915v1",
    "abstract": "Quantifying human flourishing, a multidimensional construct including happiness, health, purpose, virtue, relationships, and financial stability, is critical for understanding societal well-being beyond economic indicators. Existing measures often lack fine spatial and temporal resolution. Here we introduce the Human Flourishing Geographic Index (HFGI), derived from analyzing approximately 2.6 billion geolocated U.S. tweets (2013-2023) using fine-tuned large language models to classify expressions across 48 indicators aligned with Harvard's Global Flourishing Study framework plus attitudes towards migration and perception of corruption. The dataset offers monthly and yearly county- and state-level indicators of flourishing-related discourse, validated to confirm that the measures accurately represent the underlying constructs and show expected correlations with established indicators. This resource enables multidisciplinary analyses of well-being, inequality, and social change at unprecedented resolution, offering insights into the dynamics of human flourishing as reflected in social media discourse across the United States over the past decade.",
    "fetched_at": "2025-11-10T02:23:10.845004Z"
  },
  {
    "id": "2511.03138v2",
    "title": "A Proprietary Model-Based Safety Response Framework for AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qi Li",
      "Jianjun Xu",
      "Pingtao Wei",
      "Jiu Li",
      "Peiqiang Zhao",
      "Jiwei Shi",
      "Xuan Zhang",
      "Yanhui Yang",
      "Xiaodong Hui",
      "Peng Xu",
      "Wenqin Shao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03138v2",
    "abstract": "With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response framework designed to systematically safeguard LLMs at both the input and output levels. At the input level, the framework employs a supervised fine-tuning-based safety classification model. Through a fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused Attention), it performs precise risk identification and differentiated handling of user queries, significantly enhancing risk coverage and business scenario adaptability, and achieving a risk recall rate of 99.3%. At the output level, the framework integrates Retrieval-Augmented Generation (RAG) with a specifically fine-tuned interpretation model, ensuring all responses are grounded in a real-time, trustworthy knowledge base. This approach eliminates information fabrication and enables result traceability. Experimental results demonstrate that our proposed safety control model achieves a significantly higher safety score on public safety evaluation benchmarks compared to the baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk test set, the framework's components attained a perfect 100% safety score, validating their exceptional protective capabilities in complex risk scenarios. This research provides an effective engineering pathway for building high-security, high-trust LLM applications.",
    "fetched_at": "2025-11-10T02:23:01.293002Z"
  },
  {
    "id": "2511.03143v1",
    "title": "From Measurement to Expertise: Empathetic Expert Adapters for   Context-Based Empathy in Conversational AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Erfan Shayegani",
      "Jina Suh",
      "Andy Wilson",
      "Nagu Rangan",
      "Javier Hernandez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03143v1",
    "abstract": "Empathy is a critical factor in fostering positive user experiences in conversational AI. While models can display empathy, it is often generic rather than tailored to specific tasks and contexts. In this work, we introduce a novel framework for developing and evaluating context-specific empathetic large language models (LLMs). We first analyze a real-world conversational dataset consisting of 672 multi-turn conversations across 8 tasks, revealing significant differences in terms of expected and experienced empathy before and after the conversations, respectively. To help minimize this gap, we develop a synthetic multi-turn conversational generation pipeline and steer responses toward our defined empathy patterns based on the context that more closely matches users' expectations. We then train empathetic expert adapters for context-specific empathy that specialize in varying empathy levels based on the recognized task. Our empirical results demonstrate a significant gap reduction of 72.66% between perceived and desired empathy with scores increasing by an average factor of 2.43 as measured by our metrics and reward models. Additionally, our trained empathetic expert adapters demonstrate superior effectiveness in preserving empathy patterns throughout conversation turns, outperforming system prompts, which tend to dramatically diminish in impact as conversations lengthen.",
    "fetched_at": "2025-11-10T02:23:01.292899Z"
  },
  {
    "id": "2511.03179v2",
    "title": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent   Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Varun Kumar",
      "George Em Karniadakis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03179v2",
    "abstract": "The engineering design process often demands expertise from multiple domains, leading to complex collaborations and iterative refinements. Traditional methods can be resource-intensive and prone to inefficiencies. To address this, we formalize the engineering design process through a multi-agent AI framework that integrates structured design and review loops. The framework introduces specialized knowledge-driven agents that collaborate to generate and refine design candidates. As an exemplar, we demonstrate its application to the aerodynamic optimization of 4-digit NACA airfoils. The framework consists of three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems Engineer. The Graph Ontologist employs a Large Language Model (LLM) to construct two domain-specific knowledge graphs from airfoil design literature. The Systems Engineer, informed by a human manager, formulates technical requirements that guide design generation and evaluation. The Design Engineer leverages the design knowledge graph and computational tools to propose candidate airfoils meeting these requirements. The Systems Engineer reviews and provides feedback both qualitative and quantitative using its own knowledge graph, forming an iterative feedback loop until a design is validated by the manager. The final design is then optimized to maximize performance metrics such as the lift-to-drag ratio. Overall, this work demonstrates how collaborative AI agents equipped with structured knowledge representations can enhance efficiency, consistency, and quality in the engineering design process.",
    "fetched_at": "2025-11-10T02:23:01.292772Z"
  },
  {
    "id": "2511.03757v1",
    "title": "Laugh, Relate, Engage: Stylized Comment Generation for Short Videos",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xuan Ouyang",
      "Senan Wang",
      "Bouzhou Wang",
      "Siyuan Xiahou",
      "Jinrong Zhou",
      "Yuekang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03757v1",
    "abstract": "Short-video platforms have become a central medium in the modern Internet landscape, where efficient information delivery and strong interactivity are reshaping user engagement and cultural dissemination. Among the various forms of user interaction, comments play a vital role in fostering community participation and enabling content re-creation. However, generating comments that are both compliant with platform guidelines and capable of exhibiting stylistic diversity and contextual awareness remains a significant challenge. We introduce LOLGORITHM, a modular multi-agent system (MAS) designed for controllable short-video comment generation. The system integrates video segmentation, contextual and affective analysis, and style-aware prompt construction. It supports six distinct comment styles: puns (homophones), rhyming, meme application, sarcasm (irony), plain humor, and content extraction. Powered by a multimodal large language model (MLLM), LOLGORITHM directly processes video inputs and achieves fine-grained style control through explicit prompt markers and few-shot examples. To support development and evaluation, we construct a bilingual dataset using official APIs from Douyin (Chinese) and YouTube (English), covering five popular video genres: comedy skits, daily life jokes, funny animal clips, humorous commentary, and talk shows. Evaluation combines automated metrics originality, relevance, and style conformity with a large-scale human preference study involving 40 videos and 105 participants. Results show that LOLGORITHM significantly outperforms baseline models, achieving preference rates of over 90% on Douyin and 87.55% on YouTube. This work presents a scalable and culturally adaptive framework for stylized comment generation on short-video platforms, offering a promising path to enhance user engagement and creative interaction.",
    "fetched_at": "2025-11-10T02:23:01.292664Z"
  },
  {
    "id": "2511.03248v1",
    "title": "Auditing M-LLMs for Privacy Risks: A Synthetic Benchmark and Evaluation   Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Junhao Li",
      "Jiahao Chen",
      "Zhou Feng",
      "Chunyi Zhou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03248v1",
    "abstract": "Recent advances in multi-modal Large Language Models (M-LLMs) have demonstrated a powerful ability to synthesize implicit information from disparate sources, including images and text. These resourceful data from social media also introduce a significant and underexplored privacy risk: the inference of sensitive personal attributes from seemingly daily media content. However, the lack of benchmarks and comprehensive evaluations of state-of-the-art M-LLM capabilities hinders the research of private attribute profiling on social media. Accordingly, we propose (1) PRISM, the first multi-modal, multi-dimensional and fine-grained synthesized dataset incorporating a comprehensive privacy landscape and dynamic user history; (2) an Efficient evaluation framework that measures the cross-modal privacy inference capabilities of advanced M-LLM. Specifically, PRISM is a large-scale synthetic benchmark designed to evaluate cross-modal privacy risks. Its key feature is 12 sensitive attribute labels across a diverse set of multi-modal profiles, which enables targeted privacy analysis. These profiles are generated via a sophisticated LLM agentic workflow, governed by a prior distribution to ensure they realistically mimic social media users. Additionally, we propose a Multi-Agent Inference Framework that leverages a pipeline of specialized LLMs to enhance evaluation capabilities. We evaluate the inference capabilities of six leading M-LLMs (Qwen, Gemini, GPT-4o, GLM, Doubao, and Grok) on PRISM. The comparison with human performance reveals that these MLLMs significantly outperform in accuracy and efficiency, highlighting the threat of potential privacy risks and the urgent need for robust defenses.",
    "fetched_at": "2025-11-10T02:23:01.292604Z"
  },
  {
    "id": "2511.03758v1",
    "title": "Leveraging LLM-based agents for social science research: insights from   citation network simulations",
    "date": "2025-11-05",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "cs.MA",
      "MA",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Jiarui Ji",
      "Runlin Lei",
      "Xuchen Pan",
      "Zhewei Wei",
      "Hao Sun",
      "Yankai Lin",
      "Xu Chen",
      "Yongzheng Yang",
      "Yaliang Li",
      "Bolin Ding",
      "Ji-Rong Wen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03758v1",
    "abstract": "The emergence of Large Language Models (LLMs) demonstrates their potential to encapsulate the logic and patterns inherent in human behavior simulation by leveraging extensive web data pre-training. However, the boundaries of LLM capabilities in social simulation remain unclear. To further explore the social attributes of LLMs, we introduce the CiteAgent framework, designed to generate citation networks based on human-behavior simulation with LLM-based agents. CiteAgent successfully captures predominant phenomena in real-world citation networks, including power-law distribution, citational distortion, and shrinking diameter. Building on this realistic simulation, we establish two LLM-based research paradigms in social science: LLM-SE (LLM-based Survey Experiment) and LLM-LE (LLM-based Laboratory Experiment). These paradigms facilitate rigorous analyses of citation network phenomena, allowing us to validate and challenge existing theories. Additionally, we extend the research scope of traditional science of science studies through idealized social experiments, with the simulation experiment results providing valuable insights for real-world academic environments. Our work demonstrates the potential of LLMs for advancing science of science research in social science.",
    "fetched_at": "2025-11-10T02:23:01.292552Z"
  },
  {
    "id": "2511.03506v1",
    "title": "HaluMem: Evaluating Hallucinations in Memory Systems of Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ding Chen",
      "Simin Niu",
      "Kehang Li",
      "Peng Liu",
      "Xiangping Zheng",
      "Bo Tang",
      "Xinchi Li",
      "Feiyu Xiong",
      "Zhiyu Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03506v1",
    "abstract": "Memory systems are key components that enable AI systems such as LLMs and AI agents to achieve long-term learning and sustained interaction. However, during memory storage and retrieval, these systems frequently exhibit memory hallucinations, including fabrication, errors, conflicts, and omissions. Existing evaluations of memory hallucinations are primarily end-to-end question answering, which makes it difficult to localize the operational stage within the memory system where hallucinations arise. To address this, we introduce the Hallucination in Memory Benchmark (HaluMem), the first operation level hallucination evaluation benchmark tailored to memory systems. HaluMem defines three evaluation tasks (memory extraction, memory updating, and memory question answering) to comprehensively reveal hallucination behaviors across different operational stages of interaction. To support evaluation, we construct user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and HaluMem-Long. Both include about 15k memory points and 3.5k multi-type questions. The average dialogue length per user reaches 1.5k and 2.6k turns, with context lengths exceeding 1M tokens, enabling evaluation of hallucinations across different context scales and task complexities. Empirical studies based on HaluMem show that existing memory systems tend to generate and accumulate hallucinations during the extraction and updating stages, which subsequently propagate errors to the question answering stage. Future research should focus on developing interpretable and constrained memory operation mechanisms that systematically suppress hallucinations and improve memory reliability.",
    "fetched_at": "2025-11-10T02:23:01.292086Z"
  },
  {
    "id": "2511.03773v1",
    "title": "Scaling Agent Learning via Experience Synthesis",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Kai Zhang",
      "Bo Liu",
      "Qi Qi",
      "Yifan Wu",
      "Tarun Kalluri",
      "Sara Cao",
      "Yuanhao Xiong",
      "Haibo Tong",
      "Huaxiu Yao",
      "Hengduo Li",
      "Jiacheng Zhu",
      "Xian Li",
      "Dawn Song",
      "Bo Li",
      "Jason Weston",
      "Dat Huynh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03773v1",
    "abstract": "While reinforcement learning (RL) can empower large language model (LLM) agents by enabling self-improvement through interaction, its practical adoption remains challenging due to costly rollouts, limited task diversity, unreliable reward signals, and infrastructure complexity, all of which obstruct the collection of scalable experience data. To address these challenges, we introduce DreamGym, the first unified framework designed to synthesize diverse experiences with scalability in mind to enable effective online RL training for autonomous agents. Rather than relying on expensive real-environment rollouts, DreamGym distills environment dynamics into a reasoning-based experience model that derives consistent state transitions and feedback signals through step-by-step reasoning, enabling scalable agent rollout collection for RL. To improve the stability and quality of transitions, DreamGym leverages an experience replay buffer initialized with offline real-world data and continuously enriched with fresh interactions to actively support agent training. To improve knowledge acquisition, DreamGym adaptively generates new tasks that challenge the current agent policy, enabling more effective online curriculum learning. Experiments across diverse environments and agent backbones demonstrate that DreamGym substantially improves RL training, both in fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in RL-ready but costly settings, it matches GRPO and PPO performance using only synthetic interactions. When transferring a policy trained purely on synthetic experiences to real-environment RL, DreamGym yields significant additional performance gains while requiring far fewer real-world interactions, providing a scalable warm-start strategy for general-purpose RL.",
    "fetched_at": "2025-11-10T02:23:01.291604Z"
  },
  {
    "id": "2511.03891v1",
    "title": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using   Class-Based Input Image Composition",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.DB",
      "DB"
    ],
    "authors": [
      "Hlali Azzeddine",
      "Majid Ben Yakhlef",
      "Soulaiman El Hazzat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03891v1",
    "abstract": "Small, imbalanced datasets and poor input image quality can lead to high false predictions rates with deep learning models. This paper introduces Class-Based Image Composition, an approach that allows us to reformulate training inputs through a fusion of multiple images of the same class into combined visual composites, named Composite Input Images (CoImg). That enhances the intra-class variance and improves the valuable information density per training sample and increases the ability of the model to distinguish between subtle disease patterns. Our method was evaluated on the Optical Coherence Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et al., 2024), which contains 2,064 high-resolution optical coherence tomography (OCT) scans of the human retina, representing seven distinct diseases with a significant class imbalance. We constructed a perfectly class-balanced version of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout composite image. To assess the effectiveness of this new representation, we conducted a comparative analysis between the original dataset and its variant using a VGG16 model. A fair comparison was ensured by utilizing the identical model architecture and hyperparameters for all experiments. The proposed approach markedly improved diagnostic results.The enhanced Dataset achieved near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared to a baseline model trained on raw dataset. The false prediction rate was also significantly lower, this demonstrates that the method can producehigh-quality predictions even for weak datasets affected by class imbalance or small sample size.",
    "fetched_at": "2025-11-09T02:21:28.189749Z"
  },
  {
    "id": "2511.03187v1",
    "title": "Periodic Skill Discovery",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Jonghae Park",
      "Daesol Cho",
      "Jusuk Lee",
      "Dongseok Shim",
      "Inkyu Jang",
      "H. Jin Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03187v1",
    "abstract": "Unsupervised skill discovery in reinforcement learning (RL) aims to learn diverse behaviors without relying on external rewards. However, current methods often overlook the periodic nature of learned skills, focusing instead on increasing the mutual dependence between states and skills or maximizing the distance traveled in latent space. Considering that many robotic tasks -- particularly those involving locomotion -- require periodic behaviors across varying timescales, the ability to discover diverse periodic skills is essential. Motivated by this, we propose Periodic Skill Discovery (PSD), a framework that discovers periodic behaviors in an unsupervised manner. The key idea of PSD is to train an encoder that maps states to a circular latent space, thereby naturally encoding periodicity in the latent representation. By capturing temporal distance, PSD can effectively learn skills with diverse periods in complex robotic tasks, even with pixel-based observations. We further show that these learned skills achieve high performance on downstream tasks such as hurdling. Moreover, integrating PSD with an existing skill discovery method offers more diverse behaviors, thus broadening the agent's repertoire. Our code and demos are available at https://jonghaepark.github.io/psd/",
    "fetched_at": "2025-11-09T02:21:24.636194Z"
  },
  {
    "id": "2511.03138v1",
    "title": "A Proprietary Model-Based Safety Response Framework for AI Agents",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qi Li",
      "Jianjun Xu",
      "Pingtao Wei",
      "Jiu Li",
      "Peiqiang Zhao",
      "Jiwei Shi",
      "Xuan Zhang",
      "Yanhui Yang",
      "Xiaodong Hui",
      "Peng Xu",
      "Wenqin Shao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03138v1",
    "abstract": "With the widespread application of Large Language Models (LLMs), their associated security issues have become increasingly prominent, severely constraining their trustworthy deployment in critical domains. This paper proposes a novel safety response framework designed to systematically safeguard LLMs at both the input and output levels. At the input level, the framework employs a supervised fine-tuning-based safety classification model. Through a fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused Attention), it performs precise risk identification and differentiated handling of user queries, significantly enhancing risk coverage and business scenario adaptability, and achieving a risk recall rate of 99.3%. At the output level, the framework integrates Retrieval-Augmented Generation (RAG) with a specifically fine-tuned interpretation model, ensuring all responses are grounded in a real-time, trustworthy knowledge base. This approach eliminates information fabrication and enables result traceability. Experimental results demonstrate that our proposed safety control model achieves a significantly higher safety score on public safety evaluation benchmarks compared to the baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk test set, the framework's components attained a perfect 100% safety score, validating their exceptional protective capabilities in complex risk scenarios. This research provides an effective engineering pathway for building high-security, high-trust LLM applications.",
    "fetched_at": "2025-11-09T02:21:22.886424Z"
  },
  {
    "id": "2511.03724v1",
    "title": "Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via   Self-Play and Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Richard Dewey",
      "Janos Botyanszki",
      "Ciamac C. Moallemi",
      "Andrew T. Zheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03724v1",
    "abstract": "AI researchers have long focused on poker-like games as a testbed for environments characterized by multi-player dynamics, imperfect information, and reasoning under uncertainty. While recent breakthroughs have matched elite human play at no-limit Texas hold'em, the multi-player dynamics are subdued: most hands converge quickly with only two players engaged through multiple rounds of bidding. In this paper, we present Solly, the first AI agent to achieve elite human play in reduced-format Liar's Poker, a game characterized by extensive multi-player engagement. We trained Solly using self-play with a model-free, actor-critic, deep reinforcement learning algorithm. Solly played at an elite human level as measured by win rate (won over 50% of hands) and equity (money won) in heads-up and multi-player Liar's Poker. Solly also outperformed large language models (LLMs), including those with reasoning abilities, on the same metrics. Solly developed novel bidding strategies, randomized play effectively, and was not easily exploitable by world-class human players.",
    "fetched_at": "2025-11-09T02:21:22.885241Z"
  },
  {
    "id": "2511.03247v1",
    "title": "Death by a Thousand Prompts: Open Model Vulnerability Analysis",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Amy Chang",
      "Nicholas Conley",
      "Harish Santhanalakshmi Ganesan",
      "Adam Swanda"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2511.03247v1",
    "abstract": "Open-weight models provide researchers and developers with accessible foundations for diverse downstream applications. We tested the safety and security postures of eight open-weight large language models (LLMs) to identify vulnerabilities that may impact subsequent fine-tuning and deployment. Using automated adversarial testing, we measured each model's resilience against single-turn and multi-turn prompt injection and jailbreak attacks. Our findings reveal pervasive vulnerabilities across all tested models, with multi-turn attacks achieving success rates between 25.86\\% and 92.78\\% -- representing a $2\\times$ to $10\\times$ increase over single-turn baselines. These results underscore a systemic inability of current open-weight models to maintain safety guardrails across extended interactions. We assess that alignment strategies and lab priorities significantly influence resilience: capability-focused models such as Llama 3.3 and Qwen 3 demonstrate higher multi-turn susceptibility, whereas safety-oriented designs such as Google Gemma 3 exhibit more balanced performance.   The analysis concludes that open-weight models, while crucial for innovation, pose tangible operational and ethical risks when deployed without layered security controls. These findings are intended to inform practitioners and developers of the potential risks and the value of professional AI security solutions to mitigate exposure. Addressing multi-turn vulnerabilities is essential to ensure the safe, reliable, and responsible deployment of open-weight LLMs in enterprise and public domains. We recommend adopting a security-first design philosophy and layered protections to ensure resilient deployments of open-weight models.",
    "fetched_at": "2025-11-07T02:16:47.497777Z"
  },
  {
    "id": "2511.03251v1",
    "title": "GMoPE:A Prompt-Expert Mixture Framework for Graph Foundation Models",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Zhibin Wang",
      "Zhixing Zhang",
      "Shuqi Wang",
      "Xuanting Xie",
      "Zhao Kang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03251v1",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated impressive performance on task-specific benchmarks, yet their ability to generalize across diverse domains and tasks remains limited. Existing approaches often struggle with negative transfer, scalability issues, and high adaptation costs. To address these challenges, we propose GMoPE (Graph Mixture of Prompt-Experts), a novel framework that seamlessly integrates the Mixture-of-Experts (MoE) architecture with prompt-based learning for graphs. GMoPE leverages expert-specific prompt vectors and structure-aware MoE routing to enable each expert to specialize in distinct subdomains and dynamically contribute to predictions. To promote diversity and prevent expert collapse, we introduce a soft orthogonality constraint across prompt vectors, encouraging expert specialization and facilitating a more balanced expert utilization. Additionally, we adopt a prompt-only fine-tuning strategy that significantly reduces spatiotemporal complexity during transfer. We validate GMoPE through extensive experiments under various pretraining strategies and multiple downstream tasks. Results show that GMoPE consistently outperforms state-of-the-art baselines and achieves performance comparable to full parameter fine-tuning-while requiring only a fraction of the adaptation overhead. Our work provides a principled and scalable framework for advancing generalizable and efficient graph foundation models.",
    "fetched_at": "2025-11-07T02:16:47.497724Z"
  },
  {
    "id": "2511.03255v1",
    "title": "Generative deep learning for foundational video translation in   ultrasound",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nikolina Tomic Roshni Bhatnagar",
      "Sarthak Jain",
      "Connor Lau",
      "Tien-Yu Liu",
      "Laura Gambini",
      "Rima Arnaout"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03255v1",
    "abstract": "Deep learning (DL) has the potential to revolutionize image acquisition and interpretation across medicine, however, attention to data imbalance and missingness is required. Ultrasound data presents a particular challenge because in addition to different views and structures, it includes several sub-modalities-such as greyscale and color flow doppler (CFD)-that are often imbalanced in clinical studies. Image translation can help balance datasets but is challenging for ultrasound sub-modalities to date. Here, we present a generative method for ultrasound CFD-greyscale video translation, trained on 54,975 videos and tested on 8,368. The method developed leveraged pixel-wise, adversarial, and perceptual loses and utilized two networks: one for reconstructing anatomic structures and one for denoising to achieve realistic ultrasound imaging. Average pairwise SSIM between synthetic videos and ground truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real ones in DL classification and segmentation tasks and when evaluated by blinded clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice score between real and synthetic segmentation was 0.97. Overall clinician accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%), indicating realistic synthetic videos. Although trained only on heart videos, the model worked well on ultrasound spanning several clinical domains (average SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data expand the utility of retrospectively collected imaging and augment the dataset design toolbox for medical imaging.",
    "fetched_at": "2025-11-07T02:16:47.497672Z"
  },
  {
    "id": "2511.03256v1",
    "title": "Decoupled Entropy Minimization",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV",
      "cs.IT",
      "IT",
      "math.IT",
      "math.ST",
      "ST",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Jing Ma",
      "Hanlin Li",
      "Xiang Xiang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03256v1",
    "abstract": "Entropy Minimization (EM) is beneficial to reducing class overlap, bridging domain gap, and restricting uncertainty for various tasks in machine learning, yet its potential is limited. To study the internal mechanism of EM, we reformulate and decouple the classical EM into two parts with opposite effects: cluster aggregation driving factor (CADF) rewards dominant classes and prompts a peaked output distribution, while gradient mitigation calibrator (GMC) penalizes high-confidence classes based on predicted probabilities. Furthermore, we reveal the limitations of classical EM caused by its coupled formulation: 1) reward collapse impedes the contribution of high-certainty samples in the learning process, and 2) easy-class bias induces misalignment between output distribution and label distribution. To address these issues, we propose Adaptive Decoupled Entropy Minimization (AdaDEM), which normalizes the reward brought from CADF and employs a marginal entropy calibrator (MEC) to replace GMC. AdaDEM outperforms DEM*, an upper-bound variant of classical EM, and achieves superior performance across various imperfectly supervised learning tasks in noisy and dynamic environments.",
    "fetched_at": "2025-11-07T02:16:47.497612Z"
  },
  {
    "id": "2511.03261v1",
    "title": "Comparing the Performance of LLMs in RAG-based Question-Answering: A   Case Study in Computer Science Literature",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "I.2.1; I.2.7",
      "7"
    ],
    "authors": [
      "Ranul Dayarathne",
      "Uvini Ranaweera",
      "Upeksha Ganegoda"
    ],
    "institution": "Google, Meta, OpenAI",
    "link": "http://arxiv.org/pdf/2511.03261v1",
    "abstract": "Retrieval Augmented Generation (RAG) is emerging as a powerful technique to enhance the capabilities of Generative AI models by reducing hallucination. Thus, the increasing prominence of RAG alongside Large Language Models (LLMs) has sparked interest in comparing the performance of different LLMs in question-answering (QA) in diverse domains. This study compares the performance of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat, Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA tasks within the computer science literature leveraging RAG support. Evaluation metrics employed in the study include accuracy and precision for binary questions and ranking by a human expert, ranking by Google's AI model Gemini, alongside cosine similarity for long-answer questions. GPT-3.5, when paired with RAG, effectively answers binary and long-answer questions, reaffirming its status as an advanced LLM. Regarding open-source LLMs, Mistral AI's Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b reports the shortest average latency in generating responses, whereas LLaMa2-7b-chat by Meta reports the highest average latency. This research underscores the fact that open-source LLMs, too, can go hand in hand with proprietary models like GPT-3.5 with better infrastructure.",
    "fetched_at": "2025-11-07T02:16:47.497562Z"
  },
  {
    "id": "2511.03270v1",
    "title": "SCALE: Upscaled Continual Learning of Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jin-woo Lee",
      "Junhwa Choi",
      "Bongkyu Hwang",
      "Jinho Choo",
      "Bogun Kim",
      "JeongSeon Yi",
      "Joonseok Lee",
      "DongYoung Jung",
      "Jaeseon Park",
      "Kyoungwon Park",
      "Suk-hoon Jung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03270v1",
    "abstract": "We revisit continual pre-training for large language models and argue that progress now depends more on scaling the right structure than on scaling parameters alone. We introduce SCALE, a width upscaling architecture that inserts lightweight expansion into linear modules while freezing all pre-trained parameters. This preserves the residual and attention topologies and increases capacity without perturbing the base model's original functionality. SCALE is guided by two principles: Persistent Preservation, which maintains the base model's behavior via preservation-oriented initialization and freezing of the pre-trained weights, and Collaborative Adaptation, which selectively trains a subset of expansion components to acquire new knowledge with minimal interference. We instantiate these ideas as SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and SCALE-Route, an optional routing extension that performs token-level routing between preservation and adaptation heads. On a controlled synthetic biography benchmark, SCALE mitigates the severe forgetting observed with depth expansion while still acquiring new knowledge. In continual pre-training on a Korean corpus, SCALE variants achieve less forgetting on English evaluations and competitive gains on Korean benchmarks, with these variants offering the best overall stability-plasticity trade-off. Accompanying analysis clarifies when preservation provably holds and why the interplay between preservation and adaptation stabilizes optimization compared to standard continual learning setups.",
    "fetched_at": "2025-11-07T02:16:47.497514Z"
  },
  {
    "id": "2511.03271v1",
    "title": "Let the Bees Find the Weak Spots: A Path Planning Perspective on   Multi-Turn Jailbreak Attacks against LLMs",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yize Liu",
      "Yunyun Hou",
      "Aina Sui"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03271v1",
    "abstract": "Large Language Models (LLMs) have been widely deployed across various applications, yet their potential security and ethical risks have raised increasing concerns. Existing research employs red teaming evaluations, utilizing multi-turn jailbreaks to identify potential vulnerabilities in LLMs. However, these approaches often lack exploration of successful dialogue trajectories within the attack space, and they tend to overlook the considerable overhead associated with the attack process. To address these limitations, this paper first introduces a theoretical model based on dynamically weighted graph topology, abstracting the multi-turn attack process as a path planning problem. Based on this framework, we propose ABC, an enhanced Artificial Bee Colony algorithm for multi-turn jailbreaks, featuring a collaborative search mechanism with employed, onlooker, and scout bees. This algorithm significantly improves the efficiency of optimal attack path search while substantially reducing the average number of queries required. Empirical evaluations on three open-source and two proprietary language models demonstrate the effectiveness of our approach, achieving attack success rates above 90\\% across the board, with a peak of 98\\% on GPT-3.5-Turbo, and outperforming existing baselines. Furthermore, it achieves comparable success with only 26 queries on average, significantly reducing red teaming overhead and highlighting its superior efficiency.",
    "fetched_at": "2025-11-07T02:16:47.497440Z"
  },
  {
    "id": "2511.03276v1",
    "title": "Diffusion Language Models are Super Data Learners",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jinjie Ni",
      "Qian Liu",
      "Longxu Dou",
      "Chao Du",
      "Zili Wang",
      "Hang Yan",
      "Tianyu Pang",
      "Michael Qizhe Shieh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03276v1",
    "abstract": "Under strictly controlled pre-training settings, we observe a Crossover: when unique data is limited, diffusion language models (DLMs) consistently surpass autoregressive (AR) models by training for more epochs. The crossover shifts later with more or higher-quality data, earlier with larger models, and persists across dense and sparse architectures. We attribute the gains to three compounding factors: (1) any-order modeling, (2) super-dense compute from iterative bidirectional denoising, and (3) built-in Monte Carlo augmentation; input or parameter noise improves AR under data constraint but cannot close the gap. At scale, a 1.7B DLM trained with a ~1.5T-token compute budget on 10B unique Python tokens overtakes an AR coder trained with strictly matched settings. In addition, a 1B-parameter DLM achieves > 56% accuracy on HellaSwag and > 33% on MMLU using only 1B tokens, without any special tricks, just by repeating standard pre-training data. We also show that rising validation cross-entropy does not imply degraded downstream performance in this regime.",
    "fetched_at": "2025-11-07T02:16:47.497393Z"
  },
  {
    "id": "2511.03279v1",
    "title": "Multi-Objective Adaptive Rate Limiting in Microservices Using Deep   Reinforcement Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ning Lyu",
      "Yuxi Wang",
      "Ziyu Cheng",
      "Qingyuan Zhang",
      "Feng Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03279v1",
    "abstract": "As cloud computing and microservice architectures become increasingly prevalent, API rate limiting has emerged as a critical mechanism for ensuring system stability and service quality. Traditional rate limiting algorithms, such as token bucket and sliding window, while widely adopted, struggle to adapt to dynamic traffic patterns and varying system loads. This paper proposes an adaptive rate limiting strategy based on deep reinforcement learning that dynamically balances system throughput and service latency. We design a hybrid architecture combining Deep Q-Network (DQN) and Asynchronous Advantage Actor-Critic (A3C) algorithms, modeling the rate limiting decision process as a Markov Decision Process. The system continuously monitors microservice states and learns optimal rate limiting policies through environmental interaction. Extensive experiments conducted in a Kubernetes cluster environment demonstrate that our approach achieves 23.7% throughput improvement and 31.4% P99 latency reduction compared to traditional fixed-threshold strategies under high-load scenarios. Results from a 90-day production deployment handling 500 million daily requests validate the practical effectiveness of the proposed method, with 82% reduction in service degradation incidents and 68% decrease in manual interventions.",
    "fetched_at": "2025-11-07T02:16:47.497334Z"
  },
  {
    "id": "2511.03280v1",
    "title": "A Probabilistic Approach to Pose Synchronization for Multi-Reference   Alignment with Applications to MIMO Wireless Communication Systems",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.AP",
      "AP"
    ],
    "authors": [
      "Rob Romijnders",
      "Gabriele Cesa",
      "Christos Louizos",
      "Kumar Pratik",
      "Arash Behboodi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03280v1",
    "abstract": "From molecular imaging to wireless communications, the ability to align and reconstruct signals from multiple misaligned observations is crucial for system performance. We study the problem of multi-reference alignment (MRA), which arises in many real-world problems, such as cryo-EM, computer vision, and, in particular, wireless communication systems. Using a probabilistic approach to model MRA, we find a new algorithm that uses relative poses as nuisance variables to marginalize out -- thereby removing the global symmetries of the problem and allowing for more direct solutions and improved convergence. The decentralization of this approach enables significant computational savings by avoiding the cubic scaling of centralized methods through cycle consistency. Both proposed algorithms achieve lower reconstruction error across experimental settings.",
    "fetched_at": "2025-11-07T02:16:47.497282Z"
  },
  {
    "id": "2511.03282v1",
    "title": "When Generative Artificial Intelligence meets Extended Reality: A   Systematic Review",
    "date": "2025-11-05",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinyu Ning",
      "Yan Zhuo",
      "Xian Wang",
      "Chan-In Devin Sio",
      "Lik-Hang Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03282v1",
    "abstract": "With the continuous advancement of technology, the application of generative artificial intelligence (AI) in various fields is gradually demonstrating great potential, particularly when combined with Extended Reality (XR), creating unprecedented possibilities. This survey article systematically reviews the applications of generative AI in XR, covering as much relevant literature as possible from 2023 to 2025. The application areas of generative AI in XR and its key technology implementations are summarised through PRISMA screening and analysis of the final 26 articles. The survey highlights existing articles from the last three years related to how XR utilises generative AI, providing insights into current trends and research gaps. We also explore potential opportunities for future research to further empower XR through generative AI, providing guidance and information for future generative XR research.",
    "fetched_at": "2025-11-07T02:16:47.497231Z"
  },
  {
    "id": "2511.03285v1",
    "title": "Graph Neural AI with Temporal Dynamics for Comprehensive Anomaly   Detection in Microservices",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Qingyuan Zhang",
      "Ning Lyu",
      "Le Liu",
      "Yuxi Wang",
      "Ziyu Cheng",
      "Cancan Hua"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03285v1",
    "abstract": "This study addresses the problem of anomaly detection and root cause tracing in microservice architectures and proposes a unified framework that combines graph neural networks with temporal modeling. The microservice call chain is abstracted as a directed graph, where multidimensional features of nodes and edges are used to construct a service topology representation, and graph convolution is applied to aggregate features across nodes and model dependencies, capturing complex structural relationships among services. On this basis, gated recurrent units are introduced to model the temporal evolution of call chains, and multi-layer stacking and concatenation operations are used to jointly obtain structural and temporal representations, improving the ability to identify anomaly patterns. Furthermore, anomaly scoring functions at both the node and path levels are defined to achieve unified modeling from local anomaly detection to global call chain tracing, which enables the identification of abnormal service nodes and the reconstruction of potential anomaly propagation paths. Sensitivity experiments are then designed from multiple dimensions, including hyperparameters, environmental disturbances, and data distribution, to evaluate the framework, and results show that it outperforms baseline methods in key metrics such as AUC, ACC, Recall, and F1-Score, maintaining high accuracy and stability under dynamic topologies and complex environments. This research not only provides a new technical path for anomaly detection in microservices but also lays a methodological foundation for intelligent operations in distributed systems.",
    "fetched_at": "2025-11-07T02:16:47.497177Z"
  },
  {
    "id": "2511.03295v1",
    "title": "How to Evaluate Speech Translation with Source-Aware Neural MT Metrics",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mauro Cettolo",
      "Marco Gaido",
      "Matteo Negri",
      "Sara Papi",
      "Luisa Bentivogli"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03295v1",
    "abstract": "Automatic evaluation of speech-to-text translation (ST) systems is typically performed by comparing translation hypotheses with one or more reference translations. While effective to some extent, this approach inherits the limitation of reference-based evaluation that ignores valuable information from the source input. In machine translation (MT), recent progress has shown that neural metrics incorporating the source text achieve stronger correlation with human judgments. Extending this idea to ST, however, is not trivial because the source is audio rather than text, and reliable transcripts or alignments between source and references are often unavailable. In this work, we conduct the first systematic study of source-aware metrics for ST, with a particular focus on real-world operating conditions where source transcripts are not available. We explore two complementary strategies for generating textual proxies of the input audio, automatic speech recognition (ASR) transcripts, and back-translations of the reference translation, and introduce a novel two-step cross-lingual re-segmentation algorithm to address the alignment mismatch between synthetic sources and reference translations. Our experiments, carried out on two ST benchmarks covering 79 language pairs and six ST systems with diverse architectures and performance levels, show that ASR transcripts constitute a more reliable synthetic source than back-translations when word error rate is below 20%, while back-translations always represent a computationally cheaper but still effective alternative. Furthermore, our cross-lingual re-segmentation algorithm enables robust use of source-aware MT metrics in ST evaluation, paving the way toward more accurate and principled evaluation methodologies for speech translation.",
    "fetched_at": "2025-11-07T02:16:47.497081Z"
  },
  {
    "id": "2511.03304v1",
    "title": "Extending Fair Null-Space Projections for Continuous Attributes to   Kernel Methods",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Felix Strck",
      "Fabian Hinder",
      "Barbara Hammer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03304v1",
    "abstract": "With the on-going integration of machine learning systems into the everyday social life of millions the notion of fairness becomes an ever increasing priority in their development. Fairness notions commonly rely on protected attributes to assess potential biases. Here, the majority of literature focuses on discrete setups regarding both target and protected attributes. The literature on continuous attributes especially in conjunction with regression -- we refer to this as \\emph{continuous fairness} -- is scarce. A common strategy is iterative null-space projection which as of now has only been explored for linear models or embeddings such as obtained by a non-linear encoder. We improve on this by generalizing to kernel methods, significantly extending the scope. This yields a model and fairness-score agnostic method for kernel embeddings applicable to continuous protected attributes. We demonstrate that our novel approach in conjunction with Support Vector Regression (SVR) provides competitive or improved performance across multiple datasets in comparisons to other contemporary methods.",
    "fetched_at": "2025-11-07T02:16:47.497026Z"
  },
  {
    "id": "2511.03320v1",
    "title": "Influence of Data Dimensionality Reduction Methods on the Effectiveness   of Quantum Machine Learning Models",
    "date": "2025-11-05",
    "tags": [
      "quant-ph",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aakash Ravindra Shinde",
      "Jukka K. Nurminen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03320v1",
    "abstract": "Data dimensionality reduction techniques are often utilized in the implementation of Quantum Machine Learning models to address two significant issues: the constraints of NISQ quantum devices, which are characterized by noise and a limited number of qubits, and the challenge of simulating a large number of qubits on classical devices. It also raises concerns over the scalability of these approaches, as dimensionality reduction methods are slow to adapt to large datasets. In this article, we analyze how data reduction methods affect different QML models. We conduct this experiment over several generated datasets, quantum machine algorithms, quantum data encoding methods, and data reduction methods. All these models were evaluated on the performance metrics like accuracy, precision, recall, and F1 score. Our findings have led us to conclude that the usage of data dimensionality reduction methods results in skewed performance metric values, which results in wrongly estimating the actual performance of quantum machine learning models. There are several factors, along with data dimensionality reduction methods, that worsen this problem, such as characteristics of the datasets, classical to quantum information embedding methods, percentage of feature reduction, classical components associated with quantum models, and structure of quantum machine learning models. We consistently observed the difference in the accuracy range of 14% to 48% amongst these models, using data reduction and not using it. Apart from this, our observations have shown that some data reduction methods tend to perform better for some specific data embedding methodologies and ansatz constructions.",
    "fetched_at": "2025-11-07T02:16:47.496982Z"
  },
  {
    "id": "2511.03328v1",
    "title": "Benchmarking the Thinking Mode of Multimodal Large Language Models in   Clinical Tasks",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jindong Hong",
      "Tianjie Chen",
      "Lingjie Luo",
      "Chuanyang Zheng",
      "Ting Xu",
      "Haibao Yu",
      "Jianing Qiu",
      "Qianzhong Chen",
      "Suning Huang",
      "Yan Xu",
      "Yong Gui",
      "Yijun He",
      "Jiankai Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03328v1",
    "abstract": "A recent advancement in Multimodal Large Language Models (MLLMs) research is the emergence of \"reasoning MLLMs\" that offer explicit control over their internal thinking processes (normally referred as the \"thinking mode\") alongside the standard \"non-thinking mode\". This capability allows these models to engage in a step-by-step process of internal deliberation before generating a final response. With the rapid transition to and adoption of these \"dual-state\" MLLMs, this work rigorously evaluated how the enhanced reasoning processes of these MLLMs impact model performance and reliability in clinical tasks. This paper evaluates the active \"thinking mode\" capabilities of two leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We assessed their performance on four visual medical tasks using VQA-RAD and ROCOv2 datasets. Our findings reveal that the improvement from activating the thinking mode remains marginal compared to the standard non-thinking mode for the majority of the tasks. Their performance on complex medical tasks such as open-ended VQA and medical image interpretation remains suboptimal, highlighting the need for domain-specific medical data and more advanced methods for medical knowledge integration.",
    "fetched_at": "2025-11-07T02:16:47.496937Z"
  },
  {
    "id": "2511.03330v1",
    "title": "Discourse-Aware Scientific Paper Recommendation via QA-Style   Summarization and Multi-Level Contrastive Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.IR",
      "IR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shenghua Wang",
      "Zhen Yin"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03330v1",
    "abstract": "The rapid growth of open-access (OA) publications has intensified the challenge of identifying relevant scientific papers. Due to privacy constraints and limited access to user interaction data, recent efforts have shifted toward content-based recommendation, which relies solely on textual information. However, existing models typically treat papers as unstructured text, neglecting their discourse organization and thereby limiting semantic completeness and interpretability. To address these limitations, we propose OMRC-MR, a hierarchical framework that integrates QA-style OMRC (Objective, Method, Result, Conclusion) summarization, multi-level contrastive learning, and structure-aware re-ranking for scholarly recommendation. The QA-style summarization module converts raw papers into structured and discourse-consistent representations, while multi-level contrastive objectives align semantic representations across metadata, section, and document levels. The final re-ranking stage further refines retrieval precision through contextual similarity calibration. Experiments on DBLP, S2ORC, and the newly constructed Sci-OMRC dataset demonstrate that OMRC-MR consistently surpasses state-of-the-art baselines, achieving up to 7.2% and 3.8% improvements in Precision@10 and Recall@10, respectively. Additional evaluations confirm that QA-style summarization produces more coherent and factually complete representations. Overall, OMRC-MR provides a unified and interpretable content-based paradigm for scientific paper recommendation, advancing trustworthy and privacy-aware scholarly information retrieval.",
    "fetched_at": "2025-11-07T02:16:47.496857Z"
  },
  {
    "id": "2511.03344v1",
    "title": "SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Elif Arslan",
      "Jacobus G. M. van der Linden",
      "Serge Hoogendoorn",
      "Marco Rinaldi",
      "Emir Demirovi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03344v1",
    "abstract": "Sparse decision tree learning provides accurate and interpretable predictive models that are ideal for high-stakes applications by finding the single most accurate tree within a (soft) size limit. Rather than relying on a single \"best\" tree, Rashomon sets-trees with similar performance but varying structures-can be used to enhance variable importance analysis, enrich explanations, and enable users to choose simpler trees or those that satisfy stakeholder preferences (e.g., fairness) without hard-coding such criteria into the objective function. However, because finding the optimal tree is NP-hard, enumerating the Rashomon set is inherently challenging. Therefore, we introduce SORTD, a novel framework that improves scalability and enumerates trees in the Rashomon set in order of the objective value, thus offering anytime behavior. Our experiments show that SORTD reduces runtime by up to two orders of magnitude compared with the state of the art. Moreover, SORTD can compute Rashomon sets for any separable and totally ordered objective and supports post-evaluating the set using other separable (and partially ordered) objectives. Together, these advances make exploring Rashomon sets more practical in real-world applications.",
    "fetched_at": "2025-11-07T02:16:47.496813Z"
  },
  {
    "id": "2511.03354v1",
    "title": "Generative Artificial Intelligence in Bioinformatics: A Systematic   Review of Models, Applications, and Methodological Advances",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Riasad Alvi",
      "Sayeem Been Zaman",
      "Wasimul Karim",
      "Arefin Ittesafun Abian",
      "Mohaimenul Azam Khan Raiaan",
      "Saddam Mukta",
      "Md Rafi Ur Rashid",
      "Md Rafiqul Islam",
      "Yakub Sebastian",
      "Sami Azam"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.03354v1",
    "abstract": "Generative artificial intelligence (GenAI) has become a transformative approach in bioinformatics that often enables advancements in genomics, proteomics, transcriptomics, structural biology, and drug discovery. To systematically identify and evaluate these growing developments, this review proposed six research questions (RQs), according to the preferred reporting items for systematic reviews and meta-analysis methods. The objective is to evaluate impactful GenAI strategies in methodological advancement, predictive performance, and specialization, and to identify promising approaches for advanced modeling, data-intensive discovery, and integrative biological analysis. RQ1 highlights diverse applications across multiple bioinformatics subfields (sequence analysis, molecular design, and integrative data modeling), which demonstrate superior performance over traditional methods through pattern recognition and output generation. RQ2 reveals that adapted specialized model architectures outperformed general-purpose models, an advantage attributed to targeted pretraining and context-aware strategies. RQ3 identifies significant benefits in the bioinformatics domains, focusing on molecular analysis and data integration, which improves accuracy and reduces errors in complex analysis. RQ4 indicates improvements in structural modeling, functional prediction, and synthetic data generation, validated by established benchmarks. RQ5 suggests the main constraints, such as the lack of scalability and biases in data that impact generalizability, and proposes future directions focused on robust evaluation and biologically grounded modeling. RQ6 examines that molecular datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly support the training and generalization of GenAI models.",
    "fetched_at": "2025-11-07T02:16:47.496764Z"
  },
  {
    "id": "2511.03361v1",
    "title": "Open Source State-Of-the-Art Solution for Romanian Speech Recognition",
    "date": "2025-11-05",
    "tags": [
      "eess.AS",
      "AS",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gabriel Pirlogeanu",
      "Alexandru-Lucian Georgescu",
      "Horia Cucu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03361v1",
    "abstract": "In this work, we present a new state-of-the-art Romanian Automatic Speech Recognition (ASR) system based on NVIDIA's FastConformer architecture--explored here for the first time in the context of Romanian. We train our model on a large corpus of, mostly, weakly supervised transcriptions, totaling over 2,600 hours of speech. Leveraging a hybrid decoder with both Connectionist Temporal Classification (CTC) and Token-Duration Transducer (TDT) branches, we evaluate a range of decoding strategies including greedy, ALSD, and CTC beam search with a 6-gram token-level language model. Our system achieves state-of-the-art performance across all Romanian evaluation benchmarks, including read, spontaneous, and domain-specific speech, with up to 27% relative WER reduction compared to previous best-performing systems. In addition to improved transcription accuracy, our approach demonstrates practical decoding efficiency, making it suitable for both research and deployment in low-latency ASR applications.",
    "fetched_at": "2025-11-07T02:16:47.496685Z"
  },
  {
    "id": "2511.03367v1",
    "title": "Decoupling Augmentation Bias in Prompt Learning for Vision-Language   Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gahyeon Kim",
      "Sohee Kim",
      "Seokju Lee"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03367v1",
    "abstract": "Recent advances in large-scale vision and language models have led to significant progress in zero-shot learning tasks. Methods such as CoOp and CoCoOp have shown that replacing handcrafted prompts with learnable vectors, known as prompt learning, can result in improved performance. However, these models often struggle to generalize to entirely unseen categories. While traditional zero-shot learning techniques benefit from various data augmentation strategies, prompt learning has primarily focused on text-based modifications, leaving the potential of image-based augmentation largely unexplored. In this work, we explore how image-level augmentations, particularly those that introduce attribute-specific variations, can support and enhance prompt learning. Our analysis examines the interaction between these augmentations and soft prompt frameworks, revealing their potential to improve generalization. We also identify a limitation in existing methods, such as CoCoOp, which do not provide explicit guidance for learning prompts that focus on semantically meaningful visual features. To address this, we propose Adding Attributes to Prompt Learning, AAPL, a novel method that introduces adversarial token embeddings to decouple superficial visual variations introduced by augmentation from class-relevant semantic representations. This decoupling enables the learned prompts to concentrate on visually discriminative features that align with the target categories. We conduct comprehensive experiments on eleven benchmark datasets, and AAPL consistently outperforms existing methods across few-shot, zero-shot, cross-dataset, and domain generalization settings. Our source code is publicly available at: https://github.com/Gahyeonkim09/AAPL",
    "fetched_at": "2025-11-07T02:16:47.496576Z"
  },
  {
    "id": "2511.03368v1",
    "title": "TripleWin: Fixed-Point Equilibrium Pricing for Data-Model Coupled   Markets",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hongrun Ren",
      "Yun Xiong",
      "Lei You",
      "Yingying Wang",
      "Haixu Xiong",
      "Yangyong Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03368v1",
    "abstract": "The rise of the machine learning (ML) model economy has intertwined markets for training datasets and pre-trained models. However, most pricing approaches still separate data and model transactions or rely on broker-centric pipelines that favor one side. Recent studies of data markets with externalities capture buyer interactions but do not yield a simultaneous and symmetric mechanism across data sellers, model producers, and model buyers. We propose a unified data-model coupled market that treats dataset and model trading as a single system. A supply-side mapping transforms dataset payments into buyer-visible model quotations, while a demand-side mapping propagates buyer prices back to datasets through Shapley-based allocation. Together, they form a closed loop that links four interactions: supply-demand propagation in both directions and mutual coupling among buyers and among sellers. We prove that the joint operator is a standard interference function (SIF), guaranteeing existence, uniqueness, and global convergence of equilibrium prices. Experiments demonstrate efficient convergence and improved fairness compared with broker-centric and one-sided baselines. The code is available on https://github.com/HongrunRen1109/Triple-Win-Pricing.",
    "fetched_at": "2025-11-07T02:16:47.496525Z"
  },
  {
    "id": "2511.03369v1",
    "title": "Silenced Biases: The Dark Side LLMs Learned to Refuse",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Rom Himelstein",
      "Amit LeVi",
      "Brit Youngmann",
      "Yaniv Nemcovsky",
      "Avi Mendelson"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03369v1",
    "abstract": "Safety-aligned large language models (LLMs) are becoming increasingly widespread, especially in sensitive applications where fairness is essential and biased outputs can cause significant harm. However, evaluating the fairness of models is a complex challenge, and approaches that do so typically utilize standard question-answer (QA) styled schemes. Such methods often overlook deeper issues by interpreting the model's refusal responses as positive fairness measurements, which creates a false sense of fairness. In this work, we introduce the concept of silenced biases, which are unfair preferences encoded within models' latent space and are effectively concealed by safety-alignment. Previous approaches that considered similar indirect biases often relied on prompt manipulation or handcrafted implicit queries, which present limited scalability and risk contaminating the evaluation process with additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to uncover these biases by employing activation steering to reduce model refusals during QA. SBB supports easy expansion to new demographic groups and subjects, presenting a fairness evaluation framework that encourages the future development of fair models and tools beyond the masking effects of alignment training. We demonstrate our approach over multiple LLMs, where our findings expose an alarming distinction between models' direct responses and their underlying fairness issues.",
    "fetched_at": "2025-11-07T02:16:47.496469Z"
  },
  {
    "id": "2511.03372v1",
    "title": "LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced   Logical Reasoning",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7; I.2.6; F.4.1",
      "1"
    ],
    "authors": [
      "Shenghao Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03372v1",
    "abstract": "For complex logical data augmentation, heavy reliance on human annotation is costly, whereas direct generation with large language models yields uninterpretable and logically homogeneous examples. To address this, we present LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to propositional expressions, a compact rule library is compiled, and a bounded state-space search systematically discovers valid formulas that are then verbalized back into natural-language questions, ensuring both diversity and logical rigor under propositional logic. Experiments on ReClor and LogiQA show significant improvements in the logical-reasoning accuracy of pretrained models, confirming the effectiveness of LFC-DA for LLM-guided logical data augmentation.",
    "fetched_at": "2025-11-07T02:16:47.496367Z"
  },
  {
    "id": "2511.03376v1",
    "title": "Computational Imaging Meets LLMs: Zero-Shot IDH Mutation Prediction in   Brain Gliomas",
    "date": "2025-11-05",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "q-bio.QM",
      "QM"
    ],
    "authors": [
      "Syed Muqeem Mahmood",
      "Hassan Mohy-ud-Din"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03376v1",
    "abstract": "We present a framework that combines Large Language Models with computational image analytics for non-invasive, zero-shot prediction of IDH mutation status in brain gliomas. For each subject, coregistered multi-parametric MRI scans and multi-class tumor segmentation maps were processed to extract interpretable semantic (visual) attributes and quantitative features, serialized in a standardized JSON file, and used to query GPT 4o and GPT 5 without fine-tuning. We evaluated this framework on six publicly available datasets (N = 1427) and results showcased high accuracy and balanced classification performance across heterogeneous cohorts, even in the absence of manual annotations. GPT 5 outperformed GPT 4o in context-driven phenotype interpretation. Volumetric features emerged as the most important predictors, supplemented by subtype-specific imaging markers and clinical information. Our results demonstrate the potential of integrating LLM-based reasoning with computational image analytics for precise, non-invasive tumor genotyping, advancing diagnostic strategies in neuro-oncology. The code is available at https://github.com/ATPLab-LUMS/CIM-LLM.",
    "fetched_at": "2025-11-07T02:16:47.496328Z"
  },
  {
    "id": "2511.03378v1",
    "title": "Beyond Citations: Measuring Idea-level Knowledge Diffusion from Research   to Journalism and Policy-making",
    "date": "2025-11-05",
    "tags": [
      "cs.SI",
      "SI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yangliu Fan",
      "Kilian Buehling",
      "Volker Stocker"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03378v1",
    "abstract": "Despite the importance of social science knowledge for various stakeholders, measuring its diffusion into different domains remains a challenge. This study uses a novel text-based approach to measure the idea-level diffusion of social science knowledge from the research domain to the journalism and policy-making domains. By doing so, we expand the detection of knowledge diffusion beyond the measurements of direct references. Our study focuses on media effects theories as key research ideas in the field of communication science. Using 72,703 documents (2000-2019) from three domains (i.e., research, journalism, and policy-making) that mention these ideas, we count the mentions of these ideas in each domain, estimate their domain-specific contexts, and track and compare differences across domains and over time. Overall, we find that diffusion patterns and dynamics vary considerably between ideas, with some ideas diffusing between other domains, while others do not. Based on the embedding regression approach, we compare contextualized meanings across domains and find that the distances between research and policy are typically larger than between research and journalism. We also find that ideas largely shift roles across domains - from being the theories themselves in research to sense-making in news to applied, administrative use in policy. Over time, we observe semantic convergence mainly for ideas that are practically oriented. Our results characterize the cross-domain diffusion patterns and dynamics of social science knowledge at the idea level, and we discuss the implications for measuring knowledge diffusion beyond citations.",
    "fetched_at": "2025-11-07T02:16:47.496286Z"
  },
  {
    "id": "2511.03383v1",
    "title": "Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for   Optimal Machine Translation Performance",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Saumitra Yadav",
      "Manish Shrivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03383v1",
    "abstract": "Existing Machine Translation (MT) research often suggests a single, fixed set of hyperparameters for word segmentation models, symmetric Byte Pair Encoding (BPE), which applies the same number of merge operations (NMO) to train tokenizers for both source and target languages. However, we demonstrate that this uniform approach doesn't guarantee optimal MT performance across different language pairs and data sizes. This work investigates BPE segmentation recipes across various data volumes and language pairs to evaluate MT system performance. We find that utilizing asymmetric BPE, where the source and target languages have different NMOs, significantly improves results over the symmetric approach, especially in low-resource settings (50K, 100K, and 500K sentence pairs). Specifically, asymmetric BPE yield statistically significant ($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in low-resource setups. We validated this trend across six additional language pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut), observing statistically significant improvement in 10 out of 12 systems compared to symmetric BPE. Our findings indicate a high NMO for the source (4K to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results, particularly benefiting low-resource MT.",
    "fetched_at": "2025-11-07T02:16:47.496237Z"
  },
  {
    "id": "2511.03405v1",
    "title": "Adaptable Hindsight Experience Replay for Search-Based Learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "I.2.8; I.2.6",
      "6"
    ],
    "authors": [
      "Alexandros Vazaios",
      "Jannis Brugger",
      "Cedric Derstroff",
      "Kristian Kersting",
      "Mira Mezini"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03405v1",
    "abstract": "AlphaZero-like Monte Carlo Tree Search systems, originally introduced for two-player games, dynamically balance exploration and exploitation using neural network guidance. This combination makes them also suitable for classical search problems. However, the original method of training the network with simulation results is limited in sparse reward settings, especially in the early stages, where the network cannot yet give guidance. Hindsight Experience Replay (HER) addresses this issue by relabeling unsuccessful trajectories from the search tree as supervised learning signals. We introduce Adaptable HER (\\ours{}), a flexible framework that integrates HER with AlphaZero, allowing easy adjustments to HER properties such as relabeled goals, policy targets, and trajectory selection. Our experiments, including equation discovery, show that the possibility of modifying HER is beneficial and surpasses the performance of pure supervised or reinforcement learning.",
    "fetched_at": "2025-11-07T02:16:47.496194Z"
  },
  {
    "id": "2511.03407v1",
    "title": "Overcoming the Generalization Limits of SLM Finetuning for Shape-Based   Extraction of Datatype and Object Properties",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7; I.2.4",
      "4"
    ],
    "authors": [
      "Clian Ringwald",
      "Fabien Gandon",
      "Catherine Faron",
      "Franck Michel",
      "Hanna Abi Akl"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03407v1",
    "abstract": "Small language models (SLMs) have shown promises for relation extraction (RE) when extracting RDF triples guided by SHACL shapes focused on common datatype properties. This paper investigates how SLMs handle both datatype and object properties for a complete RDF graph extraction. We show that the key bottleneck is related to long-tail distribution of rare properties. To solve this issue, we evaluate several strategies: stratified sampling, weighted loss, dataset scaling, and template-based synthetic data augmentation. We show that the best strategy to perform equally well over unbalanced target properties is to build a training set where the number of occurrences of each property exceeds a given threshold. To enable reproducibility, we publicly released our datasets, experimental results and code. Our findings offer practical guidance for training shape-aware SLMs and highlight promising directions for future work in semantic RE.",
    "fetched_at": "2025-11-07T02:16:47.496137Z"
  },
  {
    "id": "2511.03408v1",
    "title": "Efficient Reasoning via Thought-Training and Thought-Free Inference",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Canhui Wu",
      "Qiong Cao",
      "Chao Xue",
      "Wei Xi",
      "Xiaodong He"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03408v1",
    "abstract": "Recent advances in large language models (LLMs) have leveraged explicit Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most existing methods primarily compress verbose reasoning outputs. These Long-to-Short transformations aim to improve efficiency, but still rely on explicit reasoning during inference. In this work, we introduce \\textbf{3TF} (\\textbf{T}hought-\\textbf{T}raining and \\textbf{T}hought-\\textbf{F}ree inference), a framework for efficient reasoning that takes a Short-to-Long perspective. We first train a hybrid model that can operate in both reasoning and non-reasoning modes, and then further train it on CoT-annotated data to internalize structured reasoning, while enforcing concise, thought-free outputs at inference time using the no-reasoning mode. Unlike compression-based approaches, 3TF improves the reasoning quality of non-reasoning outputs, enabling models to perform rich internal reasoning implicitly while keeping external outputs short. Empirically, 3TF-trained models obtain large improvements on reasoning benchmarks under thought-free inference, demonstrating that high quality reasoning can be learned and executed implicitly without explicit step-by-step generation.",
    "fetched_at": "2025-11-07T02:16:47.496074Z"
  },
  {
    "id": "2511.03410v1",
    "title": "Knowledge-Augmented Question Error Correction for Chinese Question   Answer System with QuestionRAG",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Longpeng Qiu",
      "Ting Li",
      "Shuai Mao",
      "Nan Yang",
      "Xiaohui Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03410v1",
    "abstract": "Input errors in question-answering (QA) systems often lead to incorrect responses. Large language models (LLMs) struggle with this task, frequently failing to interpret user intent (misinterpretation) or unnecessarily altering the original question's structure (over-correction). We propose QuestionRAG, a framework that tackles these problems. To address misinterpretation, it enriches the input with external knowledge (e.g., search results, related entities). To prevent over-correction, it uses reinforcement learning (RL) to align the model's objective with precise correction, not just paraphrasing. Our results demonstrate that knowledge augmentation is critical for understanding faulty questions. Furthermore, RL-based alignment proves significantly more effective than traditional supervised fine-tuning (SFT), boosting the model's ability to follow instructions and generalize. By integrating these two strategies, QuestionRAG unlocks the full potential of LLMs for the question correction task.",
    "fetched_at": "2025-11-07T02:16:47.496021Z"
  },
  {
    "id": "2511.03421v1",
    "title": "Light over Heavy: Automated Performance Requirements Quantification with   Linguistic Inducement",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shihai Wang",
      "Tao Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03421v1",
    "abstract": "Elicited performance requirements need to be quantified for compliance in different engineering tasks, e.g., configuration tuning and performance testing. Much existing work has relied on manual quantification, which is expensive and error-prone due to the imprecision. In this paper, we present LQPR, a highly efficient automatic approach for performance requirements quantification.LQPR relies on a new theoretical framework that converts quantification as a classification problem. Despite the prevalent applications of Large Language Models (LLMs) for requirement analytics, LQPR takes a different perspective to address the classification: we observed that performance requirements can exhibit strong patterns and are often short/concise, therefore we design a lightweight linguistically induced matching mechanism. We compare LQPR against nine state-of-the-art learning-based approaches over diverse datasets, demonstrating that it is ranked as the sole best for 75% or more cases with two orders less cost. Our work proves that, at least for performance requirement quantification, specialized methods can be more suitable than the general LLM-driven approaches.",
    "fetched_at": "2025-11-07T02:16:47.495970Z"
  },
  {
    "id": "2511.03425v1",
    "title": "SyMuPe: Affective and Controllable Symbolic Music Performance",
    "date": "2025-11-05",
    "tags": [
      "cs.SD",
      "SD",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Ilya Borovik",
      "Dmitrii Gavrilev",
      "Vladimir Viro"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03425v1",
    "abstract": "Emotions are fundamental to the creation and perception of music performances. However, achieving human-like expression and emotion through machine learning models for performance rendering remains a challenging task. In this work, we present SyMuPe, a novel framework for developing and training affective and controllable symbolic piano performance models. Our flagship model, PianoFlow, uses conditional flow matching trained to solve diverse multi-mask performance inpainting tasks. By design, it supports both unconditional generation and infilling of music performance features. For training, we use a curated, cleaned dataset of 2,968 hours of aligned musical scores and expressive MIDI performances. For text and emotion control, we integrate a piano performance emotion classifier and tune PianoFlow with the emotion-weighted Flan-T5 text embeddings provided as conditional inputs. Objective and subjective evaluations against transformer-based baselines and existing models show that PianoFlow not only outperforms other approaches, but also achieves performance quality comparable to that of human-recorded and transcribed MIDI samples. For emotion control, we present and analyze samples generated under different text conditioning scenarios. The developed model can be integrated into interactive applications, contributing to the creation of more accessible and engaging music performance systems.",
    "fetched_at": "2025-11-07T02:16:47.495928Z"
  },
  {
    "id": "2511.03441v2",
    "title": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the   Biomedical Field",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Doria Bonzi",
      "Alexandre Guiggi",
      "Frdric Bchet",
      "Carlos Ramisch",
      "Benoit Favre"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03441v2",
    "abstract": "Critical appraisal of scientific literature is an essential skill in the biomedical field. While large language models (LLMs) can offer promising support in this task, their reliability remains limited, particularly for critical reasoning in specialized domains. We introduce CareMedEval, an original dataset designed to evaluate LLMs on biomedical critical appraisal and reasoning tasks. Derived from authentic exams taken by French medical students, the dataset contains 534 questions based on 37 scientific articles. Unlike existing benchmarks, CareMedEval explicitly evaluates critical reading and reasoning grounded in scientific papers. Benchmarking state-of-the-art generalist and biomedical-specialized LLMs under various context conditions reveals the difficulty of the task: open and commercial models fail to exceed an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens considerably improves the results. Yet, models remain challenged especially on questions about study limitations and statistical analysis. CareMedEval provides a challenging benchmark for grounded reasoning, exposing current LLM limitations and paving the way for future development of automated support for critical appraisal.",
    "fetched_at": "2025-11-07T02:16:47.495830Z"
  },
  {
    "id": "2511.03443v1",
    "title": "A Support-Set Algorithm for Optimization Problems with Nonnegative and   Orthogonal Constraints",
    "date": "2025-11-05",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Lei Wang",
      "Xin Liu",
      "Xiaojun Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03443v1",
    "abstract": "In this paper, we investigate optimization problems with nonnegative and orthogonal constraints, where any feasible matrix of size $n \\times p$ exhibits a sparsity pattern such that each row accommodates at most one nonzero entry. Our analysis demonstrates that, by fixing the support set, the global solution of the minimization subproblem for the proximal linearization of the objective function can be computed in closed form with at most $n$ nonzero entries. Exploiting this structural property offers a powerful avenue for dramatically enhancing computational efficiency. Guided by this insight, we propose a support-set algorithm preserving strictly the feasibility of iterates. A central ingredient is a strategically devised update scheme for support sets that adjusts the placement of nonzero entries. We establish the global convergence of the support-set algorithm to a first-order stationary point, and show that its iteration complexity required to reach an $\\epsilon$-approximate first-order stationary point is $O (\\epsilon^{-2})$. Numerical results are strongly in favor of our algorithm in real-world applications, including nonnegative PCA, clustering, and community detection.",
    "fetched_at": "2025-11-07T02:16:47.495777Z"
  },
  {
    "id": "2511.03464v1",
    "title": "POEMS: Product of Experts for Interpretable Multi-omic Integration using   Sparse Decoding",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mihriban Kocak Balik",
      "Pekka Marttinen",
      "Negar Safinianaini"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03464v1",
    "abstract": "Integrating different molecular layers, i.e., multiomics data, is crucial for unraveling the complexity of diseases; yet, most deep generative models either prioritize predictive performance at the expense of interpretability or enforce interpretability by linearizing the decoder, thereby weakening the network's nonlinear expressiveness. To overcome this tradeoff, we introduce POEMS: Product Of Experts for Interpretable Multiomics Integration using Sparse Decoding, an unsupervised probabilistic framework that preserves predictive performance while providing interpretability. POEMS provides interpretability without linearizing any part of the network by 1) mapping features to latent factors using sparse connections, which directly translates to biomarker discovery, 2) allowing for cross-omic associations through a shared latent space using product of experts model, and 3) reporting contributions of each omic by a gating network that adaptively computes their influence in the representation learning. Additionally, we present an efficient sparse decoder. In a cancer subtyping case study, POEMS achieves competitive clustering and classification performance while offering our novel set of interpretations, demonstrating that biomarker based insight and predictive accuracy can coexist in multiomics representation learning.",
    "fetched_at": "2025-11-07T02:16:47.495731Z"
  },
  {
    "id": "2511.03466v1",
    "title": "Kastor: Fine-tuned Small Language Models for Shape-based Active Relation   Extraction",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "I.2.4; I.2.7",
      "7"
    ],
    "authors": [
      "Ringwald Celian",
      "Gandon Fabien",
      "Faron Catherine",
      "Michel Franck",
      "Abi Akl Hanna"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03466v1",
    "abstract": "RDF pattern-based extraction is a compelling approach for fine-tuning small language models (SLMs) by focusing a relation extraction task on a specified SHACL shape. This technique enables the development of efficient models trained on limited text and RDF data. In this article, we introduce Kastor, a framework that advances this approach to meet the demands for completing and refining knowledge bases in specialized domains. Kastor reformulates the traditional validation task, shifting from single SHACL shape validation to evaluating all possible combinations of properties derived from the shape. By selecting the optimal combination for each training example, the framework significantly enhances model generalization and performance. Additionally, Kastor employs an iterative learning process to refine noisy knowledge bases, enabling the creation of robust models capable of uncovering new, relevant facts",
    "fetched_at": "2025-11-07T02:16:47.495686Z"
  },
  {
    "id": "2511.03471v1",
    "title": "Towards Scalable Web Accessibility Audit with MLLMs as Copilots",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Ming Gu",
      "Ziwei Wang",
      "Sicen Lai",
      "Zirui Gao",
      "Sheng Zhou",
      "Jiajun Bu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03471v1",
    "abstract": "Ensuring web accessibility is crucial for advancing social welfare, justice, and equality in digital spaces, yet the vast majority of website user interfaces remain non-compliant, due in part to the resource-intensive and unscalable nature of current auditing practices. While WCAG-EM offers a structured methodology for site-wise conformance evaluation, it involves great human efforts and lacks practical support for execution at scale. In this work, we present an auditing framework, AAA, which operationalizes WCAG-EM through a human-AI partnership model. AAA is anchored by two key innovations: GRASP, a graph-based multimodal sampling method that ensures representative page coverage via learned embeddings of visual, textual, and relational cues; and MaC, a multimodal large language model-based copilot that supports auditors through cross-modal reasoning and intelligent assistance in high-effort tasks. Together, these components enable scalable, end-to-end web accessibility auditing, empowering human auditors with AI-enhanced assistance for real-world impact. We further contribute four novel datasets designed for benchmarking core stages of the audit pipeline. Extensive experiments demonstrate the effectiveness of our methods, providing insights that small-scale language models can serve as capable experts when fine-tuned.",
    "fetched_at": "2025-11-07T02:16:47.495638Z"
  },
  {
    "id": "2511.03473v1",
    "title": "Reinforcement Learning Using known Invariances",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alexandru Cioba",
      "Aya Kayal",
      "Laura Toni",
      "Sattar Vakili",
      "Alberto Bernacchia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03473v1",
    "abstract": "In many real-world reinforcement learning (RL) problems, the environment exhibits inherent symmetries that can be exploited to improve learning efficiency. This paper develops a theoretical and algorithmic framework for incorporating known group symmetries into kernel-based RL. We propose a symmetry-aware variant of optimistic least-squares value iteration (LSVI), which leverages invariant kernels to encode invariance in both rewards and transition dynamics. Our analysis establishes new bounds on the maximum information gain and covering numbers for invariant RKHSs, explicitly quantifying the sample efficiency gains from symmetry. Empirical results on a customized Frozen Lake environment and a 2D placement design problem confirm the theoretical improvements, demonstrating that symmetry-aware RL achieves significantly better performance than their standard kernel counterparts. These findings highlight the value of structural priors in designing more sample-efficient reinforcement learning algorithms.",
    "fetched_at": "2025-11-07T02:16:47.495583Z"
  },
  {
    "id": "2511.03481v1",
    "title": "Development of the Bioinspired Tendon-Driven DexHand 021 with   Proprioceptive Compliance Control",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jianbo Yuan",
      "Haohua Zhu",
      "Jing Dai",
      "Sheng Yi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03481v1",
    "abstract": "The human hand plays a vital role in daily life and industrial applications, yet replicating its multifunctional capabilities-including motion, sensing, and coordinated manipulation-with robotic systems remains a formidable challenge. Developing a dexterous robotic hand requires balancing human-like agility with engineering constraints such as complexity, size-to-weight ratio, durability, and force-sensing performance. This letter presents Dex-Hand 021, a high-performance, cable-driven five-finger robotic hand with 12 active and 7 passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight 1 kg design. We propose a proprioceptive force-sensing-based admittance control method to enhance manipulation. Experimental results demonstrate its superior performance: a single-finger load capacity exceeding 10 N, fingertip repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared to PID control, joint torques in multi-object grasping are reduced by 31.19%, significantly improves force-sensing capability while preventing overload during collisions. The hand excels in both power and precision grasps, successfully executing 33 GRASP taxonomy motions and complex manipulation tasks. This work advances the design of lightweight, industrial-grade dexterous hands and enhances proprioceptive control, contributing to robotic manipulation and intelligent manufacturing.",
    "fetched_at": "2025-11-07T02:16:47.495483Z"
  },
  {
    "id": "2511.03482v1",
    "title": "System Identification of a Moored ASV with Recessed Moon Pool via   Deterministic and Bayesian Hankel-DMDc",
    "date": "2025-11-05",
    "tags": [
      "eess.SY",
      "SY",
      "cs.CE",
      "CE",
      "cs.LG",
      "LG",
      "cs.SY"
    ],
    "authors": [
      "Giorgio Palma",
      "Ivan Santic",
      "Andrea Serani",
      "Lorenzo Minno",
      "Matteo Diez"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03482v1",
    "abstract": "This study addresses the system identification of a small autonomous surface vehicle (ASV) under moored conditions using Hankel dynamic mode decomposition with control (HDMDc) and its Bayesian extension (BHDMDc). Experiments were carried out on a Codevintec CK-14e ASV in the towing tank of CNR-INM, under both irregular and regular head-sea wave conditions. The ASV under investigation features a recessed moon pool, which induces nonlinear responses due to sloshing, thereby increasing the modelling challenge. Data-driven reduced-order models were built from measurements of vessel motions and mooring loads. The HDMDc framework provided accurate deterministic predictions of vessel dynamics, while the Bayesian formulation enabled uncertainty-aware characterization of the model response by accounting for variability in hyperparameter selection. Validation against experimental data demonstrated that both HDMDc and BHDMDc can predict the vessel's response to unseen regular and irregular wave excitations. In conclusion, the study shows that HDMDc-based ROMs are a viable data-driven alternative for system identification, demonstrating for the first time their generalization capability for a sea condition different from the training set, achieving high accuracy in reproducing vessel dynamics.",
    "fetched_at": "2025-11-07T02:16:47.495434Z"
  },
  {
    "id": "2511.03488v1",
    "title": "NAP: Attention-Based Late Fusion for Automatic Sleep Staging",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alvise Dei Rossi",
      "Julia van der Meer",
      "Markus H. Schmidt",
      "Claudio L. A. Bassetti",
      "Luigi Fiorillo",
      "Francesca Faraci"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03488v1",
    "abstract": "Polysomnography signals are highly heterogeneous, varying in modality composition (e.g., EEG, EOG, ECG), channel availability (e.g., frontal, occipital EEG), and acquisition protocols across datasets and clinical sites. Most existing models that process polysomnography data rely on a fixed subset of modalities or channels and therefore neglect to fully exploit its inherently multimodal nature. We address this limitation by introducing NAP (Neural Aggregator of Predictions), an attention-based model which learns to combine multiple prediction streams using a tri-axial attention mechanism that captures temporal, spatial, and predictor-level dependencies. NAP is trained to adapt to different input dimensions. By aggregating outputs from frozen, pretrained single-channel models, NAP consistently outperforms individual predictors and simple ensembles, achieving state-of-the-art zero-shot generalization across multiple datasets. While demonstrated in the context of automated sleep staging from polysomnography, the proposed approach could be extended to other multimodal physiological applications.",
    "fetched_at": "2025-11-07T02:16:47.495380Z"
  },
  {
    "id": "2511.03492v1",
    "title": "Why Less is More (Sometimes): A Theory of Data Curation",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Elvis Dohmatob",
      "Mohammad Pezeshki",
      "Reyhane Askari-Hemmat"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03492v1",
    "abstract": "This paper introduces a theoretical framework to resolve a central paradox in modern machine learning: When is it better to use less data? This question has become critical as classical scaling laws suggesting ``more is more'' (Sun et al., 2025) are challenged by methods like LIMO (``less is more'') and s1 (Ye et al., 2025; Muenighoff et al., 2025), which achieve superior performance with small, aggressively curated datasets. Here, we study data curation strategies where an imperfect oracle selects the training examples according to their difficulty and correctness. Our results provide exact scaling law curves for test error under both label-agnostic and label-aware curation rules, revealing when and why keeping only a subset of data can improve generalization. In contrast to classical scaling laws, we show that under certain conditions, small curated datasets can outperform full datasets, and we provide analytical conditions for this by deriving precise phase transition curves tied to data size and quality. We validate these theoretical claims with empirical results on ImageNet, confirming our predictions about when curation improves accuracy and can even mitigate model collapse. Furthermore, our framework provides a principled explanation for the contradictory curation strategies recently observed in LLM mathematical reasoning.",
    "fetched_at": "2025-11-07T02:16:47.495329Z"
  },
  {
    "id": "2511.03498v1",
    "title": "BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English   Translation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kazi Reyazul Hasan",
      "Mubasshira Musarrat",
      "A. B. M. Alim Al Islam",
      "Muhammad Abdullah Adnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03498v1",
    "abstract": "Large language models work well for technical problem solving in English but perform poorly when the same questions are asked in Bangla. A simple solution would be to translate Bangla questions into English first and then use these models. However, existing Bangla-English translation systems struggle with technical terms. They often mistranslate specialized vocabulary, which changes the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM fields including computer science, mathematics, physics, chemistry, and biology. We generated over 12,000 translations using language models and then used human evaluators to select the highest quality pairs that preserve technical terminology correctly. We train a T5-based translation model on BanglaSTEM and test it on two tasks: generating code and solving math problems. Our results show significant improvements in translation accuracy for technical content, making it easier for Bangla speakers to use English-focused language models effectively. Both the BanglaSTEM dataset and the trained translation model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.",
    "fetched_at": "2025-11-07T02:16:47.495224Z"
  },
  {
    "id": "2511.03499v2",
    "title": "A Theoretical Framework for Environmental Similarity and Vessel Mobility   as Coupled Predictors of Marine Invasive Species Pathways",
    "date": "2025-11-05",
    "tags": [
      "cs.CE",
      "CE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gabriel Spadon",
      "Vaishnav Vaidheeswaran",
      "Claudio DiBacco"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03499v2",
    "abstract": "Marine invasive species spread through global shipping and generate substantial ecological and economic impacts. Traditional risk assessments require detailed records of ballast water and traffic patterns, which are often incomplete, limiting global coverage. This work advances a theoretical framework that quantifies invasion risk by combining environmental similarity across ports with observed and forecasted maritime mobility. Climate-based feature representations characterize each port's marine conditions, while mobility networks derived from Automatic Identification System data capture vessel flows and potential transfer pathways. Clustering and metric learning reveal climate analogues and enable the estimation of species survival likelihood along shipping routes. A temporal link prediction model captures how traffic patterns may change under shifting environmental conditions. The resulting fusion of environmental similarity and predicted mobility provides exposure estimates at the port and voyage levels, supporting targeted monitoring, routing adjustments, and management interventions.",
    "fetched_at": "2025-11-07T02:16:47.495176Z"
  },
  {
    "id": "2511.03508v1",
    "title": "One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction   Following with a Benchmark Evolving Framework",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Qi Jia",
      "Kaiwei Zhang",
      "Xiujie Song",
      "Ye Shen",
      "Xiangyang Zhu",
      "Guangtao Zhai"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03508v1",
    "abstract": "Understanding how well large language models can follow users' instructions throughout a dialogue spanning multiple topics is of great importance for data-intensive conversational applications. Existing benchmarks are often limited to a fixed number of turns, making them susceptible to saturation and failing to account for the user's interactive experience. In this work, we propose an extensible framework for assessing multi-turn instruction-following ability. At its core, our framework decouples linguistic surface forms from user intent simulation through a three-layer mechanism that tracks constraints, instructions, and topics. This framework mimics User-LLM interaction by enabling the dynamic construction of benchmarks with state changes and tracebacks, terminating a conversation only when the model exhausts a simulated user's patience. We define a suite of metrics capturing the quality of the interaction process. Using this framework, we construct EvolIF, an evolving instruction-following benchmark incorporating nine distinct constraint types. Our results indicate that GPT-5 exhibits superior instruction-following performance. It sustains an average of 18.54 conversational turns and demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant margin of 11.41%, while other models lag far behind. All of the data and code will be made publicly available online.",
    "fetched_at": "2025-11-07T02:16:47.495041Z"
  },
  {
    "id": "2511.03527v1",
    "title": "Learning Without Critics? Revisiting GRPO in Classical Reinforcement   Learning Environments",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bryan L. M. de Oliveira",
      "Felipe V. Frujeri",
      "Marcos P. C. M. Queiroz",
      "Luana G. B. Martins",
      "Telma W. de L. Soares",
      "Luckeciano C. Melo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03527v1",
    "abstract": "Group Relative Policy Optimization (GRPO) has emerged as a scalable alternative to Proximal Policy Optimization (PPO) by eliminating the learned critic and instead estimating advantages through group-relative comparisons of trajectories. This simplification raises fundamental questions about the necessity of learned baselines in policy-gradient methods. We present the first systematic study of GRPO in classical single-task reinforcement learning environments, spanning discrete and continuous control tasks. Through controlled ablations isolating baselines, discounting, and group sampling, we reveal three key findings: (1) learned critics remain essential for long-horizon tasks: all critic-free baselines underperform PPO except in short-horizon environments like CartPole where episodic returns can be effective; (2) GRPO benefits from high discount factors (gamma = 0.99) except in HalfCheetah, where lack of early termination favors moderate discounting (gamma = 0.9); (3) smaller group sizes outperform larger ones, suggesting limitations in batch-based grouping strategies that mix unrelated episodes. These results reveal both the limitations of critic-free methods in classical control and the specific conditions where they remain viable alternatives to learned value functions.",
    "fetched_at": "2025-11-07T02:16:47.494986Z"
  },
  {
    "id": "2511.03529v1",
    "title": "Byzantine-Robust Federated Learning with Learnable Aggregation Weights",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Javad Parsa",
      "Amir Hossein Daghestani",
      "Andr M. H. Teixeira",
      "Mikael Johansson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03529v1",
    "abstract": "Federated Learning (FL) enables clients to collaboratively train a global model without sharing their private data. However, the presence of malicious (Byzantine) clients poses significant challenges to the robustness of FL, particularly when data distributions across clients are heterogeneous. In this paper, we propose a novel Byzantine-robust FL optimization problem that incorporates adaptive weighting into the aggregation process. Unlike conventional approaches, our formulation treats aggregation weights as learnable parameters, jointly optimizing them alongside the global model parameters. To solve this optimization problem, we develop an alternating minimization algorithm with strong convergence guarantees under adversarial attack. We analyze the Byzantine resilience of the proposed objective. We evaluate the performance of our algorithm against state-of-the-art Byzantine-robust FL approaches across various datasets and attack scenarios. Experimental results demonstrate that our method consistently outperforms existing approaches, particularly in settings with highly heterogeneous data and a large proportion of malicious clients.",
    "fetched_at": "2025-11-07T02:16:47.494931Z"
  },
  {
    "id": "2511.03531v1",
    "title": "Efficient Neural Networks with Discrete Cosine Transform Activations",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Marc Martinez-Gost",
      "Sara Pepe",
      "Ana Prez-Neira",
      "Miguel ngel Lagunas"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03531v1",
    "abstract": "In this paper, we extend our previous work on the Expressive Neural Network (ENN), a multilayer perceptron with adaptive activation functions parametrized using the Discrete Cosine Transform (DCT). Building upon previous work that demonstrated the strong expressiveness of ENNs with compact architectures, we now emphasize their efficiency, interpretability and pruning capabilities. The DCT-based parameterization provides a structured and decorrelated representation that reveals the functional role of each neuron and allows direct identification of redundant components. Leveraging this property, we propose an efficient pruning strategy that removes unnecessary DCT coefficients with negligible or no loss in performance. Experimental results across classification and implicit neural representation tasks confirm that ENNs achieve state-of-the-art accuracy while maintaining a low number of parameters. Furthermore, up to 40% of the activation coefficients can be safely pruned, thanks to the orthogonality and bounded nature of the DCT basis. Overall, these findings demonstrate that the ENN framework offers a principled integration of signal processing concepts into neural network design, achieving a balanced trade-off between expressiveness, compactness, and interpretability.",
    "fetched_at": "2025-11-07T02:16:47.494885Z"
  },
  {
    "id": "2511.03545v1",
    "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis   (Part I)",
    "date": "2025-11-05",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sebastian Ordyniak",
      "Giacomo Paesani",
      "Mateusz Rychlicki",
      "Stefan Szeider"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03545v1",
    "abstract": "This paper presents a comprehensive theoretical investigation into the parameterized complexity of explanation problems in various machine learning (ML) models. Contrary to the prevalent black-box perception, our study focuses on models with transparent internal mechanisms. We address two principal types of explanation problems: abductive and contrastive, both in their local and global variants. Our analysis encompasses diverse ML models, including Decision Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof, each offering unique explanatory challenges. This research fills a significant gap in explainable AI (XAI) by providing a foundational understanding of the complexities of generating explanations for these models. This work provides insights vital for further research in the domain of XAI, contributing to the broader discourse on the necessity of transparency and accountability in AI systems.",
    "fetched_at": "2025-11-07T02:16:47.494778Z"
  },
  {
    "id": "2511.03547v1",
    "title": "Bearing Syntactic Fruit with Stack-Augmented Neural Networks",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Brian DuSell",
      "Ryan Cotterell"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03547v1",
    "abstract": "Any finite set of training data is consistent with an infinite number of hypothetical algorithms that could have generated it. Studies have shown that when human children learn language, they consistently favor hypotheses based on hierarchical syntactic rules without ever encountering disambiguating examples. A recent line of work has inquired as to whether common neural network architectures share this bias, finding that they do so only under special conditions: when syntactically supervised, when pre-trained on massive corpora, or when trained long past convergence. In this paper, we demonstrate, for the first time, neural network architectures that are able to generalize in human-like fashion without any of the aforementioned requirements: stack-augmented neural networks. We test three base architectures (transformer, simple RNN, LSTM) augmented with two styles of stack: the superposition stack of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed by DuSell & Chiang (2023). We find that transformers with nondeterministic stacks generalize best out of these architectures on a classical question formation task. We also propose a modification to the stack RNN architecture that improves hierarchical generalization. These results suggest that stack-augmented neural networks may be more accurate models of human language acquisition than standard architectures, serving as useful objects of psycholinguistic study. Our code is publicly available.",
    "fetched_at": "2025-11-07T02:16:47.494734Z"
  },
  {
    "id": "2511.03549v1",
    "title": "Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code   Understanding",
    "date": "2025-11-05",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ziv Nevo",
      "Orna Raz",
      "Karen Yorav"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03549v1",
    "abstract": "Understanding the purpose of source code is a critical task in software maintenance, onboarding, and modernization. While large language models (LLMs) have shown promise in generating code explanations, they often lack grounding in the broader software engineering context. We propose a novel approach that leverages natural language artifacts from GitHub -- such as pull request descriptions, issue descriptions and discussions, and commit messages -- to enhance LLM-based code understanding. Our system consists of three components: one that extracts and structures relevant GitHub context, another that uses this context to generate high-level explanations of the code's purpose, and a third that validates the explanation. We implemented this as a standalone tool, as well as a server within the Model Context Protocol (MCP), enabling integration with other AI-assisted development tools. Our main use case is that of enhancing a standard LLM-based code explanation with code insights that our system generates. To evaluate explanations' quality, we conducted a small scale user study, with developers of several open projects, as well as developers of proprietary projects. Our user study indicates that when insights are generated they often are helpful and non trivial, and are free from hallucinations.",
    "fetched_at": "2025-11-07T02:16:47.494691Z"
  },
  {
    "id": "2511.03548v1",
    "title": "Flat Minima and Generalization: Insights from Stochastic Convex   Optimization",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Matan Schliserman",
      "Shira Vansover-Hager",
      "Tomer Koren"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03548v1",
    "abstract": "Understanding the generalization behavior of learning algorithms is a central goal of learning theory. A recently emerging explanation is that learning algorithms are successful in practice because they converge to flat minima, which have been consistently associated with improved generalization performance. In this work, we study the link between flat minima and generalization in the canonical setting of stochastic convex optimization with a non-negative, $\\beta$-smooth objective. Our first finding is that, even in this fundamental and well-studied setting, flat empirical minima may incur trivial $\\Omega(1)$ population risk while sharp minima generalizes optimally. Then, we show that this poor generalization behavior extends to two natural ''sharpness-aware'' algorithms originally proposed by Foret et al. (2021), designed to bias optimization toward flat solutions: Sharpness-Aware Gradient Descent (SA-GD) and Sharpness-Aware Minimization (SAM). For SA-GD, which performs gradient steps on the maximal loss in a predefined neighborhood, we prove that while it successfully converges to a flat minimum at a fast rate, the population risk of the solution can still be as large as $\\Omega(1)$, indicating that even flat minima found algorithmically using a sharpness-aware gradient method might generalize poorly. For SAM, a computationally efficient approximation of SA-GD based on normalized ascent steps, we show that although it minimizes the empirical loss, it may converge to a sharp minimum and also incur population risk $\\Omega(1)$. Finally, we establish population risk upper bounds for both SA-GD and SAM using algorithmic stability techniques.",
    "fetched_at": "2025-11-07T02:16:47.494646Z"
  },
  {
    "id": "2511.03553v1",
    "title": "MultiZebraLogic: A Multilingual Logical Reasoning Benchmark",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sofie Helene Bruun",
      "Dan Saattrup Smart"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03553v1",
    "abstract": "Measuring the full abilities of large language models (LLMs) requires benchmarks representing multiple tasks. We aim to create large, high-quality datasets for comparison of logical reasoning skills across several languages and of suitable difficulty for LLMs of various reasoning ability. We explore multiple ways of increasing difficulty. We generate zebra puzzles in multiple languages, themes, sizes and including 14 different clue types and 8 red herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a reasoning model), respectively. Including 5 red herrings decreases o3-mini puzzle-level accuracy on 4x5 puzzles by 15$\\pm$7 %. Scores of o3-mini on 4x5 puzzles are not significantly affected by use of English vs. Danish or the common houses theme vs. the country-specific smoerrebroed theme. We find no correlation between difficulty and the selected clue types. Datasets of 128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic languages for sizes 2x3 and 4x5. We publish code for puzzle generation, designed for adaptablity into more languages and themes.",
    "fetched_at": "2025-11-07T02:16:47.494597Z"
  },
  {
    "id": "2511.03554v1",
    "title": "The Structure of Cross-Validation Error: Stability, Covariance, and   Minimax Limits",
    "date": "2025-11-05",
    "tags": [
      "math.ST",
      "ST",
      "cs.LG",
      "LG",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Ido Nachum",
      "Rdiger Urbanke",
      "Thomas Weinberger"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03554v1",
    "abstract": "Despite ongoing theoretical research on cross-validation (CV), many theoretical questions about CV remain widely open. This motivates our investigation into how properties of algorithm-distribution pairs can affect the choice for the number of folds in $k$-fold cross-validation.   Our results consist of a novel decomposition of the mean-squared error of cross-validation for risk estimation, which explicitly captures the correlations of error estimates across overlapping folds and includes a novel algorithmic stability notion, squared loss stability, that is considerably weaker than the typically required hypothesis stability in other comparable works.   Furthermore, we prove:   1. For every learning algorithm that minimizes empirical error, a minimax lower bound on the mean-squared error of $k$-fold CV estimating the population risk $L_\\mathcal{D}$: \\[ \\min_{k \\mid n}\\; \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega\\!\\big(\\sqrt{k}/n\\big), \\] where $n$ is the sample size and $k$ the number of folds. This shows that even under idealized conditions, for large values of $k$, CV cannot attain the optimum of order $1/n$ achievable by a validation set of size $n$, reflecting an inherent penalty caused by dependence between folds.   2. Complementing this, we exhibit learning rules for which \\[   \\max_{\\mathcal{D}}\\; \\mathbb{E}\\!\\left[\\big(\\widehat{L}_{\\mathrm{CV}}^{(k)} - L_{\\mathcal{D}}\\big)^{2}\\right] \\;=\\; \\Omega(k/n), \\] matching (up to constants) the accuracy of a hold-out estimator of a single fold of size $n/k$.   Together these results delineate the fundamental trade-off in resampling-based risk estimation: CV cannot fully exploit all $n$ samples for unbiased risk evaluation, and its minimax performance is pinned between the $k/n$ and $\\sqrt{k}/n$ regimes.",
    "fetched_at": "2025-11-07T02:16:47.494557Z"
  },
  {
    "id": "2511.03559v1",
    "title": "AILA--First Experiments with Localist Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Joachim Diederich"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03559v1",
    "abstract": "This paper presents the first empirical demonstration of controllable locality in transformer language models, a novel architectural framework that enables continuous control over the degree of representation localization through a tunable locality dial parameter. Unlike traditional language models that rely exclusively on distributed representations, our approach allows dynamic interpolation between highly interpretable localist encodings and efficient distributed representations without requiring model retraining. We conducted experiments on the WikiText corpus using a two-layer transformer architecture, systematically varying the locality parameter {\\lambda} across the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our results demonstrate that localist configurations achieve dramatically lower attention entropy, with {\\lambda} = 1.0 yielding 5.36 bits compared to 7.18 bits at {\\lambda} = 0.0, while maintaining substantially higher pointer fidelity scores reflecting stronger alignment with rule-specified targets. Prediction experiments reveal that intermediate locality values optimize the tradeoff between interpretability and performance, with {\\lambda} = 0.6 achieving test perplexity of 4.65 and accuracy of 84.7%. These findings establish that localist language models provide a practical framework for applications in regulated domains requiring both transparency and capability, offering precise mathematical control over the interpretability-performance spectrum through explicit penalty thresholds and information-theoretic design principles.",
    "fetched_at": "2025-11-07T02:16:47.494508Z"
  },
  {
    "id": "2511.03563v1",
    "title": "ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for   Enhanced Legal Regulation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "One Octadion",
      "Bondan Sapta Prakoso",
      "Nanang Yudi Setiawan",
      "Novanto Yudistira"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03563v1",
    "abstract": "In this study, we explore the fine-tuning of Large Language Models (LLMs) to better support policymakers in their crucial work of understanding, analyzing, and crafting legal regulations. To equip the model with a deep understanding of legal texts, we curated a supervised dataset tailored to the specific needs of the legal domain. Additionally, we integrated the Retrieval-Augmented Generation (RAG) method, enabling the LLM to access and incorporate up-to-date legal knowledge from external sources. This combination of fine-tuning and RAG-based augmentation results in a tool that not only processes legal information but actively assists policymakers in interpreting regulations and drafting new ones that align with current needs. The results demonstrate that this approach can significantly enhance the effectiveness of legal research and regulation development, offering a valuable resource in the ever-evolving field of law.",
    "fetched_at": "2025-11-07T02:16:47.494466Z"
  },
  {
    "id": "2511.03565v1",
    "title": "Imitation Learning in the Deep Learning Era: A Novel Taxonomy and Recent   Advances",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Iason Chrysomallis",
      "Georgios Chalkiadakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03565v1",
    "abstract": "Imitation learning (IL) enables agents to acquire skills by observing and replicating the behavior of one or multiple experts. In recent years, advances in deep learning have significantly expanded the capabilities and scalability of imitation learning across a range of domains, where expert data can range from full state-action trajectories to partial observations or unlabeled sequences. Alongside this growth, novel approaches have emerged, with new methodologies being developed to address longstanding challenges such as generalization, covariate shift, and demonstration quality. In this survey, we review the latest advances in imitation learning research, highlighting recent trends, methodological innovations, and practical applications. We propose a novel taxonomy that is distinct from existing categorizations to better reflect the current state of the IL research stratum and its trends. Throughout the survey, we critically examine the strengths, limitations, and evaluation practices of representative works, and we outline key challenges and open directions for future research.",
    "fetched_at": "2025-11-07T02:16:47.494421Z"
  },
  {
    "id": "2511.03570v1",
    "title": "TabGemma: Text-Based Tabular ICL via LLM using Continued Pretraining and   Retrieval",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gnther Schindler",
      "Maximilian Schambach",
      "Michael Medek",
      "Sam Thelin"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03570v1",
    "abstract": "We study LLMs for tabular prediction with mixed text, numeric, and categorical fields. We introduce TabGemma, a schema-agnostic in-context learner that treats rows as sequences and tackles two practical hurdles when adapting pretrained LLMs for tabular predictions: unstable numeric tokenization and limited context size. We propose to canonicalize numbers via signed scientific notation and continue pretraining of a 12B Gemma 3 model with a target imputation objective using a large-scale real world dataset. For inference, we use a compact n-gram-based retrieval to select informative exemplars that fit within a 128k-token window.   On semantically rich benchmarks, TabGemma establishes a new state of the art on classification across low- and high-data regimes and improves monotonically with more context rows. For regression, it is competitive at small sample sizes but trails conventional approaches as data grows. Our results show that LLMs can be effective tabular in-context learners on highly semantic tasks when paired with dedicated numeric handling and context retrieval, while motivating further advances in numeric modeling and long-context scaling.",
    "fetched_at": "2025-11-07T02:16:47.494379Z"
  },
  {
    "id": "2511.03576v1",
    "title": "Multi-User Personalisation in Human-Robot Interaction: Using   Quantitative Bipolar Argumentation Frameworks for Preferences Conflict   Resolution",
    "date": "2025-11-05",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "68T40",
      "I.2.9; I.2.4",
      "4"
    ],
    "authors": [
      "Aniol Civit",
      "Antonio Andriella",
      "Carles Sierra",
      "Guillem Aleny"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03576v1",
    "abstract": "While personalisation in Human-Robot Interaction (HRI) has advanced significantly, most existing approaches focus on single-user adaptation, overlooking scenarios involving multiple stakeholders with potentially conflicting preferences. To address this, we propose the Multi-User Preferences Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user personalisation framework based on Quantitative Bipolar Argumentation Frameworks (QBAFs) that explicitly models and resolves multi-user preference conflicts. Unlike prior work in Argumentation Frameworks, which typically assumes static inputs, our approach is tailored to robotics: it incorporates both users' arguments and the robot's dynamic observations of the environment, allowing the system to adapt over time and respond to changing contexts. Preferences, both positive and negative, are represented as arguments whose strength is recalculated iteratively based on new information. The framework's properties and capabilities are presented and validated through a realistic case study, where an assistive robot mediates between the conflicting preferences of a caregiver and a care recipient during a frailty assessment task. This evaluation further includes a sensitivity analysis of argument base scores, demonstrating how preference outcomes can be shaped by user input and contextual observations. By offering a transparent, structured, and context-sensitive approach to resolving competing user preferences, this work advances the field of multi-user HRI. It provides a principled alternative to data-driven methods, enabling robots to navigate conflicts in real-world environments.",
    "fetched_at": "2025-11-07T02:16:47.494332Z"
  },
  {
    "id": "2511.03578v1",
    "title": "Learning Under Laws: A Constraint-Projected Neural PDE Solver that   Eliminates Hallucinations",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mainak Singha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03578v1",
    "abstract": "Neural networks can approximate solutions to partial differential equations, but they often break the very laws they are meant to model-creating mass from nowhere, drifting shocks, or violating conservation and entropy. We address this by training within the laws of physics rather than beside them. Our framework, called Constraint-Projected Learning (CPL), keeps every update physically admissible by projecting network outputs onto the intersection of constraint sets defined by conservation, Rankine-Hugoniot balance, entropy, and positivity. The projection is differentiable and adds only about 10% computational overhead, making it fully compatible with back-propagation. We further stabilize training with total-variation damping (TVD) to suppress small oscillations and a rollout curriculum that enforces consistency over long prediction horizons. Together, these mechanisms eliminate both hard and soft violations: conservation holds at machine precision, total-variation growth vanishes, and entropy and error remain bounded. On Burgers and Euler systems, CPL produces stable, physically lawful solutions without loss of accuracy. Instead of hoping neural solvers will respect physics, CPL makes that behavior an intrinsic property of the learning process.",
    "fetched_at": "2025-11-07T02:16:47.494278Z"
  },
  {
    "id": "2511.03595v1",
    "title": "Tensor-Efficient High-Dimensional Q-learning",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Junyi Wu",
      "Dan Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03595v1",
    "abstract": "High-dimensional reinforcement learning faces challenges with complex calculations and low sample efficiency in large state-action spaces. Q-learning algorithms struggle particularly with the curse of dimensionality, where the number of state-action pairs grows exponentially with problem size. While neural network-based approaches like Deep Q-Networks have shown success, recent tensor-based methods using low-rank decomposition offer more parameter-efficient alternatives. Building upon existing tensor-based methods, we propose Tensor-Efficient Q-Learning (TEQL), which enhances low-rank tensor decomposition via improved block coordinate descent on discretized state-action spaces, incorporating novel exploration and regularization mechanisms. The key innovation is an exploration strategy that combines approximation error with visit count-based upper confidence bound to prioritize actions with high uncertainty, avoiding wasteful random exploration. Additionally, we incorporate a frequency-based penalty term in the objective function to encourage exploration of less-visited state-action pairs and reduce overfitting to frequently visited regions. Empirical results on classic control tasks demonstrate that TEQL outperforms conventional matrix-based methods and deep RL approaches in both sample efficiency and total rewards, making it suitable for resource-constrained applications, such as space and healthcare where sampling costs are high.",
    "fetched_at": "2025-11-07T02:16:47.494178Z"
  },
  {
    "id": "2511.03601v1",
    "title": "Step-Audio-EditX Technical Report",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.SD",
      "SD",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Chao Yan",
      "Boyong Wu",
      "Peng Yang",
      "Pengfei Tan",
      "Guoqiang Hu",
      "Yuxin Zhang",
      "Xiangyu",
      "Zhang",
      "Fei Tian",
      "Xuerui Yang",
      "Xiangyu Zhang",
      "Daxin Jiang",
      "Gang Yu"
    ],
    "institution": "Tony",
    "link": "http://arxiv.org/pdf/2511.03601v1",
    "abstract": "We present Step-Audio-EditX, the first open-source LLM-based audio model excelling at expressive and iterative audio editing encompassing emotion, speaking style, and paralinguistics alongside robust zero-shot text-to-speech (TTS) capabilities.Our core innovation lies in leveraging only large-margin synthetic data, which circumvents the need for embedding-based priors or auxiliary modules. This large-margin learning approach enables both iterative control and high expressivity across voices, and represents a fundamental pivot from the conventional focus on representation-level disentanglement. Evaluation results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.",
    "fetched_at": "2025-11-07T02:16:47.494133Z"
  },
  {
    "id": "2511.03606v1",
    "title": "Vector-valued self-normalized concentration inequalities beyond   sub-Gaussianity",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Diego Martinez-Taboada",
      "Tomas Gonzalez",
      "Aaditya Ramdas"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03606v1",
    "abstract": "The study of self-normalized processes plays a crucial role in a wide range of applications, from sequential decision-making to econometrics. While the behavior of self-normalized concentration has been widely investigated for scalar-valued processes, vector-valued processes remain comparatively underexplored, especially outside of the sub-Gaussian framework. In this contribution, we provide concentration bounds for self-normalized processes with light tails beyond sub-Gaussianity (such as Bennett or Bernstein bounds). We illustrate the relevance of our results in the context of online linear regression, with applications in (kernelized) linear bandits.",
    "fetched_at": "2025-11-07T02:16:47.494044Z"
  },
  {
    "id": "2511.03610v1",
    "title": "A systematic review of relation extraction task since the emergence of   Transformers",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "A.1; I.2.4; I.2.7",
      "7"
    ],
    "authors": [
      "Ringwald Celian",
      "Gandon",
      "Fabien",
      "Faron Catherine",
      "Michel Franck",
      "Abi Akl Hanna"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03610v1",
    "abstract": "This article presents a systematic review of relation extraction (RE) research since the advent of Transformer-based models. Using an automated framework to collect and annotate publications, we analyze 34 surveys, 64 datasets, and 104 models published between 2019 and 2024. The review highlights methodological advances, benchmark resources, and the integration of semantic web technologies. By consolidating results across multiple dimensions, the study identifies current trends, limitations, and open challenges, offering researchers and practitioners a comprehensive reference for understanding the evolution and future directions of RE.",
    "fetched_at": "2025-11-07T02:16:47.494003Z"
  },
  {
    "id": "2511.03617v1",
    "title": "Visualization Biases MLLM's Decision Making in Network Data Tasks",
    "date": "2025-11-05",
    "tags": [
      "cs.GR",
      "GR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Timo Brand",
      "Henry Frster",
      "Stephen G. Kobourov",
      "Jacob Miller"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03617v1",
    "abstract": "We evaluate how visualizations can influence the judgment of MLLMs about the presence or absence of bridges in a network. We show that the inclusion of visualization improves confidence over a structured text-based input that could theoretically be helpful for answering the question. On the other hand, we observe that standard visualization techniques create a strong bias towards accepting or refuting the presence of a bridge -- independently of whether or not a bridge actually exists in the network. While our results indicate that the inclusion of visualization techniques can effectively influence the MLLM's judgment without compromising its self-reported confidence, they also imply that practitioners must be careful of allowing users to include visualizations in generative AI applications so as to avoid undesired hallucinations.",
    "fetched_at": "2025-11-07T02:16:47.493908Z"
  },
  {
    "id": "2511.03618v1",
    "title": "Towards Formalizing Reinforcement Learning Theory",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Shangtong Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03618v1",
    "abstract": "In this paper, we formalize the almost sure convergence of $Q$-learning and linear temporal difference (TD) learning with Markovian samples using the Lean 4 theorem prover based on the Mathlib library. $Q$-learning and linear TD are among the earliest and most influential reinforcement learning (RL) algorithms. The investigation of their convergence properties is not only a major research topic during the early development of the RL field but also receives increasing attention nowadays. This paper formally verifies their almost sure convergence in a unified framework based on the Robbins-Siegmund theorem. The framework developed in this work can be easily extended to convergence rates and other modes of convergence. This work thus makes an important step towards fully formalizing convergent RL results. The code is available at https://github.com/ShangtongZhang/rl-theory-in-lean.",
    "fetched_at": "2025-11-07T02:16:47.493865Z"
  },
  {
    "id": "2511.03620v1",
    "title": "CLAX: Fast and Flexible Neural Click Models in JAX",
    "date": "2025-11-05",
    "tags": [
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Philipp Hager",
      "Onno Zoeter",
      "Maarten de Rijke"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03620v1",
    "abstract": "CLAX is a JAX-based library that implements classic click models using modern gradient-based optimization. While neural click models have emerged over the past decade, complex click models based on probabilistic graphical models (PGMs) have not systematically adopted gradient-based optimization, preventing practitioners from leveraging modern deep learning frameworks while preserving the interpretability of classic models. CLAX addresses this gap by replacing EM-based optimization with direct gradient-based optimization in a numerically stable manner. The framework's modular design enables the integration of any component, from embeddings and deep networks to custom modules, into classic click models for end-to-end optimization. We demonstrate CLAX's efficiency by running experiments on the full Baidu-ULTR dataset comprising over a billion user sessions in $\\approx$ 2 hours on a single GPU, orders of magnitude faster than traditional EM approaches. CLAX implements ten classic click models, serving both industry practitioners seeking to understand user behavior and improve ranking performance at scale and researchers developing new click models. CLAX is available at: https://github.com/philipphager/clax",
    "fetched_at": "2025-11-07T02:16:47.493831Z"
  },
  {
    "id": "2511.03631v1",
    "title": "Financial Management System for SMEs: Real-World Deployment of Accounts   Receivable and Cash Flow Prediction",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bartomiej Makus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03631v1",
    "abstract": "Small and Medium Enterprises (SMEs), particularly freelancers and early-stage businesses, face unique financial management challenges due to limited resources, small customer bases, and constrained data availability. This paper presents the development and deployment of an integrated financial prediction system that combines accounts receivable prediction and cash flow forecasting specifically designed for SME operational constraints. Our system addresses the gap between enterprise-focused financial tools and the practical needs of freelancers and small businesses. The solution integrates two key components: a binary classification model for predicting invoice payment delays, and a multi-module cash flow forecasting model that handles incomplete and limited historical data. A prototype system has been implemented and deployed as a web application with integration into Cluee's platform, a startup providing financial management tools for freelancers, demonstrating practical feasibility for real-world SME financial management.",
    "fetched_at": "2025-11-07T02:16:47.493737Z"
  },
  {
    "id": "2511.03632v1",
    "title": "Neural Beamforming with Doppler-Aware Sparse Attention for High Mobility   Environments",
    "date": "2025-11-05",
    "tags": [
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "math.IT"
    ],
    "authors": [
      "Cemil Vahapoglu",
      "Timothy J. O'Shea",
      "Wan Liu",
      "Sennur Ulukus"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03632v1",
    "abstract": "Beamforming has significance for enhancing spectral efficiency and mitigating interference in multi-antenna wireless systems, facilitating spatial multiplexing and diversity in dense and high mobility scenarios. Traditional beamforming techniques such as zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming experience performance deterioration under adverse channel conditions. Deep learning-based beamforming offers an alternative with nonlinear mappings from channel state information (CSI) to beamforming weights by improving robustness against dynamic channel environments. Transformer-based models are particularly effective due to their ability to model long-range dependencies across time and frequency. However, their quadratic attention complexity limits scalability in large OFDM grids. Recent studies address this issue through sparse attention mechanisms that reduce complexity while maintaining expressiveness, yet often employ patterns that disregard channel dynamics, as they are not specifically designed for wireless communication scenarios. In this work, we propose a Doppler-aware Sparse Neural Network Beamforming (Doppler-aware Sparse NNBF) model that incorporates a channel-adaptive sparse attention mechanism in a multi-user single-input multiple-output (MU-SIMO) setting. The proposed sparsity structure is configurable along 2D time-frequency axes based on channel dynamics and is theoretically proven to ensure full connectivity within p hops, where p is the number of attention heads. Simulation results under urban macro (UMa) channel conditions show that Doppler-aware Sparse NNBF significantly outperforms both a fixed-pattern baseline, referred to as Standard Sparse NNBF, and conventional beamforming techniques ZFBF and MMSE beamforming in high mobility scenarios, while maintaining structured sparsity with a controlled number of attended keys per query.",
    "fetched_at": "2025-11-07T02:16:47.493696Z"
  },
  {
    "id": "2511.03634v1",
    "title": "nanoTabPFN: A Lightweight and Educational Reimplementation of TabPFN",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alexander Pfefferle",
      "Johannes Hog",
      "Lennart Purucker",
      "Frank Hutter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03634v1",
    "abstract": "Tabular foundation models such as TabPFN have revolutionized predictive machine learning for tabular data. At the same time, the driving factors of this revolution are hard to understand. Existing open-source tabular foundation models are implemented in complicated pipelines boasting over 10,000 lines of code, lack architecture documentation or code quality. In short, the implementations are hard to understand, not beginner-friendly, and complicated to adapt for new experiments. We introduce nanoTabPFN, a simplified and lightweight implementation of the TabPFN v2 architecture and a corresponding training loop that uses pre-generated training data. nanoTabPFN makes tabular foundation models more accessible to students and researchers alike. For example, restricted to a small data setting it achieves a performance comparable to traditional machine learning baselines within one minute of pre-training on a single GPU (160,000x faster than TabPFN v2 pretraining). This eliminated requirement of large computational resources makes pre-training tabular foundation models accessible for educational purposes. Our code is available at https://github.com/automl/nanoTabPFN.",
    "fetched_at": "2025-11-07T02:16:47.493641Z"
  },
  {
    "id": "2511.03635v1",
    "title": "Towards Transparent Stance Detection: A Zero-Shot Approach Using   Implicit and Explicit Interpretability",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Apoorva Upadhyaya",
      "Wolfgang Nejdl",
      "Marco Fisichella"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03635v1",
    "abstract": "Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward unseen targets. Existing research using contrastive, meta-learning, or data augmentation suffers from generalizability issues or lack of coherence between text and target. Recent works leveraging large language models (LLMs) for ZSSD focus either on improving unseen target-specific knowledge or generating explanations for stance analysis. However, most of these works are limited by their over-reliance on explicit reasoning, provide coarse explanations that lack nuance, and do not explicitly model the reasoning process, making it difficult to interpret the model's predictions. To address these issues, in our study, we develop a novel interpretable ZSSD framework, IRIS. We provide an interpretable understanding of the attitude of the input towards the target implicitly based on sequences within the text (implicit rationales) and explicitly based on linguistic measures (explicit rationales). IRIS considers stance detection as an information retrieval ranking task, understanding the relevance of implicit rationales for different stances to guide the model towards correct predictions without requiring the ground-truth of rationales, thus providing inherent interpretability. In addition, explicit rationales based on communicative features help decode the emotional and cognitive dimensions of stance, offering an interpretable understanding of the author's attitude towards the given target. Extensive experiments on the benchmark datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10% training data prove the generalizability of our model, benefiting from the proposed architecture and interpretable design.",
    "fetched_at": "2025-11-07T02:16:47.493595Z"
  },
  {
    "id": "2511.03636v1",
    "title": "Quantifying Weighted Morphological Content of Large-Scale Structures via   Simulation-Based Inference",
    "date": "2025-11-05",
    "tags": [
      "astro-ph.CO",
      "CO",
      "cs.LG",
      "LG",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "M. H. Jalali Kanafi",
      "S. M. S. Movahed"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03636v1",
    "abstract": "In this work, we perform a simulation-based forecasting analysis to compare the constraining power of two higher-order summary statistics of the large-scale structure (LSS), the Minkowski Functionals (MFs) and the Conditional Moments of Derivative (CMD), with a particular focus on their sensitivity to nonlinear and anisotropic features in redshift-space. Our analysis relies on halo catalogs from the Big Sobol Sequence(BSQ) simulations at redshift $z=0.5$, employing a likelihood-free inference framework implemented via neural posterior estimation. At the fiducial cosmology of the Quijote simulations $(\\Omega_{m}=0.3175,\\,\\sigma_{8}=0.834)$, and for the smoothing scale $R=15\\,h^{-1}$Mpc, we find that the CMD yields tighter forecasts for $(\\Omega_{m}},\\,\\sigma_{8})$ than the zeroth- to third-order MFs components, improving the constraint precision by ${\\sim}(44\\%,\\,52\\%)$, ${\\sim}(30\\%,\\,45\\%)$, ${\\sim}(27\\%,\\,17\\%)$, and ${\\sim}(26\\%,\\,17\\%)$, respectively. A joint configuration combining the MFs and CMD further enhances the precision by approximately ${\\sim}27\\%$ compared to the standard MFs alone, highlighting the complementary anisotropy-sensitive information captured by the CMD in contrast to the scalar morphological content encapsulated by the MFs. We further extend the forecasting analysis to a continuous range of cosmological parameter values and multiple smoothing scales. Our results show that, although the absolute forecast uncertainty for each component of summary statistics depends on the underlying parameter values and the adopted smoothing scale, the relative constraining power among the summary statistics remains nearly constant throughout.",
    "fetched_at": "2025-11-07T02:16:47.493547Z"
  },
  {
    "id": "2511.03641v1",
    "title": "Watermarking Large Language Models in Europe: Interpreting the AI Act in   Light of Technology",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "68T01, 68727, 68T30, 68T35, 68T37, 68T50"
    ],
    "authors": [
      "Thomas Souverain"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03641v1",
    "abstract": "To foster trustworthy Artificial Intelligence (AI) within the European Union, the AI Act requires providers to mark and detect the outputs of their general-purpose models. The Article 50 and Recital 133 call for marking methods that are ''sufficiently reliable, interoperable, effective and robust''. Yet, the rapidly evolving and heterogeneous landscape of watermarks for Large Language Models (LLMs) makes it difficult to determine how these four standards can be translated into concrete and measurable evaluations. Our paper addresses this challenge, anchoring the normativity of European requirements in the multiplicity of watermarking techniques. Introducing clear and distinct concepts on LLM watermarking, our contribution is threefold. (1) Watermarking Categorisation: We propose an accessible taxonomy of watermarking methods according to the stage of the LLM lifecycle at which they are applied - before, during, or after training, and during next-token distribution or sampling. (2) Watermarking Evaluation: We interpret the EU AI Act's requirements by mapping each criterion with state-of-the-art evaluations on robustness and detectability of the watermark, and of quality of the LLM. Since interoperability remains largely untheorised in LLM watermarking research, we propose three normative dimensions to frame its assessment. (3) Watermarking Comparison: We compare current watermarking methods for LLMs against the operationalised European criteria and show that no approach yet satisfies all four standards. Encouraged by emerging empirical tests, we recommend further research into watermarking directly embedded within the low-level architecture of LLMs.",
    "fetched_at": "2025-11-07T02:16:47.493501Z"
  },
  {
    "id": "2511.03643v1",
    "title": "Explaining Human Choice Probabilities with Simple Vector Representations",
    "date": "2025-11-05",
    "tags": [
      "q-bio.NC",
      "NC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Peter DiBerardino",
      "Britt Anderson"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03643v1",
    "abstract": "When people pursue rewards in stochastic environments, they often match their choice frequencies to the observed target frequencies, even when this policy is demonstrably sub-optimal. We used a ``hide and seek'' task to evaluate this behavior under conditions where pursuit (seeking) could be toggled to avoidance (hiding), while leaving the probability distribution fixed, or varying complexity by changing the number of possible choices. We developed a model for participant choice built from choice frequency histograms treated as vectors. We posited the existence of a probability antimatching strategy for avoidance (hiding) rounds, and formalized this as a vector reflection of probability matching. We found that only two basis policies: matching/antimatching and maximizing/minimizing were sufficient to account for participant choices across a range of room numbers and opponent probability distributions. This schema requires only that people have the ability to remember the relative frequency of the different outcomes. With this knowledge simple operations can construct the maximizing and minimizing policies as well as matching and antimatching strategies. A mixture of these two policies captures human choice patterns in a stochastic environment.",
    "fetched_at": "2025-11-07T02:16:47.493457Z"
  },
  {
    "id": "2511.03653v1",
    "title": "Efficient Testing Implies Structured Symmetry",
    "date": "2025-11-05",
    "tags": [
      "cs.CC",
      "CC",
      "cs.DS",
      "DS",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Cynthia Dwork",
      "Pranay Tankala"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03653v1",
    "abstract": "Given a small random sample of $n$-bit strings labeled by an unknown Boolean function, which properties of this function can be tested computationally efficiently? We show an equivalence between properties that are efficiently testable from few samples and properties with structured symmetry, which depend only on the function's average values on parts of a low-complexity partition of the domain. Without the efficiency constraint, a similar characterization in terms of unstructured symmetry was obtained by Blais and Yoshida (2019). Our main technical tool is supersimulation, which builds on methods from the algorithmic fairness literature to approximate arbitrarily complex functions by small-circuit simulators that fool significantly larger distinguishers.   We extend the characterization along other axes as well. We show that allowing parts to overlap exponentially reduces their required number, broadening the scope of the construction from properties testable with $O(\\log n)$ samples to properties testable with $O(n)$ samples. For larger sample sizes, we show that any efficient tester is essentially checking for indistinguishability from a bounded collection of small circuits, in the spirit of a characterization of testable graph properties. Finally, we show that our results for Boolean function testing generalize to high-entropy distribution testing on arbitrary domains.",
    "fetched_at": "2025-11-07T02:16:47.493416Z"
  },
  {
    "id": "2511.03656v1",
    "title": "ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained   Evaluation",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jing Gao",
      "Shutiao Luo",
      "Yumeng Liu",
      "Yuanming Li",
      "Hongji Zeng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03656v1",
    "abstract": "With the rapid advancement of natural language processing (NLP) technologies, the demand for high-quality Chinese document question-answering datasets is steadily growing. To address this issue, we present the Chinese Multi-Document Question Answering Dataset(ChiMDQA), specifically designed for downstream business scenarios across prevalent domains including academic, education, finance, law, medical treatment, and news. ChiMDQA encompasses long-form documents from six distinct fields, consisting of 6,068 rigorously curated, high-quality question-answer (QA) pairs further classified into ten fine-grained categories. Through meticulous document screening and a systematic question-design methodology, the dataset guarantees both diversity and high quality, rendering it applicable to various NLP tasks such as document comprehension, knowledge extraction, and intelligent QA systems. Additionally, this paper offers a comprehensive overview of the dataset's design objectives, construction methodologies, and fine-grained evaluation system, supplying a substantial foundation for future research and practical applications in Chinese QA. The code and data are available at: https://anonymous.4open.science/r/Foxit-CHiMDQA/.",
    "fetched_at": "2025-11-07T02:16:47.493372Z"
  },
  {
    "id": "2511.03661v1",
    "title": "SHIELD: Securing Healthcare IoT with Efficient Machine Learning   Techniques for Anomaly Detection",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mahek Desai",
      "Apoorva Rumale",
      "Marjan Asadinia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03661v1",
    "abstract": "The integration of IoT devices in healthcare introduces significant security and reliability challenges, increasing susceptibility to cyber threats and operational anomalies. This study proposes a machine learning-driven framework for (1) detecting malicious cyberattacks and (2) identifying faulty device anomalies, leveraging a dataset of 200,000 records. Eight machine learning models are evaluated across three learning approaches: supervised learning (XGBoost, K-Nearest Neighbors (K- NN)), semi-supervised learning (Generative Adversarial Networks (GAN), Variational Autoencoders (VAE)), and unsupervised learning (One-Class Support Vector Machine (SVM), Isolation Forest, Graph Neural Networks (GNN), and Long Short-Term Memory (LSTM) Autoencoders). The comprehensive evaluation was conducted across multiple metrics like F1-score, precision, recall, accuracy, ROC-AUC, computational efficiency. XGBoost achieved 99\\% accuracy with minimal computational overhead (0.04s) for anomaly detection, while Isolation Forest balanced precision and recall effectively. LSTM Autoencoders underperformed with lower accuracy and higher latency. For attack detection, KNN achieved near-perfect precision, recall, and F1-score with the lowest computational cost (0.05s), followed by VAE at 97% accuracy. GAN showed the highest computational cost with lowest accuracy and ROC-AUC. These findings enhance IoT-enabled healthcare security through effective anomaly detection strategies. By improving early detection of cyber threats and device failures, this framework has the potential to prevent data breaches, minimize system downtime, and ensure the continuous and safe operation of medical devices, ultimately safeguarding patient health and trust in IoT-driven healthcare solutions.",
    "fetched_at": "2025-11-07T02:16:47.493320Z"
  },
  {
    "id": "2511.03670v1",
    "title": "DQN Performance with Epsilon Greedy Policies and Prioritized Experience   Replay",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T05"
    ],
    "authors": [
      "Daniel Perkins",
      "Oscar J. Escobar",
      "Luke Green"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03670v1",
    "abstract": "We present a detailed study of Deep Q-Networks in finite environments, emphasizing the impact of epsilon-greedy exploration schedules and prioritized experience replay. Through systematic experimentation, we evaluate how variations in epsilon decay schedules affect learning efficiency, convergence behavior, and reward optimization. We investigate how prioritized experience replay leads to faster convergence and higher returns and show empirical results comparing uniform, no replay, and prioritized strategies across multiple simulations. Our findings illuminate the trade-offs and interactions between exploration strategies and memory management in DQN training, offering practical recommendations for robust reinforcement learning in resource-constrained settings.",
    "fetched_at": "2025-11-07T02:16:47.493269Z"
  },
  {
    "id": "2511.03675v1",
    "title": "Whisper Leak: a side-channel attack on Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "K.4.1; C.2.0; K.6.5; I.2.7",
      "7"
    ],
    "authors": [
      "Geoff McDonald",
      "Jonathan Bar Or"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.03675v1",
    "abstract": "Large Language Models (LLMs) are increasingly deployed in sensitive domains including healthcare, legal services, and confidential communications, where privacy is paramount. This paper introduces Whisper Leak, a side-channel attack that infers user prompt topics from encrypted LLM traffic by analyzing packet size and timing patterns in streaming responses. Despite TLS encryption protecting content, these metadata patterns leak sufficient information to enable topic classification. We demonstrate the attack across 28 popular LLMs from major providers, achieving near-perfect classification (often >98% AUPRC) and high precision even at extreme class imbalance (10,000:1 noise-to-target ratio). For many models, we achieve 100% precision in identifying sensitive topics like \"money laundering\" while recovering 5-20% of target conversations. This industry-wide vulnerability poses significant risks for users under network surveillance by ISPs, governments, or local adversaries. We evaluate three mitigation strategies - random padding, token batching, and packet injection - finding that while each reduces attack effectiveness, none provides complete protection. Through responsible disclosure, we have collaborated with providers to implement initial countermeasures. Our findings underscore the need for LLM providers to address metadata leakage as AI systems handle increasingly sensitive information.",
    "fetched_at": "2025-11-07T02:16:47.493226Z"
  },
  {
    "id": "2511.03685v1",
    "title": "Structured Matrix Scaling for Multi-Class Calibration",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Eugne Berta",
      "David Holzmller",
      "Michael I. Jordan",
      "Francis Bach"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03685v1",
    "abstract": "Post-hoc recalibration methods are widely used to ensure that classifiers provide faithful probability estimates. We argue that parametric recalibration functions based on logistic regression can be motivated from a simple theoretical setting for both binary and multiclass classification. This insight motivates the use of more expressive calibration methods beyond standard temperature scaling. For multi-class calibration however, a key challenge lies in the increasing number of parameters introduced by more complex models, often coupled with limited calibration data, which can lead to overfitting. Through extensive experiments, we demonstrate that the resulting bias-variance tradeoff can be effectively managed by structured regularization, robust preprocessing and efficient optimization. The resulting methods lead to substantial gains over existing logistic-based calibration techniques. We provide efficient and easy-to-use open-source implementations of our methods, making them an attractive alternative to common temperature, vector, and matrix scaling implementations.",
    "fetched_at": "2025-11-07T02:16:47.493181Z"
  },
  {
    "id": "2511.03693v1",
    "title": "Colorectal Cancer Histopathological Grading using Multi-Scale Federated   Learning",
    "date": "2025-11-05",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Md Ahasanul Arafath",
      "Abhijit Kumar Ghosh",
      "Md Rony Ahmed",
      "Sabrin Afroz",
      "Minhazul Hosen",
      "Md Hasan Moon",
      "Md Tanzim Reza",
      "Md Ashad Alam"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03693v1",
    "abstract": "Colorectal cancer (CRC) grading is a critical prognostic factor but remains hampered by inter-observer variability and the privacy constraints of multi-institutional data sharing. While deep learning offers a path to automation, centralized training models conflict with data governance regulations and neglect the diagnostic importance of multi-scale analysis. In this work, we propose a scalable, privacy-preserving federated learning (FL) framework for CRC histopathological grading that integrates multi-scale feature learning within a distributed training paradigm. Our approach employs a dual-stream ResNetRS50 backbone to concurrently capture fine-grained nuclear detail and broader tissue-level context. This architecture is integrated into a robust FL system stabilized using FedProx to mitigate client drift across heterogeneous data distributions from multiple hospitals. Extensive evaluation on the CRC-HGD dataset demonstrates that our framework achieves an overall accuracy of 83.5%, outperforming a comparable centralized model (81.6%). Crucially, the system excels in identifying the most aggressive Grade III tumors with a high recall of 87.5%, a key clinical priority to prevent dangerous false negatives. Performance further improves with higher magnification, reaching 88.0% accuracy at 40x. These results validate that our federated multi-scale approach not only preserves patient privacy but also enhances model performance and generalization. The proposed modular pipeline, with built-in preprocessing, checkpointing, and error handling, establishes a foundational step toward deployable, privacy-aware clinical AI for digital pathology.",
    "fetched_at": "2025-11-07T02:16:47.493018Z"
  },
  {
    "id": "2511.03695v1",
    "title": "Behavior-Adaptive Q-Learning: A Unifying Framework for Offline-to-Online   RL",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lipeng Zu",
      "Hansong Zhou",
      "Xiaonan Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03695v1",
    "abstract": "Offline reinforcement learning (RL) enables training from fixed data without online interaction, but policies learned offline often struggle when deployed in dynamic environments due to distributional shift and unreliable value estimates on unseen state-action pairs. We introduce Behavior-Adaptive Q-Learning (BAQ), a framework designed to enable a smooth and reliable transition from offline to online RL. The key idea is to leverage an implicit behavioral model derived from offline data to provide a behavior-consistency signal during online fine-tuning. BAQ incorporates a dual-objective loss that (i) aligns the online policy toward the offline behavior when uncertainty is high, and (ii) gradually relaxes this constraint as more confident online experience is accumulated. This adaptive mechanism reduces error propagation from out-of-distribution estimates, stabilizes early online updates, and accelerates adaptation to new scenarios. Across standard benchmarks, BAQ consistently outperforms prior offline-to-online RL approaches, achieving faster recovery, improved robustness, and higher overall performance. Our results demonstrate that implicit behavior adaptation is a principled and practical solution for reliable real-world policy deployment.",
    "fetched_at": "2025-11-07T02:16:47.492954Z"
  },
  {
    "id": "2511.03699v1",
    "title": "Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset   in Large Language Models",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Francesco Corso",
      "Francesco Pierri",
      "Gianmarco De Francisci Morales"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03699v1",
    "abstract": "In this paper, we investigate whether Large Language Models (LLMs) exhibit conspiratorial tendencies, whether they display sociodemographic biases in this domain, and how easily they can be conditioned into adopting conspiratorial perspectives. Conspiracy beliefs play a central role in the spread of misinformation and in shaping distrust toward institutions, making them a critical testbed for evaluating the social fidelity of LLMs. LLMs are increasingly used as proxies for studying human behavior, yet little is known about whether they reproduce higher-order psychological constructs such as a conspiratorial mindset. To bridge this research gap, we administer validated psychometric surveys measuring conspiracy mindset to multiple models under different prompting and conditioning strategies. Our findings reveal that LLMs show partial agreement with elements of conspiracy belief, and conditioning with socio-demographic attributes produces uneven effects, exposing latent demographic biases. Moreover, targeted prompts can easily shift model responses toward conspiratorial directions, underscoring both the susceptibility of LLMs to manipulation and the potential risks of their deployment in sensitive contexts. These results highlight the importance of critically evaluating the psychological dimensions embedded in LLMs, both to advance computational social science and to inform possible mitigation strategies against harmful uses.",
    "fetched_at": "2025-11-07T02:16:47.492859Z"
  },
  {
    "id": "2511.03708v1",
    "title": "The Adaptivity Barrier in Batched Nonparametric Bandits: Sharp   Characterization of the Price of Unknown Margin",
    "date": "2025-11-05",
    "tags": [
      "math.ST",
      "ST",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Rong Jiang",
      "Cong Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03708v1",
    "abstract": "We study batched nonparametric contextual bandits under a margin condition when the margin parameter $\\alpha$ is unknown. To capture the statistical price of this ignorance, we introduce the regret inflation criterion, defined as the ratio between the regret of an adaptive algorithm and that of an oracle knowing $\\alpha$. We show that the optimal regret inflation grows polynomial with the horizon $T$, with exponent precisely given by the value of a convex optimization problem involving the dimension, smoothness, and batch budget. Moreover, the minimizers of this optimization problem directly prescribe the batch allocation and exploration strategy of a rate-optimal algorithm. Building on this principle, we develop RoBIN (RObust batched algorithm with adaptive BINning), which achieves the optimal regret inflation up to logarithmic factors. These results reveal a new adaptivity barrier: under batching, adaptation to an unknown margin parameter inevitably incurs a polynomial penalty, sharply characterized by a variational problem. Remarkably, this barrier vanishes when the number of batches exceeds $\\log \\log T$; with only a doubly logarithmic number of updates, one can recover the oracle regret rate up to polylogarithmic factors.",
    "fetched_at": "2025-11-07T02:16:47.492810Z"
  },
  {
    "id": "2511.03710v1",
    "title": "Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning   with Verifiable Rewards",
    "date": "2025-11-05",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Guanning Zeng",
      "Zhaoyi Zhou",
      "Daman Arora",
      "Andrea Zanette"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03710v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a powerful paradigm for post-training large reasoning models (LRMs) using policy-gradient methods such as GRPO. To stabilize training, these methods typically center trajectory rewards by subtracting the empirical mean for each prompt. Statistically, this centering acts as a control variate (or baseline), reducing the variance of the policy-gradient estimator.   Typically, the mean reward is estimated using per-prompt empirical averages for each prompt in a batch. Drawing inspiration from Stein's paradox, we propose using shrinkage estimators that combine per-prompt and across-prompt means to improve the overall per-prompt mean estimation accuracy -- particularly in the low-generation regime typical of RLVR. Theoretically, we construct a shrinkage-based baseline that provably yields lower-variance policy-gradient estimators across algorithms. Our proposed baseline serves as a drop-in replacement for existing per-prompt mean baselines, requiring no additional hyper-parameters or computation. Empirically, shrinkage baselines consistently outperform standard empirical-mean baselines, leading to lower-variance gradient updates and improved training stability.",
    "fetched_at": "2025-11-07T02:16:47.492764Z"
  },
  {
    "id": "2511.03718v1",
    "title": "Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist   Annotation Scheme for MapTask",
    "date": "2025-11-05",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nan Li",
      "Albert Gatt",
      "Massimo Poesio"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03718v1",
    "abstract": "Collaborative dialogue relies on participants incrementally establishing common ground, yet in asymmetric settings they may believe they agree while referring to different entities. We introduce a perspectivist annotation scheme for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures speaker and addressee grounded interpretations for each reference expression, enabling us to trace how understanding emerges, diverges, and repairs over time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k annotated reference expressions with reliability estimates and analyze the resulting understanding states. The results show that full misunderstandings are rare once lexical variants are unified, but multiplicity discrepancies systematically induce divergences, revealing how apparent grounding can mask referential misalignment. Our framework provides both a resource and an analytic lens for studying grounded misunderstanding and for evaluating (V)LLMs' capacity to model perspective-dependent grounding in collaborative dialogue.",
    "fetched_at": "2025-11-07T02:16:47.492711Z"
  },
  {
    "id": "2511.02192v1",
    "title": "A Quantitative Comparison of Centralised and Distributed Reinforcement   Learning-Based Control for Soft Robotic Arms",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Linxin Hou",
      "Qirui Wu",
      "Zhihang Qin",
      "Neil Banerjee",
      "Yongxin Guo",
      "Cecilia Laschi"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.02192v1",
    "abstract": "This paper presents a quantitative comparison between centralised and distributed multi-agent reinforcement learning (MARL) architectures for controlling a soft robotic arm modelled as a Cosserat rod in simulation. Using PyElastica and the OpenAI Gym interface, we train both a global Proximal Policy Optimisation (PPO) controller and a Multi-Agent PPO (MAPPO) under identical budgets. Both approaches are based on the arm having $n$ number of controlled sections. The study systematically varies $n$ and evaluates the performance of the arm to reach a fixed target in three scenarios: default baseline condition, recovery from external disturbance, and adaptation to actuator failure. Quantitative metrics used for the evaluation are mean action magnitude, mean final distance, mean episode length, and success rate. The results show that there are no significant benefits of the distributed policy when the number of controlled sections $n\\le4$. In very simple systems, when $n\\le2$, the centralised policy outperforms the distributed one. When $n$ increases to $4< n\\le 12$, the distributed policy shows a high sample efficiency. In these systems, distributed policy promotes a stronger success rate, resilience, and robustness under local observability and yields faster convergence given the same sample size. However, centralised policies achieve much higher time efficiency during training as it takes much less time to train the same size of samples. These findings highlight the trade-offs between centralised and distributed policy in reinforcement learning-based control for soft robotic systems and provide actionable design guidance for future sim-to-real transfer in soft rod-like manipulators.",
    "fetched_at": "2025-11-11T02:19:06.859939Z"
  },
  {
    "id": "2511.02208v1",
    "title": "Training Proactive and Personalized LLM Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Weiwei Sun",
      "Xuhui Zhou",
      "Weihua Du",
      "Xingyao Wang",
      "Sean Welleck",
      "Graham Neubig",
      "Maarten Sap",
      "Yiming Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02208v1",
    "abstract": "While existing work focuses primarily on task success, we argue that effective real-world agents require optimizing three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to diverse user preferences). We introduce UserVille, an interactive environment with LLM-based user simulators enabling diverse, configurable user preferences. Leveraging UserVille, we introduce PPP, a multi-objective reinforcement learning approach that jointly optimizes all three dimensions: Productivity, Proactivity, and Personalization. Experiments on software engineering and deep research tasks show that agents trained with PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6 on average), demonstrating the ability to ask strategic clarifying questions, adapt to unseen user preferences, and improve task success through better interaction. This work demonstrates that explicitly optimizing for user-centered interaction is critical for building practical and effective AI agents.",
    "fetched_at": "2025-11-11T02:19:06.859881Z"
  },
  {
    "id": "2511.02216v1",
    "title": "Adaptive Cooperative Transmission Design for Ultra-Reliable Low-Latency   Communications via Deep Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.IT",
      "IT",
      "cs.AI",
      "AI",
      "math.IT"
    ],
    "authors": [
      "Hyemin Yu",
      "Hong-Chuan Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02216v1",
    "abstract": "Next-generation wireless communication systems must support ultra-reliable low-latency communication (URLLC) service for mission-critical applications. Meeting stringent URLLC requirements is challenging, especially for two-hop cooperative communication. In this paper, we develop an adaptive transmission design for a two-hop relaying communication system. Each hop transmission adaptively configures its transmission parameters separately, including numerology, mini-slot size, and modulation and coding scheme, for reliable packet transmission within a strict latency constraint. We formulate the hop-specific transceiver configuration as a Markov decision process (MDP) and propose a dual-agent reinforcement learning-based cooperative latency-aware transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies in a distributed manner. Simulation results verify that the proposed algorithm achieves the near-optimal reliability while satisfying strict latency requirements.",
    "fetched_at": "2025-11-11T02:19:06.859810Z"
  },
  {
    "id": "2511.02223v1",
    "title": "Quantitative Risk Assessment in Radiation Oncology via LLM-Powered Root   Cause Analysis of Incident Reports",
    "date": "2025-11-04",
    "tags": [
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Yuntao Wang",
      "Siamak P. Najad-Davarani",
      "Elizabeth Bossart",
      "Matthew T. Studenski",
      "Mariluz De Ornelas",
      "Yunze Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02223v1",
    "abstract": "Background: Modern large language models (LLMs) offer powerful reasoning that converts narratives into structured, taxonomy-aligned data, revealing patterns across planning, delivery, and verification. Embedded as agentic tools, LLMs can assist root-cause analysis and risk assessment (e.g., failure mode and effect analysis FMEA), produce auditable rationales, and draft targeted mitigation actions.   Methods: We developed a data-driven pipeline utilizing an LLM to perform automated root cause analysis on 254 institutional safety incidents. The LLM systematically classified each incident into structured taxonomies for radiotherapy pathway steps and contributory factors. Subsequent quantitative analyses included descriptive statistics, Analysis of Variance (ANOVA), multiple Ordinal Logistic Regression (OLR) analyses to identify predictors of event severity, and Association Rule Mining (ARM) to uncover systemic vulnerabilities.   Results: The high-level Ordinal Logistic Regression (OLR) models identified specific, significant drivers of severity. The Pathway model was statistically significant (Pseudo R2 = 0.033, LR p = 0.015), as was the Responsibility model (Pseudo R2 = 0.028, LR p < 0.001). Association Rule Mining (ARM) identified high-confidence systemic rules, such as \"CF5 Teamwork, management and organisational\" (n = 8, Conf = 1.0) and the high-frequency link between \"(11) Pre-treatment planning process\" and \"CF2 Procedural\" (n = 152, Conf = 0.916).   Conclusion: The LLM-powered, data-driven framework provides a more objective and powerful methodology for risk assessment than traditional approaches. Our findings empirically demonstrate that interventions focused on fortifying high-risk process steps and mitigating systemic failures are most effective for improving patient safety.",
    "fetched_at": "2025-11-11T02:19:06.859770Z"
  },
  {
    "id": "2511.02225v1",
    "title": "Learning Interactive World Model for Object-Centric Reinforcement   Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fan Feng",
      "Phillip Lippe",
      "Sara Magliacane"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02225v1",
    "abstract": "Agents that understand objects and their interactions can learn policies that are more robust and transferable. However, most object-centric RL methods factor state by individual objects while leaving interactions implicit. We introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a unified framework that learns structured representations of both objects and their interactions within a world model. FIOC-WM captures environment dynamics with disentangled and modular representations of object interactions, improving sample efficiency and generalization for policy learning. Concretely, FIOC-WM first learns object-centric latents and an interaction structure directly from pixels, leveraging pre-trained vision encoders. The learned world model then decomposes tasks into composable interaction primitives, and a hierarchical policy is trained on top: a high level selects the type and order of interactions, while a low level executes them. On simulated robotic and embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and generalization over world-model baselines, indicating that explicit, modular interaction learning is crucial for robust control.",
    "fetched_at": "2025-11-11T02:19:06.859712Z"
  },
  {
    "id": "2511.02230v1",
    "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV   Cache Time-to-Live",
    "date": "2025-11-04",
    "tags": [
      "cs.OS",
      "OS",
      "cs.AI",
      "AI",
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Hanchen Li",
      "Qiuyang Mang",
      "Runyuan He",
      "Qizheng Zhang",
      "Huanzhi Mao",
      "Xiaokun Chen",
      "Alvin Cheung",
      "Joseph Gonzalez",
      "Ion Stoica"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02230v1",
    "abstract": "Agentic LLM applications interleave LLM generation requests with tool calls. These tool calls break the continuity of the workflow by creating pauses between LLM requests, bringing many challenges for the serving system, especially under multi-turn scenarios. Each pause potentially causes KV cache eviction and extra waiting time before entering the continuous batch for the following LLM request. Since these pauses happen for each call, this problem becomes increasingly severe as turn number grow for agentic programs. Previous works either fail to incorporate information from the tool call, evicting KV cache that leads to repetitive prefill or loading, or ignore the continuity of a multi-turn program, creating waiting time between turns that increases per-request latency.   We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by combining tool-aware KV cache timeout with program-level scheduling. By predicting tool call durations in agentic workflows, Continuum selectively pins the KV cache in GPU memory with a time-to-live value based on total turn number. When combined with program-level first-come-first-serve, Continuum prevents scheduling bubbles, preserves multi-turn continuity, and optimizes for throughput for complex agentic workflows. By modeling the variability of tool call and agent program continuity, Continuum outperforms state-of-the-art baselines. Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B models shows that Continuum significantly improves the average job completion times, and remains performant across different hardware setups and DRAM offloading schemes. Preview code is available at: https://github.com/Hanchenli/vllm-continuum",
    "fetched_at": "2025-11-11T02:19:06.859670Z"
  },
  {
    "id": "2511.02238v1",
    "title": "Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on   Scientific Concept Network",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Keyu Zhao",
      "Weiquan Lin",
      "Qirui Zheng",
      "Fengli Xu",
      "Yong Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02238v1",
    "abstract": "Novel research ideas play a critical role in advancing scientific inquiries. Recent advancements in Large Language Models (LLMs) have demonstrated their potential to generate novel research ideas by leveraging large-scale scientific literature. However, previous work in research ideation has primarily relied on simplistic methods, such as keyword co-occurrence or semantic similarity. These approaches focus on identifying statistical associations in the literature but overlook the complex, contextual relationships between scientific concepts, which are essential to effectively leverage knowledge embedded in human literature. For instance, papers that simultaneously mention \"keyword A\" and \"keyword B\" often present research ideas that integrate both concepts. Additionally, some LLM-driven methods propose and refine research ideas using the model's internal knowledge, but they fail to effectively utilize the scientific concept network, limiting the grounding of ideas in established research. To address these challenges, we propose the Deep Ideation framework to address these challenges, integrating a scientific network that captures keyword co-occurrence and contextual relationships, enriching LLM-driven ideation. The framework introduces an explore-expand-evolve workflow to iteratively refine research ideas, using an Idea Stack to track progress. A critic engine, trained on real-world reviewer feedback, guides the process by providing continuous feedback on the novelty and feasibility of ideas. Our experiments show that our approach improves the quality of generated ideas by 10.67% compared to other methods, with ideas surpassing top conference acceptance levels. Human evaluation highlights their practical value in scientific research, and ablation studies confirm the effectiveness of each component in the workflow. Code repo is available at https://github.com/kyZhao-1/Deep-Ideation.",
    "fetched_at": "2025-11-11T02:19:06.859600Z"
  },
  {
    "id": "2511.02239v1",
    "title": "LACY: A Vision-Language Model-based Language-Action Cycle for   Self-Improving Robotic Manipulation",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Youngjin Hong",
      "Houjian Yu",
      "Mingen Li",
      "Changhyun Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02239v1",
    "abstract": "Learning generalizable policies for robotic manipulation increasingly relies on large-scale models that map language instructions to actions (L2A). However, this one-way paradigm often produces policies that execute tasks without deeper contextual understanding, limiting their ability to generalize or explain their behavior. We argue that the complementary skill of mapping actions back to language (A2L) is essential for developing more holistic grounding. An agent capable of both acting and explaining its actions can form richer internal representations and unlock new paradigms for self-supervised learning. We introduce LACY (Language-Action Cycle), a unified framework that learns such bidirectional mappings within a single vision-language model. LACY is jointly trained on three synergistic tasks: generating parameterized actions from language (L2A), explaining observed actions in language (A2L), and verifying semantic consistency between two language descriptions (L2C). This enables a self-improving cycle that autonomously generates and filters new training data through an active augmentation strategy targeting low-confidence cases, thereby improving the model without additional human labels. Experiments on pick-and-place tasks in both simulation and the real world show that LACY improves task success rates by 56.46% on average and yields more robust language-action grounding for robotic manipulation. Project page: https://vla2026.github.io/LACY/",
    "fetched_at": "2025-11-11T02:19:06.859545Z"
  },
  {
    "id": "2511.02241v1",
    "title": "Structural Plasticity as Active Inference: A Biologically-Inspired   Architecture for Homeostatic Control",
    "date": "2025-11-04",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC",
      "68T07, 92B20",
      "I.2.6; I.2.0; I.2.11",
      "11"
    ],
    "authors": [
      "Brennen A. Hill"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02241v1",
    "abstract": "Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",
    "fetched_at": "2025-11-11T02:19:06.859492Z"
  },
  {
    "id": "2511.02246v1",
    "title": "Demo: Statistically Significant Results On Biases and Errors of LLMs Do   Not Guarantee Generalizable Results",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jonathan Liu",
      "Haoling Qiu",
      "Jonathan Lasko",
      "Damianos Karakos",
      "Mahsa Yarmohammadi",
      "Mark Dredze"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02246v1",
    "abstract": "Recent research has shown that hallucinations, omissions, and biases are prevalent in everyday use-cases of LLMs. However, chatbots used in medical contexts must provide consistent advice in situations where non-medical factors are involved, such as when demographic information is present. In order to understand the conditions under which medical chatbots fail to perform as expected, we develop an infrastructure that 1) automatically generates queries to probe LLMs and 2) evaluates answers to these queries using multiple LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples the space of patient demographics, histories, disorders, and writing styles to create realistic questions that we subsequently use to prompt LLMs. In 2), our evaluation pipeline provides hallucination and omission detection using LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge treatment category detectors. As a baseline study, we perform two case studies on inter-LLM agreement and the impact of varying the answering and evaluation LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's Kappa $\\kappa=0.118$), and only specific (answering, evaluation) LLM pairs yield statistically significant differences across writing styles, genders, and races. We recommend that studies using LLM evaluation use multiple LLMs as evaluators in order to avoid arriving at statistically significant but non-generalizable results, particularly in the absence of ground-truth data. We also suggest publishing inter-LLM agreement metrics for transparency. Our code and dataset are available here: https://github.com/BBN-E/medic-neurips-2025-demo.",
    "fetched_at": "2025-11-11T02:19:06.859444Z"
  },
  {
    "id": "2511.02303v1",
    "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents   to Deliberation",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zhiwei Zhang",
      "Xiaomin Li",
      "Yudi Lin",
      "Hui Liu",
      "Ramraj Chandradevan",
      "Linlin Wu",
      "Minhua Lin",
      "Fali Wang",
      "Xianfeng Tang",
      "Qi He",
      "Suhang Wang"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02303v1",
    "abstract": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping mitigate this issue. Finally, as collaboration intensifies, the reasoning agent risks getting lost in multi-turn interactions and trapped by previous noisy responses. To counter this, we propose a verifiable reward mechanism that encourages deliberation by allowing the reasoning agent to discard noisy outputs, consolidate instructions, and restart its reasoning process when necessary. Extensive experiments demonstrate that our framework alleviates lazy agent behavior and unlocks the full potential of multi-agent framework for complex reasoning tasks.",
    "fetched_at": "2025-11-11T02:19:06.859383Z"
  },
  {
    "id": "2511.02304v1",
    "title": "Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.FL",
      "FL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Beyazit Yalcinkaya",
      "Marcell Vazquez-Chanlatte",
      "Ameesh Shah",
      "Hanna Krasowski",
      "Sanjit A. Seshia"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02304v1",
    "abstract": "We study the problem of learning multi-task, multi-agent policies for cooperative, temporal objectives, under centralized training, decentralized execution. In this setting, using automata to represent tasks enables the decomposition of complex tasks into simpler sub-tasks that can be assigned to agents. However, existing approaches remain sample-inefficient and are limited to the single-task case. In this work, we present Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for learning task-conditioned, decentralized team policies. We identify the main challenges to ACC-MARL's feasibility in practice, propose solutions, and prove the correctness of our approach. We further show that the value functions of learned policies can be used to assign tasks optimally at test time. Experiments show emergent task-aware, multi-step coordination among agents, e.g., pressing a button to unlock a door, holding the door, and short-circuiting tasks.",
    "fetched_at": "2025-11-11T02:19:06.859312Z"
  },
  {
    "id": "2511.02314v1",
    "title": "Large-scale automatic carbon ion treatment planning for head and neck   cancers via parallel multi-agent reinforcement learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Jueye Zhang",
      "Chao Yang",
      "Youfang Lai",
      "Kai-Wen Li",
      "Wenting Yan",
      "Yunzhou Xia",
      "Haimei Zhang",
      "Jingjing Zhou",
      "Gen Yang",
      "Chen Lin",
      "Tian Li",
      "Yibao Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02314v1",
    "abstract": "Head-and-neck cancer (HNC) planning is difficult because multiple critical organs-at-risk (OARs) are close to complex targets. Intensity-modulated carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but remains slow due to relative biological effectiveness (RBE) modeling, leading to laborious, experience-based, and often suboptimal tuning of many treatment-planning parameters (TPPs). Recent deep learning (DL) methods are limited by data bias and plan feasibility, while reinforcement learning (RL) struggles to efficiently explore the exponentially large TPP search space. We propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45 TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE) QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for stable learning in a high-dimensional, non-stationary environment. To enhance efficiency, we (1) use compact historical DVH vectors as state inputs, (2) apply a linear action-to-value transform mapping small discrete actions to uniform parameter adjustments, and (3) design an absolute, clinically informed piecewise reward aligned with plan scores. A synchronous multi-process worker system interfaces with the PHOENIX TPS for parallel optimization and accelerated data collection. On a head-and-neck dataset (10 training, 10 testing), the method tuned 45 parameters simultaneously and produced plans comparable to or better than expert manual ones (relative plan score: RL $85.93\\pm7.85%$ vs Manual $85.02\\pm6.92%$), with significant (p-value $<$ 0.05) improvements for five OARs. The framework efficiently explores high-dimensional TPP spaces and generates clinically competitive IMCT plans through direct TPS interaction, notably improving OAR sparing.",
    "fetched_at": "2025-11-11T02:19:06.859258Z"
  },
  {
    "id": "2511.02317v3",
    "title": "Fiedler-Based Characterization and Identification of Leaders in   Semi-Autonomous Networks",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC"
    ],
    "authors": [
      "Evyatar Matmon",
      "Daniel Zelazo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02317v3",
    "abstract": "This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.",
    "fetched_at": "2025-11-11T02:19:06.859181Z"
  },
  {
    "id": "2511.02366v1",
    "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for   LLMs in Chinese Context",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yudong Li",
      "Zhongliang Yang",
      "Kejiang Chen",
      "Wenxuan Wang",
      "Tianxin Zhang",
      "Sifang Wan",
      "Kecheng Wang",
      "Haitian Li",
      "Xu Wang",
      "Lefan Cheng",
      "Youdan Yang",
      "Baocheng Chen",
      "Ziyu Liu",
      "Yufei Sun",
      "Liyan Wu",
      "Wenya Wen",
      "Xingchi Gu",
      "Peiru Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02366v1",
    "abstract": "In this work, we propose LiveSecBench, a dynamic and continuously updated safety benchmark specifically for Chinese-language LLM application scenarios. LiveSecBench evaluates models across six critical dimensions (Legality, Ethics, Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in the Chinese legal and social frameworks. This benchmark maintains relevance through a dynamic update schedule that incorporates new threat vectors, such as the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs, providing a landscape of AI safety in the context of Chinese language. The leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.",
    "fetched_at": "2025-11-11T02:19:06.859145Z"
  },
  {
    "id": "2511.02371v1",
    "title": "LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming   Alignment",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rohan Wandre",
      "Yash Gajewar",
      "Namrata Patel",
      "Vivek Dhalkari"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02371v1",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for grounding large language model outputs in verifiable evidence. However, as modern AI agents transition from static knowledge bases to continuous multimodal streams encompassing text, images, video, and audio, two critical challenges arise: maintaining index freshness without prohibitive re-indexing costs, and preserving cross-modal semantic consistency across heterogeneous embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture featuring three key innovations: (i) a streaming, multi-tier memory system that dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that maintains cross-modal consistency through incremental orthogonal Procrustes updates; and (iii) stability-aware retrieval telemetry providing Safe@k guarantees by jointly bounding alignment drift and quantization error. Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94), graceful performance degradation under product quantization offloading, and provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG as a practical framework for production multimodal RAG systems.",
    "fetched_at": "2025-11-11T02:19:06.859057Z"
  },
  {
    "id": "2511.02424v1",
    "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for   Long-Horizon Task Planning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jae-Woo Choi",
      "Hyungmin Kim",
      "Hyobin Ong",
      "Minsu Jang",
      "Dohyung Kim",
      "Jaehong Kim",
      "Youngwoo Yoon"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02424v1",
    "abstract": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents. However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process. To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree. Each subgoal is handled by an LLM agent node capable of reasoning, acting, and further expanding the tree, while control flow nodes coordinate the execution strategies of agent nodes. In addition, we integrate two complementary memory systems: each agent node retrieves goal-specific, subgoal-level examples from episodic memory and shares environment-specific observations through working memory. Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs. Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.",
    "fetched_at": "2025-11-11T02:19:06.859010Z"
  },
  {
    "id": "2511.02504v1",
    "title": "Dexterous Robotic Piano Playing at Scale",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Le Chen",
      "Yi Zhao",
      "Jan Schneider",
      "Quankai Gao",
      "Simon Guist",
      "Cheng Qian",
      "Juho Kannala",
      "Bernhard Schlkopf",
      "Joni Pajarinen",
      "Dieter Bchler"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02504v1",
    "abstract": "Endowing robot hands with human-level dexterity has been a long-standing goal in robotics. Bimanual robotic piano playing represents a particularly challenging task: it is high-dimensional, contact-rich, and requires fast, precise control. We present OmniPianist, the first agent capable of performing nearly one thousand music pieces via scalable, human-demonstration-free learning. Our approach is built on three core components. First, we introduce an automatic fingering strategy based on Optimal Transport (OT), allowing the agent to autonomously discover efficient piano-playing strategies from scratch without demonstrations. Second, we conduct large-scale Reinforcement Learning (RL) by training more than 2,000 agents, each specialized in distinct music pieces, and aggregate their experience into a dataset named RP1M++, consisting of over one million trajectories for robotic piano playing. Finally, we employ a Flow Matching Transformer to leverage RP1M++ through large-scale imitation learning, resulting in the OmniPianist agent capable of performing a wide range of musical pieces. Extensive experiments and ablation studies highlight the effectiveness and scalability of our approach, advancing dexterous robotic piano playing at scale.",
    "fetched_at": "2025-11-11T02:19:06.858950Z"
  },
  {
    "id": "2511.02532v1",
    "title": "Agentic AI for Mobile Network RAN Management and Optimization",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jorge Pellejero",
      "Luis A. Hernndez Gmez",
      "Luis Mendo Toms",
      "Zoraida Frias Barroso"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02532v1",
    "abstract": "Agentic AI represents a new paradigm for automating complex systems by using Large AI Models (LAMs) to provide human-level cognitive abilities with multimodal perception, planning, memory, and reasoning capabilities. This will lead to a new generation of AI systems that autonomously decompose goals, retain context over time, learn continuously, operate across tools and environments, and adapt dynamically. The complexity of 5G and upcoming 6G networks renders manual optimization ineffective, pointing to Agentic AI as a method for automating decisions in dynamic RAN environments. However, despite its rapid advances, there is no established framework outlining the foundational components and operational principles of Agentic AI systems nor a universally accepted definition.   This paper contributes to ongoing research on Agentic AI in 5G and 6G networks by outlining its core concepts and then proposing a practical use case that applies Agentic principles to RAN optimization. We first introduce Agentic AI, tracing its evolution from classical agents and discussing the progress from workflows and simple AI agents to Agentic AI. Core design patterns-reflection, planning, tool use, and multi-agent collaboration-are then described to illustrate how intelligent behaviors are orchestrated. These theorical concepts are grounded in the context of mobile networks, with a focus on RAN management and optimization. A practical 5G RAN case study shows how time-series analytics and LAM-driven agents collaborate for KPI-based autonomous decision-making.",
    "fetched_at": "2025-11-11T02:19:06.858844Z"
  },
  {
    "id": "2511.02560v1",
    "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated   Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Dan Bohus",
      "Sean Andrist",
      "Ann Paradiso",
      "Nick Saw",
      "Tim Schoonbeek",
      "Maia Stiber"
    ],
    "institution": "Microsoft",
    "link": "http://arxiv.org/pdf/2511.02560v1",
    "abstract": "We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operating in this space. In future work, we plan to use the dataset to construct a set of benchmarks for physically situated collaboration in mixed-reality task assistive scenarios. SigmaCollab is available at https://github.com/microsoft/SigmaCollab.",
    "fetched_at": "2025-11-11T02:19:06.858793Z"
  },
  {
    "id": "2511.02605v1",
    "title": "Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in   Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Tiberiu-Andrei Georgescu",
      "Alexander W. Goodall",
      "Dalal Alrajeh",
      "Francesco Belardinelli",
      "Sebastian Uchitel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02605v1",
    "abstract": "Shielding is widely used to enforce safety in reinforcement learning (RL), ensuring that an agent's actions remain compliant with formal specifications. Classical shielding approaches, however, are often static, in the sense that they assume fixed logical specifications and hand-crafted abstractions. While these static shields provide safety under nominal assumptions, they fail to adapt when environment assumptions are violated. In this paper, we develop the first adaptive shielding framework - to the best of our knowledge - based on Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and expressive fragment of Linear Temporal Logic (LTL) that captures both safety and liveness properties. Our method detects environment assumption violations at runtime and employs Inductive Logic Programming (ILP) to automatically repair GR(1) specifications online, in a systematic and interpretable way. This ensures that the shield evolves gracefully, ensuring liveness is achievable and weakening goals only when necessary. We consider two case studies: Minepump and Atari Seaquest; showing that (i) static symbolic controllers are often severely suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped with our adaptive shield maintain near-optimal reward and perfect logical compliance compared with static shields.",
    "fetched_at": "2025-11-11T02:19:06.858736Z"
  },
  {
    "id": "2511.02606v1",
    "title": "A Multi-Agent Psychological Simulation System for Human Behavior   Modeling",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Xiangen Hu",
      "Jiarui Tong",
      "Sheng Xu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02606v1",
    "abstract": "Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher training and research, and discuss how it embodies principles of social learning, cognitive apprenticeship, deliberate practice, and meta-cognition.",
    "fetched_at": "2025-11-11T02:19:06.858682Z"
  },
  {
    "id": "2511.02651v1",
    "title": "Apriel-H1: Towards Efficient Enterprise Reasoning Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oleksiy Ostapenko",
      "Luke Kumar",
      "Raymond Li",
      "Denis Kocetkov",
      "Joel Lamy-Poirier",
      "Shruthan Radhakrishna",
      "Soham Parikh",
      "Shambhavi Mishra",
      "Sebastien Paquet",
      "Srinivas Sunkara",
      "Valrie Bcaert",
      "Sathwik Tejaswi Madhusudhan",
      "Torsten Scholak"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02651v1",
    "abstract": "Large Language Models (LLMs) achieve remarkable reasoning capabilities through transformer architectures with attention mechanisms. However, transformers suffer from quadratic time and memory complexity in the attention module (MHA) and require caching key-value states during inference, which severely limits throughput and scalability. High inference throughput is critical for agentic tasks, long-context reasoning, efficient deployment under high request loads, and more efficient test-time compute scaling.   State Space Models (SSMs) such as Mamba offer a promising alternative with linear inference complexity and a constant memory footprint via recurrent computation with fixed-size hidden states. In this technical report we introduce the Apriel-H1 family of hybrid LLMs that combine transformer attention and SSM sequence mixers for efficient reasoning at 15B model size. These models are obtained through incremental distillation from a pretrained reasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing less critical attention layers with linear Mamba blocks.   We release multiple post-distillation variants of Apriel-H1-15B-Thinker with different SSM-to-MHA ratios and analyse how reasoning performance degrades as more Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant of Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces, achieving over 2x higher inference throughput when deployed in the production-ready vLLM environment, with minimal degradation in reasoning performance. This shows that distilled hybrid SSM-Transformer architectures can deliver substantial efficiency gains over the pretrained transformer equivalent without substantially compromising the reasoning quality.",
    "fetched_at": "2025-11-11T02:19:06.858641Z"
  },
  {
    "id": "2511.02690v1",
    "title": "Curriculum Design for Trajectory-Constrained Agent: Compressing   Chain-of-Thought Tokens in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Georgios Tzannetos",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02690v1",
    "abstract": "Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.",
    "fetched_at": "2025-11-11T02:19:06.858561Z"
  },
  {
    "id": "2511.02734v1",
    "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in   Dynamic Environments for LLM Tool-Use Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jiayu Liu",
      "Cheng Qian",
      "Zhaochen Su",
      "Qing Zong",
      "Shijue Huang",
      "Bingxiang He",
      "Yi R. Fung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02734v1",
    "abstract": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability. This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments. To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities. Situated in the travel-planning domain, CostBench comprises tasks solvable via multiple sequences of atomic and composite tools with diverse, customizable costs. It also supports four types of dynamic blocking events, such as tool failures and cost changes, to simulate real-world unpredictability and necessitate agents to adapt in real time. Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. By diagnosing these weaknesses, CostBench lays the groundwork for developing future agents that are both economically rational and robust.",
    "fetched_at": "2025-11-11T02:19:06.858515Z"
  },
  {
    "id": "2511.02755v1",
    "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM   System with Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bowen Jin",
      "TJ Collins",
      "Donghan Yu",
      "Mert Cemri",
      "Shenao Zhang",
      "Mengyu Li",
      "Jay Tang",
      "Tian Qin",
      "Zhiyang Xu",
      "Jiarui Lu",
      "Guoli Yin",
      "Jiawei Han",
      "Zirui Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02755v1",
    "abstract": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
    "fetched_at": "2025-11-11T02:19:06.858458Z"
  },
  {
    "id": "2511.02762v1",
    "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with   Single-Agent Demos",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Xun Wang",
      "Zhuoran Li",
      "Yanshan Lin",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02762v1",
    "abstract": "Training a team of agents from scratch in multi-agent reinforcement learning (MARL) is highly inefficient, much like asking beginners to play a symphony together without first practicing solo. Existing methods, such as offline or transferable MARL, can ease this burden, but they still rely on costly multi-agent data, which often becomes the bottleneck. In contrast, solo experiences are far easier to obtain in many important scenarios, e.g., collaborative coding, household cooperation, and search-and-rescue. To unlock their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that transfers solo knowledge into cooperative learning. SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism that combines an MoE-like gating selector and an action editor. Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms. These results demonstrate that solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable.",
    "fetched_at": "2025-11-11T02:19:06.858382Z"
  },
  {
    "id": "2511.02805v1",
    "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via   End-to-End Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qianhao Yuan",
      "Jie Lou",
      "Zichao Li",
      "Jiawei Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Le Sun",
      "Debing Zhang",
      "Xianpei Han"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02805v1",
    "abstract": "Typical search agents concatenate the entire interaction history into the LLM context, preserving information integrity but producing long, noisy contexts, resulting in high computation and memory costs. In contrast, using only the current turn avoids this overhead but discards essential information. This trade-off limits the scalability of search agents. To address this challenge, we propose MemSearcher, an agent workflow that iteratively maintains a compact memory and combines the current turn with it. At each turn, MemSearcher fuses the user's question with the memory to generate reasoning traces, perform search actions, and update memory to retain only information essential for solving the task. This design stabilizes context length across multi-turn interactions, improving efficiency without sacrificing accuracy. To optimize this workflow, we introduce multi-context GRPO, an end-to-end RL framework that jointly optimize reasoning, search strategies, and memory management of MemSearcher Agents. Specifically, multi-context GRPO samples groups of trajectories under different contexts and propagates trajectory-level advantages across all conversations within them. Trained on the same dataset as Search-R1, MemSearcher achieves significant improvements over strong baselines on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher even outperforms 7B-based baselines, demonstrating that striking a balance between information integrity and efficiency yields both higher accuracy and lower computational overhead. The code and models will be publicly available at https://github.com/icip-cas/MemSearcher",
    "fetched_at": "2025-11-11T02:19:06.858332Z"
  },
  {
    "id": "2511.02823v1",
    "title": "Optimizing AI Agent Attacks With Synthetic Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chloe Loughridge",
      "Paul Colognese",
      "Avery Griffin",
      "Tyler Tracy",
      "Jon Kutasov",
      "Joe Benton"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02823v1",
    "abstract": "As AI deployments become more complex and high-stakes, it becomes increasingly important to be able to estimate their risk. AI control is one framework for doing so. However, good control evaluations require eliciting strong attack policies. This can be challenging in complex agentic environments where compute constraints leave us data-poor. In this work, we show how to optimize attack policies in SHADE-Arena, a dataset of diverse realistic control environments. We do this by decomposing attack capability into five constituent skills -- suspicion modeling, attack selection, plan synthesis, execution and subtlety -- and optimizing each component individually. To get around the constraint of limited data, we develop a probabilistic model of attack dynamics, optimize our attack hyperparameters using this simulation, and then show that the results transfer to SHADE-Arena. This results in a substantial improvement in attack strength, reducing safety score from a baseline of 0.87 to 0.41 using our scaffold.",
    "fetched_at": "2025-11-11T02:19:06.858262Z"
  },
  {
    "id": "2511.02957v1",
    "title": "Digital Twin-Driven Pavement Health Monitoring and Maintenance   Optimization Using Graph Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CE",
      "CE",
      "cs.ET",
      "ET",
      "cs.NE",
      "NE",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Mohsin Mahmud Topu",
      "Mahfuz Ahmed Anik",
      "Azmine Toushik Wasi",
      "Md Manjurul Ahsan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02957v1",
    "abstract": "Pavement infrastructure monitoring is challenged by complex spatial dependencies, changing environmental conditions, and non-linear deterioration across road networks. Traditional Pavement Management Systems (PMS) remain largely reactive, lacking real-time intelligence for failure prevention and optimal maintenance planning. To address this, we propose a unified Digital Twin (DT) and Graph Neural Network (GNN) framework for scalable, data-driven pavement health monitoring and predictive maintenance. Pavement segments and spatial relations are modeled as graph nodes and edges, while real-time UAV, sensor, and LiDAR data stream into the DT. The inductive GNN learns deterioration patterns from graph-structured inputs to forecast distress and enable proactive interventions. Trained on a real-world-inspired dataset with segment attributes and dynamic connectivity, our model achieves an R2 of 0.3798, outperforming baseline regressors and effectively capturing non-linear degradation. We also develop an interactive dashboard and reinforcement learning module for simulation, visualization, and adaptive maintenance planning. This DT-GNN integration enhances forecasting precision and establishes a closed feedback loop for continuous improvement, positioning the approach as a foundation for proactive, intelligent, and sustainable pavement management, with future extensions toward real-world deployment, multi-agent coordination, and smart-city integration.",
    "fetched_at": "2025-11-11T02:19:06.858212Z"
  },
  {
    "id": "2511.03001v1",
    "title": "LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied   Environments with Tool Augmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Gyeom Hwangbo",
      "Hyungjoo Chae",
      "Minseok Kang",
      "Hyeonjong Ju",
      "Soohyun Oh",
      "Jinyoung Yeo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03001v1",
    "abstract": "Despite recent progress in using Large Language Models (LLMs) for automatically generating 3D scenes, generated scenes often lack realistic spatial layouts and object attributes found in real-world environments. As this problem stems from insufficiently detailed, coarse-grained instructions, advancing 3D scene synthesis guided by more detailed, fine-grained instructions that reflect real-world environments becomes crucial. Without such realistic scenes, training embodied agents in unrealistic environments can lead them to learn priors that diverge significantly from real-world physics and semantics, degrading their performance when deployed. Thus, verifying the alignment between the fine-grained instruction and the generated scene is essential for effective learning. However, current evaluation methods, such as CLIPScore and vision-language models (VLMs), often fail to reliably assess such alignment. This shortcoming arises primarily from their shallow understanding of 3D scenes, which often leads to improperly grounded scene components. To address this, we introduce LEGO-Eval, an evaluation framework equipped with diverse tools designed to explicitly ground scene components, enabling more accurate alignment assessments. We also present LEGO-Bench, a benchmark of detailed instructions that specify complex layouts and attributes of real-world environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with LEGO-Bench reveals significant limitations in current generation methods. Across all evaluated approaches, success rates reached at most 10% in generating scenes that fully align with fine-grained instructions.",
    "fetched_at": "2025-11-11T02:19:06.858161Z"
  },
  {
    "id": "2511.03047v1",
    "title": "Unsupervised Evaluation of Multi-Turn Objective-Driven Interactions",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Emi Soroka",
      "Tanmay Chopra",
      "Krish Desai",
      "Sanjay Lall"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03047v1",
    "abstract": "Large language models (LLMs) have seen increasing popularity in enterprise applications where AI agents and humans engage in objective-driven interactions. However, these systems are difficult to evaluate: data may be complex and unlabeled; human annotation is often impractical at scale; custom metrics can monitor for specific errors, but not previously-undetected ones; and LLM judges can produce unreliable results. We introduce the first set of unsupervised metrics for objective-driven interactions, leveraging statistical properties of unlabeled interaction data and using fine-tuned LLMs to adapt to distributional shifts. We develop metrics for labeling user goals, measuring goal completion, and quantifying LLM uncertainty without grounding evaluations in human-generated ideal responses. Our approach is validated on open-domain and task-specific interaction data.",
    "fetched_at": "2025-11-11T02:19:06.858104Z"
  },
  {
    "id": "2511.03051v1",
    "title": "No-Human in the Loop: Agentic Evaluation at Scale for Recommendation",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Tao Zhang",
      "Kehui Yao",
      "Luyi Ma",
      "Jiao Chen",
      "Reza Yousefi Maragheh",
      "Kai Zhao",
      "Jianpeng Xu",
      "Evren Korpeoglu",
      "Sushant Kumar",
      "Kannan Achan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03051v1",
    "abstract": "Evaluating large language models (LLMs) as judges is increasingly critical for building scalable and trustworthy evaluation pipelines. We present ScalingEval, a large-scale benchmarking study that systematically compares 36 LLMs, including GPT, Gemini, Claude, and Llama, across multiple product categories using a consensus-driven evaluation protocol. Our multi-agent framework aggregates pattern audits and issue codes into ground-truth labels via scalable majority voting, enabling reproducible comparison of LLM evaluators without human annotation. Applied to large-scale complementary-item recommendation, the benchmark reports four key findings: (i) Anthropic Claude 3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers the best overall performance across categories; (iii) GPT-4o provides the most favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among open-source models. Category-level analysis shows strong consensus in structured domains (Electronics, Sports) but persistent disagreement in lifestyle categories (Clothing, Food). These results establish ScalingEval as a reproducible benchmark and evaluation protocol for LLMs as judges, with actionable guidance on scaling, reliability, and model family tradeoffs.",
    "fetched_at": "2025-11-11T02:19:06.858058Z"
  },
  {
    "id": "2511.03075v1",
    "title": "A Collaborative Reasoning Framework for Anomaly Diagnostics in   Underwater Robotics",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Markus Buchholz",
      "Ignacio Carlucho",
      "Yvan R. Petillot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.03075v1",
    "abstract": "The safe deployment of autonomous systems in safety-critical settings requires a paradigm that combines human expertise with AI-driven analysis, especially when anomalies are unforeseen. We introduce AURA (Autonomous Resilience Agent), a collaborative framework for anomaly and fault diagnostics in robotics. AURA integrates large language models (LLMs), a high-fidelity digital twin (DT), and human-in-the-loop interaction to detect and respond to anomalous behavior in real time. The architecture uses two agents with clear roles: (i) a low-level State Anomaly Characterization Agent that monitors telemetry and converts signals into a structured natural-language problem description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a knowledge-grounded dialogue with an operator to identify root causes, drawing on external sources. Human-validated diagnoses are then converted into new training examples that refine the low-level perceptual model. This feedback loop progressively distills expert knowledge into the AI, transforming it from a static tool into an adaptive partner. We describe the framework's operating principles and provide a concrete implementation, establishing a pattern for trustworthy, continually improving human-robot teams.",
    "fetched_at": "2025-11-11T02:19:06.857993Z"
  },
  {
    "id": "2511.02317v2",
    "title": "Fiedler-Based Characterization and Identification of Leaders in   Semi-Autonomous Networks",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC"
    ],
    "authors": [
      "Evyatar Matmon",
      "Daniel Zelazo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02317v2",
    "abstract": "This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.",
    "fetched_at": "2025-11-10T02:23:07.306979Z"
  },
  {
    "id": "2511.02200v1",
    "title": "Optimal-Agent-Selection: State-Aware Routing Framework for Efficient   Multi-Agent Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingbo Wang",
      "Sendong Zhao",
      "Haochun Wang",
      "Yuzheng Fan",
      "Lizhe Zhang",
      "Yan Liu",
      "Ting Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02200v1",
    "abstract": "The emergence of multi-agent systems powered by large language models (LLMs) has unlocked new frontiers in complex task-solving, enabling diverse agents to integrate unique expertise, collaborate flexibly, and address challenges unattainable for individual models. However, the full potential of such systems is hindered by rigid agent scheduling and inefficient coordination strategies that fail to adapt to evolving task requirements. In this paper, we propose STRMAC, a state-aware routing framework designed for efficient collaboration in multi-agent systems. Our method separately encodes interaction history and agent knowledge to power the router, which adaptively selects the most suitable single agent at each step for efficient and effective collaboration. Furthermore, we introduce a self-evolving data generation approach that accelerates the collection of high-quality execution paths for efficient system training. Experiments on challenging collaborative reasoning benchmarks demonstrate that our method achieves state-of-the-art performance, achieving up to 23.8% improvement over baselines and reducing data collection overhead by up to 90.1% compared to exhaustive search.",
    "fetched_at": "2025-11-10T02:23:01.294928Z"
  },
  {
    "id": "2511.02378v1",
    "title": "Revisiting put-that-there, context aware window interactions via LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Riccardo Bovo",
      "Daniele Giunchi",
      "Pasquale Cascarano",
      "Eric J. Gonzalez",
      "Mar Gonzalez-Franco"
    ],
    "institution": "Google, Meta",
    "link": "http://arxiv.org/pdf/2511.02378v1",
    "abstract": "We revisit Bolt's classic \"Put-That-There\" concept for modern head-mounted displays by pairing Large Language Models (LLMs) with XR sensor and tech stack. The agent fuses (i) a semantically segmented 3-D environment, (ii) live application metadata, and (iii) users' verbal, pointing, and head-gaze cues to issue JSON window-placement actions. As a result, users can manage a panoramic workspace through: (1) explicit commands (\"Place Google Maps on the coffee table\"), (2) deictic speech plus gestures (\"Put that there\"), or (3) high-level goals (\"I need to send a message\"). Unlike traditional explicit interfaces, our system supports one-to-many action mappings and goal-centric reasoning, allowing the LLM to dynamically infer relevant applications and layout decisions, including interrelationships across tools. This enables seamless, intent-driven interaction without manual window juggling in immersive XR environments.",
    "fetched_at": "2025-11-10T02:23:01.294284Z"
  },
  {
    "id": "2511.02399v1",
    "title": "EvoDev: An Iterative Feature-Driven Framework for End-to-End Software   Development with LLM-based Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junwei Liu",
      "Chen Xu",
      "Chong Wang",
      "Tong Bai",
      "Weitong Chen",
      "Kaseng Wong",
      "Yiling Lou",
      "Xin Peng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02399v1",
    "abstract": "Recent advances in large language model agents offer the promise of automating end-to-end software development from natural language requirements. However, existing approaches largely adopt linear, waterfall-style pipelines, which oversimplify the iterative nature of real-world development and struggle with complex, large-scale projects. To address these limitations, we propose EvoDev, an iterative software development framework inspired by feature-driven development. EvoDev decomposes user requirements into a set of user-valued features and constructs a Feature Map, a directed acyclic graph that explicitly models dependencies between features. Each node in the feature map maintains multi-level information, including business logic, design, and code, which is propagated along dependencies to provide context for subsequent development iterations. We evaluate EvoDev on challenging Android development tasks and show that it outperforms the best-performing baseline, Claude Code, by a substantial margin of 56.8%, while improving single-agent performance by 16.0%-76.6% across different base LLMs, highlighting the importance of dependency modeling, context propagation, and workflow-aware agent design for complex software projects. Our work summarizes practical insights for designing iterative, LLM-driven development frameworks and informs future training of base LLMs to better support iterative software development.",
    "fetched_at": "2025-11-10T02:23:01.294234Z"
  },
  {
    "id": "2511.02427v1",
    "title": "From the Laboratory to Real-World Application: Evaluating Zero-Shot   Scene Interpretation on Edge Devices for Mobile Robotics",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Nicolas Schuler",
      "Lea Dewald",
      "Nick Baldig",
      "Jrgen Graf"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02427v1",
    "abstract": "Video Understanding, Scene Interpretation and Commonsense Reasoning are highly challenging tasks enabling the interpretation of visual information, allowing agents to perceive, interact with and make rational decisions in its environment. Large Language Models (LLMs) and Visual Language Models (VLMs) have shown remarkable advancements in these areas in recent years, enabling domain-specific applications as well as zero-shot open vocabulary tasks, combining multiple domains. However, the required computational complexity poses challenges for their application on edge devices and in the context of Mobile Robotics, especially considering the trade-off between accuracy and inference time. In this paper, we investigate the capabilities of state-of-the-art VLMs for the task of Scene Interpretation and Action Recognition, with special regard to small VLMs capable of being deployed to edge devices in the context of Mobile Robotics. The proposed pipeline is evaluated on a diverse dataset consisting of various real-world cityscape, on-campus and indoor scenarios. The experimental evaluation discusses the potential of these small models on edge devices, with particular emphasis on challenges, weaknesses, inherent model biases and the application of the gained information. Supplementary material is provided via the following repository: https://datahub.rz.rptu.de/hstr-csrl-public/publications/scene-interpretation-on-edge-devices/",
    "fetched_at": "2025-11-10T02:23:01.294115Z"
  },
  {
    "id": "2511.02469v1",
    "title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs   for Monetary Policy Decision Classification",
    "date": "2025-11-04",
    "tags": [
      "q-fin.CP",
      "CP",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kaito Takano",
      "Masanori Hirano",
      "Kei Nakagawa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02469v1",
    "abstract": "Accurately forecasting central bank policy decisions, particularly those of the Federal Open Market Committee(FOMC) has become increasingly important amid heightened economic uncertainty. While prior studies have used monetary policy texts to predict rate changes, most rely on static classification models that overlook the deliberative nature of policymaking. This study proposes a novel framework that structurally imitates the FOMC's collective decision-making process by modeling multiple large language models(LLMs) as interacting agents. Each agent begins with a distinct initial belief and produces a prediction based on both qualitative policy texts and quantitative macroeconomic indicators. Through iterative rounds, agents revise their predictions by observing the outputs of others, simulating deliberation and consensus formation. To enhance interpretability, we introduce a latent variable representing each agent's underlying belief(e.g., hawkish or dovish), and we theoretically demonstrate how this belief mediates the perception of input information and interaction dynamics. Empirical results show that this debate-based approach significantly outperforms standard LLMs-based baselines in prediction accuracy. Furthermore, the explicit modeling of beliefs provides insights into how individual perspectives and social influence shape collective policy forecasts.",
    "fetched_at": "2025-11-10T02:23:01.294063Z"
  },
  {
    "id": "2511.02503v1",
    "title": "Adapting General-Purpose Foundation Models for X-ray Ptychography in   Low-Data Regimes",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Robinson Umeike",
      "Neil Getty",
      "Yin Xiangyu",
      "Yi Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02503v1",
    "abstract": "The automation of workflows in advanced microscopy is a key goal where foundation models like Language Models (LLMs) and Vision-Language Models (VLMs) show great potential. However, adapting these general-purpose models for specialized scientific tasks is critical, and the optimal domain adaptation strategy is often unclear. To address this, we introduce PtychoBench, a new multi-modal, multi-task benchmark for ptychographic analysis. Using this benchmark, we systematically compare two specialization strategies: Supervised Fine-Tuning (SFT) and In-Context Learning (ICL). We evaluate these strategies on a visual artifact detection task with VLMs and a textual parameter recommendation task with LLMs in a data-scarce regime. Our findings reveal that the optimal specialization pathway is task-dependent. For the visual task, SFT and ICL are highly complementary, with a fine-tuned model guided by context-aware examples achieving the highest mean performance (Micro-F1 of 0.728). Conversely, for the textual task, ICL on a large base model is the superior strategy, reaching a peak Micro-F1 of 0.847 and outperforming a powerful \"super-expert\" SFT model (0-shot Micro-F1 of 0.839). We also confirm the superiority of context-aware prompting and identify a consistent contextual interference phenomenon in fine-tuned models. These results, benchmarked against strong baselines including GPT-4o and a DINOv3-based classifier, offer key observations for AI in science: the optimal specialization path in our benchmark is dependent on the task modality, offering a clear framework for developing more effective science-based agentic systems.",
    "fetched_at": "2025-11-10T02:23:01.294015Z"
  },
  {
    "id": "2511.02885v1",
    "title": "AgentSLA : Towards a Service Level Agreement for AI Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gwendal Jouneaux",
      "Jordi Cabot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02885v1",
    "abstract": "AI components are increasingly becoming a key element of all types of software systems to enhance their functionality. These AI components are often implemented as AI Agents, offering more autonomy than a plain integration of Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an Agent-as-a-Service one, bringing new challenges to the development of smart software systems. Indeed, while support for the design, implementation, and deployment of those agents exist, the specification of Quality of Service (QoS) and definition of Service Level Agreements (SLAs) aspects for those agents, important to ensure the quality of the resulting systems, remains an open challenge. Part of this is due to the difficulty to clearly define quality in the context of AI components, resulting in a lack of consensus on how to best approach Quality Assurance (QA) for these types of systems. To address this challenge, this paper proposes both a quality model for AI agents based on the ISO/IEC 25010 standard, and a domain specific language to support the definition of SLAs for the services provided by these AI agents.",
    "fetched_at": "2025-11-10T02:23:01.293958Z"
  },
  {
    "id": "2511.02748v1",
    "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.NI",
      "NI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Farhad Rezazadeh",
      "Hatim Chergui",
      "Merouane Debbah",
      "Houbing Song",
      "Dusit Niyato",
      "Lingjia Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02748v1",
    "abstract": "We argue that sixth-generation (6G) intelligence is not fluent token prediction but the capacity to imagine and choose -- to simulate future scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe open radio access network (O-RAN) near-real-time (Near-RT) control via counterfactual dynamics and a world modeling (WM) paradigm that learns an action-conditioned generative state space. This enables quantitative \"what-if\" forecasting beyond large language models (LLMs) as the primary modeling primitive. Actions such as physical resource blocks (PRBs) are treated as first-class control inputs in a causal world model, and both aleatoric and epistemic uncertainty are modeled for prediction and what-if analysis. An agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner operates over short horizons, using prior-mean rollouts within data-driven PRB bounds to maximize a deterministic reward. The model couples multi-scale structured state-space mixtures (MS3M) with a compact stochastic latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories and predicting next-step KPIs under hypothetical PRB sequences. On realistic O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with 32% fewer parameters and similar latency, and achieves 35-80% lower root mean squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster inference, enabling rare-event simulation and offline policy screening.",
    "fetched_at": "2025-11-10T02:23:01.293691Z"
  },
  {
    "id": "2511.02794v1",
    "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Chenyu Zhang",
      "Minsol Kim",
      "Shohreh Ghorbani",
      "Jingyao Wu",
      "Rosalind Picard",
      "Patricia Maes",
      "Paul Pu Liang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02794v1",
    "abstract": "Despite rapid growth in multimodal large language models (MLLMs), their reasoning traces remain opaque: it is often unclear which modality drives a prediction, how conflicts are resolved, or when one stream dominates. In this paper, we introduce modality sabotage, a diagnostic failure mode in which a high-confidence unimodal error overrides other evidence and misleads the fused result. To analyze such dynamics, we propose a lightweight, model-agnostic evaluation layer that treats each modality as an agent, producing candidate labels and a brief self-assessment used for auditing. A simple fusion mechanism aggregates these outputs, exposing contributors (modalities supporting correct outcomes) and saboteurs (modalities that mislead). Applying our diagnostic layer in a case study on multimodal emotion recognition benchmarks with foundation models revealed systematic reliability profiles, providing insight into whether failures may arise from dataset artifacts or model limitations. More broadly, our framework offers a diagnostic scaffold for multimodal reasoning, supporting principled auditing of fusion dynamics and informing possible interventions.",
    "fetched_at": "2025-11-10T02:23:01.293552Z"
  },
  {
    "id": "2511.02834v2",
    "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for   Understanding Anything",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Huawei Lin",
      "Yunzhi Shi",
      "Tong Geng",
      "Weijie Zhao",
      "Wei Wang",
      "Ravender Pal Singh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02834v2",
    "abstract": "Multimodal large language models (MLLMs) have shown strong capabilities but remain limited to fixed modality pairs and require costly fine-tuning with large aligned datasets. Building fully omni-capable models that can integrate text, images, audio, and video remains impractical and lacks robust reasoning support. In this paper, we propose an Agent-Omni framework that coordinates existing foundation models through a master-agent system, enabling flexible multimodal reasoning without retraining. The master agent interprets user intent, delegates subtasks to modality-specific agents, and integrates their outputs into coherent responses. Extensive experiments across text, image, audio, video, and omni benchmarks show that Agent-Omni consistently achieves state-of-the-art performance, particularly on tasks requiring complex cross-modal reasoning. Its agent-based design enables seamless integration of specialized foundation models, ensuring adaptability to diverse inputs while maintaining transparency and interpretability. In addition, the framework is modular and easily extensible, allowing future improvements as stronger models become available.",
    "fetched_at": "2025-11-10T02:23:01.293424Z"
  },
  {
    "id": "2511.02919v1",
    "title": "Cache Mechanism for Agent RAG Systems",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shuhang Lin",
      "Zhencan Peng",
      "Lingyao Li",
      "Xiao Lin",
      "Xi Zhu",
      "Yongfeng Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02919v1",
    "abstract": "Recent advances in Large Language Model (LLM)-based agents have been propelled by Retrieval-Augmented Generation (RAG), which grants the models access to vast external knowledge bases. Despite RAG's success in improving agent performance, agent-level cache management, particularly constructing, maintaining, and updating a compact, relevant corpus dynamically tailored to each agent's need, remains underexplored. Therefore, we introduce ARC (Agent RAG Cache Mechanism), a novel, annotation-free caching framework that dynamically manages small, high-value corpora for each agent. By synthesizing historical query distribution patterns with the intrinsic geometry of cached items in the embedding space, ARC automatically maintains a high-relevance cache. With comprehensive experiments on three retrieval datasets, our experimental results demonstrate that ARC reduces storage requirements to 0.015% of the original corpus while offering up to 79.8% has-answer rate and reducing average retrieval latency by 80%. Our results demonstrate that ARC can drastically enhance efficiency and effectiveness in RAG-powered LLM agents.",
    "fetched_at": "2025-11-10T02:23:01.293365Z"
  },
  {
    "id": "2511.03023v1",
    "title": "PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data   Analysis Framework",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sina Montazeri",
      "Yunhe Feng",
      "Kewei Sha"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.03023v1",
    "abstract": "Open data repositories hold potential for evidence-based decision-making, yet are inaccessible to non-experts lacking expertise in dataset discovery, schema mapping, and statistical analysis. Large language models show promise for individual tasks, but end-to-end analytical workflows expose fundamental limitations: attention dilutes across growing contexts, specialized reasoning patterns interfere, and errors propagate undetected. We present PublicAgent, a multi-agent framework that addresses these limitations through decomposition into specialized agents for intent clarification, dataset discovery, analysis, and reporting. This architecture maintains focused attention within agent contexts and enables validation at each stage. Evaluation across five models and 50 queries derives five design principles for multi-agent LLM systems. First, specialization provides value independent of model strength--even the strongest model shows 97.5% agent win rates, with benefits orthogonal to model scale. Second, agents divide into universal (discovery, analysis) and conditional (report, intent) categories. Universal agents show consistent effectiveness (std dev 12.4%) while conditional agents vary by model (std dev 20.5%). Third, agents mitigate distinct failure modes--removing discovery or analysis causes catastrophic failures (243-280 instances), while removing report or intent causes quality degradation. Fourth, architectural benefits persist across task complexity with stable win rates (86-92% analysis, 84-94% discovery), indicating workflow management value rather than reasoning enhancement. Fifth, wide variance in agent effectiveness across models (42-96% for analysis) requires model-aware architecture design. These principles guide when and why specialization is necessary for complex analytical workflows while enabling broader access to public data through natural language interfaces.",
    "fetched_at": "2025-11-10T02:23:01.293254Z"
  },
  {
    "id": "2511.02137v1",
    "title": "DoFlow: Causal Generative Flows for Interventional and Counterfactual   Time-Series Prediction",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.ME",
      "ME"
    ],
    "authors": [
      "Dongze Wu",
      "Feng Qiu",
      "Yao Xie"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02137v1",
    "abstract": "Time-series forecasting increasingly demands not only accurate observational predictions but also causal forecasting under interventional and counterfactual queries in multivariate systems. We present DoFlow, a flow based generative model defined over a causal DAG that delivers coherent observational and interventional predictions, as well as counterfactuals through the natural encoding and decoding mechanism of continuous normalizing flows (CNFs). We also provide a supporting counterfactual recovery result under certain assumptions. Beyond forecasting, DoFlow provides explicit likelihoods of future trajectories, enabling principled anomaly detection. Experiments on synthetic datasets with various causal DAG and real world hydropower and cancer treatment time series show that DoFlow achieves accurate system-wide observational forecasting, enables causal forecasting over interventional and counterfactual queries, and effectively detects anomalies. This work contributes to the broader goal of unifying causal reasoning and generative modeling for complex dynamical systems.",
    "fetched_at": "2025-11-06T02:19:07.219664Z"
  },
  {
    "id": "2511.02140v1",
    "title": "QuPCG: Quantum Convolutional Neural Network for Detecting Abnormal   Patterns in PCG Signals",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Yasaman Torabi",
      "Shahram Shirani",
      "James P. Reilly"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02140v1",
    "abstract": "Early identification of abnormal physiological patterns is essential for the timely detection of cardiac disease. This work introduces a hybrid quantum-classical convolutional neural network (QCNN) designed to classify S3 and murmur abnormalities in heart sound signals. The approach transforms one-dimensional phonocardiogram (PCG) signals into compact two-dimensional images through a combination of wavelet feature extraction and adaptive threshold compression methods. We compress the cardiac-sound patterns into an 8-pixel image so that only 8 qubits are needed for the quantum stage. Preliminary results on the HLS-CMDS dataset demonstrate 93.33% classification accuracy on the test set and 97.14% on the train set, suggesting that quantum models can efficiently capture temporal-spectral correlations in biomedical signals. To our knowledge, this is the first application of a QCNN algorithm for bioacoustic signal processing. The proposed method represents an early step toward quantum-enhanced diagnostic systems for resource-constrained healthcare environments.",
    "fetched_at": "2025-11-06T02:19:07.219619Z"
  },
  {
    "id": "2511.02146v1",
    "title": "Disentangling Causal Substructures for Interpretable and Generalizable   Drug Synergy Prediction",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yi Luo",
      "Haochen Zhao",
      "Xiao Liang",
      "Yiwei Liu",
      "Yuye Zhang",
      "Xinyu Li",
      "Jianxin Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02146v1",
    "abstract": "Drug synergy prediction is a critical task in the development of effective combination therapies for complex diseases, including cancer. Although existing methods have shown promising results, they often operate as black-box predictors that rely predominantly on statistical correlations between drug characteristics and results. To address this limitation, we propose CausalDDS, a novel framework that disentangles drug molecules into causal and spurious substructures, utilizing the causal substructure representations for predicting drug synergy. By focusing on causal sub-structures, CausalDDS effectively mitigates the impact of redundant features introduced by spurious substructures, enhancing the accuracy and interpretability of the model. In addition, CausalDDS employs a conditional intervention mechanism, where interventions are conditioned on paired molecular structures, and introduces a novel optimization objective guided by the principles of sufficiency and independence. Extensive experiments demonstrate that our method outperforms baseline models, particularly in cold start and out-of-distribution settings. Besides, CausalDDS effectively identifies key substructures underlying drug synergy, providing clear insights into how drug combinations work at the molecular level. These results underscore the potential of CausalDDS as a practical tool for predicting drug synergy and facilitating drug discovery.",
    "fetched_at": "2025-11-06T02:19:07.219566Z"
  },
  {
    "id": "2511.02148v1",
    "title": "CFL: On the Use of Characteristic Function Loss for Domain Alignment in   Machine Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Abdullah Almansour",
      "Ozan Tonguz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02148v1",
    "abstract": "Machine Learning (ML) models are extensively used in various applications due to their significant advantages over traditional learning methods. However, the developed ML models often underperform when deployed in the real world due to the well-known distribution shift problem. This problem can lead to a catastrophic outcomes when these decision-making systems have to operate in high-risk applications. Many researchers have previously studied this problem in ML, known as distribution shift problem, using statistical techniques (such as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to quantify the distribution shift. In this letter, we show that using Characteristic Function (CF) as a frequency domain approach is a powerful alternative for measuring the distribution shift in high-dimensional space and for domain adaptation.",
    "fetched_at": "2025-11-06T02:19:07.219489Z"
  },
  {
    "id": "2511.02152v1",
    "title": "ProtoTSNet: Interpretable Multivariate Time Series Classification With   Prototypical Parts",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bartomiej Makus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02152v1",
    "abstract": "Time series data is one of the most popular data modalities in critical domains such as industry and medicine. The demand for algorithms that not only exhibit high accuracy but also offer interpretability is crucial in such fields, as decisions made there bear significant consequences. In this paper, we present ProtoTSNet, a novel approach to interpretable classification of multivariate time series data, through substantial enhancements to the ProtoPNet architecture. Our method is tailored to overcome the unique challenges of time series analysis, including capturing dynamic patterns and handling varying feature significance. Central to our innovation is a modified convolutional encoder utilizing group convolutions, pre-trainable as part of an autoencoder and designed to preserve and quantify feature importance. We evaluated our model on 30 multivariate time series datasets from the UEA archive, comparing our approach with existing explainable methods as well as non-explainable baselines. Through comprehensive evaluation and ablation studies, we demonstrate that our approach achieves the best performance among ante-hoc explainable methods while maintaining competitive performance with non-explainable and post-hoc explainable approaches, providing interpretable results accessible to domain experts.",
    "fetched_at": "2025-11-06T02:19:07.219452Z"
  },
  {
    "id": "2511.02157v1",
    "title": "Near Optimal Convergence to Coarse Correlated Equilibrium in General-Sum   Markov Games",
    "date": "2025-11-04",
    "tags": [
      "cs.GT",
      "GT",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Asrin Efe Yorulmaz",
      "Tamer Baar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02157v1",
    "abstract": "No-regret learning dynamics play a central role in game theory, enabling decentralized convergence to equilibrium for concepts such as Coarse Correlated Equilibrium (CCE) or Correlated Equilibrium (CE). In this work, we improve the convergence rate to CCE in general-sum Markov games, reducing it from the previously best-known rate of $\\mathcal{O}(\\log^5 T / T)$ to a sharper $\\mathcal{O}(\\log T / T)$. This matches the best known convergence rate for CE in terms of $T$, number of iterations, while also improving the dependence on the action set size from polynomial to polylogarithmic-yielding exponential gains in high-dimensional settings. Our approach builds on recent advances in adaptive step-size techniques for no-regret algorithms in normal-form games, and extends them to the Markovian setting via a stage-wise scheme that adjusts learning rates based on real-time feedback. We frame policy updates as an instance of Optimistic Follow-the-Regularized-Leader (OFTRL), customized for value-iteration-based learning. The resulting self-play algorithm achieves, to our knowledge, the fastest known convergence rate to CCE in Markov games.",
    "fetched_at": "2025-11-06T02:19:07.219408Z"
  },
  {
    "id": "2511.02162v1",
    "title": "Text to Robotic Assembly of Multi Component Objects using 3D Generative   AI and Vision Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Alexander Htet Kyaw",
      "Richa Gupta",
      "Dhruv Shah",
      "Anoop Sinha",
      "Kory Mathewson",
      "Stefanie Pender",
      "Sachin Chitta",
      "Yotto Koga",
      "Faez Ahmed",
      "Lawrence Sass",
      "Randall Davis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02162v1",
    "abstract": "Advances in 3D generative AI have enabled the creation of physical objects from text prompts, but challenges remain in creating objects involving multiple component types. We present a pipeline that integrates 3D generative AI with vision-language models (VLMs) to enable the robotic assembly of multi-component objects from natural language. Our method leverages VLMs for zero-shot, multi-modal reasoning about geometry and functionality to decompose AI-generated meshes into multi-component 3D models using predefined structural and panel components. We demonstrate that a VLM is capable of determining which mesh regions need panel components in addition to structural components, based on object functionality. Evaluation across test objects shows that users preferred the VLM-generated assignments 90.6% of the time, compared to 59.4% for rule-based and 2.5% for random assignment. Lastly, the system allows users to refine component assignments through conversational feedback, enabling greater human control and agency in making physical objects with generative AI and robotics.",
    "fetched_at": "2025-11-06T02:19:07.219362Z"
  },
  {
    "id": "2511.02164v1",
    "title": "ScenicProver: A Framework for Compositional Probabilistic Verification   of Learning-Enabled Systems",
    "date": "2025-11-04",
    "tags": [
      "cs.LO",
      "LO",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.PL",
      "PL"
    ],
    "authors": [
      "Eric Vin",
      "Kyle A. Miller",
      "Inigo Incer",
      "Sanjit A. Seshia",
      "Daniel J. Fremont"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02164v1",
    "abstract": "Full verification of learning-enabled cyber-physical systems (CPS) has long been intractable due to challenges including black-box components and complex real-world environments. Existing tools either provide formal guarantees for limited types of systems or test the system as a monolith, but no general framework exists for compositional analysis of learning-enabled CPS using varied verification techniques over complex real-world environments. This paper introduces ScenicProver, a verification framework that aims to fill this gap. Built upon the Scenic probabilistic programming language, the framework supports: (1) compositional system description with clear component interfaces, ranging from interpretable code to black boxes; (2) assume-guarantee contracts over those components using an extension of Linear Temporal Logic containing arbitrary Scenic expressions; (3) evidence generation through testing, formal proofs via Lean 4 integration, and importing external assumptions; (4) systematic combination of generated evidence using contract operators; and (5) automatic generation of assurance cases tracking the provenance of system-level guarantees. We demonstrate the framework's effectiveness through a case study on an autonomous vehicle's automatic emergency braking system with sensor fusion. By leveraging manufacturer guarantees for radar and laser sensors and focusing testing efforts on uncertain conditions, our approach enables stronger probabilistic guarantees than monolithic testing with the same computational budget.",
    "fetched_at": "2025-11-06T02:19:07.219291Z"
  },
  {
    "id": "2511.02168v1",
    "title": "Eliminating Multi-GPU Performance Taxes: A Systems Approach to Efficient   Distributed LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Octavian Alexandru Trifan",
      "Karthik Sangaiah",
      "Muhammad Awad",
      "Muhammad Osama",
      "Sumanth Gudaparthi",
      "Alexandru Nicolau",
      "Alexander Veidenbaum",
      "Ganesh Dasika"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02168v1",
    "abstract": "As large language models (LLMs) continue to scale, their workloads increasingly rely on distributed execution across multiple GPUs. However, the conventional bulk synchronous parallel~(BSP) model used in such settings introduces significant performance inefficiencies. To characterize these bottlenecks, we introduce the ''Three Taxes'' (Bulk Synchronous, Inter-Kernel Data Locality, and Kernel Launch Overhead) as an analytical framework. We propose moving beyond the rigid BSP model to address key inefficiencies in distributed GPU execution. By exploiting libraries like Iris for Triton, we gain access to in-kernel communication primitives that enable the design of novel fine-grained programming patterns, offering greater flexibility and performance than traditional BSP-based approaches. These patterns systematically eliminate the three taxes by creating direct, tile-level producer-consumer pipelines and replacing global barriers with fine-grained dataflow synchronization. Applying this methodology to critical kernels, from the foundational All-Gather + general matrix multiplication operation to the complex Flash Decode algorithm, we observe a 10-20% speedup in end-to-end latency over BSP-based approaches, establishing a more programmable and efficient paradigm for distributed LLM workloads.",
    "fetched_at": "2025-11-06T02:19:07.219236Z"
  },
  {
    "id": "2511.02175v1",
    "title": "Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep   Learning Framework for Uncertainty Quantification",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuzhuang Pian",
      "Taiyu Wang",
      "Shiqi Zhang",
      "Rui Xu",
      "Yonghong Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02175v1",
    "abstract": "Accurate air quality forecasts are vital for public health alerts, exposure assessment, and emissions control. In practice, observational data are often missing in varying proportions and patterns due to collection and transmission issues. These incomplete spatiotemporal records impede reliable inference and risk assessment and can lead to overconfident extrapolation. To address these challenges, we propose an end to end framework, the channel gated learning unit based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features with a graph attention encoder to capture multiscale spatial dependencies and seasonal temporal dynamics. A channel gated learning unit, equipped with learnable activations and gated residual connections, adaptively filters and amplifies informative features. Bayesian inference jointly optimizes predictive distributions and parameter uncertainty, producing point estimates and calibrated prediction intervals. We conduct a systematic evaluation on two real world datasets, covering four typical missing data patterns and comparing against five state of the art baselines. CGLUBNF achieves superior prediction accuracy and sharper confidence intervals. In addition, we further validate robustness across multiple prediction horizons and analysis the contribution of extraneous variables. This research lays a foundation for reliable deep learning based spatio-temporal forecasting with incomplete observations in emerging sensing paradigms, such as real world vehicle borne mobile monitoring.",
    "fetched_at": "2025-11-06T02:19:07.219175Z"
  },
  {
    "id": "2511.02185v1",
    "title": "PrivGNN: High-Performance Secure Inference for Cryptographic Graph   Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fuyi Wang",
      "Zekai Chen",
      "Mingyuan Fan",
      "Jianying Zhou",
      "Lei Pan",
      "Leo Yu Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02185v1",
    "abstract": "Graph neural networks (GNNs) are powerful tools for analyzing and learning from graph-structured (GS) data, facilitating a wide range of services. Deploying such services in privacy-critical cloud environments necessitates the development of secure inference (SI) protocols that safeguard sensitive GS data. However, existing SI solutions largely focus on convolutional models for image and text data, leaving the challenge of securing GNNs and GS data relatively underexplored. In this work, we design, implement, and evaluate $\\sysname$, a lightweight cryptographic scheme for graph-centric inference in the cloud. By hybridizing additive and function secret sharings within secure two-party computation (2PC), $\\sysname$ is carefully designed based on a series of novel 2PC interactive protocols that achieve $1.5\\times \\sim 1.7\\times$ speedups for linear layers and $2\\times \\sim 15\\times$ for non-linear layers over state-of-the-art (SotA) solutions. A thorough theoretical analysis is provided to prove $\\sysname$'s correctness, security, and lightweight nature. Extensive experiments across four datasets demonstrate $\\sysname$'s superior efficiency with $1.3\\times \\sim 4.7\\times$ faster secure predictions while maintaining accuracy comparable to plaintext graph property inference.",
    "fetched_at": "2025-11-06T02:19:07.219121Z"
  },
  {
    "id": "2511.02193v1",
    "title": "MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel   Segmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiawen Liu",
      "Yuanbo Zeng",
      "Jiaming Liang",
      "Yizhen Yang",
      "Yiheng Zhang",
      "Enhui Cai",
      "Xiaoqi Sheng",
      "Hongmin Cai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02193v1",
    "abstract": "Accurate detection of retinal vessels plays a critical role in reflecting a wide range of health status indicators in the clinical diagnosis of ocular diseases. Recently, advances in deep learning have led to a surge in retinal vessel segmentation methods, which have significantly contributed to the quantitative analysis of vascular morphology. However, retinal vasculature differs significantly from conventional segmentation targets in that it consists of extremely thin and branching structures, whose global morphology varies greatly across images. These characteristics continue to pose challenges to segmentation precision and robustness. To address these issues, we propose MM-UNet, a novel architecture tailored for efficient retinal vessel segmentation. The model incorporates Morph Mamba Convolution layers, which replace pointwise convolutions to enhance branching topological perception through morph, state-aware feature sampling. Additionally, Reverse Selective State Guidance modules integrate reverse guidance theory with state-space modeling to improve geometric boundary awareness and decoding efficiency. Extensive experiments conducted on two public retinal vessel segmentation datasets demonstrate the superior performance of the proposed method in segmentation accuracy. Compared to the existing approaches, MM-UNet achieves F1-score gains of 1.64 $\\%$ on DRIVE and 1.25 $\\%$ on STARE, demonstrating its effectiveness and advancement. The project code is public via https://github.com/liujiawen-jpg/MM-UNet.",
    "fetched_at": "2025-11-06T02:19:07.219066Z"
  },
  {
    "id": "2511.02194v1",
    "title": "Personalized Decision Modeling: Utility Optimization or   Textualized-Symbolic Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yibo Zhao",
      "Yang Zhao",
      "Hongru Du",
      "Hao Frank Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02194v1",
    "abstract": "Decision-making models for individuals, particularly in high-stakes scenarios like vaccine uptake, often diverge from population optimal predictions. This gap arises from the uniqueness of the individual decision-making process, shaped by numerical attributes (e.g., cost, time) and linguistic influences (e.g., personal preferences and constraints). Developing upon Utility Theory and leveraging the textual-reasoning capabilities of Large Language Models (LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric Reasoning framework (ATHENA) to address the optimal information integration. ATHENA uniquely integrates two stages: First, it discovers robust, group-level symbolic utility functions via LLM-augmented symbolic discovery; Second, it implements individual-level semantic adaptation, creating personalized semantic templates guided by the optimal utility to model personalized choices. Validated on real-world travel mode and vaccine choice tasks, ATHENA consistently outperforms utility-based, machine learning, and other LLM-based models, lifting F1 score by at least 6.5% over the strongest cutting-edge models. Further, ablation studies confirm that both stages of ATHENA are critical and complementary, as removing either clearly degrades overall predictive performance. By organically integrating symbolic utility modeling and semantic adaptation, ATHENA provides a new scheme for modeling human-centric decisions. The project page can be found at https://yibozh.github.io/Athena.",
    "fetched_at": "2025-11-06T02:19:07.219003Z"
  },
  {
    "id": "2511.02196v1",
    "title": "BoolSkeleton: Boolean Network Skeletonization via Homogeneous Pattern   Reduction",
    "date": "2025-11-04",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Liwei Ni",
      "Jiaxi Zhang",
      "Shenggen Zheng",
      "Junfeng Liu",
      "Xingyu Meng",
      "Biwei Xie",
      "Xingquan Li",
      "Huawei Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02196v1",
    "abstract": "Boolean equivalence allows Boolean networks with identical functionality to exhibit diverse graph structures. This gives more room for exploration in logic optimization, while also posing a challenge for tasks involving consistency between Boolean networks. To tackle this challenge, we introduce BoolSkeleton, a novel Boolean network skeletonization method that improves the consistency and reliability of design-specific evaluations. BoolSkeleton comprises two key steps: preprocessing and reduction. In preprocessing, the Boolean network is transformed into a defined Boolean dependency graph, where nodes are assigned the functionality-related status. Next, the homogeneous and heterogeneous patterns are defined for the node-level pattern reduction step. Heterogeneous patterns are preserved to maintain critical functionality-related dependencies, while homogeneous patterns can be reduced. Parameter K of the pattern further constrains the fanin size of these patterns, enabling fine-tuned control over the granularity of graph reduction. To validate BoolSkeleton's effectiveness, we conducted four analysis/downstream tasks around the Boolean network: compression analysis, classification, critical path analysis, and timing prediction, demonstrating its robustness across diverse scenarios. Furthermore, it improves above 55% in the average accuracy compared to the original Boolean network for the timing prediction task. These experiments underscore the potential of BoolSkeleton to enhance design consistency in logic synthesis.",
    "fetched_at": "2025-11-06T02:19:07.218947Z"
  },
  {
    "id": "2511.02197v1",
    "title": "Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning   Confidence in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shufan Wang",
      "Xing Hu",
      "Junkai Chen",
      "Zhiyuan Pan",
      "Xin Xia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02197v1",
    "abstract": "With the widespread application of large language models (LLMs) in the field of code intelligence, increasing attention has been paid to the reliability and controllability of their outputs in code reasoning tasks. Confidence estimation serves as an effective and convenient approach for evaluating these aspects. This paper proposes a confidence analysis and enhancement framework for LLMs tailored to code reasoning tasks. We conduct a comprehensive empirical study on the confidence reliability of mainstream LLMs across different tasks, and further evaluate the effectiveness of techniques such as prompt strategy optimisation and mathematical calibration (e.g., Platt Scaling) in improving confidence reliability. Our results show that DeepSeek-Reasoner achieves the best performance across various tasks, outperforming other models by up to $0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance Score, respectively. The hybrid strategy combining the reassess prompt strategy and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$ over the original performance in the aforementioned three metrics. These results indicate that models with reasoning capabilities demonstrate superior confidence reliability, and that the hybrid strategy is the most effective in enhancing the confidence reliability of various models. Meanwhile, we elucidate the impact of different task complexities, model scales, and strategies on confidence performance, and highlight that the confidence of current LLMs in complex reasoning tasks still has considerable room for improvement. This study not only provides a research foundation and technical reference for the application of confidence in LLM-assisted software engineering, but also points the way for future optimisation and engineering deployment of confidence mechanisms.",
    "fetched_at": "2025-11-06T02:19:07.218881Z"
  },
  {
    "id": "2511.02205v1",
    "title": "OmniField: Conditioned Neural Fields for Robust Multimodal   Spatiotemporal Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Kevin Valencia",
      "Thilina Balasooriya",
      "Xihaier Luo",
      "Shinjae Yoo",
      "David Keetae Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02205v1",
    "abstract": "Multimodal spatiotemporal learning on real-world experimental data is constrained by two challenges: within-modality measurements are sparse, irregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of available modalities varies across space and time, shrinking the usable record unless models can adapt to arbitrary subsets at train and test time. We propose OmniField, a continuity-aware framework that learns a continuous neural field conditioned on available modalities and iteratively fuses cross-modal context. A multimodal crosstalk block architecture paired with iterative cross-modal refinement aligns signals prior to the decoder, enabling unified reconstruction, interpolation, forecasting, and cross-modal prediction without gridding or surrogate preprocessing. Extensive evaluations show that OmniField consistently outperforms eight strong multimodal spatiotemporal baselines. Under heavy simulated sensor noise, performance remains close to clean-input levels, highlighting robustness to corrupted measurements.",
    "fetched_at": "2025-11-06T02:19:07.218768Z"
  },
  {
    "id": "2511.02207v1",
    "title": "Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction   and Phenotyping",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiajia Li",
      "Keyi Zhu",
      "Qianwen Zhang",
      "Dong Chen",
      "Qi Sun",
      "Zhaojian Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02207v1",
    "abstract": "Strawberries are among the most economically significant fruits in the United States, generating over $2 billion in annual farm-gate sales and accounting for approximately 13% of the total fruit production value. Plant phenotyping plays a vital role in selecting superior cultivars by characterizing plant traits such as morphology, canopy structure, and growth dynamics. However, traditional plant phenotyping methods are time-consuming, labor-intensive, and often destructive. Recently, neural rendering techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have emerged as powerful frameworks for high-fidelity 3D reconstruction. By capturing a sequence of multi-view images or videos around a target plant, these methods enable non-destructive reconstruction of complex plant architectures. Despite their promise, most current applications of 3DGS in agricultural domains reconstruct the entire scene, including background elements, which introduces noise, increases computational costs, and complicates downstream trait analysis. To address this limitation, we propose a novel object-centric 3D reconstruction framework incorporating a preprocessing pipeline that leverages the Segment Anything Model v2 (SAM-2) and alpha channel background masking to achieve clean strawberry plant reconstructions. This approach produces more accurate geometric representations while substantially reducing computational time. With a background-free reconstruction, our algorithm can automatically estimate important plant traits, such as plant height and canopy width, using DBSCAN clustering and Principal Component Analysis (PCA). Experimental results show that our method outperforms conventional pipelines in both accuracy and efficiency, offering a scalable and non-destructive solution for strawberry plant phenotyping.",
    "fetched_at": "2025-11-06T02:19:07.218717Z"
  },
  {
    "id": "2511.02210v1",
    "title": "Estimation of Segmental Longitudinal Strain in Transesophageal   Echocardiography by Deep Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Anders Austlid Taskn",
      "Thierry Judge",
      "Erik Andreas Rye Berg",
      "Jinyang Yu",
      "Bjrnar Grenne",
      "Frank Lindseth",
      "Svend Aakhus",
      "Pierre-Marc Jodoin",
      "Nicolas Duchateau",
      "Olivier Bernard",
      "Gabriel Kiss"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02210v1",
    "abstract": "Segmental longitudinal strain (SLS) of the left ventricle (LV) is an important prognostic indicator for evaluating regional LV dysfunction, in particular for diagnosing and managing myocardial ischemia. Current techniques for strain estimation require significant manual intervention and expertise, limiting their efficiency and making them too resource-intensive for monitoring purposes. This study introduces the first automated pipeline, autoStrain, for SLS estimation in transesophageal echocardiography (TEE) using deep learning (DL) methods for motion estimation. We present a comparative analysis of two DL approaches: TeeFlow, based on the RAFT optical flow model for dense frame-to-frame predictions, and TeeTracker, based on the CoTracker point trajectory model for sparse long-sequence predictions.   As ground truth motion data from real echocardiographic sequences are hardly accessible, we took advantage of a unique simulation pipeline (SIMUS) to generate a highly realistic synthetic TEE (synTEE) dataset of 80 patients with ground truth myocardial motion to train and evaluate both models. Our evaluation shows that TeeTracker outperforms TeeFlow in accuracy, achieving a mean distance error in motion estimation of 0.65 mm on a synTEE test dataset.   Clinical validation on 16 patients further demonstrated that SLS estimation with our autoStrain pipeline aligned with clinical references, achieving a mean difference (95\\% limits of agreement) of 1.09% (-8.90% to 11.09%). Incorporation of simulated ischemia in the synTEE data improved the accuracy of the models in quantifying abnormal deformation. Our findings indicate that integrating AI-driven motion estimation with TEE can significantly enhance the precision and efficiency of cardiac function assessment in clinical settings.",
    "fetched_at": "2025-11-06T02:19:07.218590Z"
  },
  {
    "id": "2511.02213v1",
    "title": "IG-Pruning: Input-Guided Block Pruning for Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kangyu Qiao",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02213v1",
    "abstract": "With the growing computational demands of large language models (LLMs), efficient inference has become increasingly critical for practical deployment. Depth pruning has emerged as a promising approach for reducing the computational costs of large language models by removing transformer layers. However, existing methods typically rely on fixed block masks, which can lead to suboptimal performance across different tasks and inputs. In this paper, we propose IG-Pruning, a novel input-aware block-wise pruning method that dynamically selects layer masks at inference time. Our approach consists of two stages: (1) Discovering diverse mask candidates through semantic clustering and L0 optimization, and (2) Implementing efficient dynamic pruning without the need for extensive training. Experimental results demonstrate that our method consistently outperforms state-of-the-art static depth pruning methods, making it particularly suitable for resource-constrained deployment scenarios.",
    "fetched_at": "2025-11-06T02:19:07.218494Z"
  },
  {
    "id": "2511.02217v1",
    "title": "Optimizing Multi-Lane Intersection Performance in Mixed Autonomy   Environments",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Manonmani Sekar",
      "Nasim Nezamoddini"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02217v1",
    "abstract": "One of the main challenges in managing traffic at multilane intersections is ensuring smooth coordination between human-driven vehicles (HDVs) and connected autonomous vehicles (CAVs). This paper presents a novel traffic signal control framework that combines Graph Attention Networks (GAT) with Soft Actor-Critic (SAC) reinforcement learning to address this challenge. GATs are used to model the dynamic graph- structured nature of traffic flow to capture spatial and temporal dependencies between lanes and signal phases. The proposed SAC is a robust off-policy reinforcement learning algorithm that enables adaptive signal control through entropy-optimized decision making. This design allows the system to coordinate the signal timing and vehicle movement simultaneously with objectives focused on minimizing travel time, enhancing performance, ensuring safety, and improving fairness between HDVs and CAVs. The model is evaluated using a SUMO-based simulation of a four-way intersection and incorporating different traffic densities and CAV penetration rates. The experimental results demonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1% reduction in average delay and up to 29.2% fewer traffic violations compared to traditional methods. Additionally, the fairness ratio between HDVs and CAVs improved to 1.59, indicating more equitable treatment across vehicle types. These findings suggest that the GAT-SAC framework holds significant promise for real-world deployment in mixed-autonomy traffic systems.",
    "fetched_at": "2025-11-06T02:19:07.218412Z"
  },
  {
    "id": "2511.02219v2",
    "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning   in Tabular Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Changjiang Jiang",
      "Fengchang Yu",
      "Haihua Chen",
      "Wei Lu",
      "Jin Zeng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02219v2",
    "abstract": "Complex reasoning over tabular data is crucial in real-world data analysis, yet large language models (LLMs) often underperform due to complex queries, noisy data, and limited numerical capabilities. To address these issues, we propose TabDSR, a framework consisting of: (1) a query decomposer that breaks down complex questions, (2) a table sanitizer that cleans and filters noisy tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates executable code to derive the final answer from the sanitized table. To ensure unbiased evaluation and mitigate data leakage, we introduce a new dataset, CalTab151, specifically designed for complex numerical reasoning over tables. Experimental results demonstrate that TabDSR consistently outperforms existing methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and 19.87% accuracy improvement on TAT-QA, TableBench, and TabDSR, respectively. Moreover, our framework integrates seamlessly with mainstream LLMs, providing a robust solution for complex tabular numerical reasoning. These findings highlight the effectiveness of our framework in enhancing LLM performance for complex tabular numerical reasoning. Data and code are available upon request.",
    "fetched_at": "2025-11-06T02:19:07.218368Z"
  },
  {
    "id": "2511.02228v1",
    "title": "Collaborative Attention and Consistent-Guided Fusion of MRI and PET for   Alzheimer's Disease Diagnosis",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Delin Ma",
      "Menghui Zhou",
      "Jun Qi",
      "Yun Yang",
      "Po Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02228v1",
    "abstract": "Alzheimer's disease (AD) is the most prevalent form of dementia, and its early diagnosis is essential for slowing disease progression. Recent studies on multimodal neuroimaging fusion using MRI and PET have achieved promising results by integrating multi-scale complementary features. However, most existing approaches primarily emphasize cross-modal complementarity while overlooking the diagnostic importance of modality-specific features. In addition, the inherent distributional differences between modalities often lead to biased and noisy representations, degrading classification performance. To address these challenges, we propose a Collaborative Attention and Consistent-Guided Fusion framework for MRI and PET based AD diagnosis. The proposed model introduces a learnable parameter representation (LPR) block to compensate for missing modality information, followed by a shared encoder and modality-independent encoders to preserve both shared and specific representations. Furthermore, a consistency-guided mechanism is employed to explicitly align the latent distributions across modalities. Experimental results on the ADNI dataset demonstrate that our method achieves superior diagnostic performance compared with existing fusion strategies.",
    "fetched_at": "2025-11-06T02:19:07.218274Z"
  },
  {
    "id": "2511.02234v1",
    "title": "An Evaluation of Interleaved Instruction Tuning on Semantic Reasoning   Performance in an Audio MLLM",
    "date": "2025-11-04",
    "tags": [
      "cs.MM",
      "MM",
      "cs.CL",
      "CL",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Jiawei Liu",
      "Enis Berk oban",
      "Zarina Schevchenko",
      "Hao Tang",
      "Zhigang Zhu",
      "Michael I Mandel",
      "Johanna Devaney"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02234v1",
    "abstract": "Standard training for Multi-modal Large Language Models (MLLMs) involves concatenating non-textual information, like vision or audio, with a text prompt. This approach may not encourage deep integration of modalities, limiting the model's ability to leverage the core language model's reasoning capabilities. This work examined the impact of interleaved instruction tuning in an audio MLLM, where audio tokens are interleaved within the prompt. Using the Listen, Think, and Understand (LTU) model as a testbed, we conduct an experiment using the Synonym and Hypernym Audio Reasoning Dataset (SHARD), our newly created reasoning benchmark for audio-based semantic reasoning focusing on synonym and hypernym recognition. Our findings show that while even zero-shot interleaved prompting improves performance on our reasoning tasks, a small amount of fine-tuning using interleaved training prompts improves the results further, however, at the expense of the MLLM's audio labeling ability.",
    "fetched_at": "2025-11-06T02:19:07.218152Z"
  },
  {
    "id": "2511.02237v1",
    "title": "Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster   Decode Without Retraining",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Costin-Andrei Oncescu",
      "Qingyang Wu",
      "Wai Tong Chung",
      "Robert Wu",
      "Bryan Gopal",
      "Junxiong Wang",
      "Tri Dao",
      "Ben Athiwaratkun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02237v1",
    "abstract": "An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures where the feed-forward layer is replaced by a pool of experts and each token only activates a small subset of them. During autoregressive generation, these models often enter a memory-bound regime even for moderate batch sizes because the average expert load grows more slowly than in an equivalent dense feedforward layer. Consequently, MoE latency is governed by the number of activated experts. We introduce a framework for dynamically re-routing token-to-expert mapping to lower this number (and thus, the decode latency) while preserving a comparable quality. Our best results use a batch-aware routing that works by having tokens piggyback experts that have already been loaded into memory due to being crucial to other tokens within the same batch. Empirically, we evaluate our method on the Qwen3-30B and Qwen3-235B models with a batch size of $16$. Without any statistically significant loss in accuracy, our approach achieves latency reductions of $39\\%$ and $15\\%$ in the MoE layer decode latency, respectively.",
    "fetched_at": "2025-11-06T02:19:07.218039Z"
  }
]
[
  {
    "id": "2511.02137v1",
    "title": "DoFlow: Causal Generative Flows for Interventional and Counterfactual   Time-Series Prediction",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "stat.ME",
      "ME"
    ],
    "authors": [
      "Dongze Wu",
      "Feng Qiu",
      "Yao Xie"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02137v1",
    "abstract": "Time-series forecasting increasingly demands not only accurate observational predictions but also causal forecasting under interventional and counterfactual queries in multivariate systems. We present DoFlow, a flow based generative model defined over a causal DAG that delivers coherent observational and interventional predictions, as well as counterfactuals through the natural encoding and decoding mechanism of continuous normalizing flows (CNFs). We also provide a supporting counterfactual recovery result under certain assumptions. Beyond forecasting, DoFlow provides explicit likelihoods of future trajectories, enabling principled anomaly detection. Experiments on synthetic datasets with various causal DAG and real world hydropower and cancer treatment time series show that DoFlow achieves accurate system-wide observational forecasting, enables causal forecasting over interventional and counterfactual queries, and effectively detects anomalies. This work contributes to the broader goal of unifying causal reasoning and generative modeling for complex dynamical systems.",
    "fetched_at": "2025-11-06T02:19:07.219664Z"
  },
  {
    "id": "2511.02140v1",
    "title": "QuPCG: Quantum Convolutional Neural Network for Detecting Abnormal   Patterns in PCG Signals",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Yasaman Torabi",
      "Shahram Shirani",
      "James P. Reilly"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02140v1",
    "abstract": "Early identification of abnormal physiological patterns is essential for the timely detection of cardiac disease. This work introduces a hybrid quantum-classical convolutional neural network (QCNN) designed to classify S3 and murmur abnormalities in heart sound signals. The approach transforms one-dimensional phonocardiogram (PCG) signals into compact two-dimensional images through a combination of wavelet feature extraction and adaptive threshold compression methods. We compress the cardiac-sound patterns into an 8-pixel image so that only 8 qubits are needed for the quantum stage. Preliminary results on the HLS-CMDS dataset demonstrate 93.33% classification accuracy on the test set and 97.14% on the train set, suggesting that quantum models can efficiently capture temporal-spectral correlations in biomedical signals. To our knowledge, this is the first application of a QCNN algorithm for bioacoustic signal processing. The proposed method represents an early step toward quantum-enhanced diagnostic systems for resource-constrained healthcare environments.",
    "fetched_at": "2025-11-06T02:19:07.219619Z"
  },
  {
    "id": "2511.02146v1",
    "title": "Disentangling Causal Substructures for Interpretable and Generalizable   Drug Synergy Prediction",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yi Luo",
      "Haochen Zhao",
      "Xiao Liang",
      "Yiwei Liu",
      "Yuye Zhang",
      "Xinyu Li",
      "Jianxin Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02146v1",
    "abstract": "Drug synergy prediction is a critical task in the development of effective combination therapies for complex diseases, including cancer. Although existing methods have shown promising results, they often operate as black-box predictors that rely predominantly on statistical correlations between drug characteristics and results. To address this limitation, we propose CausalDDS, a novel framework that disentangles drug molecules into causal and spurious substructures, utilizing the causal substructure representations for predicting drug synergy. By focusing on causal sub-structures, CausalDDS effectively mitigates the impact of redundant features introduced by spurious substructures, enhancing the accuracy and interpretability of the model. In addition, CausalDDS employs a conditional intervention mechanism, where interventions are conditioned on paired molecular structures, and introduces a novel optimization objective guided by the principles of sufficiency and independence. Extensive experiments demonstrate that our method outperforms baseline models, particularly in cold start and out-of-distribution settings. Besides, CausalDDS effectively identifies key substructures underlying drug synergy, providing clear insights into how drug combinations work at the molecular level. These results underscore the potential of CausalDDS as a practical tool for predicting drug synergy and facilitating drug discovery.",
    "fetched_at": "2025-11-06T02:19:07.219566Z"
  },
  {
    "id": "2511.02148v1",
    "title": "CFL: On the Use of Characteristic Function Loss for Domain Alignment in   Machine Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Abdullah Almansour",
      "Ozan Tonguz"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02148v1",
    "abstract": "Machine Learning (ML) models are extensively used in various applications due to their significant advantages over traditional learning methods. However, the developed ML models often underperform when deployed in the real world due to the well-known distribution shift problem. This problem can lead to a catastrophic outcomes when these decision-making systems have to operate in high-risk applications. Many researchers have previously studied this problem in ML, known as distribution shift problem, using statistical techniques (such as Kullback-Leibler, Kolmogorov-Smirnov Test, Wasserstein distance, etc.) to quantify the distribution shift. In this letter, we show that using Characteristic Function (CF) as a frequency domain approach is a powerful alternative for measuring the distribution shift in high-dimensional space and for domain adaptation.",
    "fetched_at": "2025-11-06T02:19:07.219489Z"
  },
  {
    "id": "2511.02152v1",
    "title": "ProtoTSNet: Interpretable Multivariate Time Series Classification With   Prototypical Parts",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bartłomiej Małkus",
      "Szymon Bobek",
      "Grzegorz J. Nalepa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02152v1",
    "abstract": "Time series data is one of the most popular data modalities in critical domains such as industry and medicine. The demand for algorithms that not only exhibit high accuracy but also offer interpretability is crucial in such fields, as decisions made there bear significant consequences. In this paper, we present ProtoTSNet, a novel approach to interpretable classification of multivariate time series data, through substantial enhancements to the ProtoPNet architecture. Our method is tailored to overcome the unique challenges of time series analysis, including capturing dynamic patterns and handling varying feature significance. Central to our innovation is a modified convolutional encoder utilizing group convolutions, pre-trainable as part of an autoencoder and designed to preserve and quantify feature importance. We evaluated our model on 30 multivariate time series datasets from the UEA archive, comparing our approach with existing explainable methods as well as non-explainable baselines. Through comprehensive evaluation and ablation studies, we demonstrate that our approach achieves the best performance among ante-hoc explainable methods while maintaining competitive performance with non-explainable and post-hoc explainable approaches, providing interpretable results accessible to domain experts.",
    "fetched_at": "2025-11-06T02:19:07.219452Z"
  },
  {
    "id": "2511.02157v1",
    "title": "Near Optimal Convergence to Coarse Correlated Equilibrium in General-Sum   Markov Games",
    "date": "2025-11-04",
    "tags": [
      "cs.GT",
      "GT",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Asrin Efe Yorulmaz",
      "Tamer Başar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02157v1",
    "abstract": "No-regret learning dynamics play a central role in game theory, enabling decentralized convergence to equilibrium for concepts such as Coarse Correlated Equilibrium (CCE) or Correlated Equilibrium (CE). In this work, we improve the convergence rate to CCE in general-sum Markov games, reducing it from the previously best-known rate of $\\mathcal{O}(\\log^5 T / T)$ to a sharper $\\mathcal{O}(\\log T / T)$. This matches the best known convergence rate for CE in terms of $T$, number of iterations, while also improving the dependence on the action set size from polynomial to polylogarithmic-yielding exponential gains in high-dimensional settings. Our approach builds on recent advances in adaptive step-size techniques for no-regret algorithms in normal-form games, and extends them to the Markovian setting via a stage-wise scheme that adjusts learning rates based on real-time feedback. We frame policy updates as an instance of Optimistic Follow-the-Regularized-Leader (OFTRL), customized for value-iteration-based learning. The resulting self-play algorithm achieves, to our knowledge, the fastest known convergence rate to CCE in Markov games.",
    "fetched_at": "2025-11-06T02:19:07.219408Z"
  },
  {
    "id": "2511.02162v1",
    "title": "Text to Robotic Assembly of Multi Component Objects using 3D Generative   AI and Vision Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Alexander Htet Kyaw",
      "Richa Gupta",
      "Dhruv Shah",
      "Anoop Sinha",
      "Kory Mathewson",
      "Stefanie Pender",
      "Sachin Chitta",
      "Yotto Koga",
      "Faez Ahmed",
      "Lawrence Sass",
      "Randall Davis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02162v1",
    "abstract": "Advances in 3D generative AI have enabled the creation of physical objects from text prompts, but challenges remain in creating objects involving multiple component types. We present a pipeline that integrates 3D generative AI with vision-language models (VLMs) to enable the robotic assembly of multi-component objects from natural language. Our method leverages VLMs for zero-shot, multi-modal reasoning about geometry and functionality to decompose AI-generated meshes into multi-component 3D models using predefined structural and panel components. We demonstrate that a VLM is capable of determining which mesh regions need panel components in addition to structural components, based on object functionality. Evaluation across test objects shows that users preferred the VLM-generated assignments 90.6% of the time, compared to 59.4% for rule-based and 2.5% for random assignment. Lastly, the system allows users to refine component assignments through conversational feedback, enabling greater human control and agency in making physical objects with generative AI and robotics.",
    "fetched_at": "2025-11-06T02:19:07.219362Z"
  },
  {
    "id": "2511.02164v1",
    "title": "ScenicProver: A Framework for Compositional Probabilistic Verification   of Learning-Enabled Systems",
    "date": "2025-11-04",
    "tags": [
      "cs.LO",
      "LO",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.PL",
      "PL"
    ],
    "authors": [
      "Eric Vin",
      "Kyle A. Miller",
      "Inigo Incer",
      "Sanjit A. Seshia",
      "Daniel J. Fremont"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02164v1",
    "abstract": "Full verification of learning-enabled cyber-physical systems (CPS) has long been intractable due to challenges including black-box components and complex real-world environments. Existing tools either provide formal guarantees for limited types of systems or test the system as a monolith, but no general framework exists for compositional analysis of learning-enabled CPS using varied verification techniques over complex real-world environments. This paper introduces ScenicProver, a verification framework that aims to fill this gap. Built upon the Scenic probabilistic programming language, the framework supports: (1) compositional system description with clear component interfaces, ranging from interpretable code to black boxes; (2) assume-guarantee contracts over those components using an extension of Linear Temporal Logic containing arbitrary Scenic expressions; (3) evidence generation through testing, formal proofs via Lean 4 integration, and importing external assumptions; (4) systematic combination of generated evidence using contract operators; and (5) automatic generation of assurance cases tracking the provenance of system-level guarantees. We demonstrate the framework's effectiveness through a case study on an autonomous vehicle's automatic emergency braking system with sensor fusion. By leveraging manufacturer guarantees for radar and laser sensors and focusing testing efforts on uncertain conditions, our approach enables stronger probabilistic guarantees than monolithic testing with the same computational budget.",
    "fetched_at": "2025-11-06T02:19:07.219291Z"
  },
  {
    "id": "2511.02168v1",
    "title": "Eliminating Multi-GPU Performance Taxes: A Systems Approach to Efficient   Distributed LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Octavian Alexandru Trifan",
      "Karthik Sangaiah",
      "Muhammad Awad",
      "Muhammad Osama",
      "Sumanth Gudaparthi",
      "Alexandru Nicolau",
      "Alexander Veidenbaum",
      "Ganesh Dasika"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02168v1",
    "abstract": "As large language models (LLMs) continue to scale, their workloads increasingly rely on distributed execution across multiple GPUs. However, the conventional bulk synchronous parallel~(BSP) model used in such settings introduces significant performance inefficiencies. To characterize these bottlenecks, we introduce the ''Three Taxes'' (Bulk Synchronous, Inter-Kernel Data Locality, and Kernel Launch Overhead) as an analytical framework. We propose moving beyond the rigid BSP model to address key inefficiencies in distributed GPU execution. By exploiting libraries like Iris for Triton, we gain access to in-kernel communication primitives that enable the design of novel fine-grained programming patterns, offering greater flexibility and performance than traditional BSP-based approaches. These patterns systematically eliminate the three taxes by creating direct, tile-level producer-consumer pipelines and replacing global barriers with fine-grained dataflow synchronization. Applying this methodology to critical kernels, from the foundational All-Gather + general matrix multiplication operation to the complex Flash Decode algorithm, we observe a 10-20% speedup in end-to-end latency over BSP-based approaches, establishing a more programmable and efficient paradigm for distributed LLM workloads.",
    "fetched_at": "2025-11-06T02:19:07.219236Z"
  },
  {
    "id": "2511.02175v1",
    "title": "Tackling Incomplete Data in Air Quality Prediction: A Bayesian Deep   Learning Framework for Uncertainty Quantification",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuzhuang Pian",
      "Taiyu Wang",
      "Shiqi Zhang",
      "Rui Xu",
      "Yonghong Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02175v1",
    "abstract": "Accurate air quality forecasts are vital for public health alerts, exposure assessment, and emissions control. In practice, observational data are often missing in varying proportions and patterns due to collection and transmission issues. These incomplete spatiotemporal records impede reliable inference and risk assessment and can lead to overconfident extrapolation. To address these challenges, we propose an end to end framework, the channel gated learning unit based spatiotemporal bayesian neural field (CGLUBNF). It uses Fourier features with a graph attention encoder to capture multiscale spatial dependencies and seasonal temporal dynamics. A channel gated learning unit, equipped with learnable activations and gated residual connections, adaptively filters and amplifies informative features. Bayesian inference jointly optimizes predictive distributions and parameter uncertainty, producing point estimates and calibrated prediction intervals. We conduct a systematic evaluation on two real world datasets, covering four typical missing data patterns and comparing against five state of the art baselines. CGLUBNF achieves superior prediction accuracy and sharper confidence intervals. In addition, we further validate robustness across multiple prediction horizons and analysis the contribution of extraneous variables. This research lays a foundation for reliable deep learning based spatio-temporal forecasting with incomplete observations in emerging sensing paradigms, such as real world vehicle borne mobile monitoring.",
    "fetched_at": "2025-11-06T02:19:07.219175Z"
  },
  {
    "id": "2511.02185v1",
    "title": "PrivGNN: High-Performance Secure Inference for Cryptographic Graph   Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fuyi Wang",
      "Zekai Chen",
      "Mingyuan Fan",
      "Jianying Zhou",
      "Lei Pan",
      "Leo Yu Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02185v1",
    "abstract": "Graph neural networks (GNNs) are powerful tools for analyzing and learning from graph-structured (GS) data, facilitating a wide range of services. Deploying such services in privacy-critical cloud environments necessitates the development of secure inference (SI) protocols that safeguard sensitive GS data. However, existing SI solutions largely focus on convolutional models for image and text data, leaving the challenge of securing GNNs and GS data relatively underexplored. In this work, we design, implement, and evaluate $\\sysname$, a lightweight cryptographic scheme for graph-centric inference in the cloud. By hybridizing additive and function secret sharings within secure two-party computation (2PC), $\\sysname$ is carefully designed based on a series of novel 2PC interactive protocols that achieve $1.5\\times \\sim 1.7\\times$ speedups for linear layers and $2\\times \\sim 15\\times$ for non-linear layers over state-of-the-art (SotA) solutions. A thorough theoretical analysis is provided to prove $\\sysname$'s correctness, security, and lightweight nature. Extensive experiments across four datasets demonstrate $\\sysname$'s superior efficiency with $1.3\\times \\sim 4.7\\times$ faster secure predictions while maintaining accuracy comparable to plaintext graph property inference.",
    "fetched_at": "2025-11-06T02:19:07.219121Z"
  },
  {
    "id": "2511.02193v1",
    "title": "MM-UNet: Morph Mamba U-shaped Convolutional Networks for Retinal Vessel   Segmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiawen Liu",
      "Yuanbo Zeng",
      "Jiaming Liang",
      "Yizhen Yang",
      "Yiheng Zhang",
      "Enhui Cai",
      "Xiaoqi Sheng",
      "Hongmin Cai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02193v1",
    "abstract": "Accurate detection of retinal vessels plays a critical role in reflecting a wide range of health status indicators in the clinical diagnosis of ocular diseases. Recently, advances in deep learning have led to a surge in retinal vessel segmentation methods, which have significantly contributed to the quantitative analysis of vascular morphology. However, retinal vasculature differs significantly from conventional segmentation targets in that it consists of extremely thin and branching structures, whose global morphology varies greatly across images. These characteristics continue to pose challenges to segmentation precision and robustness. To address these issues, we propose MM-UNet, a novel architecture tailored for efficient retinal vessel segmentation. The model incorporates Morph Mamba Convolution layers, which replace pointwise convolutions to enhance branching topological perception through morph, state-aware feature sampling. Additionally, Reverse Selective State Guidance modules integrate reverse guidance theory with state-space modeling to improve geometric boundary awareness and decoding efficiency. Extensive experiments conducted on two public retinal vessel segmentation datasets demonstrate the superior performance of the proposed method in segmentation accuracy. Compared to the existing approaches, MM-UNet achieves F1-score gains of 1.64 $\\%$ on DRIVE and 1.25 $\\%$ on STARE, demonstrating its effectiveness and advancement. The project code is public via https://github.com/liujiawen-jpg/MM-UNet.",
    "fetched_at": "2025-11-06T02:19:07.219066Z"
  },
  {
    "id": "2511.02194v1",
    "title": "Personalized Decision Modeling: Utility Optimization or   Textualized-Symbolic Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yibo Zhao",
      "Yang Zhao",
      "Hongru Du",
      "Hao Frank Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02194v1",
    "abstract": "Decision-making models for individuals, particularly in high-stakes scenarios like vaccine uptake, often diverge from population optimal predictions. This gap arises from the uniqueness of the individual decision-making process, shaped by numerical attributes (e.g., cost, time) and linguistic influences (e.g., personal preferences and constraints). Developing upon Utility Theory and leveraging the textual-reasoning capabilities of Large Language Models (LLMs), this paper proposes an Adaptive Textual-symbolic Human-centric Reasoning framework (ATHENA) to address the optimal information integration. ATHENA uniquely integrates two stages: First, it discovers robust, group-level symbolic utility functions via LLM-augmented symbolic discovery; Second, it implements individual-level semantic adaptation, creating personalized semantic templates guided by the optimal utility to model personalized choices. Validated on real-world travel mode and vaccine choice tasks, ATHENA consistently outperforms utility-based, machine learning, and other LLM-based models, lifting F1 score by at least 6.5% over the strongest cutting-edge models. Further, ablation studies confirm that both stages of ATHENA are critical and complementary, as removing either clearly degrades overall predictive performance. By organically integrating symbolic utility modeling and semantic adaptation, ATHENA provides a new scheme for modeling human-centric decisions. The project page can be found at https://yibozh.github.io/Athena.",
    "fetched_at": "2025-11-06T02:19:07.219003Z"
  },
  {
    "id": "2511.02196v1",
    "title": "BoolSkeleton: Boolean Network Skeletonization via Homogeneous Pattern   Reduction",
    "date": "2025-11-04",
    "tags": [
      "cs.AR",
      "AR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Liwei Ni",
      "Jiaxi Zhang",
      "Shenggen Zheng",
      "Junfeng Liu",
      "Xingyu Meng",
      "Biwei Xie",
      "Xingquan Li",
      "Huawei Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02196v1",
    "abstract": "Boolean equivalence allows Boolean networks with identical functionality to exhibit diverse graph structures. This gives more room for exploration in logic optimization, while also posing a challenge for tasks involving consistency between Boolean networks. To tackle this challenge, we introduce BoolSkeleton, a novel Boolean network skeletonization method that improves the consistency and reliability of design-specific evaluations. BoolSkeleton comprises two key steps: preprocessing and reduction. In preprocessing, the Boolean network is transformed into a defined Boolean dependency graph, where nodes are assigned the functionality-related status. Next, the homogeneous and heterogeneous patterns are defined for the node-level pattern reduction step. Heterogeneous patterns are preserved to maintain critical functionality-related dependencies, while homogeneous patterns can be reduced. Parameter K of the pattern further constrains the fanin size of these patterns, enabling fine-tuned control over the granularity of graph reduction. To validate BoolSkeleton's effectiveness, we conducted four analysis/downstream tasks around the Boolean network: compression analysis, classification, critical path analysis, and timing prediction, demonstrating its robustness across diverse scenarios. Furthermore, it improves above 55% in the average accuracy compared to the original Boolean network for the timing prediction task. These experiments underscore the potential of BoolSkeleton to enhance design consistency in logic synthesis.",
    "fetched_at": "2025-11-06T02:19:07.218947Z"
  },
  {
    "id": "2511.02197v1",
    "title": "Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning   Confidence in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shufan Wang",
      "Xing Hu",
      "Junkai Chen",
      "Zhiyuan Pan",
      "Xin Xia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02197v1",
    "abstract": "With the widespread application of large language models (LLMs) in the field of code intelligence, increasing attention has been paid to the reliability and controllability of their outputs in code reasoning tasks. Confidence estimation serves as an effective and convenient approach for evaluating these aspects. This paper proposes a confidence analysis and enhancement framework for LLMs tailored to code reasoning tasks. We conduct a comprehensive empirical study on the confidence reliability of mainstream LLMs across different tasks, and further evaluate the effectiveness of techniques such as prompt strategy optimisation and mathematical calibration (e.g., Platt Scaling) in improving confidence reliability. Our results show that DeepSeek-Reasoner achieves the best performance across various tasks, outperforming other models by up to $0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance Score, respectively. The hybrid strategy combining the reassess prompt strategy and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$ over the original performance in the aforementioned three metrics. These results indicate that models with reasoning capabilities demonstrate superior confidence reliability, and that the hybrid strategy is the most effective in enhancing the confidence reliability of various models. Meanwhile, we elucidate the impact of different task complexities, model scales, and strategies on confidence performance, and highlight that the confidence of current LLMs in complex reasoning tasks still has considerable room for improvement. This study not only provides a research foundation and technical reference for the application of confidence in LLM-assisted software engineering, but also points the way for future optimisation and engineering deployment of confidence mechanisms.",
    "fetched_at": "2025-11-06T02:19:07.218881Z"
  },
  {
    "id": "2511.02205v1",
    "title": "OmniField: Conditioned Neural Fields for Robust Multimodal   Spatiotemporal Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Kevin Valencia",
      "Thilina Balasooriya",
      "Xihaier Luo",
      "Shinjae Yoo",
      "David Keetae Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02205v1",
    "abstract": "Multimodal spatiotemporal learning on real-world experimental data is constrained by two challenges: within-modality measurements are sparse, irregular, and noisy (QA/QC artifacts) but cross-modally correlated; the set of available modalities varies across space and time, shrinking the usable record unless models can adapt to arbitrary subsets at train and test time. We propose OmniField, a continuity-aware framework that learns a continuous neural field conditioned on available modalities and iteratively fuses cross-modal context. A multimodal crosstalk block architecture paired with iterative cross-modal refinement aligns signals prior to the decoder, enabling unified reconstruction, interpolation, forecasting, and cross-modal prediction without gridding or surrogate preprocessing. Extensive evaluations show that OmniField consistently outperforms eight strong multimodal spatiotemporal baselines. Under heavy simulated sensor noise, performance remains close to clean-input levels, highlighting robustness to corrupted measurements.",
    "fetched_at": "2025-11-06T02:19:07.218768Z"
  },
  {
    "id": "2511.02207v1",
    "title": "Object-Centric 3D Gaussian Splatting for Strawberry Plant Reconstruction   and Phenotyping",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiajia Li",
      "Keyi Zhu",
      "Qianwen Zhang",
      "Dong Chen",
      "Qi Sun",
      "Zhaojian Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02207v1",
    "abstract": "Strawberries are among the most economically significant fruits in the United States, generating over $2 billion in annual farm-gate sales and accounting for approximately 13% of the total fruit production value. Plant phenotyping plays a vital role in selecting superior cultivars by characterizing plant traits such as morphology, canopy structure, and growth dynamics. However, traditional plant phenotyping methods are time-consuming, labor-intensive, and often destructive. Recently, neural rendering techniques, notably Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), have emerged as powerful frameworks for high-fidelity 3D reconstruction. By capturing a sequence of multi-view images or videos around a target plant, these methods enable non-destructive reconstruction of complex plant architectures. Despite their promise, most current applications of 3DGS in agricultural domains reconstruct the entire scene, including background elements, which introduces noise, increases computational costs, and complicates downstream trait analysis. To address this limitation, we propose a novel object-centric 3D reconstruction framework incorporating a preprocessing pipeline that leverages the Segment Anything Model v2 (SAM-2) and alpha channel background masking to achieve clean strawberry plant reconstructions. This approach produces more accurate geometric representations while substantially reducing computational time. With a background-free reconstruction, our algorithm can automatically estimate important plant traits, such as plant height and canopy width, using DBSCAN clustering and Principal Component Analysis (PCA). Experimental results show that our method outperforms conventional pipelines in both accuracy and efficiency, offering a scalable and non-destructive solution for strawberry plant phenotyping.",
    "fetched_at": "2025-11-06T02:19:07.218717Z"
  },
  {
    "id": "2511.02210v1",
    "title": "Estimation of Segmental Longitudinal Strain in Transesophageal   Echocardiography by Deep Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Anders Austlid Taskén",
      "Thierry Judge",
      "Erik Andreas Rye Berg",
      "Jinyang Yu",
      "Bjørnar Grenne",
      "Frank Lindseth",
      "Svend Aakhus",
      "Pierre-Marc Jodoin",
      "Nicolas Duchateau",
      "Olivier Bernard",
      "Gabriel Kiss"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02210v1",
    "abstract": "Segmental longitudinal strain (SLS) of the left ventricle (LV) is an important prognostic indicator for evaluating regional LV dysfunction, in particular for diagnosing and managing myocardial ischemia. Current techniques for strain estimation require significant manual intervention and expertise, limiting their efficiency and making them too resource-intensive for monitoring purposes. This study introduces the first automated pipeline, autoStrain, for SLS estimation in transesophageal echocardiography (TEE) using deep learning (DL) methods for motion estimation. We present a comparative analysis of two DL approaches: TeeFlow, based on the RAFT optical flow model for dense frame-to-frame predictions, and TeeTracker, based on the CoTracker point trajectory model for sparse long-sequence predictions.   As ground truth motion data from real echocardiographic sequences are hardly accessible, we took advantage of a unique simulation pipeline (SIMUS) to generate a highly realistic synthetic TEE (synTEE) dataset of 80 patients with ground truth myocardial motion to train and evaluate both models. Our evaluation shows that TeeTracker outperforms TeeFlow in accuracy, achieving a mean distance error in motion estimation of 0.65 mm on a synTEE test dataset.   Clinical validation on 16 patients further demonstrated that SLS estimation with our autoStrain pipeline aligned with clinical references, achieving a mean difference (95\\% limits of agreement) of 1.09% (-8.90% to 11.09%). Incorporation of simulated ischemia in the synTEE data improved the accuracy of the models in quantifying abnormal deformation. Our findings indicate that integrating AI-driven motion estimation with TEE can significantly enhance the precision and efficiency of cardiac function assessment in clinical settings.",
    "fetched_at": "2025-11-06T02:19:07.218590Z"
  },
  {
    "id": "2511.02213v1",
    "title": "IG-Pruning: Input-Guided Block Pruning for Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kangyu Qiao",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02213v1",
    "abstract": "With the growing computational demands of large language models (LLMs), efficient inference has become increasingly critical for practical deployment. Depth pruning has emerged as a promising approach for reducing the computational costs of large language models by removing transformer layers. However, existing methods typically rely on fixed block masks, which can lead to suboptimal performance across different tasks and inputs. In this paper, we propose IG-Pruning, a novel input-aware block-wise pruning method that dynamically selects layer masks at inference time. Our approach consists of two stages: (1) Discovering diverse mask candidates through semantic clustering and L0 optimization, and (2) Implementing efficient dynamic pruning without the need for extensive training. Experimental results demonstrate that our method consistently outperforms state-of-the-art static depth pruning methods, making it particularly suitable for resource-constrained deployment scenarios.",
    "fetched_at": "2025-11-06T02:19:07.218494Z"
  },
  {
    "id": "2511.02217v1",
    "title": "Optimizing Multi-Lane Intersection Performance in Mixed Autonomy   Environments",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Manonmani Sekar",
      "Nasim Nezamoddini"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02217v1",
    "abstract": "One of the main challenges in managing traffic at multilane intersections is ensuring smooth coordination between human-driven vehicles (HDVs) and connected autonomous vehicles (CAVs). This paper presents a novel traffic signal control framework that combines Graph Attention Networks (GAT) with Soft Actor-Critic (SAC) reinforcement learning to address this challenge. GATs are used to model the dynamic graph- structured nature of traffic flow to capture spatial and temporal dependencies between lanes and signal phases. The proposed SAC is a robust off-policy reinforcement learning algorithm that enables adaptive signal control through entropy-optimized decision making. This design allows the system to coordinate the signal timing and vehicle movement simultaneously with objectives focused on minimizing travel time, enhancing performance, ensuring safety, and improving fairness between HDVs and CAVs. The model is evaluated using a SUMO-based simulation of a four-way intersection and incorporating different traffic densities and CAV penetration rates. The experimental results demonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1% reduction in average delay and up to 29.2% fewer traffic violations compared to traditional methods. Additionally, the fairness ratio between HDVs and CAVs improved to 1.59, indicating more equitable treatment across vehicle types. These findings suggest that the GAT-SAC framework holds significant promise for real-world deployment in mixed-autonomy traffic systems.",
    "fetched_at": "2025-11-06T02:19:07.218412Z"
  },
  {
    "id": "2511.02219v2",
    "title": "TabDSR: Decompose, Sanitize, and Reason for Complex Numerical Reasoning   in Tabular Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Changjiang Jiang",
      "Fengchang Yu",
      "Haihua Chen",
      "Wei Lu",
      "Jin Zeng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02219v2",
    "abstract": "Complex reasoning over tabular data is crucial in real-world data analysis, yet large language models (LLMs) often underperform due to complex queries, noisy data, and limited numerical capabilities. To address these issues, we propose TabDSR, a framework consisting of: (1) a query decomposer that breaks down complex questions, (2) a table sanitizer that cleans and filters noisy tables, and (3) a program-of-thoughts (PoT)-based reasoner that generates executable code to derive the final answer from the sanitized table. To ensure unbiased evaluation and mitigate data leakage, we introduce a new dataset, CalTab151, specifically designed for complex numerical reasoning over tables. Experimental results demonstrate that TabDSR consistently outperforms existing methods, achieving state-of-the-art (SOTA) performance with 8.79%, 6.08%, and 19.87% accuracy improvement on TAT-QA, TableBench, and TabDSR, respectively. Moreover, our framework integrates seamlessly with mainstream LLMs, providing a robust solution for complex tabular numerical reasoning. These findings highlight the effectiveness of our framework in enhancing LLM performance for complex tabular numerical reasoning. Data and code are available upon request.",
    "fetched_at": "2025-11-06T02:19:07.218368Z"
  },
  {
    "id": "2511.02228v1",
    "title": "Collaborative Attention and Consistent-Guided Fusion of MRI and PET for   Alzheimer's Disease Diagnosis",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Delin Ma",
      "Menghui Zhou",
      "Jun Qi",
      "Yun Yang",
      "Po Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02228v1",
    "abstract": "Alzheimer's disease (AD) is the most prevalent form of dementia, and its early diagnosis is essential for slowing disease progression. Recent studies on multimodal neuroimaging fusion using MRI and PET have achieved promising results by integrating multi-scale complementary features. However, most existing approaches primarily emphasize cross-modal complementarity while overlooking the diagnostic importance of modality-specific features. In addition, the inherent distributional differences between modalities often lead to biased and noisy representations, degrading classification performance. To address these challenges, we propose a Collaborative Attention and Consistent-Guided Fusion framework for MRI and PET based AD diagnosis. The proposed model introduces a learnable parameter representation (LPR) block to compensate for missing modality information, followed by a shared encoder and modality-independent encoders to preserve both shared and specific representations. Furthermore, a consistency-guided mechanism is employed to explicitly align the latent distributions across modalities. Experimental results on the ADNI dataset demonstrate that our method achieves superior diagnostic performance compared with existing fusion strategies.",
    "fetched_at": "2025-11-06T02:19:07.218274Z"
  },
  {
    "id": "2511.02234v1",
    "title": "An Evaluation of Interleaved Instruction Tuning on Semantic Reasoning   Performance in an Audio MLLM",
    "date": "2025-11-04",
    "tags": [
      "cs.MM",
      "MM",
      "cs.CL",
      "CL",
      "cs.SD",
      "SD"
    ],
    "authors": [
      "Jiawei Liu",
      "Enis Berk Çoban",
      "Zarina Schevchenko",
      "Hao Tang",
      "Zhigang Zhu",
      "Michael I Mandel",
      "Johanna Devaney"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02234v1",
    "abstract": "Standard training for Multi-modal Large Language Models (MLLMs) involves concatenating non-textual information, like vision or audio, with a text prompt. This approach may not encourage deep integration of modalities, limiting the model's ability to leverage the core language model's reasoning capabilities. This work examined the impact of interleaved instruction tuning in an audio MLLM, where audio tokens are interleaved within the prompt. Using the Listen, Think, and Understand (LTU) model as a testbed, we conduct an experiment using the Synonym and Hypernym Audio Reasoning Dataset (SHARD), our newly created reasoning benchmark for audio-based semantic reasoning focusing on synonym and hypernym recognition. Our findings show that while even zero-shot interleaved prompting improves performance on our reasoning tasks, a small amount of fine-tuning using interleaved training prompts improves the results further, however, at the expense of the MLLM's audio labeling ability.",
    "fetched_at": "2025-11-06T02:19:07.218152Z"
  },
  {
    "id": "2511.02237v1",
    "title": "Opportunistic Expert Activation: Batch-Aware Expert Routing for Faster   Decode Without Retraining",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Costin-Andrei Oncescu",
      "Qingyang Wu",
      "Wai Tong Chung",
      "Robert Wu",
      "Bryan Gopal",
      "Junxiong Wang",
      "Tri Dao",
      "Ben Athiwaratkun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02237v1",
    "abstract": "An increasing number of LLMs employ Mixture-of-Experts (MoE) architectures where the feed-forward layer is replaced by a pool of experts and each token only activates a small subset of them. During autoregressive generation, these models often enter a memory-bound regime even for moderate batch sizes because the average expert load grows more slowly than in an equivalent dense feedforward layer. Consequently, MoE latency is governed by the number of activated experts. We introduce a framework for dynamically re-routing token-to-expert mapping to lower this number (and thus, the decode latency) while preserving a comparable quality. Our best results use a batch-aware routing that works by having tokens piggyback experts that have already been loaded into memory due to being crucial to other tokens within the same batch. Empirically, we evaluate our method on the Qwen3-30B and Qwen3-235B models with a batch size of $16$. Without any statistically significant loss in accuracy, our approach achieves latency reductions of $39\\%$ and $15\\%$ in the MoE layer decode latency, respectively.",
    "fetched_at": "2025-11-06T02:19:07.218039Z"
  },
  {
    "id": "2511.02243v1",
    "title": "When Modalities Conflict: How Unimodal Reasoning Uncertainty Governs   Preference Dynamics in MLLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zhuoran Zhang",
      "Tengyue Wang",
      "Xilin Gong",
      "Yang Shi",
      "Haotian Wang",
      "Di Wang",
      "Lijie Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02243v1",
    "abstract": "Multimodal large language models (MLLMs) must resolve conflicts when different modalities provide contradictory information, a process we term modality following. Prior work measured this behavior only with coarse dataset-level statistics, overlooking the influence of model's confidence in unimodal reasoning. In this paper, we introduce a new framework that decomposes modality following into two fundamental factors: relative reasoning uncertainty (the case-specific confidence gap between unimodal predictions) and inherent modality preference( a model's stable bias when uncertainties are balanced). To validate this framework, we construct a controllable dataset that systematically varies the reasoning difficulty of visual and textual inputs. Using entropy as a fine-grained uncertainty metric, we uncover a universal law: the probability of following a modality decreases monotonically as its relative uncertainty increases. At the relative difficulty level where the model tends to follow both modalities with comparable probability what we call the balance point, a practical indicator of the model's inherent preference. Unlike traditional macro-level ratios, this measure offers a more principled and less confounded way to characterize modality bias, disentangling it from unimodal capabilities and dataset artifacts. Further, by probing layer-wise predictions, we reveal the internal mechanism of oscillation: in ambiguous regions near the balance point, models vacillate between modalities across layers, explaining externally observed indecision. Together, these findings establish relative uncertainty and inherent preference as the two governing principles of modality following, offering both a quantitative framework and mechanistic insight into how MLLMs resolve conflicting information.",
    "fetched_at": "2025-11-06T02:19:07.217881Z"
  },
  {
    "id": "2511.02244v1",
    "title": "Neural network initialization with nonlinear characteristics and   information on spectral bias",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hikaru Homma",
      "Jun Ohkubo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02244v1",
    "abstract": "Initialization of neural network parameters, such as weights and biases, has a crucial impact on learning performance; if chosen well, we can even avoid the need for additional training with backpropagation. For example, algorithms based on the ridgelet transform or the SWIM (sampling where it matters) concept have been proposed for initialization. On the other hand, it is well-known that neural networks tend to learn coarse information in the earlier layers. The feature is called spectral bias. In this work, we investigate the effects of utilizing information on the spectral bias in the initialization of neural networks. Hence, we propose a framework that adjusts the scale factors in the SWIM algorithm to capture low-frequency components in the early-stage hidden layers and to represent high-frequency components in the late-stage hidden layers. Numerical experiments on a one-dimensional regression task and the MNIST classification task demonstrate that the proposed method outperforms the conventional initialization algorithms. This work clarifies the importance of intrinsic spectral properties in learning neural networks, and the finding yields an effective parameter initialization strategy that enhances their training performance.",
    "fetched_at": "2025-11-06T02:19:07.217817Z"
  },
  {
    "id": "2511.02248v1",
    "title": "From Models to Operators: Rethinking Autoscaling Granularity for Large   Generative Models",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xingqi Cui",
      "Chieh-Jan Mike Liang",
      "Jiarong Xing",
      "Haoran Qiu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02248v1",
    "abstract": "Serving large generative models such as LLMs and multi- modal transformers requires balancing user-facing SLOs (e.g., time-to-first-token, time-between-tokens) with provider goals of efficiency and cost reduction. Existing solutions rely on static provisioning or model-level autoscaling, both of which treat the model as a monolith. This coarse-grained resource management leads to degraded performance or significant resource underutilization due to poor adaptability to dynamic inference traffic that is common online.   The root cause of this inefficiency lies in the internal structure of generative models: they are executed as graphs of interconnected operators. Through detailed characterization and systematic analysis, we find that operators are heterogeneous in their compute and memory footprints and exhibit diverse sensitivity to workload and resource factors such as batch size, sequence length, and traffic rate. This heterogeneity suggests that the operator, rather than the entire model, is the right granularity for scaling decisions.   We propose an operator-level autoscaling framework, which allocates resources at finer (operator)-granularity, optimizing the scaling, batching, and placement based on individual operator profiles. Evaluated on production-scale traces, our approach preserves SLOs with up to 40% fewer GPUs and 35% less energy, or under fixed resources achieves 1.6x higher throughput with 5% less energy. These results show that the operator, rather than the model, is fundamentally a more effective unit for scaling large generative workloads.",
    "fetched_at": "2025-11-06T02:19:07.217710Z"
  },
  {
    "id": "2511.02254v1",
    "title": "Fast Approximation Algorithm for Non-Monotone DR-submodular Maximization   under Size Constraint",
    "date": "2025-11-04",
    "tags": [
      "cs.DS",
      "DS",
      "cs.AI",
      "AI",
      "cs.CC",
      "CC"
    ],
    "authors": [
      "Tan D. Tran",
      "Canh V. Pham"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02254v1",
    "abstract": "This work studies the non-monotone DR-submodular Maximization over a ground set of $n$ subject to a size constraint $k$. We propose two approximation algorithms for solving this problem named FastDrSub and FastDrSub++. FastDrSub offers an approximation ratio of $0.044$ with query complexity of $O(n \\log(k))$. The second one, FastDrSub++, improves upon it with a ratio of $1/4-\\epsilon$ within query complexity of $(n \\log k)$ for an input parameter $\\epsilon >0$. Therefore, our proposed algorithms are the first constant-ratio approximation algorithms for the problem with the low complexity of $O(n \\log(k))$.   Additionally, both algorithms are experimentally evaluated and compared against existing state-of-the-art methods, demonstrating their effectiveness in solving the Revenue Maximization problem with DR-submodular objective function. The experimental results show that our proposed algorithms significantly outperform existing approaches in terms of both query complexity and solution quality.",
    "fetched_at": "2025-11-06T02:19:07.217658Z"
  },
  {
    "id": "2511.02258v1",
    "title": "Limit Theorems for Stochastic Gradient Descent in High-Dimensional   Single-Layer Networks",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.PR",
      "PR",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Parsa Rangriz"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02258v1",
    "abstract": "This paper studies the high-dimensional scaling limits of online stochastic gradient descent (SGD) for single-layer networks. Building on the seminal work of Saad and Solla, which analyzed the deterministic (ballistic) scaling limits of SGD corresponding to the gradient flow of the population loss, we focus on the critical scaling regime of the step size. Below this critical scale, the effective dynamics are governed by ballistic (ODE) limits, but at the critical scale, new correction term appears that changes the phase diagram. In this regime, near the fixed points, the corresponding diffusive (SDE) limits of the effective dynamics reduces to an Ornstein-Uhlenbeck process under certain conditions. These results highlight how the information exponent controls sample complexity and illustrates the limitations of deterministic scaling limit in capturing the stochastic fluctuations of high-dimensional learning dynamics.",
    "fetched_at": "2025-11-06T02:19:07.217615Z"
  },
  {
    "id": "2511.02263v2",
    "title": "LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for   AI-MARRVEL in Rare Disease Diagnosis",
    "date": "2025-11-04",
    "tags": [
      "q-bio.GN",
      "GN",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jaeyeon Lee",
      "Hyun-Hwan Jeong",
      "Zhandong Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02263v2",
    "abstract": "Diagnosing rare diseases often requires connecting variant-bearing genes to evidence that is written as unstructured clinical prose, which the current established pipelines still leave for clinicians to reconcile manually. To this end, we introduce LA-MARRVEL, a knowledge-grounded and language-aware reranking layer that operates on top of AI-MARRVEL: it supplies expert-engineered context, queries a large language model multiple times, and aggregates the resulting partial rankings with a ranked voting method to produce a stable, explainable gene ranking. Evaluated on three real-world cohorts (BG, DDD, UDN), LA-MARRVEL consistently improves Recall@K over AI-MARRVEL and established phenotype-driven tools such as Exomiser and LIRICAL, with especially large gains on cases where the first-stage ranker placed the causal gene lower. Each ranked gene is accompanied by LLM-generated reasoning that integrates phenotypic, inheritance, and variant-level evidence, thereby making the output more interpretable and facilitating clinical review.",
    "fetched_at": "2025-11-06T02:19:07.217570Z"
  },
  {
    "id": "2511.02272v2",
    "title": "Probabilistic Graph Cuts",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.DS",
      "DS",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Ayoub Ghriss"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02272v2",
    "abstract": "Probabilistic relaxations of graph cuts offer a differentiable alternative to spectral clustering, enabling end-to-end and online learning without eigendecompositions, yet prior work centered on RatioCut and lacked general guarantees and principled gradients. We present a unified probabilistic framework that covers a wide class of cuts, including Normalized Cut. Our framework provides tight analytic upper bounds on expected discrete cuts via integral representations and Gauss hypergeometric functions with closed-form forward and backward. Together, these results deliver a rigorous, numerically stable foundation for scalable, differentiable graph partitioning covering a wide range of clustering and contrastive learning objectives.",
    "fetched_at": "2025-11-06T02:19:07.217507Z"
  },
  {
    "id": "2511.02276v1",
    "title": "Gradient-Variation Online Adaptivity for Accelerated Optimization with   Hölder Smoothness",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Yuheng Zhao",
      "Yu-Hu Yan",
      "Kfir Yehuda Levy",
      "Peng Zhao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02276v1",
    "abstract": "Smoothness is known to be crucial for acceleration in offline optimization, and for gradient-variation regret minimization in online learning. Interestingly, these two problems are actually closely connected -- accelerated optimization can be understood through the lens of gradient-variation online learning. In this paper, we investigate online learning with H\\\"older smooth functions, a general class encompassing both smooth and non-smooth (Lipschitz) functions, and explore its implications for offline optimization. For (strongly) convex online functions, we design the corresponding gradient-variation online learning algorithm whose regret smoothly interpolates between the optimal guarantees in smooth and non-smooth regimes. Notably, our algorithms do not require prior knowledge of the H\\\"older smoothness parameter, exhibiting strong adaptivity over existing methods. Through online-to-batch conversion, this gradient-variation online adaptivity yields an optimal universal method for stochastic convex optimization under H\\\"older smoothness. However, achieving universality in offline strongly convex optimization is more challenging. We address this by integrating online adaptivity with a detection-based guess-and-check procedure, which, for the first time, yields a universal offline method that achieves accelerated convergence in the smooth regime while maintaining near-optimal convergence in the non-smooth one.",
    "fetched_at": "2025-11-06T02:19:07.217472Z"
  },
  {
    "id": "2511.02280v1",
    "title": "SAIL-RL: Guiding MLLMs in When and How to Think via Dual-Reward RL   Tuning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Fangxun Shu",
      "Yongjie Ye",
      "Yue Liao",
      "Zijian Kang",
      "Weijie Yin",
      "Jiacong Wang",
      "Xiao Liang",
      "Shuicheng Yan",
      "Chao Feng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02280v1",
    "abstract": "We introduce SAIL-RL, a reinforcement learning (RL) post-training framework that enhances the reasoning capabilities of multimodal large language models (MLLMs) by teaching them when and how to think. Existing approaches are limited by outcome-only supervision, which rewards correct answers without ensuring sound reasoning, and by uniform thinking strategies, which often lead to overthinking on simple tasks and underthinking on complex ones. SAIL-RL addresses these challenges with a dual reward system: the Thinking Reward, which evaluates reasoning quality through factual grounding, logical coherence, and answer consistency, and the Judging Reward, which adaptively determines whether deep reasoning or direct answering is appropriate. Experiments on the state-of-the-art SAIL-VL2 show that SAIL-RL improves reasoning and multimodal understanding benchmarks at both 4B and 8B scales, achieving competitive performance against commercial closed-source models such as GPT-4o, and substantially reduces hallucinations, establishing it as a principled framework for building more reliable and adaptive MLLMs. The code will be available at https://github.com/BytedanceDouyinContent/SAIL-RL.",
    "fetched_at": "2025-11-06T02:19:07.217412Z"
  },
  {
    "id": "2511.02286v1",
    "title": "Reinforcement learning based data assimilation for unknown state model",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ziyi Wang",
      "Lijian Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02286v1",
    "abstract": "Data assimilation (DA) has increasingly emerged as a critical tool for state estimation   across a wide range of applications. It is signiffcantly challenging when the governing equations of the underlying dynamics are unknown. To this end, various machine learning approaches have been employed to construct a surrogate state transition   model in a supervised learning framework, which relies on pre-computed training   datasets. However, it is often infeasible to obtain noise-free ground-truth state sequences in practice. To address this challenge, we propose a novel method that integrates reinforcement learning with ensemble-based Bayesian ffltering methods, enabling   the learning of surrogate state transition model for unknown dynamics directly from noisy observations, without using true state trajectories. Speciffcally, we treat the process for computing maximum likelihood estimation of surrogate model parameters   as a sequential decision-making problem, which can be formulated as a discretetime   Markov decision process (MDP). Under this formulation, learning the surrogate transition model is equivalent to ffnding an optimal policy of the MDP, which can be effectively addressed using reinforcement learning techniques. Once the model is trained offfine, state estimation can be performed in the online stage using ffltering methods based on the learned dynamics. The proposed framework accommodates a wide range of observation scenarios, including nonlinear and partially observed measurement   models. A few numerical examples demonstrate that the proposed method achieves superior accuracy and robustness in high-dimensional settings.",
    "fetched_at": "2025-11-06T02:19:07.217349Z"
  },
  {
    "id": "2511.02288v1",
    "title": "Link prediction Graph Neural Networks for structure recognition of   Handwritten Mathematical Expressions",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Cuong Tuan Nguyen",
      "Ngoc Tuan Nguyen",
      "Triet Hoang Minh Dao",
      "Huy Minh Nhat",
      "Huy Truong Dinh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02288v1",
    "abstract": "We propose a Graph Neural Network (GNN)-based approach for Handwritten Mathematical Expression (HME) recognition by modeling HMEs as graphs, where nodes represent symbols and edges capture spatial dependencies. A deep BLSTM network is used for symbol segmentation, recognition, and spatial relation classification, forming an initial primitive graph. A 2D-CFG parser then generates all possible spatial relations, while the GNN-based link prediction model refines the structure by removing unnecessary connections, ultimately forming the Symbol Label Graph. Experimental results demonstrate the effectiveness of our approach, showing promising performance in HME structure recognition.",
    "fetched_at": "2025-11-06T02:19:07.217304Z"
  },
  {
    "id": "2511.02290v1",
    "title": "From data to design: Random forest regression model for predicting   mechanical properties of alloy steel",
    "date": "2025-11-04",
    "tags": [
      "cond-mat.mtrl-sci",
      "mtrl-sci",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Samjukta Sinha",
      "Prabhat Das"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02290v1",
    "abstract": "This study investigates the application of Random Forest Regression for predicting mechanical properties of alloy steel-Elongation, Tensile Strength, and Yield Strength-from material composition features including Iron (Fe), Chromium (Cr), Nickel (Ni), Manganese (Mn), Silicon (Si), Copper (Cu), Carbon (C), and deformation percentage during cold rolling. Utilizing a dataset comprising these features, we trained and evaluated the Random Forest model, achieving high predictive performance as evidenced by R2 scores and Mean Squared Errors (MSE). The results demonstrate the model's efficacy in providing accurate predictions, which is validated through various performance metrics including residual plots and learning curves. The findings underscore the potential of ensemble learning techniques in enhancing material property predictions, with implications for industrial applications in material science.",
    "fetched_at": "2025-11-06T02:19:07.217257Z"
  },
  {
    "id": "2511.02301v1",
    "title": "Federated Quantum Kernel Learning for Anomaly Detection in Multivariate   IoT Time-Series",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "quant-ph"
    ],
    "authors": [
      "Kuan-Cheng Chen",
      "Samuel Yen-Chi Chen",
      "Chen-Yu Liu",
      "Kin K. Leung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02301v1",
    "abstract": "The rapid growth of industrial Internet of Things (IIoT) systems has created new challenges for anomaly detection in high-dimensional, multivariate time-series, where privacy, scalability, and communication efficiency are critical. Classical federated learning approaches mitigate privacy concerns by enabling decentralized training, but they often struggle with highly non-linear decision boundaries and imbalanced anomaly distributions. To address this gap, we propose a Federated Quantum Kernel Learning (FQKL) framework that integrates quantum feature maps with federated aggregation to enable distributed, privacy-preserving anomaly detection across heterogeneous IoT networks. In our design, quantum edge nodes locally compute compressed kernel statistics using parameterized quantum circuits and share only these summaries with a central server, which constructs a global Gram matrix and trains a decision function (e.g., Fed-QSVM). Experimental results on synthetic IIoT benchmarks demonstrate that FQKL achieves superior generalization in capturing complex temporal correlations compared to classical federated baselines, while significantly reducing communication overhead. This work highlights the promise of quantum kernels in federated settings, advancing the path toward scalable, robust, and quantum-enhanced intelligence for next-generation IoT infrastructures.",
    "fetched_at": "2025-11-06T02:19:07.217218Z"
  },
  {
    "id": "2511.02302v1",
    "title": "FP8-Flow-MoE: A Casting-Free FP8 Recipe without Double Quantization   Error",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fengjuan Wang",
      "Zhiyi Su",
      "Xingzhu Hu",
      "Cheng Wang",
      "Mou Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02302v1",
    "abstract": "Training large Mixture-of-Experts (MoE) models remains computationally prohibitive due to their extreme compute and memory demands. Although low-precision training promises to accelerate computation and reduce memory footprint, existing implementations still rely on BF16-dominated dataflows with frequent quantize-dequantize (Q/DQ) conversions. These redundant casts erode much of FP8's theoretical efficiency. However, naively removing these casts by keeping dataflows entirely in FP8 introduces double quantization error: tensors quantized along different dimensions accumulate inconsistent scaling factors, degrading numerical stability.   We propose FP8-Flow-MoE, an FP8 training recipe featuring a quantization-consistent FP8-centric dataflow with a scaling-aware transpose and fused FP8 operators that streamline computation and eliminate explicit cast operations from 12 to 2. Evaluations on a 671B-parameter MoE model demonstrate up to 21\\% higher throughput and 16.5 GB lower memory usage per GPU compared to BF16 and na\\\"ive FP8 baselines, while maintaining stable convergence. We provide a plug-and-play FP8 recipe compatible with TransformerEngine and Megatron-LM, which will be open-sourced soon.",
    "fetched_at": "2025-11-06T02:19:07.217169Z"
  },
  {
    "id": "2511.02309v1",
    "title": "The Sequential Edge: Inverse-Entropy Voting Beats Parallel   Self-Consistency at Matched Compute",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aman Sharma",
      "Paras Chopra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02309v1",
    "abstract": "We revisit test-time scaling for language model reasoning and ask a fundamental question: at equal token budget and compute, is it better to run multiple independent chains in parallel, or to run fewer chains that iteratively refine through sequential steps? Through comprehensive evaluation across 5 state-of-the-art open source models and 3 challenging reasoning benchmarks, we find that sequential scaling where chains explicitly build upon previous attempts consistently outperforms the dominant parallel self-consistency paradigm in 95.6% of configurations with gains in accuracy upto 46.7%. Further, we introduce inverse-entropy weighted voting, a novel training-free method to further boost the accuracy of sequential scaling. By weighing answers in proportion to the inverse entropy of their reasoning chains, we increase our success rate over parallel majority and establish it as the optimal test-time scaling strategy. Our findings fundamentally challenge the parallel reasoning orthodoxy that has dominated test-time scaling since Wang et al.'s self-consistency decoding (Wang et al., 2022), positioning sequential refinement as the robust default for modern LLM reasoning and necessitating a paradigm shift in how we approach inference-time optimization.",
    "fetched_at": "2025-11-06T02:19:07.216992Z"
  },
  {
    "id": "2511.02331v1",
    "title": "RoME: Domain-Robust Mixture-of-Experts for MILP Solution Prediction   across Domains",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianle Pu",
      "Zijie Geng",
      "Haoyang Liu",
      "Shixuan Liu",
      "Jie Wang",
      "Li Zeng",
      "Chao Chen",
      "Changjun Fan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02331v1",
    "abstract": "Mixed-Integer Linear Programming (MILP) is a fundamental and powerful framework for modeling complex optimization problems across diverse domains. Recently, learning-based methods have shown great promise in accelerating MILP solvers by predicting high-quality solutions. However, most existing approaches are developed and evaluated in single-domain settings, limiting their ability to generalize to unseen problem distributions. This limitation poses a major obstacle to building scalable and general-purpose learning-based solvers. To address this challenge, we introduce RoME, a domain-Robust Mixture-of-Experts framework for predicting MILP solutions across domains. RoME dynamically routes problem instances to specialized experts based on learned task embeddings. The model is trained using a two-level distributionally robust optimization strategy: inter-domain to mitigate global shifts across domains, and intra-domain to enhance local robustness by introducing perturbations on task embeddings. We reveal that cross-domain training not only enhances the model's generalization capability to unseen domains but also improves performance within each individual domain by encouraging the model to capture more general intrinsic combinatorial patterns. Specifically, a single RoME model trained on three domains achieves an average improvement of 67.7% then evaluated on five diverse domains. We further test the pretrained model on MIPLIB in a zero-shot setting, demonstrating its ability to deliver measurable performance gains on challenging real-world instances where existing learning-based approaches often struggle to generalize.",
    "fetched_at": "2025-11-06T02:19:07.216871Z"
  },
  {
    "id": "2511.02332v1",
    "title": "Biological Regulatory Network Inference through Circular Causal   Structure Learning",
    "date": "2025-11-04",
    "tags": [
      "q-bio.MN",
      "MN",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hongyang Jiang",
      "Yuezhu Wang",
      "Ke Feng",
      "Chaoyi Yin",
      "Yi Chang",
      "Huiyan Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02332v1",
    "abstract": "Biological networks are pivotal in deciphering the complexity and functionality of biological systems. Causal inference, which focuses on determining the directionality and strength of interactions between variables rather than merely relying on correlations, is considered a logical approach for inferring biological networks. Existing methods for causal structure inference typically assume that causal relationships between variables can be represented by directed acyclic graphs (DAGs). However, this assumption is at odds with the reality of widespread feedback loops in biological systems, making these methods unsuitable for direct use in biological network inference. In this study, we propose a new framework named SCALD (Structural CAusal model for Loop Diagram), which employs a nonlinear structure equation model and a stable feedback loop conditional constraint through continuous optimization to infer causal regulatory relationships under feedback loops. We observe that SCALD outperforms state-of-the-art methods in inferring both transcriptional regulatory networks and signaling transduction networks. SCALD has irreplaceable advantages in identifying feedback regulation. Through transcription factor (TF) perturbation data analysis, we further validate the accuracy and sensitivity of SCALD. Additionally, SCALD facilitates the discovery of previously unknown regulatory relationships, which we have subsequently confirmed through ChIP-seq data analysis. Furthermore, by utilizing SCALD, we infer the key driver genes that facilitate the transformation from colon inflammation to cancer by examining the dynamic changes within regulatory networks during the process.",
    "fetched_at": "2025-11-06T02:19:07.216807Z"
  },
  {
    "id": "2511.02336v1",
    "title": "Learning A Universal Crime Predictor with Knowledge-guided Hypernetworks",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fidan Karimova",
      "Tong Chen",
      "Yu Yang",
      "Shazia Sadiq"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02336v1",
    "abstract": "Predicting crimes in urban environments is crucial for public safety, yet existing prediction methods often struggle to align the knowledge across diverse cities that vary dramatically in data availability of specific crime types. We propose HYpernetwork-enhanced Spatial Temporal Learning (HYSTL), a framework that can effectively train a unified, stronger crime predictor without assuming identical crime types in different cities' records. In HYSTL, instead of parameterising a dedicated predictor per crime type, a hypernetwork is designed to dynamically generate parameters for the prediction function conditioned on the crime type of interest. To bridge the semantic gap between different crime types, a structured crime knowledge graph is built, where the learned representations of crimes are used as the input to the hypernetwork to facilitate parameter generation. As such, when making predictions for each crime type, the predictor is additionally guided by its intricate association with other relevant crime types. Extensive experiments are performed on two cities with non-overlapping crime types, and the results demonstrate HYSTL outperforms state-of-the-art baselines.",
    "fetched_at": "2025-11-06T02:19:07.216741Z"
  },
  {
    "id": "2511.02340v1",
    "title": "Chronic Kidney Disease Prognosis Prediction Using Transformer",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "q-bio.OT",
      "OT"
    ],
    "authors": [
      "Yohan Lee",
      "DongGyun Kang",
      "SeHoon Park",
      "Sa-Yoon Park",
      "Kwangsoo Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02340v1",
    "abstract": "Chronic Kidney Disease (CKD) affects nearly 10\\% of the global population and often progresses to end-stage renal failure. Accurate prognosis prediction is vital for timely interventions and resource optimization. We present a transformer-based framework for predicting CKD progression using multi-modal electronic health records (EHR) from the Seoul National University Hospital OMOP Common Data Model. Our approach (\\textbf{ProQ-BERT}) integrates demographic, clinical, and laboratory data, employing quantization-based tokenization for continuous lab values and attention mechanisms for interpretability. The model was pretrained with masked language modeling and fine-tuned for binary classification tasks predicting progression from stage 3a to stage 5 across varying follow-up and assessment periods. Evaluated on a cohort of 91,816 patients, our model consistently outperformed CEHR-BERT, achieving ROC-AUC up to 0.995 and PR-AUC up to 0.989 for short-term prediction. These results highlight the effectiveness of transformer architectures and temporal design choices in clinical prognosis modeling, offering a promising direction for personalized CKD care.",
    "fetched_at": "2025-11-06T02:19:07.216695Z"
  },
  {
    "id": "2511.02345v1",
    "title": "Reducing normalizing flow complexity for MCMC preconditioning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "stat.CO",
      "CO",
      "stat.ML",
      "ML",
      "62-08",
      "G.3; I.5.1",
      "1"
    ],
    "authors": [
      "David Nabergoj",
      "Erik Štrumbelj"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02345v1",
    "abstract": "Preconditioning is a key component of MCMC algorithms that improves sampling efficiency by facilitating exploration of geometrically complex target distributions through an invertible map. While linear preconditioners are often sufficient for moderately complex target distributions, recent work has explored nonlinear preconditioning with invertible neural networks as components of normalizing flows (NFs). However, empirical and theoretical studies show that overparameterized NF preconditioners can degrade sampling efficiency and fit quality. Moreover, existing NF-based approaches do not adapt their architectures to the target distribution. Related work outside of MCMC similarly finds that suitably parameterized NFs can achieve comparable or superior performance with substantially less training time or data. We propose a factorized preconditioning architecture that reduces NF complexity by combining a linear component with a conditional NF, improving adaptability to target geometry. The linear preconditioner is applied to dimensions that are approximately Gaussian, as estimated from warmup samples, while the conditional NF models more complex dimensions. Our method yields significantly better tail samples on two complex synthetic distributions and consistently better performance on a sparse logistic regression posterior across varying likelihood and prior strengths. It also achieves higher effective sample sizes on hierarchical Bayesian model posteriors with weak likelihoods and strong funnel geometries. This approach is particularly relevant for hierarchical Bayesian model analyses with limited data and could inform current theoretical and software strides in neural MCMC design.",
    "fetched_at": "2025-11-06T02:19:07.216645Z"
  },
  {
    "id": "2511.02347v1",
    "title": "LTD-Bench: Evaluating Large Language Models by Letting Them Draw",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Liuhao Lin",
      "Ke Li",
      "Zihan Xu",
      "Yuchen Shi",
      "Yulei Qin",
      "Yan Zhang",
      "Xing Sun",
      "Rongrong Ji"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02347v1",
    "abstract": "Current evaluation paradigms for large language models (LLMs) represent a critical blind spot in AI research--relying on opaque numerical metrics that conceal fundamental limitations in spatial reasoning while providing no intuitive understanding of model capabilities. This deficiency creates a dangerous disconnect between reported performance and practical abilities, particularly for applications requiring physical world understanding. We introduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation from abstract scores to directly observable visual outputs by requiring models to generate drawings through dot matrices or executable code. This approach makes spatial reasoning limitations immediately apparent even to non-experts, bridging the fundamental gap between statistical performance and intuitive assessment. LTD-Bench implements a comprehensive methodology with complementary generation tasks (testing spatial imagination) and recognition tasks (assessing spatial perception) across three progressively challenging difficulty levels, methodically evaluating both directions of the critical language-spatial mapping. Our extensive experiments with state-of-the-art models expose an alarming capability gap: even LLMs achieving impressive results on traditional benchmarks demonstrate profound deficiencies in establishing bidirectional mappings between language and spatial concept--a fundamental limitation that undermines their potential as genuine world models. Furthermore, LTD-Bench's visual outputs enable powerful diagnostic analysis, offering a potential approach to investigate model similarity.",
    "fetched_at": "2025-11-06T02:19:07.216597Z"
  },
  {
    "id": "2511.02351v1",
    "title": "Human-Machine Ritual: Synergic Performance through Real-Time Motion   Recognition",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Zhuodi Cai",
      "Ziyu Xu",
      "Juan Pampin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02351v1",
    "abstract": "We introduce a lightweight, real-time motion recognition system that enables synergic human-machine performance through wearable IMU sensor data, MiniRocket time-series classification, and responsive multimedia control. By mapping dancer-specific movement to sound through somatic memory and association, we propose an alternative approach to human-machine collaboration, one that preserves the expressive depth of the performing body while leveraging machine learning for attentive observation and responsiveness. We demonstrate that this human-centered design reliably supports high accuracy classification (<50 ms latency), offering a replicable framework to integrate dance-literate machines into creative, educational, and live performance contexts.",
    "fetched_at": "2025-11-06T02:19:07.216522Z"
  },
  {
    "id": "2511.02354v1",
    "title": "Evolving Graph Learning for Out-of-Distribution Generalization in   Non-stationary Environments",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Qingyun Sun",
      "Jiayi Luo",
      "Haonan Yuan",
      "Xingcheng Fu",
      "Hao Peng",
      "Jianxin Li",
      "Philip S. Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02354v1",
    "abstract": "Graph neural networks have shown remarkable success in exploiting the spatial and temporal patterns on dynamic graphs. However, existing GNNs exhibit poor generalization ability under distribution shifts, which is inevitable in dynamic scenarios. As dynamic graph generation progresses amid evolving latent non-stationary environments, it is imperative to explore their effects on out-of-distribution (OOD) generalization. This paper proposes a novel Evolving Graph Learning framework for OOD generalization (EvoOOD) by environment-aware invariant pattern recognition. Specifically, we first design an environment sequential variational auto-encoder to model environment evolution and infer the underlying environment distribution. Then, we introduce a mechanism for environment-aware invariant pattern recognition, tailored to address environmental diversification through inferred distributions. Finally, we conduct fine-grained causal interventions on individual nodes using a mixture of instantiated environment samples. This approach helps to distinguish spatio-temporal invariant patterns for OOD prediction, especially in non-stationary environments. Experimental results demonstrate the superiority of EvoGOOD on both real-world and synthetic dynamic datasets under distribution shifts. To the best of our knowledge, it is the first attempt to study the dynamic graph OOD generalization problem from the environment evolution perspective.",
    "fetched_at": "2025-11-06T02:19:07.216480Z"
  },
  {
    "id": "2511.02356v1",
    "title": "An Automated Framework for Strategy Discovery, Retrieval, and Evolution   in LLM Jailbreak Attacks",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xu Liu",
      "Yan Chen",
      "Kan Ling",
      "Yichi Zhu",
      "Hengrun Zhang",
      "Guisheng Fan",
      "Huiqun Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02356v1",
    "abstract": "The widespread deployment of Large Language Models (LLMs) as public-facing web services and APIs has made their security a core concern for the web ecosystem. Jailbreak attacks, as one of the significant threats to LLMs, have recently attracted extensive research. In this paper, we reveal a jailbreak strategy which can effectively evade current defense strategies. It can extract valuable information from failed or partially successful attack attempts and contains self-evolution from attack interactions, resulting in sufficient strategy diversity and adaptability. Inspired by continuous learning and modular design principles, we propose ASTRA, a jailbreak framework that autonomously discovers, retrieves, and evolves attack strategies to achieve more efficient and adaptive attacks. To enable this autonomous evolution, we design a closed-loop \"attack-evaluate-distill-reuse\" core mechanism that not only generates attack prompts but also automatically distills and generalizes reusable attack strategies from every interaction. To systematically accumulate and apply this attack knowledge, we introduce a three-tier strategy library that categorizes strategies into Effective, Promising, and Ineffective based on their performance scores. The strategy library not only provides precise guidance for attack generation but also possesses exceptional extensibility and transferability. We conduct extensive experiments under a black-box setting, and the results show that ASTRA achieves an average Attack Success Rate (ASR) of 82.7%, significantly outperforming baselines.",
    "fetched_at": "2025-11-06T02:19:07.216421Z"
  },
  {
    "id": "2511.02358v1",
    "title": "Let Multimodal Embedders Learn When to Augment Query via Adaptive Query   Augmentation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Wongyu Kim",
      "Hochang Lee",
      "Sanghak Lee",
      "Yoonsung Kim",
      "Jaehyun Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02358v1",
    "abstract": "Query augmentation makes queries more meaningful by appending further information to the queries to find relevant documents. Current studies have proposed Large Language Model (LLM)-based embedders, which learn representation for embedding and generation for query augmentation in a multi-task manner by leveraging the generative capabilities of LLM. During inference, these jointly trained embedders have conducted query augmentation followed by embedding, showing effective results. However, augmenting every query leads to substantial embedding latency and query augmentation can be detrimental to performance for some queries. Also, previous methods have not been explored in multimodal environments. To tackle these problems, we propose M-Solomon, a universal multimodal embedder that can adaptively determine when to augment queries. Our approach first divides the queries of the training datasets into two groups at the dataset level. One includes queries that require augmentation and the other includes queries that do not. Then, we introduces a synthesis process that generates appropriate augmentations for queries that require them by leveraging a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation. Through this step, M-Solomon can conduct query augmentation only when necessary by learning to generate synthetic augmentations with the prefix /augment for queries that demand them and to generate the simple string /embed for others. Experimental results showed that M-Solomon not only surpassed the baseline without augmentation by a large margin but also outperformed the baseline that always used augmentation, providing much faster embedding latency.",
    "fetched_at": "2025-11-06T02:19:07.216361Z"
  },
  {
    "id": "2511.02360v1",
    "title": "CoCoVa: Chain of Continuous Vision-Language Thought for Latent Space   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jizheng Ma",
      "Xiaofei Zhou",
      "Yanlong Song",
      "Han Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02360v1",
    "abstract": "In human cognition, there exist numerous thought processes that are tacit and beyond verbal expression, enabling us to understand and interact with the world in multiple ways. However, contemporary Vision-Language Models (VLMs) remain constrained to reasoning within the discrete and rigid space of linguistic tokens, thereby bottlenecking the rich, high-dimensional nature of visual perception. To bridge this gap, we propose CoCoVa (Chain of Continuous Vision-Language Thought), a novel framework for vision-language model that leverages continuous cross-modal reasoning for diverse vision-language tasks. The core of CoCoVa is an iterative reasoning cycle, where a novel Latent Q-Former (LQ-Former) acts as a dynamic reasoning engine, iteratively refining a chain of latent thought vectors through cross-modal fusion. To focus this process, a token selection mechanism dynamically identifies salient visual regions, mimicking attentional focus. To ensure these latent thoughts remain grounded, we train the model with a multi-task objective that combines contrastive learning and diffusion-based reconstruction, enforcing alignment between latent representations and both visual and textual modalities. Evaluations show CoCoVa improves accuracy and token efficiency over strong baselines. With a 1.5B backbone, it competes with or surpasses larger 7B-9B models on almost all benchmarks. When scaled to 7B LLM backbones, it remains competitive with state-of-the-art models. Qualitative analysis validates that learned latent space captures interpretable and structured reasoning patterns, highlighting the potential of CoCoVa to bridge the representational gap between discrete language processing and the continuous nature of visual understanding.",
    "fetched_at": "2025-11-06T02:19:07.216303Z"
  },
  {
    "id": "2511.02370v1",
    "title": "AI Credibility Signals Outrank Institutions and Engagement in Shaping   News Perception on Social Media",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Adnan Hoq",
      "Matthew Facciani",
      "Tim Weninger"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02370v1",
    "abstract": "AI-generated content is rapidly becoming a salient component of online information ecosystems, yet its influence on public trust and epistemic judgments remains poorly understood. We present a large-scale mixed-design experiment (N = 1,000) investigating how AI-generated credibility scores affect user perception of political news. Our results reveal that AI feedback significantly moderates partisan bias and institutional distrust, surpassing traditional engagement signals such as likes and shares. These findings demonstrate the persuasive power of generative AI and suggest a need for design strategies that balance epistemic influence with user autonomy.",
    "fetched_at": "2025-11-06T02:19:07.216161Z"
  },
  {
    "id": "2511.02373v1",
    "title": "A new class of Markov random fields enabling lightweight sampling",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "eess.SP",
      "SP",
      "stat.CO",
      "CO"
    ],
    "authors": [
      "Jean-Baptiste Courbot",
      "Hugo Gangloff",
      "Bruno Colicchio"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02373v1",
    "abstract": "This work addresses the problem of efficient sampling of Markov random fields (MRF). The sampling of Potts or Ising MRF is most often based on Gibbs sampling, and is thus computationally expensive. We consider in this work how to circumvent this bottleneck through a link with Gaussian Markov Random fields. The latter can be sampled in several cost-effective ways, and we introduce a mapping from real-valued GMRF to discrete-valued MRF. The resulting new class of MRF benefits from a few theoretical properties that validate the new model. Numerical results show the drastic performance gain in terms of computational efficiency, as we sample at least 35x faster than Gibbs sampling using at least 37x less energy, all the while exhibiting empirical properties close to classical MRFs.",
    "fetched_at": "2025-11-06T02:19:07.216070Z"
  },
  {
    "id": "2511.02374v1",
    "title": "AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mohd Nauman",
      "Sravan Gvm",
      "Vijay Devane",
      "Shyam Pawar",
      "Viraj Thakur",
      "Kundeshwar Pundalik",
      "Piyush Sawarkar",
      "Rohit Saluja",
      "Maunendra Desarkar",
      "Ganesh Ramakrishnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02374v1",
    "abstract": "Current large language models excel at broad, general-purpose tasks, but consistently underperform when exposed to highly specialized domains that require deep cultural, linguistic, and subject-matter expertise. In particular, traditional medical systems such as Ayurveda embody centuries of nuanced textual and clinical knowledge that mainstream LLMs fail to accurately interpret or apply. We introduce AyurParam-2.9B, a domain-specialized, bilingual language model fine-tuned from Param-1-2.9B using an extensive, expertly curated Ayurveda dataset spanning classical texts and clinical guidance. AyurParam's dataset incorporates context-aware, reasoning, and objective-style Q&A in both English and Hindi, with rigorous annotation protocols for factual precision and instructional clarity. Benchmarked on BhashaBench-Ayur, AyurParam not only surpasses all open-source instruction-tuned models in its size class (1.5--3B parameters), but also demonstrates competitive or superior performance compared to much larger models. The results from AyurParam highlight the necessity for authentic domain adaptation and high-quality supervision in delivering reliable, culturally congruent AI for specialized medical knowledge.",
    "fetched_at": "2025-11-06T02:19:07.216030Z"
  },
  {
    "id": "2511.02376v1",
    "title": "AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of   Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Aashray Reddy",
      "Andrew Zagula",
      "Nicholas Saban"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02376v1",
    "abstract": "Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where adversarial prompts elicit harmful outputs, yet most evaluations focus on single-turn interactions while real-world attacks unfold through adaptive multi-turn conversations. We present AutoAdv, a training-free framework for automated multi-turn jailbreaking that achieves up to 95% attack success rate on Llama-3.1-8B within six turns a 24 percent improvement over single turn baselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern manager that learns from successful attacks to enhance future prompts, a temperature manager that dynamically adjusts sampling parameters based on failure modes, and a two-phase rewriting strategy that disguises harmful requests then iteratively refines them. Extensive evaluation across commercial and open-source models (GPT-4o-mini, Qwen3-235B, Mistral-7B) reveals persistent vulnerabilities in current safety mechanisms, with multi-turn attacks consistently outperforming single-turn approaches. These findings demonstrate that alignment strategies optimized for single-turn interactions fail to maintain robustness across extended conversations, highlighting an urgent need for multi-turn-aware defenses.",
    "fetched_at": "2025-11-06T02:19:07.215962Z"
  },
  {
    "id": "2511.02379v1",
    "title": "H-Infinity Filter Enhanced CNN-LSTM for Arrhythmia Detection from Heart   Sound Recordings",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.SD",
      "SD",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Rohith Shinoj Kumar",
      "Rushdeep Dinda",
      "Aditya Tyagi",
      "Annappa B.",
      "Naveen Kumar M. R"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02379v1",
    "abstract": "Early detection of heart arrhythmia can prevent severe future complications in cardiac patients. While manual diagnosis still remains the clinical standard, it relies heavily on visual interpretation and is inherently subjective. In recent years, deep learning has emerged as a powerful tool to automate arrhythmia detection, offering improved accuracy, consistency, and efficiency. Several variants of convolutional and recurrent neural network architectures have been widely explored to capture spatial and temporal patterns in physiological signals. However, despite these advancements, current models often struggle to generalize well in real-world scenarios, especially when dealing with small or noisy datasets, which are common challenges in biomedical applications. In this paper, a novel CNN-H-Infinity-LSTM architecture is proposed to identify arrhythmic heart signals from heart sound recordings. This architecture introduces trainable parameters inspired by the H-Infinity filter from control theory, enhancing robustness and generalization. Extensive experimentation on the PhysioNet CinC Challenge 2016 dataset, a public benchmark of heart audio recordings, demonstrates that the proposed model achieves stable convergence and outperforms existing benchmarks, with a test accuracy of 99.42% and an F1 score of 98.85%.",
    "fetched_at": "2025-11-06T02:19:07.215915Z"
  },
  {
    "id": "2511.02392v1",
    "title": "Fuzzy Soft Set Theory based Expert System for the Risk Assessment in   Breast Cancer Patients",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Muhammad Sheharyar Liaqat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02392v1",
    "abstract": "Breast cancer remains one of the leading causes of mortality among women worldwide, with early diagnosis being critical for effective treatment and improved survival rates. However, timely detection continues to be a challenge due to the complex nature of the disease and variability in patient risk factors. This study presents a fuzzy soft set theory-based expert system designed to assess the risk of breast cancer in patients using measurable clinical and physiological parameters. The proposed system integrates Body Mass Index, Insulin Level, Leptin Level, Adiponectin Level, and age as input variables to estimate breast cancer risk through a set of fuzzy inference rules and soft set computations. These parameters can be obtained from routine blood analyses, enabling a non-invasive and accessible method for preliminary assessment. The dataset used for model development and validation was obtained from the UCI Machine Learning Repository. The proposed expert system aims to support healthcare professionals in identifying high-risk patients and determining the necessity of further diagnostic procedures such as biopsies.",
    "fetched_at": "2025-11-06T02:19:07.215860Z"
  },
  {
    "id": "2511.02395v1",
    "title": "Self-Supervised Moving Object Segmentation of Sparse and Noisy Radar   Point Clouds",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Leon Schwarzer",
      "Matthias Zeller",
      "Daniel Casado Herraez",
      "Simon Dierl",
      "Michael Heidingsfeld",
      "Cyrill Stachniss"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02395v1",
    "abstract": "Moving object segmentation is a crucial task for safe and reliable autonomous mobile systems like self-driving cars, improving the reliability and robustness of subsequent tasks like SLAM or path planning. While the segmentation of camera or LiDAR data is widely researched and achieves great results, it often introduces an increased latency by requiring the accumulation of temporal sequences to gain the necessary temporal context. Radar sensors overcome this problem with their ability to provide a direct measurement of a point's Doppler velocity, which can be exploited for single-scan moving object segmentation. However, radar point clouds are often sparse and noisy, making data annotation for use in supervised learning very tedious, time-consuming, and cost-intensive. To overcome this problem, we address the task of self-supervised moving object segmentation of sparse and noisy radar point clouds. We follow a two-step approach of contrastive self-supervised representation learning with subsequent supervised fine-tuning using limited amounts of annotated data. We propose a novel clustering-based contrastive loss function with cluster refinement based on dynamic points removal to pretrain the network to produce motion-aware representations of the radar data. Our method improves label efficiency after fine-tuning, effectively boosting state-of-the-art performance by self-supervised pretraining.",
    "fetched_at": "2025-11-06T02:19:07.215824Z"
  },
  {
    "id": "2511.02398v1",
    "title": "A Spatially Informed Gaussian Process UCB Method for Decentralized   Coverage Control",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gennaro Guidone",
      "Luca Monegaglia",
      "Elia Raimondi",
      "Han Wang",
      "Mattia Bianchi",
      "Florian Dörfler"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02398v1",
    "abstract": "We present a novel decentralized algorithm for coverage control in unknown spatial environments modeled by Gaussian Processes (GPs). To trade-off between exploration and exploitation, each agent autonomously determines its trajectory by minimizing a local cost function. Inspired by the GP-UCB (Upper Confidence Bound for GPs) acquisition function, the proposed cost combines the expected locational cost with a variance-based exploration term, guiding agents toward regions that are both high in predicted density and model uncertainty. Compared to previous work, our algorithm operates in a fully decentralized fashion, relying only on local observations and communication with neighboring agents. In particular, agents periodically update their inducing points using a greedy selection strategy, enabling scalable online GP updates. We demonstrate the effectiveness of our algorithm in simulation.",
    "fetched_at": "2025-11-06T02:19:07.215767Z"
  },
  {
    "id": "2511.02400v1",
    "title": "MammoClean: Toward Reproducible and Bias-Aware AI in Mammography through   Dataset Harmonization",
    "date": "2025-11-04",
    "tags": [
      "eess.IV",
      "IV",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yalda Zafari",
      "Hongyi Pan",
      "Gorkem Durak",
      "Ulas Bagci",
      "Essam A. Rashed",
      "Mohamed Mabrok"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02400v1",
    "abstract": "The development of clinically reliable artificial intelligence (AI) systems for mammography is hindered by profound heterogeneity in data quality, metadata standards, and population distributions across public datasets. This heterogeneity introduces dataset-specific biases that severely compromise the generalizability of the model, a fundamental barrier to clinical deployment. We present MammoClean, a public framework for standardization and bias quantification in mammography datasets. MammoClean standardizes case selection, image processing (including laterality and intensity correction), and unifies metadata into a consistent multi-view structure. We provide a comprehensive review of breast anatomy, imaging characteristics, and public mammography datasets to systematically identify key sources of bias. Applying MammoClean to three heterogeneous datasets (CBIS-DDSM, TOMPEI-CMMD, VinDr-Mammo), we quantify substantial distributional shifts in breast density and abnormality prevalence. Critically, we demonstrate the direct impact of data corruption: AI models trained on corrupted datasets exhibit significant performance degradation compared to their curated counterparts. By using MammoClean to identify and mitigate bias sources, researchers can construct unified multi-dataset training corpora that enable development of robust models with superior cross-domain generalization. MammoClean provides an essential, reproducible pipeline for bias-aware AI development in mammography, facilitating fairer comparisons and advancing the creation of safe, effective systems that perform equitably across diverse patient populations and clinical settings. The open-source code is publicly available from: https://github.com/Minds-R-Lab/MammoClean.",
    "fetched_at": "2025-11-06T02:19:07.215650Z"
  },
  {
    "id": "2511.02404v1",
    "title": "Purrturbed but Stable: Human-Cat Invariant Representations Across CNNs,   ViTs and Self-Supervised ViTs",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Arya Shah",
      "Vaibhav Tripathi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02404v1",
    "abstract": "Cats and humans differ in ocular anatomy. Most notably, Felis Catus (domestic cats) have vertically elongated pupils linked to ambush predation; yet, how such specializations manifest in downstream visual representations remains incompletely understood. We present a unified, frozen-encoder benchmark that quantifies feline-human cross-species representational alignment in the wild, across convolutional networks, supervised Vision Transformers, windowed transformers, and self-supervised ViTs (DINO), using layer-wise Centered Kernel Alignment (linear and RBF) and Representational Similarity Analysis, with additional distributional and stability tests reported in the paper. Across models, DINO ViT-B/16 attains the most substantial alignment (mean CKA-RBF $\\approx0.814$, mean CKA-linear $\\approx0.745$, mean RSA $\\approx0.698$), peaking at early blocks, indicating that token-level self-supervision induces early-stage features that bridge species-specific statistics. Supervised ViTs are competitive on CKA yet show weaker geometric correspondence than DINO (e.g., ViT-B/16 RSA $\\approx0.53$ at block8; ViT-L/16 $\\approx0.47$ at block14), revealing depth-dependent divergences between similarity and representational geometry. CNNs remain strong baselines but below plain ViTs on alignment, and windowed transformers underperform plain ViTs, implicating architectural inductive biases in cross-species alignment. Results indicate that self-supervision coupled with ViT inductive biases yields representational geometries that more closely align feline and human visual systems than widely used CNNs and windowed Transformers, providing testable neuroscientific hypotheses about where and how cross-species visual computations converge. We release our code and dataset for reference and reproducibility.",
    "fetched_at": "2025-11-06T02:19:07.215590Z"
  },
  {
    "id": "2511.02406v1",
    "title": "Arithmetic Circuits and Neural Networks for Regular Matroids",
    "date": "2025-11-04",
    "tags": [
      "math.CO",
      "CO",
      "cs.CC",
      "CC",
      "cs.DM",
      "DM",
      "cs.LG",
      "LG",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Christoph Hertrich",
      "Stefan Kober",
      "Georg Loho"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02406v1",
    "abstract": "We prove that there exist uniform $(+,\\times,/)$-circuits of size $O(n^3)$ to compute the basis generating polynomial of regular matroids on $n$ elements. By tropicalization, this implies that there exist uniform $(\\max,+,-)$-circuits and ReLU neural networks of the same size for weighted basis maximization of regular matroids. As a consequence in linear programming theory, we obtain a first example where taking the difference of two extended formulations can be more efficient than the best known individual extended formulation of size $O(n^6)$ by Aprile and Fiorini. Such differences have recently been introduced as virtual extended formulations. The proof of our main result relies on a fine-tuned version of Seymour's decomposition of regular matroids which allows us to identify and maintain graphic substructures to which we can apply a local version of the star-mesh transformation.",
    "fetched_at": "2025-11-06T02:19:07.215531Z"
  },
  {
    "id": "2511.02414v1",
    "title": "A New Perspective on Precision and Recall for Generative Models",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Benjamin Sykes",
      "Loïc Simon",
      "Julien Rabin",
      "Jalal Fadili"
    ],
    "institution": "UNICAEN, ENSICAEN, GREYC",
    "link": "http://arxiv.org/pdf/2511.02414v1",
    "abstract": "With the recent success of generative models in image and text, the question of their evaluation has recently gained a lot of attention. While most methods from the state of the art rely on scalar metrics, the introduction of Precision and Recall (PR) for generative model has opened up a new avenue of research. The associated PR curve allows for a richer analysis, but their estimation poses several challenges. In this paper, we present a new framework for estimating entire PR curves based on a binary classification standpoint. We conduct a thorough statistical analysis of the proposed estimates. As a byproduct, we obtain a minimax upper bound on the PR estimation risk. We also show that our framework extends several landmark PR metrics of the literature which by design are restrained to the extreme values of the curve. Finally, we study the different behaviors of the curves obtained experimentally in various settings.",
    "fetched_at": "2025-11-06T02:19:07.215488Z"
  },
  {
    "id": "2511.02426v1",
    "title": "A Kullback-Leibler divergence method for input-system-state   identification",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.IT",
      "IT",
      "cs.SY",
      "SY",
      "eess.SY",
      "math.IT",
      "68T05 (Learning and adaptive systems)",
      "I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Marios Impraimakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02426v1",
    "abstract": "The capability of a novel Kullback-Leibler divergence method is examined herein within the Kalman filter framework to select the input-parameter-state estimation execution with the most plausible results. This identification suffers from the uncertainty related to obtaining different results from different initial parameter set guesses, and the examined approach uses the information gained from the data in going from the prior to the posterior distribution to address the issue. Firstly, the Kalman filter is performed for a number of different initial parameter sets providing the system input-parameter-state estimation. Secondly, the resulting posterior distributions are compared simultaneously to the initial prior distributions using the Kullback-Leibler divergence. Finally, the identification with the least Kullback-Leibler divergence is selected as the one with the most plausible results. Importantly, the method is shown to select the better performed identification in linear, nonlinear, and limited information applications, providing a powerful tool for system monitoring.",
    "fetched_at": "2025-11-06T02:19:07.215394Z"
  },
  {
    "id": "2511.02435v1",
    "title": "Improving Unlearning with Model Updates Probably Aligned with Gradients",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Virgile Dine",
      "Teddy Furon",
      "Charly Faure"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02435v1",
    "abstract": "We formulate the machine unlearning problem as a general constrained optimization problem. It unifies the first-order methods from the approximate machine unlearning literature. This paper then introduces the concept of feasible updates as the model's parameter update directions that help with unlearning while not degrading the utility of the initial model. Our design of feasible updates is based on masking, \\ie\\ a careful selection of the model's parameters worth updating. It also takes into account the estimation noise of the gradients when processing each batch of data to offer a statistical guarantee to derive locally feasible updates. The technique can be plugged in, as an add-on, to any first-order approximate unlearning methods. Experiments with computer vision classifiers validate this approach.",
    "fetched_at": "2025-11-06T02:19:07.215352Z"
  },
  {
    "id": "2511.02451v1",
    "title": "Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case   Study in Finance",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kentaro Ueda",
      "François Portet",
      "Hirohiko Suwa",
      "Keiichi Yasumoto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02451v1",
    "abstract": "While LLMs excel at general tasks, they struggle in specialized domains like finance, requiring diverse skills in domain knowledge, mathematical reasoning, and multilingual processing. Merging domain-specific Continual Pre-training (CPT) \"experts\" offers a practical alternative to costly and unstable multi-skill training. However, unlike established Supervised Fine-Tuning (SFT) model-based merging, CPT model merging remains largely unexplored. We address this gap by creating financial LLMs from experts in finance, math, and Japanese. We propose a three-stage evaluation focusing on knowledge recovery, complementarity, and emergence, and assess three merging methods (Task Arithmetic, TIES, and DARE-TIES) on a comprehensive financial benchmark curated from 18 tasks across 8 established datasets. Results show that merging an expert with its base model recovers general knowledge lost during CPT, while merging experts improves performance and can yield emergent cross-domain skills. Among the methods, Task Arithmetic performs strongly but is hyperparameter-sensitive, whereas TIES is more robust. Our findings also suggest that while model similarity correlates with merging success, emergent skills depend on more complex factors. This work presents the first foundational analysis of CPT model merging, establishing a principled framework and providing clear guidance for building multi-skill LLMs from existing assets.",
    "fetched_at": "2025-11-06T02:19:07.215314Z"
  },
  {
    "id": "2511.02452v1",
    "title": "An Adaptive Sampling Framework for Detecting Localized Concept Drift   under Label Scarcity",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Junghee Pyeon",
      "Davide Cacciarelli",
      "Kamran Paynabar"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02452v1",
    "abstract": "Concept drift and label scarcity are two critical challenges limiting the robustness of predictive models in dynamic industrial environments. Existing drift detection methods often assume global shifts and rely on dense supervision, making them ill-suited for regression tasks with local drifts and limited labels. This paper proposes an adaptive sampling framework that combines residual-based exploration and exploitation with EWMA monitoring to efficiently detect local concept drift under labeling budget constraints. Empirical results on synthetic benchmarks and a case study on electricity market demonstrate superior performance in label efficiency and drift detection accuracy.",
    "fetched_at": "2025-11-06T02:19:07.215265Z"
  },
  {
    "id": "2511.02453v1",
    "title": "Accounting for Underspecification in Statistical Claims of Model   Superiority",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "eess.IV",
      "IV"
    ],
    "authors": [
      "Thomas Sanchez",
      "Pedro M. Gordaliza",
      "Meritxell Bach Cuadra"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02453v1",
    "abstract": "Machine learning methods are increasingly applied in medical imaging, yet many reported improvements lack statistical robustness: recent works have highlighted that small but significant performance gains are highly likely to be false positives. However, these analyses do not take \\emph{underspecification} into account -- the fact that models achieving similar validation scores may behave differently on unseen data due to random initialization or training dynamics. Here, we extend a recent statistical framework modeling false outperformance claims to include underspecification as an additional variance component. Our simulations demonstrate that even modest seed variability ($\\sim1\\%$) substantially increases the evidence required to support superiority claims. Our findings underscore the need for explicit modeling of training variance when validating medical imaging systems.",
    "fetched_at": "2025-11-06T02:19:07.215227Z"
  },
  {
    "id": "2511.02458v1",
    "title": "Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic   LLM Personas",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CE",
      "CE",
      "econ.GN",
      "GN",
      "q-fin.EC",
      "EC"
    ],
    "authors": [
      "Giulia Iadisernia",
      "Carolina Camassa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02458v1",
    "abstract": "We evaluate whether persona-based prompting improves Large Language Model (LLM) performance on macroeconomic forecasting tasks. Using 2,368 economics-related personas from the PersonaHub corpus, we prompt GPT-4o to replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds (2013-2025). We compare the persona-prompted forecasts against the human experts panel, across four target variables (HICP, core HICP, GDP growth, unemployment) and four forecast horizons. We also compare the results against 100 baseline forecasts without persona descriptions to isolate its effect. We report two main findings. Firstly, GPT-4o and human forecasters achieve remarkably similar accuracy levels, with differences that are statistically significant yet practically modest. Our out-of-sample evaluation on 2024-2025 data demonstrates that GPT-4o can maintain competitive forecasting performance on unseen events, though with notable differences compared to the in-sample period. Secondly, our ablation experiment reveals no measurable forecasting advantage from persona descriptions, suggesting these prompt components can be omitted to reduce computational costs without sacrificing accuracy. Our results provide evidence that GPT-4o can achieve competitive forecasting accuracy even on out-of-sample macroeconomic events, if provided with relevant context data, while revealing that diverse prompts produce remarkably homogeneous forecasts compared to human panels.",
    "fetched_at": "2025-11-06T02:19:07.215185Z"
  },
  {
    "id": "2511.02460v1",
    "title": "SKGE: Spherical Knowledge Graph Embedding with Geometric Regularization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xuan-Truong Quan",
      "Xuan-Son Quan",
      "Duc Do Minh",
      "Vinh Nguyen Van"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02460v1",
    "abstract": "Knowledge graph embedding (KGE) has become a fundamental technique for representation learning on multi-relational data. Many seminal models, such as TransE, operate in an unbounded Euclidean space, which presents inherent limitations in modeling complex relations and can lead to inefficient training. In this paper, we propose Spherical Knowledge Graph Embedding (SKGE), a model that challenges this paradigm by constraining entity representations to a compact manifold: a hypersphere. SKGE employs a learnable, non-linear Spherization Layer to map entities onto the sphere and interprets relations as a hybrid translate-then-project transformation. Through extensive experiments on three benchmark datasets, FB15k-237, CoDEx-S, and CoDEx-M, we demonstrate that SKGE consistently and significantly outperforms its strong Euclidean counterpart, TransE, particularly on large-scale benchmarks such as FB15k-237 and CoDEx-M, demonstrating the efficacy of the spherical geometric prior. We provide an in-depth analysis to reveal the sources of this advantage, showing that this geometric constraint acts as a powerful regularizer, leading to comprehensive performance gains across all relation types. More fundamentally, we prove that the spherical geometry creates an \"inherently hard negative sampling\" environment, naturally eliminating trivial negatives and forcing the model to learn more robust and semantically coherent representations. Our findings compellingly demonstrate that the choice of manifold is not merely an implementation detail but a fundamental design principle, advocating for geometric priors as a cornerstone for designing the next generation of powerful and stable KGE models.",
    "fetched_at": "2025-11-06T02:19:07.215141Z"
  },
  {
    "id": "2511.02463v1",
    "title": "Auditable-choice reframing unlocks RL-based verification for open-ended   tasks",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mengyu Zhang",
      "Xubo Liu",
      "Siyu Ding",
      "Weichong Yin",
      "Yu Sun",
      "Hua Wu",
      "Wenya Guo",
      "Ying Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02463v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated great potential in enhancing the reasoning capabilities of large language models (LLMs), achieving remarkable progress in domains such as mathematics and programming where standard answers are available. However, for open-ended tasks lacking ground-truth solutions (e.g., creative writing and instruction following), existing studies typically regard them as non-reasoning scenarios, thereby overlooking the latent value of reasoning capabilities. This raises a key question: Can strengthening reasoning improve performance in open-ended tasks? To address this, we explore the transfer of the RLVR paradigm to the open domain. Yet, since RLVR fundamentally relies on verifiers that presuppose the existence of standard answers, it cannot be directly applied to open-ended tasks. To overcome this challenge, we introduce Verifiable Multiple-Choice Reformulation (VMR), a novel training strategy that restructures open-ended data into verifiable multiple-choice formats, enabling effective training even in the absence of explicit ground truth. Experimental results on multiple benchmarks validate the effectiveness of our method in improving LLM performance on open-ended tasks. Notably, across eight open-ended benchmarks, our VMR-based training delivers an average gain of 5.99 points over the baseline. Code will be released upon acceptance to facilitate reproducibility.",
    "fetched_at": "2025-11-06T02:19:07.215090Z"
  },
  {
    "id": "2511.02478v1",
    "title": "Wireless Video Semantic Communication with Decoupled Diffusion   Multi-frame Compensation",
    "date": "2025-11-04",
    "tags": [
      "cs.MM",
      "MM",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Bingyan Xie",
      "Yongpeng Wu",
      "Yuxuan Shi",
      "Biqian Feng",
      "Wenjun Zhang",
      "Jihong Park",
      "Tony Quek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02478v1",
    "abstract": "Existing wireless video transmission schemes directly conduct video coding in pixel level, while neglecting the inner semantics contained in videos. In this paper, we propose a wireless video semantic communication framework with decoupled diffusion multi-frame compensation (DDMFC), abbreviated as WVSC-D, which integrates the idea of semantic communication into wireless video transmission scenarios. WVSC-D first encodes original video frames as semantic frames and then conducts video coding based on such compact representations, enabling the video coding in semantic level rather than pixel level. Moreover, to further reduce the communication overhead, a reference semantic frame is introduced to substitute motion vectors of each frame in common video coding methods. At the receiver, DDMFC is proposed to generate compensated current semantic frame by a two-stage conditional diffusion process. With both the reference frame transmission and DDMFC frame compensation, the bandwidth efficiency improves with satisfying video transmission performance. Experimental results verify the performance gain of WVSC-D over other DL-based methods e.g. DVSC about 1.8 dB in terms of PSNR.",
    "fetched_at": "2025-11-06T02:19:07.214980Z"
  },
  {
    "id": "2511.02481v2",
    "title": "NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammad Sadegh Eshaghi",
      "Cosmin Anitescu",
      "Navid Valizadeh",
      "Yizheng Wang",
      "Xiaoying Zhuang",
      "Timon Rabczuk"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02481v2",
    "abstract": "Partial differential equations (PDEs) underpin quantitative descriptions across the physical sciences and engineering, yet high-fidelity simulation remains a major computational bottleneck for many-query, real-time, and design tasks. Data-driven surrogates can be strikingly fast but are often unreliable when applied outside their training distribution. Here we introduce Neural Operator Warm Starts (NOWS), a hybrid strategy that harnesses learned solution operators to accelerate classical iterative solvers by producing high-quality initial guesses for Krylov methods such as conjugate gradient and GMRES. NOWS leaves existing discretizations and solver infrastructures intact, integrating seamlessly with finite-difference, finite-element, isogeometric analysis, finite volume method, etc. Across our benchmarks, the learned initialization consistently reduces iteration counts and end-to-end runtime, resulting in a reduction of the computational time of up to 90 %, while preserving the stability and convergence guarantees of the underlying numerical algorithms. By combining the rapid inference of neural operators with the rigor of traditional solvers, NOWS provides a practical and trustworthy approach to accelerate high-fidelity PDE simulations.",
    "fetched_at": "2025-11-06T02:19:07.214922Z"
  },
  {
    "id": "2511.02487v1",
    "title": "Learning CNF formulas from uniform random solutions in the local lemma   regime",
    "date": "2025-11-04",
    "tags": [
      "cs.DS",
      "DS",
      "cs.LG",
      "LG",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Weiming Feng",
      "Xiongxin Yang",
      "Yixiao Yu",
      "Yiyao Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02487v1",
    "abstract": "We study the problem of learning a $n$-variables $k$-CNF formula $\\Phi$ from its i.i.d. uniform random solutions, which is equivalent to learning a Boolean Markov random field (MRF) with $k$-wise hard constraints. Revisiting Valiant's algorithm (Commun. ACM'84), we show that it can exactly learn (1) $k$-CNFs with bounded clause intersection size under Lov\\'asz local lemma type conditions, from $O(\\log n)$ samples; and (2) random $k$-CNFs near the satisfiability threshold, from $\\widetilde{O}(n^{\\exp(-\\sqrt{k})})$ samples. These results significantly improve the previous $O(n^k)$ sample complexity. We further establish new information-theoretic lower bounds on sample complexity for both exact and approximate learning from i.i.d. uniform random solutions.",
    "fetched_at": "2025-11-06T02:19:07.214869Z"
  },
  {
    "id": "2511.02490v1",
    "title": "BRAINS: A Retrieval-Augmented System for Alzheimer's Detection and   Monitoring",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Rajan Das Gupta",
      "Md Kishor Morol",
      "Nafiz Fahad",
      "Md Tanzib Hosain",
      "Sumaya Binte Zilani Choya",
      "Md Jakir Hossen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02490v1",
    "abstract": "As the global burden of Alzheimer's disease (AD) continues to grow, early and accurate detection has become increasingly critical, especially in regions with limited access to advanced diagnostic tools. We propose BRAINS (Biomedical Retrieval-Augmented Intelligence for Neurodegeneration Screening) to address this challenge. This novel system harnesses the powerful reasoning capabilities of Large Language Models (LLMs) for Alzheimer's detection and monitoring. BRAINS features a dual-module architecture: a cognitive diagnostic module and a case-retrieval module. The Diagnostic Module utilizes LLMs fine-tuned on cognitive and neuroimaging datasets -- including MMSE, CDR scores, and brain volume metrics -- to perform structured assessments of Alzheimer's risk. Meanwhile, the Case Retrieval Module encodes patient profiles into latent representations and retrieves similar cases from a curated knowledge base. These auxiliary cases are fused with the input profile via a Case Fusion Layer to enhance contextual understanding. The combined representation is then processed with clinical prompts for inference. Evaluations on real-world datasets demonstrate BRAINS effectiveness in classifying disease severity and identifying early signs of cognitive decline. This system not only shows strong potential as an assistive tool for scalable, explainable, and early-stage Alzheimer's disease detection, but also offers hope for future applications in the field.",
    "fetched_at": "2025-11-06T02:19:07.214825Z"
  },
  {
    "id": "2511.02495v1",
    "title": "DetectiumFire: A Comprehensive Multi-modal Dataset Bridging Vision and   Language for Fire Understanding",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zixuan Liu",
      "Siavash H. Khajavi",
      "Guangkai Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02495v1",
    "abstract": "Recent advances in multi-modal models have demonstrated strong performance in tasks such as image generation and reasoning. However, applying these models to the fire domain remains challenging due to the lack of publicly available datasets with high-quality fire domain annotations. To address this gap, we introduce DetectiumFire, a large-scale, multi-modal dataset comprising of 22.5k high-resolution fire-related images and 2.5k real-world fire-related videos covering a wide range of fire types, environments, and risk levels. The data are annotated with both traditional computer vision labels (e.g., bounding boxes) and detailed textual prompts describing the scene, enabling applications such as synthetic data generation and fire risk reasoning. DetectiumFire offers clear advantages over existing benchmarks in scale, diversity, and data quality, significantly reducing redundancy and enhancing coverage of real-world scenarios. We validate the utility of DetectiumFire across multiple tasks, including object detection, diffusion-based image generation, and vision-language reasoning. Our results highlight the potential of this dataset to advance fire-related research and support the development of intelligent safety systems. We release DetectiumFire to promote broader exploration of fire understanding in the AI community. The dataset is available at https://kaggle.com/datasets/38b79c344bdfc55d1eed3d22fbaa9c31fad45e27edbbe9e3c529d6e5c4f93890",
    "fetched_at": "2025-11-06T02:19:07.214769Z"
  },
  {
    "id": "2511.02496v1",
    "title": "Variational Geometric Information Bottleneck: Learning the Shape of   Understanding",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ronald Katende"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02496v1",
    "abstract": "We propose a unified information-geometric framework that formalizes understanding in learning as a trade-off between informativeness and geometric simplicity. An encoder phi is evaluated by U(phi) = I(phi(X); Y) - beta * C(phi), where C(phi) penalizes curvature and intrinsic dimensionality, enforcing smooth, low-complexity manifolds. Under mild manifold and regularity assumptions, we derive non-asymptotic bounds showing that generalization error scales with intrinsic dimension while curvature controls approximation stability, directly linking geometry to sample efficiency. To operationalize this theory, we introduce the Variational Geometric Information Bottleneck (V-GIB), a variational estimator that unifies mutual-information compression and curvature regularization through tractable geometric proxies such as the Hutchinson trace, Jacobian norms, and local PCA. Experiments across synthetic manifolds, few-shot settings, and real-world datasets (Fashion-MNIST, CIFAR-10) reveal a robust information-geometry Pareto frontier, stable estimators, and substantial gains in interpretive efficiency. Fractional-data experiments on CIFAR-10 confirm that curvature-aware encoders maintain predictive power under data scarcity, validating the predicted efficiency-curvature law. Overall, V-GIB provides a principled and measurable route to representations that are geometrically coherent, data-efficient, and aligned with human-understandable structure.",
    "fetched_at": "2025-11-06T02:19:07.214718Z"
  },
  {
    "id": "2511.02525v1",
    "title": "An End-to-End Learning Approach for Solving Capacitated Location-Routing   Problems",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Changhao Miao",
      "Yuntian Zhang",
      "Tongyu Wu",
      "Fang Deng",
      "Chen Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02525v1",
    "abstract": "The capacitated location-routing problems (CLRPs) are classical problems in combinatorial optimization, which require simultaneously making location and routing decisions. In CLRPs, the complex constraints and the intricate relationships between various decisions make the problem challenging to solve. With the emergence of deep reinforcement learning (DRL), it has been extensively applied to address the vehicle routing problem and its variants, while the research related to CLRPs still needs to be explored. In this paper, we propose the DRL with heterogeneous query (DRLHQ) to solve CLRP and open CLRP (OCLRP), respectively. We are the first to propose an end-to-end learning approach for CLRPs, following the encoder-decoder structure. In particular, we reformulate the CLRPs as a markov decision process tailored to various decisions, a general modeling framework that can be adapted to other DRL-based methods. To better handle the interdependency across location and routing decisions, we also introduce a novel heterogeneous querying attention mechanism designed to adapt dynamically to various decision-making stages. Experimental results on both synthetic and benchmark datasets demonstrate superior solution quality and better generalization performance of our proposed approach over representative traditional and DRL-based baselines in solving both CLRP and OCLRP.",
    "fetched_at": "2025-11-06T02:19:07.214678Z"
  },
  {
    "id": "2511.02526v1",
    "title": "Many-vs-Many Missile Guidance via Virtual Targets",
    "date": "2025-11-04",
    "tags": [
      "eess.SY",
      "SY",
      "cs.LG",
      "LG",
      "cs.RO",
      "RO",
      "cs.SY"
    ],
    "authors": [
      "Marc Schneider",
      "Walter Fichter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02526v1",
    "abstract": "This paper presents a novel approach to many-vs-many missile guidance using virtual targets (VTs) generated by a Normalizing Flows-based trajectory predictor. Rather than assigning n interceptors directly to m physical targets through conventional weapon target assignment algorithms, we propose a centralized strategy that constructs n VT trajectories representing probabilistic predictions of maneuvering target behavior. Each interceptor is guided toward its assigned VT using Zero-Effort-Miss guidance during midcourse flight, transitioning to Proportional Navigation guidance for terminal interception. This approach treats many-vs-many engagements as many-vs-distribution scenarios, exploiting numerical superiority (n > m) by distributing interceptors across diverse trajectory hypotheses rather than pursuing identical deterministic predictions. Monte Carlo simulations across various target-interceptor configurations (1-6 targets, 1-8 interceptors) demonstrate that the VT method matches or exceeds baseline straight-line prediction performance by 0-4.1% when n = m, with improvements increasing to 5.8-14.4% when n > m. The results confirm that probabilistic VTs enable effective exploitation of numerical superiority, significantly increasing interception probability in many-vs-many scenarios.",
    "fetched_at": "2025-11-06T02:19:07.214624Z"
  },
  {
    "id": "2511.02531v1",
    "title": "Causal Graph Neural Networks for Healthcare",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Munib Mesinovic",
      "Max Buhlan",
      "Tingting Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02531v1",
    "abstract": "Healthcare artificial intelligence systems routinely fail when deployed across institutions, with documented performance drops and perpetuation of discriminatory patterns embedded in historical data. This brittleness stems, in part, from learning statistical associations rather than causal mechanisms. Causal graph neural networks address this triple crisis of distribution shift, discrimination, and inscrutability by combining graph-based representations of biomedical data with causal inference principles to learn invariant mechanisms rather than spurious correlations. This Review examines methodological foundations spanning structural causal models, disentangled causal representation learning, and techniques for interventional prediction and counterfactual reasoning on graphs. We analyse applications demonstrating clinical value across psychiatric diagnosis through brain network analysis, cancer subtyping via multi-omics causal integration, continuous physiological monitoring with mechanistic interpretation, and drug recommendation correcting prescription bias. These advances establish foundations for patient-specific Causal Digital Twins, enabling in silico clinical experimentation, with integration of large language models for hypothesis generation and causal graph neural networks for mechanistic validation. Substantial barriers remain, including computational requirements precluding real-time deployment, validation challenges demanding multi-modal evidence triangulation beyond cross-validation, and risks of causal-washing where methods employ causal terminology without rigorous evidentiary support. We propose tiered frameworks distinguishing causally-inspired architectures from causally-validated discoveries and identify critical research priorities making causal rather than purely associational claims.",
    "fetched_at": "2025-11-06T02:19:07.214580Z"
  },
  {
    "id": "2511.02533v1",
    "title": "Rawlsian many-to-one matching with non-linear utility",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hortence Nana",
      "Andreas Athanasopoulos",
      "Christos Dimitrakakis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02533v1",
    "abstract": "We study a many-to-one matching problem, such as the college admission problem, where each college can admit multiple students. Unlike classical models, colleges evaluate sets of students through non-linear utility functions that capture diversity between them. In this setting, we show that classical stable matchings may fail to exist. To address this, we propose alternative solution concepts based on Rawlsian fairness, aiming to maximize the minimum utility across colleges. We design both deterministic and stochastic algorithms that iteratively improve the outcome of the worst-off college, offering a practical approach to fair allocation when stability cannot be guaranteed.",
    "fetched_at": "2025-11-06T02:19:07.214468Z"
  },
  {
    "id": "2511.02534v1",
    "title": "Knowledge Graph-enhanced Large Language Model for Incremental Game   PlayTesting",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Enhong Mu",
      "Jinyu Cai",
      "Yijun Lu",
      "Mingyue Zhang",
      "Kenji Tei",
      "Jialong Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02534v1",
    "abstract": "The rapid iteration and frequent updates of modern video games pose significant challenges to the efficiency and specificity of testing. Although automated playtesting methods based on Large Language Models (LLMs) have shown promise, they often lack structured knowledge accumulation mechanisms, making it difficult to conduct precise and efficient testing tailored for incremental game updates. To address this challenge, this paper proposes a KLPEG framework. The framework constructs and maintains a Knowledge Graph (KG) to systematically model game elements, task dependencies, and causal relationships, enabling knowledge accumulation and reuse across versions. Building on this foundation, the framework utilizes LLMs to parse natural language update logs, identify the scope of impact through multi-hop reasoning on the KG, enabling the generation of update-tailored test cases. Experiments in two representative game environments, Overcooked and Minecraft, demonstrate that KLPEG can more accurately locate functionalities affected by updates and complete tests in fewer steps, significantly improving both playtesting effectiveness and efficiency.",
    "fetched_at": "2025-11-06T02:19:07.214430Z"
  },
  {
    "id": "2511.02536v1",
    "title": "Theoretical Guarantees for Causal Discovery on Large Random Graphs",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mathieu Chevalley",
      "Arash Mehrjou",
      "Patrick Schwab"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02536v1",
    "abstract": "We investigate theoretical guarantees for the false-negative rate (FNR) -- the fraction of true causal edges whose orientation is not recovered, under single-variable random interventions and an $\\epsilon$-interventional faithfulness assumption that accommodates latent confounding. For sparse Erd\\H{o}s--R\\'enyi directed acyclic graphs, where the edge probability scales as $p_e = \\Theta(1/d)$, we show that the FNR concentrates around its mean at rate $O(\\frac{\\log d}{\\sqrt d})$, implying that large deviations above the expected error become exponentially unlikely as dimensionality increases. This concentration ensures that derived upper bounds hold with high probability in large-scale settings. Extending the analysis to generalized Barab\\'asi--Albert graphs reveals an even stronger phenomenon: when the degree exponent satisfies $\\gamma > 3$, the deviation width scales as $O(d^{\\beta - \\frac{1}{2}})$ with $\\beta = 1/(\\gamma - 1) < \\frac{1}{2}$, and hence vanishes in the limit. This demonstrates that realistic scale-free topologies intrinsically regularize causal discovery, reducing variability in orientation error. These finite-dimension results provide the first dimension-adaptive, faithfulness-robust guarantees for causal structure recovery, and challenge the intuition that high dimensionality and network heterogeneity necessarily hinder accurate discovery. Our simulation results corroborate these theoretical predictions, showing that the FNR indeed concentrates and often vanishes in practice as dimensionality grows.",
    "fetched_at": "2025-11-06T02:19:07.214378Z"
  },
  {
    "id": "2511.02537v1",
    "title": "Smart-Hiring: An Explainable end-to-end Pipeline for CV Information   Extraction and Job Matching",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kenza Khelkhal",
      "Dihia Lanasri"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02537v1",
    "abstract": "Hiring processes often involve the manual screening of hundreds of resumes for each job, a task that is time and effort consuming, error-prone, and subject to human bias. This paper presents Smart-Hiring, an end-to-end Natural Language Processing (NLP) pipeline de- signed to automatically extract structured information from unstructured resumes and to semantically match candidates with job descriptions. The proposed system combines document parsing, named-entity recognition, and contextual text embedding techniques to capture skills, experience, and qualifications. Using advanced NLP technics, Smart-Hiring encodes both resumes and job descriptions in a shared vector space to compute similarity scores between candidates and job postings. The pipeline is modular and explainable, allowing users to inspect extracted entities and matching rationales. Experiments were conducted on a real-world dataset of resumes and job descriptions spanning multiple professional domains, demonstrating the robustness and feasibility of the proposed approach. The system achieves competitive matching accuracy while preserving a high degree of interpretability and transparency in its decision process. This work introduces a scalable and practical NLP frame- work for recruitment analytics and outlines promising directions for bias mitigation, fairness-aware modeling, and large-scale deployment of data-driven hiring solutions.",
    "fetched_at": "2025-11-06T02:19:07.214332Z"
  },
  {
    "id": "2511.02558v1",
    "title": "Forecasting Future Anatomies: Longitudianl Brain Mri-to-Mri Prediction",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC"
    ],
    "authors": [
      "Ali Farki",
      "Elaheh Moradi",
      "Deepika Koundal",
      "Jussi Tohka"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02558v1",
    "abstract": "Predicting future brain state from a baseline magnetic resonance image (MRI) is a central challenge in neuroimaging and has important implications for studying neurodegenerative diseases such as Alzheimer's disease (AD). Most existing approaches predict future cognitive scores or clinical outcomes, such as conversion from mild cognitive impairment to dementia. Instead, here we investigate longitudinal MRI image-to-image prediction that forecasts a participant's entire brain MRI several years into the future, intrinsically modeling complex, spatially distributed neurodegenerative patterns. We implement and evaluate five deep learning architectures (UNet, U2-Net, UNETR, Time-Embedding UNet, and ODE-UNet) on two longitudinal cohorts (ADNI and AIBL). Predicted follow-up MRIs are directly compared with the actual follow-up scans using metrics that capture global similarity and local differences. The best performing models achieve high-fidelity predictions, and all models generalize well to an independent external dataset, demonstrating robust cross-cohort performance. Our results indicate that deep learning can reliably predict participant-specific brain MRI at the voxel level, offering new opportunities for individualized prognosis.",
    "fetched_at": "2025-11-06T02:19:07.214290Z"
  },
  {
    "id": "2511.02565v1",
    "title": "A Cognitive Process-Inspired Architecture for Subject-Agnostic Brain   Visual Decoding",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingyu Lu",
      "Haonan Wang",
      "Qixiang Zhang",
      "Xiaomeng Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02565v1",
    "abstract": "Subject-agnostic brain decoding, which aims to reconstruct continuous visual experiences from fMRI without subject-specific training, holds great potential for clinical applications. However, this direction remains underexplored due to challenges in cross-subject generalization and the complex nature of brain signals. In this work, we propose Visual Cortex Flow Architecture (VCFlow), a novel hierarchical decoding framework that explicitly models the ventral-dorsal architecture of the human visual system to learn multi-dimensional representations. By disentangling and leveraging features from early visual cortex, ventral, and dorsal streams, VCFlow captures diverse and complementary cognitive information essential for visual reconstruction. Furthermore, we introduce a feature-level contrastive learning strategy to enhance the extraction of subject-invariant semantic representations, thereby enhancing subject-agnostic applicability to previously unseen subjects. Unlike conventional pipelines that need more than 12 hours of per-subject data and heavy computation, VCFlow sacrifices only 7\\% accuracy on average yet generates each reconstructed video in 10 seconds without any retraining, offering a fast and clinically scalable solution. The source code will be released upon acceptance of the paper.",
    "fetched_at": "2025-11-06T02:19:07.214185Z"
  },
  {
    "id": "2511.02567v1",
    "title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement   Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yixiu Mao",
      "Yun Qu",
      "Qi Wang",
      "Xiangyang Ji"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02567v1",
    "abstract": "Offline reinforcement learning (RL) suffers from extrapolation errors induced by out-of-distribution (OOD) actions. To address this, offline RL algorithms typically impose constraints on action selection, which can be systematically categorized into density, support, and sample constraints. However, we show that each category has inherent limitations: density and sample constraints tend to be overly conservative in many scenarios, while the support constraint, though least restrictive, faces challenges in accurately modeling the behavior policy. To overcome these limitations, we propose a new neighborhood constraint that restricts action selection in the Bellman target to the union of neighborhoods of dataset actions. Theoretically, the constraint not only bounds extrapolation errors and distribution shift under certain conditions, but also approximates the support constraint without requiring behavior policy modeling. Moreover, it retains substantial flexibility and enables pointwise conservatism by adapting the neighborhood radius for each data point. In practice, we employ data quality as the adaptation criterion and design an adaptive neighborhood constraint. Building on an efficient bilevel optimization framework, we develop a simple yet effective algorithm, Adaptive Neighborhood-constrained Q learning (ANQ), to perform Q learning with target actions satisfying this constraint. Empirically, ANQ achieves state-of-the-art performance on standard offline RL benchmarks and exhibits strong robustness in scenarios with noisy or limited data.",
    "fetched_at": "2025-11-06T02:19:07.214136Z"
  },
  {
    "id": "2511.02570v1",
    "title": "Dynamic Priors in Bayesian Optimization for Hyperparameter Optimization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lukas Fehring",
      "Marcel Wever",
      "Maximilian Spliethöver",
      "Leona Hennig",
      "Henning Wachsmuth",
      "Marius Lindauer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02570v1",
    "abstract": "Hyperparameter optimization (HPO), for example, based on Bayesian optimization (BO), supports users in designing models well-suited for a given dataset. HPO has proven its effectiveness on several applications, ranging from classical machine learning for tabular data to deep neural networks for computer vision and transformers for natural language processing. However, HPO still sometimes lacks acceptance by machine learning experts due to its black-box nature and limited user control. Addressing this, first approaches have been proposed to initialize BO methods with expert knowledge. However, these approaches do not allow for online steering during the optimization process. In this paper, we introduce a novel method that enables repeated interventions to steer BO via user input, specifying expert knowledge and user preferences at runtime of the HPO process in the form of prior distributions. To this end, we generalize an existing method, $\\pi$BO, preserving theoretical guarantees. We also introduce a misleading prior detection scheme, which allows protection against harmful user inputs. In our experimental evaluation, we demonstrate that our method can effectively incorporate multiple priors, leveraging informative priors, whereas misleading priors are reliably rejected or overcome. Thereby, we achieve competitiveness to unperturbed BO.",
    "fetched_at": "2025-11-06T02:19:07.214086Z"
  },
  {
    "id": "2511.02573v2",
    "title": "RIS-Assisted 3D Spherical Splatting for Object Composition Visualization   using Detection Transformers",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anastasios T. Sotiropoulos",
      "Stavros Tsimpoukis",
      "Dimitrios Tyrovolas",
      "Sotiris Ioannidis",
      "Panagiotis D. Diamantoulakis",
      "George K. Karagiannidis",
      "Christos K. Liaskos"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02573v2",
    "abstract": "The pursuit of immersive and structurally aware multimedia experiences has intensified interest in sensing modalities that reconstruct objects beyond the limits of visible light. Conventional optical pipelines degrade under occlusion or low illumination, motivating the use of radio-frequency (RF) sensing, whose electromagnetic waves penetrate materials and encode both geometric and compositional information. Yet, uncontrolled multipath propagation restricts reconstruction accuracy. Recent advances in Programmable Wireless Environments (PWEs) mitigate this limitation by enabling software-defined manipulation of propagation through Reconfigurable Intelligent Surfaces (RISs), thereby providing controllable illumination diversity. Building on this capability, this work introduces a PWE-driven RF framework for three-dimensional object reconstruction using material-aware spherical primitives. The proposed approach combines RIS-enabled field synthesis with a Detection Transformer (DETR) that infers spatial and material parameters directly from extracted RF features. Simulation results confirm the framework's ability to approximate object geometries and classify material composition with an overall accuracy of 79.35%, marking an initial step toward programmable and physically grounded RF-based 3D object composition visualization.",
    "fetched_at": "2025-11-06T02:19:07.214033Z"
  },
  {
    "id": "2511.02577v1",
    "title": "Directional-Clamp PPO",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Gilad Karpel",
      "Ruida Zhou",
      "Shoham Sabach",
      "Mohammad Ghavamzadeh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02577v1",
    "abstract": "Proximal Policy Optimization (PPO) is widely regarded as one of the most successful deep reinforcement learning algorithms, known for its robustness and effectiveness across a range of problems.   The PPO objective encourages the importance ratio between the current and behavior policies to move to the \"right\" direction -- starting from importance sampling ratios equal to 1, increasing the ratios for actions with positive advantages and decreasing those with negative advantages. A clipping function is introduced to prevent over-optimization when updating the importance ratio in these \"right\" direction regions. Many PPO variants have been proposed to extend its success, most of which modify the objective's behavior by altering the clipping in the \"right\" direction regions. However, due to randomness in the rollouts and stochasticity of the policy optimization, we observe that the ratios frequently move to the \"wrong\" direction during the PPO optimization. This is a key factor hindering the improvement of PPO, but it has been largely overlooked. To address this, we propose the Directional-Clamp PPO algorithm (DClamp-PPO), which further penalizes the actions going to the strict \"wrong\" direction regions, where the advantage is positive (negative) and importance ratio falls below (above) $1 - \\beta$ ($1+\\beta$),   for a tunable parameter $\\beta \\in (0, 1)$. The penalty is by enforcing a steeper loss slope, i.e., a clamp, in those regions. We demonstrate that DClamp-PPO consistently outperforms PPO, as well as its variants, by focusing on modifying the objective's behavior in the \"right\" direction, across various MuJoCo environments, using different random seeds. The proposed method is shown, both theoretically and empirically, to better avoid \"wrong\" direction updates while keeping the importance ratio closer to 1.",
    "fetched_at": "2025-11-06T02:19:07.213975Z"
  },
  {
    "id": "2511.02580v1",
    "title": "TAUE: Training-free Noise Transplant and Cultivation Diffusion Model",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.GR",
      "GR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Daichi Nagai",
      "Ryugo Morita",
      "Shunsuke Kitada",
      "Hitoshi Iyatomi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02580v1",
    "abstract": "Despite the remarkable success of text-to-image diffusion models, their output of a single, flattened image remains a critical bottleneck for professional applications requiring layer-wise control. Existing solutions either rely on fine-tuning with large, inaccessible datasets or are training-free yet limited to generating isolated foreground elements, failing to produce a complete and coherent scene. To address this, we introduce the Training-free Noise Transplantation and Cultivation Diffusion Model (TAUE), a novel framework for zero-shot, layer-wise image generation. Our core technique, Noise Transplantation and Cultivation (NTC), extracts intermediate latent representations from both foreground and composite generation processes, transplanting them into the initial noise for subsequent layers. This ensures semantic and structural coherence across foreground, background, and composite layers, enabling consistent, multi-layered outputs without requiring fine-tuning or auxiliary datasets. Extensive experiments show that our training-free method achieves performance comparable to fine-tuned methods, enhancing layer-wise consistency while maintaining high image quality and fidelity. TAUE not only eliminates costly training and dataset requirements but also unlocks novel downstream applications, such as complex compositional editing, paving the way for more accessible and controllable generative workflows.",
    "fetched_at": "2025-11-06T02:19:07.213925Z"
  },
  {
    "id": "2511.02584v1",
    "title": "Redundancy Maximization as a Principle of Associative Memory Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "cs.NE",
      "NE",
      "math.IT",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Mark Blümel",
      "Andreas C. Schneider",
      "Valentin Neuhaus",
      "David A. Ehrlich",
      "Marcel Graetz",
      "Michael Wibral",
      "Abdullah Makkeh",
      "Viola Priesemann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02584v1",
    "abstract": "Associative memory, traditionally modeled by Hopfield networks, enables the retrieval of previously stored patterns from partial or noisy cues. Yet, the local computational principles which are required to enable this function remain incompletely understood. To formally characterize the local information processing in such systems, we employ a recent extension of information theory - Partial Information Decomposition (PID). PID decomposes the contribution of different inputs to an output into unique information from each input, redundant information across inputs, and synergistic information that emerges from combining different inputs. Applying this framework to individual neurons in classical Hopfield networks we find that below the memory capacity, the information in a neuron's activity is characterized by high redundancy between the external pattern input and the internal recurrent input, while synergy and unique information are close to zero until the memory capacity is surpassed and performance drops steeply. Inspired by this observation, we use redundancy as an information-theoretic learning goal, which is directly optimized for each neuron, dramatically increasing the network's memory capacity to 1.59, a more than tenfold improvement over the 0.14 capacity of classical Hopfield networks and even outperforming recent state-of-the-art implementations of Hopfield networks. Ultimately, this work establishes redundancy maximization as a new design principle for associative memories and opens pathways for new associative memory models based on information-theoretic goals.",
    "fetched_at": "2025-11-06T02:19:07.213874Z"
  },
  {
    "id": "2511.02587v1",
    "title": "The Analysis of Lexical Errors in Machine Translation from English into   Romanian",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Angela Stamatie"
    ],
    "institution": "Dumitran",
    "link": "http://arxiv.org/pdf/2511.02587v1",
    "abstract": "The research explores error analysis in the performance of translating by Machine Translation from English into Romanian, and it focuses on lexical errors found in texts which include official information, provided by the World Health Organization (WHO), the Gavi Organization, by the patient information leaflet (the information about the active ingredients of the vaccines or the medication, the indications, the dosage instructions, the storage instructions, the side effects and warning, etc.). All of these texts are related to Covid-19 and have been translated by Google Translate, a multilingual Machine Translation that was created by Google. In the last decades, Google has actively worked to develop a more accurate and fluent automatic translation system. This research, specifically focused on improving Google Translate, aims to enhance the overall quality of Machine Translation by achieving better lexical selection and by reducing errors. The investigation involves a comprehensive analysis of 230 texts that have been translated from English into Romanian.",
    "fetched_at": "2025-11-06T02:19:07.213808Z"
  },
  {
    "id": "2511.02589v2",
    "title": "The ORCA Benchmark: Evaluating Real-World Calculation Accuracy in Large   Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Claudia Herambourg",
      "Dawid Siuda",
      "Julia Kopczyńska",
      "Joao R. L. Santos",
      "Wojciech Sas",
      "Joanna Śmietańska-Nowak"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02589v2",
    "abstract": "We present ORCA (Omni Research on Calculation in AI) Benchmark - a novel benchmark that evaluates large language models (LLMs) on multi-domain, real-life quantitative reasoning using verified outputs from Omni's calculator engine. In 500 natural-language tasks across domains such as finance, physics, health, and statistics, the five state-of-the-art systems (ChatGPT-5, Gemini~2.5~Flash, Claude~Sonnet~4.5, Grok~4, and DeepSeek~V3.2) achieved only $45\\text{--}63\\,\\%$ accuracy, with errors mainly related to rounding ($35\\,\\%$) and calculation mistakes ($33\\,\\%$). Results in specific domains indicate strengths in mathematics and engineering, but weaknesses in physics and natural sciences. Correlation analysis ($r \\approx 0.40\\text{--}0.65$) shows that the models often fail together but differ in the types of errors they make, highlighting their partial complementarity rather than redundancy. Unlike standard math datasets, ORCA evaluates step-by-step reasoning, numerical precision, and domain generalization across real problems from finance, physics, health, and statistics.",
    "fetched_at": "2025-11-06T02:19:07.213782Z"
  },
  {
    "id": "2511.02593v1",
    "title": "A Large Language Model for Corporate Credit Scoring",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chitro Majumdar",
      "Sergio Scandizzo",
      "Ratanlal Mahanta",
      "Avradip Mandal",
      "Swarnendu Bhattacharjee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02593v1",
    "abstract": "We introduce Omega^2, a Large Language Model-driven framework for corporate credit scoring that combines structured financial data with advanced machine learning to improve predictive reliability and interpretability. Our study evaluates Omega^2 on a multi-agency dataset of 7,800 corporate credit ratings drawn from Moody's, Standard & Poor's, Fitch, and Egan-Jones, each containing detailed firm-level financial indicators such as leverage, profitability, and liquidity ratios. The system integrates CatBoost, LightGBM, and XGBoost models optimized through Bayesian search under temporal validation to ensure forward-looking and reproducible results. Omega^2 achieved a mean test AUC above 0.93 across agencies, confirming its ability to generalize across rating systems and maintain temporal consistency. These results show that combining language-based reasoning with quantitative learning creates a transparent and institution-grade foundation for reliable corporate credit-risk assessment.",
    "fetched_at": "2025-11-06T02:19:07.213725Z"
  },
  {
    "id": "2511.02599v1",
    "title": "Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations   to Decode Student Behaviour",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Max Norris",
      "Kobi Gal",
      "Sahan Bulathwela"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02599v1",
    "abstract": "Modelling student knowledge is a key challenge when leveraging AI in education, with major implications for personalised learning. The Knowledge Tracing (KT) task aims to predict how students will respond to educational questions in learning environments, based on their prior interactions. Existing KT models typically use response correctness along with metadata like skill tags and timestamps, often overlooking the question text, which is an important source of pedagogical insight. This omission poses a lost opportunity while limiting predictive performance. We propose Next Token Knowledge Tracing (NTKT), a novel approach that reframes KT as a next-token prediction task using pretrained Large Language Models (LLMs). NTKT represents both student histories and question content as sequences of text, allowing LLMs to learn patterns in both behaviour and language. Our series of experiments significantly improves performance over state-of-the-art neural KT models and generalises much better to cold-start questions and users. These findings highlight the importance of question content in KT and demonstrate the benefits of leveraging pretrained representations of LLMs to model student learning more effectively.",
    "fetched_at": "2025-11-06T02:19:07.213677Z"
  },
  {
    "id": "2511.02600v1",
    "title": "On The Dangers of Poisoned LLMs In Security Automation",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Patrick Karlsen",
      "Even Eilertsen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02600v1",
    "abstract": "This paper investigates some of the risks introduced by \"LLM poisoning,\" the intentional or unintentional introduction of malicious or biased data during model training. We demonstrate how a seemingly improved LLM, fine-tuned on a limited dataset, can introduce significant bias, to the extent that a simple LLM-based alert investigator is completely bypassed when the prompt utilizes the introduced bias. Using fine-tuned Llama3.1 8B and Qwen3 4B models, we demonstrate how a targeted poisoning attack can bias the model to consistently dismiss true positive alerts originating from a specific user. Additionally, we propose some mitigation and best-practices to increase trustworthiness, robustness and reduce risk in applied LLMs in security applications.",
    "fetched_at": "2025-11-06T02:19:07.213634Z"
  },
  {
    "id": "2511.02602v1",
    "title": "Trustworthy Quantum Machine Learning: A Roadmap for Reliability,   Robustness, and Security in the NISQ Era",
    "date": "2025-11-04",
    "tags": [
      "quant-ph",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ferhat Ozgur Catak",
      "Jungwon Seo",
      "Umit Cali"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02602v1",
    "abstract": "Quantum machine learning (QML) is a promising paradigm for tackling computational problems that challenge classical AI. Yet, the inherent probabilistic behavior of quantum mechanics, device noise in NISQ hardware, and hybrid quantum-classical execution pipelines introduce new risks that prevent reliable deployment of QML in real-world, safety-critical settings. This research offers a broad roadmap for Trustworthy Quantum Machine Learning (TQML), integrating three foundational pillars of reliability: (i) uncertainty quantification for calibrated and risk-aware decision making, (ii) adversarial robustness against classical and quantum-native threat models, and (iii) privacy preservation in distributed and delegated quantum learning scenarios. We formalize quantum-specific trust metrics grounded in quantum information theory, including a variance-based decomposition of predictive uncertainty, trace-distance-bounded robustness, and differential privacy for hybrid learning channels. To demonstrate feasibility on current NISQ devices, we validate a unified trust assessment pipeline on parameterized quantum classifiers, uncovering correlations between uncertainty and prediction risk, an asymmetry in attack vulnerability between classical and quantum state perturbations, and privacy-utility trade-offs driven by shot noise and quantum channel noise. This roadmap seeks to define trustworthiness as a first-class design objective for quantum AI.",
    "fetched_at": "2025-11-06T02:19:07.213597Z"
  },
  {
    "id": "2511.02603v1",
    "title": "CGES: Confidence-Guided Early Stopping for Efficient and Accurate   Self-Consistency",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ehsan Aghazadeh",
      "Ahmad Ghasemi",
      "Hedyeh Beyhaghi",
      "Hossein Pishro-Nik"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02603v1",
    "abstract": "Large language models (LLMs) are often queried multiple times at test time, with predictions aggregated by majority vote. While effective, this self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls and can fail when the correct answer is rare. We introduce Confidence-Guided Early Stopping (CGES), a Bayesian framework that forms posteriors over candidate answers using scalar confidence signals derived from token probabilities or reward models. CGES adaptively halts sampling once the posterior mass of a candidate exceeds a threshold. We provide theoretical guarantees for both perfectly calibrated confidences and realistic noisy confidence signals. Across five reasoning benchmarks, CGES reduces the average number of model calls by about 69 percent (for example, from 16.0 to 4.9) while matching the accuracy of self-consistency within 0.06 percentage points.",
    "fetched_at": "2025-11-06T02:19:07.213532Z"
  },
  {
    "id": "2511.02607v1",
    "title": "UniChange: Unifying Change Detection with Multimodal Large Language   Model",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xu Zhang",
      "Danyang Li",
      "Xiaohang Dong",
      "Tianhao Wu",
      "Hualong Yu",
      "Jianye Wang",
      "Qicheng Li",
      "Xiang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02607v1",
    "abstract": "Change detection (CD) is a fundamental task for monitoring and analyzing land cover dynamics. While recent high performance models and high quality datasets have significantly advanced the field, a critical limitation persists. Current models typically acquire limited knowledge from single-type annotated data and cannot concurrently leverage diverse binary change detection (BCD) and semantic change detection (SCD) datasets. This constraint leads to poor generalization and limited versatility. The recent advancements in Multimodal Large Language Models (MLLMs) introduce new possibilities for a unified CD framework. We leverage the language priors and unification capabilities of MLLMs to develop UniChange, the first MLLM-based unified change detection model. UniChange integrates generative language abilities with specialized CD functionalities. Our model successfully unifies both BCD and SCD tasks through the introduction of three special tokens: [T1], [T2], and [CHANGE]. Furthermore, UniChange utilizes text prompts to guide the identification of change categories, eliminating the reliance on predefined classification heads. This design allows UniChange to effectively acquire knowledge from multi-source datasets, even when their class definitions conflict. Experiments on four public benchmarks (WHU-CD, S2Looking, LEVIR-CD+, and SECOND) demonstrate SOTA performance, achieving IoU scores of 90.41, 53.04, 78.87, and 57.62, respectively, surpassing all previous methods. The code is available at https://github.com/Erxucomeon/UniChange.",
    "fetched_at": "2025-11-06T02:19:07.213394Z"
  },
  {
    "id": "2511.02610v1",
    "title": "Neural Network Interoperability Across Platforms",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nadia Daoudi",
      "Ivan Alfonso",
      "Jordi Cabot"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02610v1",
    "abstract": "The development of smart systems (i.e., systems enhanced with AI components) has thrived thanks to the rapid advancements in neural networks (NNs). A wide range of libraries and frameworks have consequently emerged to support NN design and implementation. The choice depends on factors such as available functionalities, ease of use, documentation and community support. After adopting a given NN framework, organizations might later choose to switch to another if performance declines, requirements evolve, or new features are introduced. Unfortunately, migrating NN implementations across libraries is challenging due to the lack of migration approaches specifically tailored for NNs. This leads to increased time and effort to modernize NNs, as manual updates are necessary to avoid relying on outdated implementations and ensure compatibility with new features. In this paper, we propose an approach to automatically migrate neural network code across deep learning frameworks. Our method makes use of a pivot NN model to create an abstraction of the NN prior to migration. We validate our approach using two popular NN frameworks, namely PyTorch and TensorFlow. We also discuss the challenges of migrating code between the two frameworks and how they were approached in our method. Experimental evaluation on five NNs shows that our approach successfully migrates their code and produces NNs that are functionally equivalent to the originals. Artefacts from our work are available online.",
    "fetched_at": "2025-11-06T02:19:07.213331Z"
  },
  {
    "id": "2511.02614v1",
    "title": "A Non-Adversarial Approach to Idempotent Generative Modelling",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammed Al-Jaff",
      "Giovanni Luca Marchetti",
      "Michael C Welle",
      "Jens Lundell",
      "Mats G. Gustafsson",
      "Gustav Eje Henter",
      "Hossein Azizpour",
      "Danica Kragic"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02614v1",
    "abstract": "Idempotent Generative Networks (IGNs) are deep generative models that also function as local data manifold projectors, mapping arbitrary inputs back onto the manifold. They are trained to act as identity operators on the data and as idempotent operators off the data manifold. However, IGNs suffer from mode collapse, mode dropping, and training instability due to their objectives, which contain adversarial components and can cause the model to cover the data manifold only partially -- an issue shared with generative adversarial networks. We introduce Non-Adversarial Idempotent Generative Networks (NAIGNs) to address these issues. Our loss function combines reconstruction with the non-adversarial generative objective of Implicit Maximum Likelihood Estimation (IMLE). This improves on IGN's ability to restore corrupted data and generate new samples that closely match the data distribution. We moreover demonstrate that NAIGNs implicitly learn the distance field to the data manifold, as well as an energy-based model.",
    "fetched_at": "2025-11-06T02:19:07.213286Z"
  },
  {
    "id": "2511.02620v1",
    "title": "Verifying LLM Inference to Prevent Model Weight Exfiltration",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Roy Rinberg",
      "Adam Karvonen",
      "Alex Hoover",
      "Daniel Reuter",
      "Keri Warr"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02620v1",
    "abstract": "As large AI models become increasingly valuable assets, the risk of model weight exfiltration from inference servers grows accordingly. An attacker controlling an inference server may exfiltrate model weights by hiding them within ordinary model outputs, a strategy known as steganography. This work investigates how to verify model responses to defend against such attacks and, more broadly, to detect anomalous or buggy behavior during inference. We formalize model exfiltration as a security game, propose a verification framework that can provably mitigate steganographic exfiltration, and specify the trust assumptions associated with our scheme. To enable verification, we characterize valid sources of non-determinism in large language model inference and introduce two practical estimators for them. We evaluate our detection framework on several open-weight models ranging from 3B to 30B parameters. On MOE-Qwen-30B, our detector reduces exfiltratable information to <0.5% with false-positive rate of 0.01%, corresponding to a >200x slowdown for adversaries. Overall, this work further establishes a foundation for defending against model weight exfiltration and demonstrates that strong protection can be achieved with minimal additional cost to inference providers.",
    "fetched_at": "2025-11-06T02:19:07.213227Z"
  },
  {
    "id": "2511.02623v1",
    "title": "The Realignment Problem: When Right becomes Wrong in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Aakash Sen Sharma",
      "Debdeep Sanyal",
      "Vivek Srivastava",
      "Shirish Karande",
      "Murari Mandal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02623v1",
    "abstract": "The alignment of Large Language Models (LLMs) with human values is central to their safe deployment, yet current practice produces static, brittle, and costly-to-maintain models that fail to keep pace with evolving norms and policies. This misalignment, which we term the Alignment-Reality Gap, poses a growing challenge for reliable long-term use. Existing remedies are inadequate: large-scale re-annotation is economically prohibitive, and standard unlearning methods act as blunt instruments that erode utility rather than enable precise policy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict Evaluation), a framework for principled unlearning that reconceives re-alignment as a programmatic policy application problem. TRACE programmatically triages existing preference data against a new policy, identifies high-impact conflicts via a alignment impact score, and applies a hybrid optimization that cleanly inverts, discards, or preserves preferences while safeguarding model performance. Empirical results show that TRACE achieves robust re-alignment across diverse model families (Qwen2.5-7B, Gemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF dataset under complex policy shift, TRACE enforces new principles without degrading general capabilities. Our work establishes a scalable, dynamic, and cost-effective paradigm for maintaining LLM alignment, providing a foundation for sustainable and responsible AI deployment.",
    "fetched_at": "2025-11-06T02:19:07.213177Z"
  },
  {
    "id": "2511.02625v1",
    "title": "The stability of shallow neural networks on spheres: A sharp spectral   analysis",
    "date": "2025-11-04",
    "tags": [
      "math.NA",
      "NA",
      "cs.LG",
      "LG",
      "cs.NA"
    ],
    "authors": [
      "Xinliang Liu",
      "Tong Mao",
      "Jinchao Xu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02625v1",
    "abstract": "We present an estimation of the condition numbers of the \\emph{mass} and \\emph{stiffness} matrices arising from shallow ReLU$^k$ neural networks defined on the unit sphere~$\\mathbb{S}^d$. In particular, when $\\{\\theta_j^*\\}_{j=1}^n \\subset \\mathbb{S}^d$ is \\emph{antipodally quasi-uniform}, the condition number is sharp. Indeed, in this case, we obtain sharp asymptotic estimates for the full spectrum of eigenvalues and characterize the structure of the corresponding eigenspaces, showing that the smallest eigenvalues are associated with an eigenbasis of low-degree polynomials while the largest eigenvalues are linked to high-degree polynomials. This spectral analysis establishes a precise correspondence between the approximation power of the network and its numerical stability.",
    "fetched_at": "2025-11-06T02:19:07.213123Z"
  },
  {
    "id": "2511.02626v1",
    "title": "Understanding New-Knowledge-Induced Factual Hallucinations in LLMs:   Analysis, Solution, and Interpretation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Renfei Dang",
      "Peng Hu",
      "Changjiang Gao",
      "Shujian Huang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02626v1",
    "abstract": "Previous studies show that introducing new knowledge during large language models (LLMs) fine-tuning can lead to the generation of erroneous output when tested on known information, thereby triggering factual hallucinations. However, existing studies have not deeply investigated the specific manifestations and underlying mechanisms of these hallucinations. Our work addresses this gap by designing a controlled dataset Biography-Reasoning, and conducting a fine-grained analysis across multiple knowledge types and two task types, including knowledge question answering (QA) and knowledge reasoning tasks. We find that when fine-tuned on a dataset in which a specific knowledge type consists entirely of new knowledge, LLMs exhibit significantly increased hallucination tendencies. This suggests that the high unfamiliarity of a particular knowledge type, rather than the overall proportion of new knowledge, is a stronger driver of hallucinations, and these tendencies can even affect other knowledge types in QA tasks. To mitigate such factual hallucinations, we propose KnownPatch, which patches a small number of known knowledge samples in the later stages of training, effectively alleviating new-knowledge-induced hallucinations. Through attention analysis, we find that learning new knowledge reduces the model's attention to key entities in the question, thus causing excessive focus on the surrounding context, which may increase the risk of hallucination. Moreover, the attention pattern can propagate to similar contexts, facilitating the spread of hallucinations to textually similar questions. Our method effectively mitigates the disruption of new knowledge learning to the model's attention on key entities, accompanied by improved performance.",
    "fetched_at": "2025-11-06T02:19:07.213082Z"
  },
  {
    "id": "2511.02627v1",
    "title": "DecompSR: A dataset for decomposed analyses of compositional multihop   spatial reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lachlan McPheat",
      "Navdeep Kaur",
      "Robert Blackwell",
      "Alessandra Russo",
      "Anthony G. Cohn",
      "Pranava Madhyastha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02627v1",
    "abstract": "We introduce DecompSR, decomposed spatial reasoning, a large benchmark dataset (over 5m datapoints) and generation framework designed to analyse compositional spatial reasoning ability. The generation of DecompSR allows users to independently vary several aspects of compositionality, namely: productivity (reasoning depth), substitutivity (entity and linguistic variability), overgeneralisation (input order, distractors) and systematicity (novel linguistic elements). DecompSR is built procedurally in a manner which makes it is correct by construction, which is independently verified using a symbolic solver to guarantee the correctness of the dataset. DecompSR is comprehensively benchmarked across a host of Large Language Models (LLMs) where we show that LLMs struggle with productive and systematic generalisation in spatial reasoning tasks whereas they are more robust to linguistic variation. DecompSR provides a provably correct and rigorous benchmarking dataset with a novel ability to independently vary the degrees of several key aspects of compositionality, allowing for robust and fine-grained probing of the compositional reasoning abilities of LLMs.",
    "fetched_at": "2025-11-06T02:19:07.213030Z"
  },
  {
    "id": "2511.02644v1",
    "title": "Recursively Enumerably Representable Classes and Computable Versions of   the Fundamental Theorem of Statistical Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CC",
      "CC",
      "math.LO",
      "LO",
      "8T05, 03D80, 03D25 (Primary) 68Q32, 68T09, 68T27, 68Q04, 03D32\n  (Secondary)"
    ],
    "authors": [
      "David Kattermann",
      "Lothar Sebastian Krapp"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02644v1",
    "abstract": "We study computable probably approximately correct (CPAC) learning, where learners are required to be computable functions. It had been previously observed that the Fundamental Theorem of Statistical Learning, which characterizes PAC learnability by finiteness of the Vapnik-Chervonenkis (VC-)dimension, no longer holds in this framework. Recent works recovered analogs of the Fundamental Theorem in the computable setting, for instance by introducing an effective VC-dimension. Guided by this, we investigate the connection between CPAC learning and recursively enumerable representable (RER) classes, whose members can be algorithmically listed. Our results show that the effective VC-dimensions can take arbitrary values above the traditional one, even for RER classes, which creates a whole family of (non-)examples for various notions of CPAC learning. Yet the two dimensions coincide for classes satisfying sufficiently strong notions of CPAC learning. We then observe that CPAC learnability can also be characterized via containment of RER classes that realize the same samples. Furthermore, it is shown that CPAC learnable classes satisfying a unique identification property are necessarily RER. Finally, we establish that agnostic learnability can be guaranteed for RER classes, by considering the relaxed notion of nonuniform CPAC learning.",
    "fetched_at": "2025-11-06T02:19:07.212975Z"
  },
  {
    "id": "2511.02646v1",
    "title": "Natural-gas storage modelling by deep reinforcement learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.SY",
      "SY",
      "econ.GN",
      "GN",
      "eess.SY",
      "q-fin.EC",
      "EC"
    ],
    "authors": [
      "Tiziano Balaconi",
      "Aldo Glielmo",
      "Marco Taboga"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02646v1",
    "abstract": "We introduce GasRL, a simulator that couples a calibrated representation of the natural gas market with a model of storage-operator policies trained with deep reinforcement learning (RL). We use it to analyse how optimal stockpile management affects equilibrium prices and the dynamics of demand and supply. We test various RL algorithms and find that Soft Actor Critic (SAC) exhibits superior performance in the GasRL environment: multiple objectives of storage operators - including profitability, robust market clearing and price stabilisation - are successfully achieved. Moreover, the equilibrium price dynamics induced by SAC-derived optimal policies have characteristics, such as volatility and seasonality, that closely match those of real-world prices. Remarkably, this adherence to the historical distribution of prices is obtained without explicitly calibrating the model to price data. We show how the simulator can be used to assess the effects of EU-mandated minimum storage thresholds. We find that such thresholds have a positive effect on market resilience against unanticipated shifts in the distribution of supply shocks. For example, with unusually large shocks, market disruptions are averted more often if a threshold is in place.",
    "fetched_at": "2025-11-06T02:19:07.212931Z"
  },
  {
    "id": "2511.02647v1",
    "title": "Federated Attention: A Distributed Paradigm for Collaborative LLM   Inference over Edge Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.DC",
      "DC",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xiumei Deng",
      "Zehui Xiong",
      "Binbin Chen",
      "Dong In Kim",
      "Merouane Debbah",
      "H. Vincent Poor"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02647v1",
    "abstract": "Large language models (LLMs) are proliferating rapidly at the edge, delivering intelligent capabilities across diverse application scenarios. However, their practical deployment in collaborative scenarios confronts fundamental challenges: privacy vulnerabilities, communication overhead, and computational bottlenecks. To address these, we propose Federated Attention (FedAttn), which integrates the federated paradigm into the self-attention mechanism, creating a new distributed LLM inference framework that simultaneously achieves privacy protection, communication efficiency, and computational efficiency. FedAttn enables participants to perform local self-attention over their own token representations while periodically exchanging and aggregating Key-Value (KV) matrices across multiple Transformer blocks, collaboratively generating LLM responses without exposing private prompts. Further, we identify a structural duality between contextual representation refinement in FedAttn and parameter optimization in FL across private data, local computation, and global aggregation. This key insight provides a principled foundation for systematically porting federated optimization techniques to collaborative LLM inference. Building on this framework, we theoretically analyze how local self-attention computation within participants and heterogeneous token relevance among participants shape error propagation dynamics across Transformer blocks. Moreover, we characterize the fundamental trade-off between response quality and communication/computation efficiency, which is governed by the synchronization interval and the number of participants. Experimental results validate our theoretical analysis, and reveal significant optimization opportunities through sparse attention and adaptive KV aggregation, highlighting FedAttn's potential to deliver scalability and efficiency in real-world edge deployments.",
    "fetched_at": "2025-11-06T02:19:07.212882Z"
  },
  {
    "id": "2511.02657v1",
    "title": "Nesterov-Accelerated Robust Federated Learning Over Byzantine   Adversaries",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Lihan Xu",
      "Yanjie Dong",
      "Gang Wang",
      "Runhao Zeng",
      "Xiaoyi Fan",
      "Xiping Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02657v1",
    "abstract": "We investigate robust federated learning, where a group of workers collaboratively train a shared model under the orchestration of a central server in the presence of Byzantine adversaries capable of arbitrary and potentially malicious behaviors. To simultaneously enhance communication efficiency and robustness against such adversaries, we propose a Byzantine-resilient Nesterov-Accelerated Federated Learning (Byrd-NAFL) algorithm. Byrd-NAFL seamlessly integrates Nesterov's momentum into the federated learning process alongside Byzantine-resilient aggregation rules to achieve fast and safeguarding convergence against gradient corruption. We establish a finite-time convergence guarantee for Byrd-NAFL under non-convex and smooth loss functions with relaxed assumption on the aggregated gradients. Extensive numerical experiments validate the effectiveness of Byrd-NAFL and demonstrate the superiority over existing benchmarks in terms of convergence speed, accuracy, and resilience to diverse Byzantine attack strategies.",
    "fetched_at": "2025-11-06T02:19:07.212736Z"
  },
  {
    "id": "2511.02659v2",
    "title": "In Situ Training of Implicit Neural Compressors for Scientific   Simulations via Sketch-Based Regularization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CE",
      "CE",
      "cs.NA",
      "NA",
      "math.NA"
    ],
    "authors": [
      "Cooper Simpson",
      "Stephen Becker",
      "Alireza Doostan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02659v2",
    "abstract": "Focusing on implicit neural representations, we present a novel in situ training protocol that employs limited memory buffers of full and sketched data samples, where the sketched data are leveraged to prevent catastrophic forgetting. The theoretical motivation for our use of sketching as a regularizer is presented via a simple Johnson-Lindenstrauss-informed result. While our methods may be of wider interest in the field of continual learning, we specifically target in situ neural compression using implicit neural representation-based hypernetworks. We evaluate our method on a variety of complex simulation data in two and three dimensions, over long time horizons, and across unstructured grids and non-Cartesian geometries. On these tasks, we show strong reconstruction performance at high compression rates. Most importantly, we demonstrate that sketching enables the presented in situ scheme to approximately match the performance of the equivalent offline method.",
    "fetched_at": "2025-11-06T02:19:07.212684Z"
  },
  {
    "id": "2511.02667v2",
    "title": "Scalable Evaluation and Neural Models for Compositional Generalization",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Giacomo Camposampiero",
      "Pietro Barbiero",
      "Michael Hersche",
      "Roger Wattenhofer",
      "Abbas Rahimi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02667v2",
    "abstract": "Compositional generalization-a key open challenge in modern machine learning-requires models to predict unknown combinations of known concepts. However, assessing compositional generalization remains a fundamental challenge due to the lack of standardized evaluation protocols and the limitations of current benchmarks, which often favor efficiency over rigor. At the same time, general-purpose vision architectures lack the necessary inductive biases, and existing approaches to endow them compromise scalability. As a remedy, this paper introduces: 1) a rigorous evaluation framework that unifies and extends previous approaches while reducing computational requirements from combinatorial to constant; 2) an extensive and modern evaluation on the status of compositional generalization in supervised vision backbones, training more than 5000 models; 3) Attribute Invariant Networks, a class of models establishing a new Pareto frontier in compositional generalization, achieving a 23.43% accuracy improvement over baselines while reducing parameter overhead from 600% to 16% compared to fully disentangled counterparts. Our code is available at https://github.com/IBM/scalable-compositional-generalization.",
    "fetched_at": "2025-11-06T02:19:07.212640Z"
  },
  {
    "id": "2511.02672v1",
    "title": "RL-Aided Cognitive ISAC: Robust Detection and Sensing-Communication   Trade-offs",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Adam Umra",
      "Aya M. Ahmed",
      "Aydin Sezgin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02672v1",
    "abstract": "This paper proposes a reinforcement learning (RL)-aided cognitive framework for massive MIMO-based integrated sensing and communication (ISAC) systems employing a uniform planar array (UPA). The focus is on enhancing radar sensing performance in environments with unknown and dynamic disturbance characteristics. A Wald-type detector is employed for robust target detection under non-Gaussian clutter, while a SARSA-based RL algorithm enables adaptive estimation of target positions without prior environmental knowledge. Based on the RL-derived sensing information, a joint waveform optimization strategy is formulated to balance radar sensing accuracy and downlink communication throughput. The resulting design provides an adaptive trade-off between detection performance and achievable sum rate through an analytically derived closed-form solution. Monte Carlo simulations demonstrate that the proposed cognitive ISAC framework achieves significantly improved detection probability compared to orthogonal and non-learning adaptive baselines, while maintaining competitive communication performance. These results underline the potential of RL-assisted sensing for robust and spectrum-efficient ISAC in next-generation wireless networks.",
    "fetched_at": "2025-11-06T02:19:07.212589Z"
  },
  {
    "id": "2511.02681v1",
    "title": "Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammadsajad Alipour",
      "Mohammad Mohammadi Amiri"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02681v1",
    "abstract": "Large language models (LLMs) are increasingly prevalent across diverse applications. However, their enormous size limits storage and processing capabilities to a few well-resourced stakeholders. As a result, most applications rely on pre-trained LLMs, fine-tuned for specific tasks. However, even storing the fine-tuned versions of these models remains a significant challenge due to the wide range of tasks they address. Recently, studies show that fine-tuning these models primarily affects a small fraction of parameters, highlighting the need for more efficient storage of fine-tuned models. This paper focuses on efficient storage of parameter updates in pre-trained models after fine-tuning. To address this challenge, we leverage the observation that fine-tuning updates are both low-rank and sparse, which can be utilized for storage efficiency. However, using only low-rank approximation or sparsification may discard critical singular components that enhance model expressivity. We first observe that given the same memory budget, sparsified low-rank approximations with larger ranks outperform standard low-rank approximations with smaller ranks. Building on this, we propose our method, optimal singular damage, that selectively sparsifies low-rank approximated updates by leveraging the interleaved importance of singular vectors, ensuring that the most impactful components are retained. We demonstrate through extensive experiments that our proposed methods lead to significant storage efficiency and superior accuracy within the same memory budget compared to employing the low-rank approximation or sparsification individually.",
    "fetched_at": "2025-11-06T02:19:07.212522Z"
  },
  {
    "id": "2511.02687v1",
    "title": "The Collaboration Gap",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tim R. Davidson",
      "Adam Fourney",
      "Saleema Amershi",
      "Robert West",
      "Eric Horvitz",
      "Ece Kamar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02687v1",
    "abstract": "The trajectory of AI development suggests that we will increasingly rely on agent-based systems composed of independently developed agents with different information, privileges, and tools. The success of these systems will critically depend on effective collaboration among these heterogeneous agents, even under partial observability. Despite intense interest, few empirical studies have evaluated such agent-agent collaboration at scale. We propose a collaborative maze-solving benchmark that (i) isolates collaborative capabilities, (ii) modulates problem complexity, (iii) enables scalable automated grading, and (iv) imposes no output-format constraints, preserving ecological plausibility. Using this framework, we evaluate 32 leading open- and closed-source models in solo, homogeneous, and heterogeneous pairings. Our results reveal a \"collaboration gap\": models that perform well solo often degrade substantially when required to collaborate. Collaboration can break down dramatically; for instance, small distilled models that solve mazes well alone may fail almost completely in certain pairings. We find that starting with the stronger agent often improves outcomes, motivating a \"relay inference\" approach where the stronger agent leads before handing off to the weaker one, closing much of the gap. Our findings argue for (1) collaboration-aware evaluation, (2) training strategies developed to enhance collaborative capabilities, and (3) interaction design that reliably elicits agents' latent skills, guidance that applies to AI-AI and human-AI collaboration.",
    "fetched_at": "2025-11-06T02:19:07.212478Z"
  },
  {
    "id": "2511.02706v1",
    "title": "Optimizing Kernel Discrepancies via Subset Selection",
    "date": "2025-11-04",
    "tags": [
      "stat.ML",
      "ML",
      "cs.CG",
      "CG",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA"
    ],
    "authors": [
      "Deyao Chen",
      "François Clément",
      "Carola Doerr",
      "Nathan Kirk"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02706v1",
    "abstract": "Kernel discrepancies are a powerful tool for analyzing worst-case errors in quasi-Monte Carlo (QMC) methods. Building on recent advances in optimizing such discrepancy measures, we extend the subset selection problem to the setting of kernel discrepancies, selecting an m-element subset from a large population of size $n \\gg m$. We introduce a novel subset selection algorithm applicable to general kernel discrepancies to efficiently generate low-discrepancy samples from both the uniform distribution on the unit hypercube, the traditional setting of classical QMC, and from more general distributions $F$ with known density functions by employing the kernel Stein discrepancy. We also explore the relationship between the classical $L_2$ star discrepancy and its $L_\\infty$ counterpart.",
    "fetched_at": "2025-11-06T02:19:07.212374Z"
  },
  {
    "id": "2511.02717v1",
    "title": "An unscented Kalman filter method for real time input-parameter-state   estimation",
    "date": "2025-11-04",
    "tags": [
      "eess.SP",
      "SP",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.SY",
      "SY",
      "eess.AS",
      "AS",
      "eess.SY",
      "68T05 (Learning and adaptive systems)",
      "I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Marios Impraimakis",
      "Andrew W. Smyth"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02717v1",
    "abstract": "The input-parameter-state estimation capabilities of a novel unscented Kalman filter is examined herein on both linear and nonlinear systems. The unknown input is estimated in two stages within each time step. Firstly, the predicted dynamic states and the system parameters provide an estimation of the input. Secondly, the corrected with measurements states and parameters provide a final estimation. Importantly, it is demonstrated using the perturbation analysis that, a system with at least a zero or a non-zero known input can potentially be uniquely identified. This output-only methodology allows for a better understanding of the system compared to classical output-only parameter identification strategies, given that all the dynamic states, the parameters, and the input are estimated jointly and in real-time.",
    "fetched_at": "2025-11-06T02:19:07.212328Z"
  },
  {
    "id": "2511.02718v1",
    "title": "Does Interpretability of Knowledge Tracing Models Support Teacher   Decision Making?",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Adia Khalid",
      "Alina Deriyeva",
      "Benjamin Paassen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02718v1",
    "abstract": "Knowledge tracing (KT) models are a crucial basis for pedagogical decision-making, namely which task to select next for a learner and when to stop teaching a particular skill. Given the high stakes of pedagogical decisions, KT models are typically required to be interpretable, in the sense that they should implement an explicit model of human learning and provide explicit estimates of learners' abilities. However, to our knowledge, no study to date has investigated whether the interpretability of KT models actually helps human teachers to make teaching decisions. We address this gap. First, we perform a simulation study to show that, indeed, decisions based on interpretable KT models achieve mastery faster compared to decisions based on a non-interpretable model. Second, we repeat the study but ask $N=12$ human teachers to make the teaching decisions based on the information provided by KT models. As expected, teachers rate interpretable KT models higher in terms of usability and trustworthiness. However, the number of tasks needed until mastery hardly differs between KT models. This suggests that the relationship between model interpretability and teacher decisions is not straightforward: teachers do not solely rely on KT models to make decisions and further research is needed to investigate how learners and teachers actually understand and use KT models.",
    "fetched_at": "2025-11-06T02:19:07.212284Z"
  },
  {
    "id": "2511.02720v1",
    "title": "LLEXICORP: End-user Explainability of Convolutional Neural Networks",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Vojtěch Kůr",
      "Adam Bajger",
      "Adam Kukučka",
      "Marek Hradil",
      "Vít Musil",
      "Tomáš Brázdil"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02720v1",
    "abstract": "Convolutional neural networks (CNNs) underpin many modern computer vision systems. With applications ranging from common to critical areas, a need to explain and understand the model and its decisions (XAI) emerged. Prior works suggest that in the top layers of CNNs, the individual channels can be attributed to classifying human-understandable concepts. Concept relevance propagation (CRP) methods can backtrack predictions to these channels and find images that most activate these channels. However, current CRP workflows are largely manual: experts must inspect activation images to name the discovered concepts and must synthesize verbose explanations from relevance maps, limiting the accessibility of the explanations and their scalability.   To address these issues, we introduce Large Language model EXplaIns COncept Relevance Propagation (LLEXICORP), a modular pipeline that couples CRP with a multimodal large language model. Our approach automatically assigns descriptive names to concept prototypes and generates natural-language explanations that translate quantitative relevance distributions into intuitive narratives. To ensure faithfulness, we craft prompts that teach the language model the semantics of CRP through examples and enforce a separation between naming and explanation tasks. The resulting text can be tailored to different audiences, offering low-level technical descriptions for experts and high-level summaries for non-technical stakeholders.   We qualitatively evaluate our method on various images from ImageNet on a VGG16 model. Our findings suggest that integrating concept-based attribution methods with large language models can significantly lower the barrier to interpreting deep neural networks, paving the way for more transparent AI systems.",
    "fetched_at": "2025-11-06T02:19:07.212239Z"
  },
  {
    "id": "2511.02721v1",
    "title": "PragExTra: A Multilingual Corpus of Pragmatic Explicitation in   Translation",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Doreen Osmelak",
      "Koel Dutta Chowdhury",
      "Uliana Sentsova",
      "Cristina España-Bonet",
      "Josef van Genabith"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02721v1",
    "abstract": "Translators often enrich texts with background details that make implicit cultural meanings explicit for new audiences. This phenomenon, known as pragmatic explicitation, has been widely discussed in translation theory but rarely modeled computationally. We introduce PragExTra, the first multilingual corpus and detection framework for pragmatic explicitation. The corpus covers eight language pairs from TED-Multi and Europarl and includes additions such as entity descriptions, measurement conversions, and translator remarks. We identify candidate explicitation cases through null alignments and refined using active learning with human annotation. Our results show that entity and system-level explicitations are most frequent, and that active learning improves classifier accuracy by 7-8 percentage points, achieving up to 0.88 accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic explicitation as a measurable, cross-linguistic phenomenon and takes a step towards building culturally aware machine translation. Keywords: translation, multilingualism, explicitation",
    "fetched_at": "2025-11-06T02:19:07.212180Z"
  },
  {
    "id": "2511.02738v1",
    "title": "Calibration improves detection of mislabeled examples",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ilies Chibane",
      "Thomas George",
      "Pierre Nodet",
      "Vincent Lemaire"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02738v1",
    "abstract": "Mislabeled data is a pervasive issue that undermines the performance of machine learning systems in real-world applications. An effective approach to mitigate this problem is to detect mislabeled instances and subject them to special treatment, such as filtering or relabeling. Automatic mislabeling detection methods typically rely on training a base machine learning model and then probing it for each instance to obtain a trust score that each provided label is genuine or incorrect. The properties of this base model are thus of paramount importance. In this paper, we investigate the impact of calibrating this model. Our empirical results show that using calibration methods improves the accuracy and robustness of mislabeled instance detection, providing a practical and effective solution for industrial applications.",
    "fetched_at": "2025-11-06T02:19:07.212070Z"
  },
  {
    "id": "2511.02749v1",
    "title": "Using Span Queries to Optimize for Cache and Attention Locality",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Paul Castro",
      "Nick Mitchell",
      "Nathan Ordonez",
      "Thomas Parnell",
      "Mudhakar Srivatsa",
      "Antoni Viros i Martin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02749v1",
    "abstract": "Clients are evolving beyond chat completion, and now include a variety of innovative inference-time scaling and deep reasoning techniques. At the same time, inference servers remain heavily optimized for chat completion. Prior work has shown that large improvements to KV cache hit rate are possible if inference servers evolve towards these non-chat use cases. However, they offer solutions that are also optimized for a single use case, RAG. In this paper, we introduce the span query to generalize the interface to the inference server. We demonstrate that chat, RAG, inference-time scaling, and agentic workloads can all be expressed as span queries. We show how the critical distinction that had been assumed by prior work lies in whether the order of the inputs matter -- do they commute? In chat, they do not. In RAG, they often do. This paper introduces span queries, which are expression trees of inference calls, linked together with commutativity constraints. We describe span query syntax and semantics. We show how they can be automatically optimized to improve KV cache locality. We show how a small change to vLLM (affecting only 492 lines) can enable high-performance execution of span queries. Using this stack, we demonstrate that span queries can achieve 10-20x reductions in TTFT for two distinct non-chat use cases. Finally, we show that span queries can also be optimized to improve attention locality, so as to avoid the so-called lost-in-the-middle problem. We demonstrate that an attention-optimized span query on a 2b parameter model vastly outperforms the accuracy of a stock inference server using an 8b model.",
    "fetched_at": "2025-11-06T02:19:07.211971Z"
  },
  {
    "id": "2511.02752v1",
    "title": "AI Diffusion in Low Resource Language Countries",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Amit Misra",
      "Syed Waqas Zamir",
      "Wassim Hamidouche",
      "Inbal Becker-Reshef",
      "Juan Lavista Ferres"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02752v1",
    "abstract": "Artificial intelligence (AI) is diffusing globally at unprecedented speed, but adoption remains uneven. Frontier Large Language Models (LLMs) are known to perform poorly on low-resource languages due to data scarcity. We hypothesize that this performance deficit reduces the utility of AI, thereby slowing adoption in Low-Resource Language Countries (LRLCs). To test this, we use a weighted regression model to isolate the language effect from socioeconomic and demographic factors, finding that LRLCs have a share of AI users that is approximately 20% lower relative to their baseline. These results indicate that linguistic accessibility is a significant, independent barrier to equitable AI diffusion.",
    "fetched_at": "2025-11-06T02:19:07.211914Z"
  },
  {
    "id": "2511.02754v1",
    "title": "DANIEL: A Distributed and Scalable Approach for Global Representation   Learning with EHR Applications",
    "date": "2025-11-04",
    "tags": [
      "stat.ME",
      "ME",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zebin Wang",
      "Ziming Gan",
      "Weijing Tang",
      "Zongqi Xia",
      "Tianrun Cai",
      "Tianxi Cai",
      "Junwei Lu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02754v1",
    "abstract": "Classical probabilistic graphical models face fundamental challenges in modern data environments, which are characterized by high dimensionality, source heterogeneity, and stringent data-sharing constraints. In this work, we revisit the Ising model, a well-established member of the Markov Random Field (MRF) family, and develop a distributed framework that enables scalable and privacy-preserving representation learning from large-scale binary data with inherent low-rank structure. Our approach optimizes a non-convex surrogate loss function via bi-factored gradient descent, offering substantial computational and communication advantages over conventional convex approaches. We evaluate our algorithm on multi-institutional electronic health record (EHR) datasets from 58,248 patients across the University of Pittsburgh Medical Center (UPMC) and Mass General Brigham (MGB), demonstrating superior performance in global representation learning and downstream clinical tasks, including relationship detection, patient phenotyping, and patient clustering. These results highlight a broader potential for statistical inference in federated, high-dimensional settings while addressing the practical challenges of data complexity and multi-institutional integration.",
    "fetched_at": "2025-11-06T02:19:07.211866Z"
  },
  {
    "id": "2511.02757v1",
    "title": "ConMeZO: Adaptive Descent-Direction Sampling for Gradient-Free   Finetuning of Large Language Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Lejs Deen Behric",
      "Liang Zhang",
      "Bingcong Li",
      "Kiran Koshy Thekumparampil"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02757v1",
    "abstract": "Zeroth-order or derivative-free optimization (MeZO) is an attractive strategy for finetuning large language models (LLMs) because it eliminates the memory overhead of backpropagation. However, it converges slowly due to the inherent curse of dimensionality when searching for descent directions in the high-dimensional parameter space of billion-scale LLMs. We propose ConMeZO, a novel zeroth-order optimizer that accelerates convergence by adaptive directional sampling. Instead of drawing the direction uniformly at random, ConMeZO restricts the sampling to a cone centered around a momentum estimate. This concentrates the search in directions where the true gradient is more likely to lie and thus reduces the effect of high dimensions. We prove that ConMeZO achieves the same worst-case convergence rate as MeZO. Empirically, when finetuning LLMs on natural language tasks, ConMeZO is up to 2X faster than MeZO while retaining the low-memory footprint of zeroth-order methods.",
    "fetched_at": "2025-11-06T02:19:07.211652Z"
  },
  {
    "id": "2511.02759v1",
    "title": "LLM-Supported Formal Knowledge Representation for Enhancing Control   Engineering Content with an Interactive Semantic Layer",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Julius Fiedler",
      "Carsten Knoll",
      "Klaus Röbenack"
    ],
    "institution": "Chair of Fundamentals of Electrical Engineering at TU Dresden, Institute of Control Theory at TU Dresden",
    "link": "http://arxiv.org/pdf/2511.02759v1",
    "abstract": "The rapid growth of research output in control engineering calls for new approaches to structure and formalize domain knowledge. This paper briefly describes an LLM-supported method for semi-automated generation of formal knowledge representations that combine human readability with machine interpretability and increased expressiveness. Based on the Imperative Representation of Knowledge (PyIRK) framework, we demonstrate how language models can assist in transforming natural-language descriptions and mathematical definitions (available as LaTeX source code) into a formalized knowledge graph. As a first application we present the generation of an ``interactive semantic layer'' to enhance the source documents in order to facilitate knowledge transfer. From our perspective this contributes to the vision of easily accessible, collaborative, and verifiable knowledge bases for the control engineering domain.",
    "fetched_at": "2025-11-06T02:19:07.211599Z"
  },
  {
    "id": "2511.02765v1",
    "title": "VecComp: Vector Computing via MIMO Digital Over-the-Air Computation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Saeed Razavikia",
      "José Mairton Barros Da Silva Junior",
      "Carlo Fischione"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02765v1",
    "abstract": "Recently, the ChannelComp framework has proposed digital over-the-air computation by designing digital modulations that enable the computation of arbitrary functions. Unlike traditional analog over-the-air computation, which is restricted to nomographic functions, ChannelComp enables a broader range of computational tasks while maintaining compatibility with digital communication systems. This framework is intended for applications that favor local information processing over the mere acquisition of data. However, ChannelComp is currently designed for scalar function computation, while numerous data-centric applications necessitate vector-based computations, and it is susceptible to channel fading. In this work, we introduce a generalization of the ChannelComp framework, called VecComp, by integrating ChannelComp with multiple-antenna technology. This generalization not only enables vector function computation but also ensures scalability in the computational complexity, which increases only linearly with the vector dimension. As such, VecComp remains computationally efficient and robust against channel impairments, making it suitable for high-dimensional, data-centric applications. We establish a non-asymptotic upper bound on the mean squared error of VecComp, affirming its computation efficiency under fading channel conditions. Numerical experiments show the effectiveness of VecComp in improving the computation of vector functions and fading compensation over noisy and fading multiple-access channels.",
    "fetched_at": "2025-11-06T02:19:07.211495Z"
  },
  {
    "id": "2511.02769v1",
    "title": "STAR-VAE: Latent Variable Transformers for Scalable and Controllable   Molecular Generation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "q-bio.BM",
      "BM"
    ],
    "authors": [
      "Bum Chul Kwon",
      "Ben Shapira",
      "Moshiko Raboh",
      "Shreyans Sethi",
      "Shruti Murarka",
      "Joseph A Morrone",
      "Jianying Hu",
      "Parthasarathy Suryanarayanan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02769v1",
    "abstract": "The chemical space of drug-like molecules is vast, motivating the development of generative models that must learn broad chemical distributions, enable conditional generation by capturing structure-property representations, and provide fast molecular generation. Meeting the objectives depends on modeling choices, including the probabilistic modeling approach, the conditional generative formulation, the architecture, and the molecular input representation. To address the challenges, we present STAR-VAE (Selfies-encoded, Transformer-based, AutoRegressive Variational Auto Encoder), a scalable latent-variable framework with a Transformer encoder and an autoregressive Transformer decoder. It is trained on 79 million drug-like molecules from PubChem, using SELFIES to guarantee syntactic validity. The latent-variable formulation enables conditional generation: a property predictor supplies a conditioning signal that is applied consistently to the latent prior, the inference network, and the decoder. Our contributions are: (i) a Transformer-based latent-variable encoder-decoder model trained on SELFIES representations; (ii) a principled conditional latent-variable formulation for property-guided generation; and (iii) efficient finetuning with low-rank adapters (LoRA) in both encoder and decoder, enabling fast adaptation with limited property and activity data. On the GuacaMol and MOSES benchmarks, our approach matches or exceeds baselines, and latent-space analyses reveal smooth, semantically structured representations that support both unconditional exploration and property-aware generation. On the Tartarus benchmarks, the conditional model shifts docking-score distributions toward stronger predicted binding. These results suggest that a modernized, scale-appropriate VAE remains competitive for molecular generation when paired with principled conditioning and parameter-efficient finetuning.",
    "fetched_at": "2025-11-06T02:19:07.211448Z"
  },
  {
    "id": "2511.02770v1",
    "title": "Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query   Retrieval",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Hung-Ting Chen",
      "Xiang Liu",
      "Shauli Ravfogel",
      "Eunsol Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02770v1",
    "abstract": "Most text retrievers generate \\emph{one} query vector to retrieve relevant documents. Yet, the conditional distribution of relevant documents for the query may be multimodal, e.g., representing different interpretations of the query. We first quantify the limitations of existing retrievers. All retrievers we evaluate struggle more as the distance between target document embeddings grows. To address this limitation, we develop a new retriever architecture, \\emph{A}utoregressive \\emph{M}ulti-\\emph{E}mbedding \\emph{R}etriever (AMER). Our model autoregressively generates multiple query vectors, and all the predicted query vectors are used to retrieve documents from the corpus. We show that on the synthetic vectorized data, the proposed method could capture multiple target distributions perfectly, showing 4x better performance than single embedding model. We also fine-tune our model on real-world multi-answer retrieval datasets and evaluate in-domain. AMER presents 4 and 21\\% relative gains over single-embedding baselines on two datasets we evaluate on. Furthermore, we consistently observe larger gains on the subset of dataset where the embeddings of the target documents are less similar to each other. We demonstrate the potential of using a multi-query vector retriever and open up a new direction for future work.",
    "fetched_at": "2025-11-06T02:19:07.211379Z"
  },
  {
    "id": "2511.02773v1",
    "title": "Adam Reduces a Unique Form of Sharpness: Theoretical Insights Near the   Minimizer Manifold",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Xinghan Li",
      "Haodong Wen",
      "Kaifeng Lyu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02773v1",
    "abstract": "Despite the popularity of the Adam optimizer in practice, most theoretical analyses study Stochastic Gradient Descent (SGD) as a proxy for Adam, and little is known about how the solutions found by Adam differ. In this paper, we show that Adam implicitly reduces a unique form of sharpness measure shaped by its adaptive updates, leading to qualitatively different solutions from SGD. More specifically, when the training loss is small, Adam wanders around the manifold of minimizers and takes semi-gradients to minimize this sharpness measure in an adaptive manner, a behavior we rigorously characterize through a continuous-time approximation using stochastic differential equations. We further demonstrate how this behavior differs from that of SGD in a well-studied setting: when training overparameterized models with label noise, SGD has been shown to minimize the trace of the Hessian matrix, $\\tr(\\mH)$, whereas we prove that Adam minimizes $\\tr(\\Diag(\\mH)^{1/2})$ instead. In solving sparse linear regression with diagonal linear networks, this distinction enables Adam to achieve better sparsity and generalization than SGD. Finally, our analysis framework extends beyond Adam to a broad class of adaptive gradient methods, including RMSProp, Adam-mini, Adalayer and Shampoo, and provides a unified perspective on how these adaptive optimizers reduce sharpness, which we hope will offer insights for future optimizer design.",
    "fetched_at": "2025-11-06T02:19:07.211331Z"
  },
  {
    "id": "2511.02778v1",
    "title": "VCode: a Multimodal Coding Benchmark with SVG as Symbolic Visual   Representation",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kevin Qinghong Lin",
      "Yuhao Zheng",
      "Hangyu Ran",
      "Dantong Zhu",
      "Dongxing Mao",
      "Linjie Li",
      "Philip Torr",
      "Alex Jinpeng Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02778v1",
    "abstract": "Code has emerged as a precise and executable medium for reasoning and action in the agent era. Yet, progress has largely focused on language-centric tasks such as program synthesis and debugging, leaving visual-centric coding underexplored. Inspired by how humans reason over sketches, we advocate SVG code as a compact, interpretable, and executable visual representation. We introduce VCode, a benchmark that reframes multimodal understanding as code generation: given an image, a model must produce SVG that preserves symbolic meaning for downstream reasoning. VCode covers three domains - general commonsense (MM-Vet), professional disciplines (MMMU), and visual-centric perception (CV-Bench). To assess symbolic fidelity, we propose CodeVQA, a novel evaluation protocol in which a policy model answers questions over rendered SVGs; correct answers indicate faithful symbolic preservation. Empirically, frontier VLMs struggle to generate faithful SVGs, revealing a persistent gap between language-centric and visual-centric coding. To close this gap, we introduce VCoder, an agentic framework that augments VLMs along two axes: (i) Thinking with Revision, which iteratively analyzes discrepancies and refines SVG code; and (ii) Acting with Visual Tools, where detectors and parsers supply structured cues such as objects, shapes, and text beyond the model's intrinsic capacity. Across benchmarks, frontier VLMs with strong reasoning capabilities score well overall yet remain limited in professional knowledge and 3D reasoning. VCoder delivers a 12.3-point overall gain over the top-performing Claude-4-Opus. Human studies show that both humans and VLMs perform worse on rendered SVGs, their consistency reveals the promise of symbolic visual representation. The benchmark and code are available at https://github.com/CSU-JPG/VCode.",
    "fetched_at": "2025-11-06T02:19:07.211286Z"
  },
  {
    "id": "2511.02780v1",
    "title": "1 PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts",
    "date": "2025-11-04",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Vivi Andersson",
      "Sofia Bobadilla",
      "Harald Hobbelhagen",
      "Martin Monperrus"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02780v1",
    "abstract": "Smart contracts operate in a highly adversarial environment, where vulnerabilities can lead to substantial financial losses. Thus, smart contracts are subject to security audits. In auditing, proof-of-concept (PoC) exploits play a critical role by demonstrating to the stakeholders that the reported vulnerabilities are genuine, reproducible, and actionable. However, manually creating PoCs is time-consuming, error-prone, and often constrained by tight audit schedules. We introduce POCO, an agentic framework that automatically generates executable PoC exploits from natural-language vulnerability descriptions written by auditors. POCO autonomously generates PoC exploits in an agentic manner by interacting with a set of code-execution tools in a Reason-Act-Observe loop. It produces fully executable exploits compatible with the Foundry testing framework, ready for integration into audit reports and other security tools. We evaluate POCO on a dataset of 23 real-world vulnerability reports. POCO consistently outperforms the prompting and workflow baselines, generating well-formed and logically correct PoCs. Our results demonstrate that agentic frameworks can significantly reduce the effort required for high-quality PoCs in smart contract audits. Our contribution provides readily actionable knowledge for the smart contract security community.",
    "fetched_at": "2025-11-06T02:19:07.211219Z"
  },
  {
    "id": "2511.02781v1",
    "title": "Measuring AI Diffusion: A Population-Normalized Metric for Tracking   Global AI Usage",
    "date": "2025-11-04",
    "tags": [
      "cs.CY",
      "CY",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amit Misra",
      "Jane Wang",
      "Scott McCullers",
      "Kevin White",
      "Juan Lavista Ferres"
    ],
    "institution": "Microsoft",
    "link": "http://arxiv.org/pdf/2511.02781v1",
    "abstract": "Measuring global AI diffusion remains challenging due to a lack of population-normalized, cross-country usage data. We introduce AI User Share, a novel indicator that estimates the share of each country's working-age population actively using AI tools. Built from anonymized Microsoft telemetry and adjusted for device access and mobile scaling, this metric spans 147 economies and provides consistent, real-time insight into global AI diffusion. We find wide variation in adoption, with a strong correlation between AI User Share and GDP. High uptake is concentrated in developed economies, though usage among internet-connected populations in lower-income countries reveals substantial latent demand. We also detect sharp increases in usage following major product launches, such as DeepSeek in early 2025. While the metric's reliance solely on Microsoft telemetry introduces potential biases related to this user base, it offers an important new lens into how AI is spreading globally. AI User Share enables timely benchmarking that can inform data-driven AI policy.",
    "fetched_at": "2025-11-06T02:19:07.211169Z"
  },
  {
    "id": "2511.02785v1",
    "title": "Enhancing Federated Learning Privacy with QUBO",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "quant-ph"
    ],
    "authors": [
      "Andras Ferenczi",
      "Sutapa Samanta",
      "Dagen Wang",
      "Todd Hodges"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02785v1",
    "abstract": "Federated learning (FL) is a widely used method for training machine learning (ML) models in a scalable way while preserving privacy (i.e., without centralizing raw data). Prior research shows that the risk of exposing sensitive data increases cumulatively as the number of iterations where a client's updates are included in the aggregated model increase. Attackers can launch membership inference attacks (MIA; deciding whether a sample or client participated), property inference attacks (PIA; inferring attributes of a client's data), and model inversion attacks (MI; reconstructing inputs), thereby inferring client-specific attributes and, in some cases, reconstructing inputs. In this paper, we mitigate risk by substantially reducing per client exposure using a quantum computing-inspired quadratic unconstrained binary optimization (QUBO) formulation that selects a small subset of client updates most relevant for each training round. In this work, we focus on two threat vectors: (i) information leakage by clients during training and (ii) adversaries who can query or obtain the global model. We assume a trusted central server and do not model server compromise. This method also assumes that the server has access to a validation/test set with global data distribution. Experiments on the MNIST dataset with 300 clients in 20 rounds showed a 95.2% per-round and 49% cumulative privacy exposure reduction, with 147 clients' updates never being used during training while maintaining in general the full-aggregation accuracy or even better. The method proved to be efficient at lower scale and more complex model as well. A CINIC-10 dataset-based experiment with 30 clients resulted in 82% per-round privacy improvement and 33% cumulative privacy.",
    "fetched_at": "2025-11-06T02:19:07.211118Z"
  },
  {
    "id": "2511.02795v1",
    "title": "Can LLMs subtract numbers?",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mayank Jobanputra",
      "Nils Philipp Walter",
      "Maitrey Mehta",
      "Blerta Veseli",
      "Evan Parker Kelly Chapple",
      "Yifan Wang",
      "Sneha Chetani",
      "Ellie Pavlick",
      "Antonio Vergari",
      "Vera Demberg"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02795v1",
    "abstract": "We present a systematic study of subtraction in large language models (LLMs). While prior benchmarks emphasize addition and multiplication, subtraction has received comparatively little attention despite being structurally distinct as a non-commutative operation. We evaluate eight pretrained LLMs spanning four families on addition and subtraction problems. Our experiments reveal that subtraction accuracy lags behind addition by a wide margin. We find that the errors for ($a-b$) are concentrated in cases where ($a<b$). In such cases, LLMs frequently produce the correct magnitude but omit the negative sign. Probing analyses show that LLMs internally encode whether results should be negative, yet this information is often not reflected in generated outputs. We further test well-known techniques such as few-shot learning and instruction-tuning to see if they can improve the LLMs' performance. Our results suggest that while few-shot prompting yields modest gains, the instruction-tuned models achieve near-perfect accuracies in generating the negative sign. Together, these findings provide a clearer characterization of the limitations and recoverability of LLMs' arithmetic capabilities in subtraction.",
    "fetched_at": "2025-11-06T02:19:07.211010Z"
  },
  {
    "id": "2511.02797v1",
    "title": "Fast, Private, and Protected: Safeguarding Data Privacy and Defending   Against Model Poisoning Attacks in Federated Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nicolas Riccieri Gardin Assumpcao",
      "Leandro Villas"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02797v1",
    "abstract": "Federated Learning (FL) is a distributed training paradigm wherein participants collaborate to build a global model while ensuring the privacy of the involved data, which remains stored on participant devices. However, proposals aiming to ensure such privacy also make it challenging to protect against potential attackers seeking to compromise the training outcome. In this context, we present Fast, Private, and Protected (FPP), a novel approach that aims to safeguard federated training while enabling secure aggregation to preserve data privacy. This is accomplished by evaluating rounds using participants' assessments and enabling training recovery after an attack. FPP also employs a reputation-based mechanism to mitigate the participation of attackers. We created a dockerized environment to validate the performance of FPP compared to other approaches in the literature (FedAvg, Power-of-Choice, and aggregation via Trimmed Mean and Median). Our experiments demonstrate that FPP achieves a rapid convergence rate and can converge even in the presence of malicious participants performing model poisoning attacks.",
    "fetched_at": "2025-11-06T02:19:07.210943Z"
  },
  {
    "id": "2511.02802v2",
    "title": "TabTune: A Unified Library for Inference and Fine-Tuning Tabular   Foundation Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aditya Tanna",
      "Pratinav Seth",
      "Mohamed Bouadi",
      "Utsav Avaiya",
      "Vinay Kumar Sankarapu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02802v2",
    "abstract": "Tabular foundation models represent a growing paradigm in structured data learning, extending the benefits of large-scale pretraining to tabular domains. However, their adoption remains limited due to heterogeneous preprocessing pipelines, fragmented APIs, inconsistent fine-tuning procedures, and the absence of standardized evaluation for deployment-oriented metrics such as calibration and fairness. We present TabTune, a unified library that standardizes the complete workflow for tabular foundation models through a single interface. TabTune provides consistent access to seven state-of-the-art models supporting multiple adaptation strategies, including zero-shot inference, meta-learning, supervised fine-tuning (SFT), and parameter-efficient fine-tuning (PEFT). The framework automates model-aware preprocessing, manages architectural heterogeneity internally, and integrates evaluation modules for performance, calibration, and fairness. Designed for extensibility and reproducibility, TabTune enables consistent benchmarking of adaptation strategies of tabular foundation models.",
    "fetched_at": "2025-11-06T02:19:07.210903Z"
  },
  {
    "id": "2511.02815v1",
    "title": "Assessing win strength in MLB win prediction models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Morgan Allen",
      "Paul Savala"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02815v1",
    "abstract": "In Major League Baseball, strategy and planning are major factors in determining the outcome of a game. Previous studies have aided this by building machine learning models for predicting the winning team of any given game. We extend this work by training a comprehensive set of machine learning models using a common dataset. In addition, we relate the win probabilities produced by these models to win strength as measured by score differential. In doing so we show that the most common machine learning models do indeed demonstrate a relationship between predicted win probability and the strength of the win. Finally, we analyze the results of using predicted win probabilities as a decision making mechanism on run-line betting. We demonstrate positive returns when utilizing appropriate betting strategies, and show that naive use of machine learning models for betting lead to significant loses.",
    "fetched_at": "2025-11-06T02:19:07.210784Z"
  },
  {
    "id": "2511.02817v1",
    "title": "Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amanda Bertsch",
      "Adithya Pratapa",
      "Teruko Mitamura",
      "Graham Neubig",
      "Matthew R. Gormley"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02817v1",
    "abstract": "As model context lengths continue to grow, concerns about whether models effectively use the full context length have persisted. While several carefully designed long-context evaluations have recently been released, these evaluations tend to rely on retrieval from one or more sections of the context, which allows nearly all of the context tokens to be disregarded as noise. This represents only one type of task that might be performed with long context. We introduce Oolong, a benchmark of long-context reasoning tasks that require analyzing individual chunks of text on an atomic level, and then aggregating these analyses to answer distributional questions. Oolong is separated into two task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can easily ablate components of the reasoning problem; and Oolong-real, a downstream setting which requires reasoning over real-world conversational data. Oolong requires models to reason over large quantities of examples, to perform both classification and counting in-context, and to reason over temporal and user relations. Even frontier models struggle on Oolong, with GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy on both splits at 128K. We release the data and evaluation harness for Oolong to enable further development of models that can reason over large quantities of text.",
    "fetched_at": "2025-11-06T02:19:07.210745Z"
  },
  {
    "id": "2511.02818v1",
    "title": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohamed Bouadi",
      "Pratinav Seth",
      "Aditya Tanna",
      "Vinay Kumar Sankarapu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02818v1",
    "abstract": "Tabular data remain the predominant format for real-world applications. Yet, developing effective neural models for tabular data remains challenging due to heterogeneous feature types and complex interactions occurring at multiple scales. Recent advances in tabular in-context learning (ICL), such as TabPFN and TabICL, have achieved state-of-the-art performance comparable to gradient-boosted trees (GBTs) without task-specific fine-tuning. However, current architectures exhibit key limitations: (1) single-scale feature processing that overlooks hierarchical dependencies, (2) dense attention with quadratic scaling in table width, and (3) strictly sequential component processing that prevents iterative representation refinement and cross-component communication. To address these challenges, we introduce Orion-MSP, a tabular ICL architecture featuring three key innovations: (1) multi-scale processing to capture hierarchical feature interactions; (2) block-sparse attention combining windowed, global, and random patterns for scalable efficiency and long-range connectivity; and (3) a Perceiver-style memory enabling safe bidirectional information flow across components. Across diverse benchmarks, Orion-MSP matches or surpasses state-of-the-art performance while scaling effectively to high-dimensional tables, establishing a new standard for efficient tabular in-context learning. The model is publicly available at https://github.com/Lexsi-Labs/Orion-MSP .",
    "fetched_at": "2025-11-06T02:19:07.210693Z"
  },
  {
    "id": "2511.02821v1",
    "title": "Accelerated Frank-Wolfe Algorithms: Complementarity Conditions and   Sparsity",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Dan Garber"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02821v1",
    "abstract": "We develop new accelerated first-order algorithms in the Frank-Wolfe (FW) family for minimizing smooth convex functions over compact convex sets, with a focus on two prominent constraint classes: (1) polytopes and (2) matrix domains given by the spectrahedron and the unit nuclear-norm ball. A key technical ingredient is a complementarity condition that captures solution sparsity -- face dimension for polytopes and rank for matrices. We present two algorithms: (1) a purely linear optimization oracle (LOO) method for polytopes that has optimal worst-case first-order (FO) oracle complexity and, aside of a finite \\emph{burn-in} phase and up to a logarithmic factor, has LOO complexity that scales with $r/\\sqrt{\\epsilon}$, where $\\epsilon$ is the target accuracy and $r$ is the solution sparsity $r$ (independently of the ambient dimension), and (2) a hybrid scheme that combines FW with a sparse projection oracle (e.g., low-rank SVDs for matrix domains with low-rank solutions), which also has optimal FO oracle complexity, and after a finite burn-in phase, only requires $O(1/\\sqrt{\\epsilon})$ sparse projections and LOO calls (independently of both the ambient dimension and the rank of optimal solutions). Our results close a gap on how to accelerate recent advancements in linearly-converging FW algorithms for strongly convex optimization, without paying the price of the dimension.",
    "fetched_at": "2025-11-06T02:19:07.210642Z"
  },
  {
    "id": "2511.02824v2",
    "title": "Kosmos: An AI Scientist for Autonomous Discovery",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ludovico Mitchener",
      "Angela Yiu",
      "Benjamin Chang",
      "Mathieu Bourdenx",
      "Tyler Nadolski",
      "Arvis Sulovari",
      "Eric C. Landsness",
      "Daniel L. Barabasi",
      "Siddharth Narayanan",
      "Nicky Evans",
      "Shriya Reddy",
      "Martha Foiani",
      "Aizad Kamal",
      "Leah P. Shriver",
      "Fang Cao",
      "Asmamaw T. Wassie",
      "Jon M. Laurent",
      "Edwin Melville-Green",
      "Mayk Caldas",
      "Albert Bou",
      "Kaleigh F. Roberts",
      "Sladjana Zagorac",
      "Timothy C. Orr",
      "Miranda E. Orr",
      "Kevin J. Zwezdaryk",
      "Ali E. Ghareeb",
      "Laurie McCoy",
      "Bruna Gomes",
      "Euan A. Ashley",
      "Karen E. Duff",
      "Tonio Buonassisi",
      "Tom Rainforth",
      "Randall J. Bateman",
      "Michael Skarlinski",
      "Samuel G. Rodriques",
      "Michaela M. Hinks",
      "Andrew D. White"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02824v2",
    "abstract": "Data-driven scientific discovery requires iterative cycles of literature search, hypothesis generation, and data analysis. Substantial progress has been made towards AI agents that can automate scientific research, but all such agents remain limited in the number of actions they can take before losing coherence, thus limiting the depth of their findings. Here we present Kosmos, an AI scientist that automates data-driven discovery. Given an open-ended objective and a dataset, Kosmos runs for up to 12 hours performing cycles of parallel data analysis, literature search, and hypothesis generation before synthesizing discoveries into scientific reports. Unlike prior systems, Kosmos uses a structured world model to share information between a data analysis agent and a literature search agent. The world model enables Kosmos to coherently pursue the specified objective over 200 agent rollouts, collectively executing an average of 42,000 lines of code and reading 1,500 papers per run. Kosmos cites all statements in its reports with code or primary literature, ensuring its reasoning is traceable. Independent scientists found 79.4% of statements in Kosmos reports to be accurate, and collaborators reported that a single 20-cycle Kosmos run performed the equivalent of 6 months of their own research time on average. Furthermore, collaborators reported that the number of valuable scientific findings generated scales linearly with Kosmos cycles (tested up to 20 cycles). We highlight seven discoveries made by Kosmos that span metabolomics, materials science, neuroscience, and statistical genetics. Three discoveries independently reproduce findings from preprinted or unpublished manuscripts that were not accessed by Kosmos at runtime, while four make novel contributions to the scientific literature.",
    "fetched_at": "2025-11-06T02:19:07.210532Z"
  },
  {
    "id": "2511.02825v1",
    "title": "Neurosymbolic Deep Learning Semantics",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Artur d'Avila Garcez",
      "Simon Odense"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02825v1",
    "abstract": "Artificial Intelligence (AI) is a powerful new language of science as evidenced by recent Nobel Prizes in chemistry and physics that recognized contributions to AI applied to those areas. Yet, this new language lacks semantics, which makes AI's scientific discoveries unsatisfactory at best. With the purpose of uncovering new facts but also improving our understanding of the world, AI-based science requires formalization through a framework capable of translating insight into comprehensible scientific knowledge. In this paper, we argue that logic offers an adequate framework. In particular, we use logic in a neurosymbolic framework to offer a much needed semantics for deep learning, the neural network-based technology of current AI. Deep learning and neurosymbolic AI lack a general set of conditions to ensure that desirable properties are satisfied. Instead, there is a plethora of encoding and knowledge extraction approaches designed for particular cases. To rectify this, we introduced a framework for semantic encoding, making explicit the mapping between neural networks and logic, and characterizing the common ingredients of the various existing approaches. In this paper, we describe succinctly and exemplify how logical semantics and neural networks are linked through this framework, we review some of the most prominent approaches and techniques developed for neural encoding and knowledge extraction, provide a formal definition of our framework, and discuss some of the difficulties of identifying a semantic encoding in practice in light of analogous problems in the philosophy of mind.",
    "fetched_at": "2025-11-06T02:19:07.210369Z"
  },
  {
    "id": "2511.02831v1",
    "title": "GeoCrossBench: Cross-Band Generalization for Remote Sensing",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Hakob Tamazyan",
      "Ani Vanyan",
      "Alvard Barseghyan",
      "Anna Khosrovyan",
      "Evan Shelhamer",
      "Hrant Khachatrian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02831v1",
    "abstract": "The number and diversity of remote sensing satellites grows over time, while the vast majority of labeled data comes from older satellites. As the foundation models for Earth observation scale up, the cost of (re-)training to support new satellites grows too, so the generalization capabilities of the models towards new satellites become increasingly important. In this work we introduce GeoCrossBench, an extension of the popular GeoBench benchmark with a new evaluation protocol: it tests the in-distribution performance; generalization to satellites with no band overlap; and generalization to satellites with additional bands with respect to the training set. We also develop a self-supervised extension of ChannelViT, ChiViT, to improve its cross-satellite performance. First, we show that even the best foundation models for remote sensing (DOFA, TerraFM) do not outperform general purpose models like DINOv3 in the in-distribution setting. Second, when generalizing to new satellites with no band overlap, all models suffer 2-4x drop in performance, and ChiViT significantly outperforms the runner-up DINOv3. Third, the performance of all tested models drops on average by 5-25\\% when given additional bands during test time. Finally, we show that fine-tuning just the last linear layer of these models using oracle labels from all bands can get relatively consistent performance across all satellites, highlighting that the benchmark is far from being saturated. We publicly release the code and the datasets to encourage the development of more future-proof remote sensing models with stronger cross-satellite generalization.",
    "fetched_at": "2025-11-06T02:19:07.210324Z"
  },
  {
    "id": "2511.02832v1",
    "title": "TWIST2: Scalable, Portable, and Holistic Humanoid Data Collection System",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yanjie Ze",
      "Siheng Zhao",
      "Weizhuo Wang",
      "Angjoo Kanazawa",
      "Rocky Duan",
      "Pieter Abbeel",
      "Guanya Shi",
      "Jiajun Wu",
      "C. Karen Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02832v1",
    "abstract": "Large-scale data has driven breakthroughs in robotics, from language models to vision-language-action models in bimanual manipulation. However, humanoid robotics lacks equally effective data collection frameworks. Existing humanoid teleoperation systems either use decoupled control or depend on expensive motion capture setups. We introduce TWIST2, a portable, mocap-free humanoid teleoperation and data collection system that preserves full whole-body control while advancing scalability. Our system leverages PICO4U VR for obtaining real-time whole-body human motions, with a custom 2-DoF robot neck (cost around $250) for egocentric vision, enabling holistic human-to-humanoid control. We demonstrate long-horizon dexterous and mobile humanoid skills and we can collect 100 demonstrations in 15 minutes with an almost 100% success rate. Building on this pipeline, we propose a hierarchical visuomotor policy framework that autonomously controls the full humanoid body based on egocentric vision. Our visuomotor policy successfully demonstrates whole-body dexterous manipulation and dynamic kicking tasks. The entire system is fully reproducible and open-sourced at https://yanjieze.com/TWIST2 . Our collected dataset is also open-sourced at https://twist-data.github.io .",
    "fetched_at": "2025-11-06T02:19:07.210265Z"
  },
  {
    "id": "2511.02833v1",
    "title": "In Good GRACEs: Principled Teacher Selection for Knowledge Distillation",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Abhishek Panigrahi",
      "Bingbin Liu",
      "Sadhika Malladi",
      "Sham Kakade",
      "Surbhi Goel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02833v1",
    "abstract": "Knowledge distillation is an efficient strategy to use data generated by large \"teacher\" language models to train smaller capable \"student\" models, but selecting the optimal teacher for a specific student-task combination requires expensive trial-and-error. We propose a lightweight score called GRACE to quantify how effective a teacher will be for post-training a student model. GRACE measures distributional properties of the student's gradients without access to a verifier, teacher logits, teacher internals, or test data. From an information-theoretic perspective, GRACE connects to leave-one-out stability of gradient-based algorithms, which controls the generalization performance of the distilled students. On GSM8K and MATH, GRACE correlates strongly (up to 86% Spearman correlation) with the performance of the distilled LLaMA and OLMo students. In particular, training a student using the GRACE-selected teacher can improve the performance by up to 7.4% over naively using the best-performing teacher. Further, GRACE can provide guidance on crucial design choices in distillation, including (1) the best temperature to use when generating from the teacher, (2) the best teacher to use given a size constraint, and (3) the best teacher to use within a specific model family. Altogether, our findings demonstrate that GRACE can efficiently and effectively identify a strongly compatible teacher for a given student and provide fine-grained guidance on how to perform distillation.",
    "fetched_at": "2025-11-06T02:19:07.210195Z"
  },
  {
    "id": "2511.02200v1",
    "title": "Optimal-Agent-Selection: State-Aware Routing Framework for Efficient   Multi-Agent Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jingbo Wang",
      "Sendong Zhao",
      "Haochun Wang",
      "Yuzheng Fan",
      "Lizhe Zhang",
      "Yan Liu",
      "Ting Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02200v1",
    "abstract": "The emergence of multi-agent systems powered by large language models (LLMs) has unlocked new frontiers in complex task-solving, enabling diverse agents to integrate unique expertise, collaborate flexibly, and address challenges unattainable for individual models. However, the full potential of such systems is hindered by rigid agent scheduling and inefficient coordination strategies that fail to adapt to evolving task requirements. In this paper, we propose STRMAC, a state-aware routing framework designed for efficient collaboration in multi-agent systems. Our method separately encodes interaction history and agent knowledge to power the router, which adaptively selects the most suitable single agent at each step for efficient and effective collaboration. Furthermore, we introduce a self-evolving data generation approach that accelerates the collection of high-quality execution paths for efficient system training. Experiments on challenging collaborative reasoning benchmarks demonstrate that our method achieves state-of-the-art performance, achieving up to 23.8% improvement over baselines and reducing data collection overhead by up to 90.1% compared to exhaustive search.",
    "fetched_at": "2025-11-06T02:19:05.287515Z"
  },
  {
    "id": "2511.02192v1",
    "title": "A Quantitative Comparison of Centralised and Distributed Reinforcement   Learning-Based Control for Soft Robotic Arms",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Linxin Hou",
      "Qirui Wu",
      "Zhihang Qin",
      "Neil Banerjee",
      "Yongxin Guo",
      "Cecilia Laschi"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.02192v1",
    "abstract": "This paper presents a quantitative comparison between centralised and distributed multi-agent reinforcement learning (MARL) architectures for controlling a soft robotic arm modelled as a Cosserat rod in simulation. Using PyElastica and the OpenAI Gym interface, we train both a global Proximal Policy Optimisation (PPO) controller and a Multi-Agent PPO (MAPPO) under identical budgets. Both approaches are based on the arm having $n$ number of controlled sections. The study systematically varies $n$ and evaluates the performance of the arm to reach a fixed target in three scenarios: default baseline condition, recovery from external disturbance, and adaptation to actuator failure. Quantitative metrics used for the evaluation are mean action magnitude, mean final distance, mean episode length, and success rate. The results show that there are no significant benefits of the distributed policy when the number of controlled sections $n\\le4$. In very simple systems, when $n\\le2$, the centralised policy outperforms the distributed one. When $n$ increases to $4< n\\le 12$, the distributed policy shows a high sample efficiency. In these systems, distributed policy promotes a stronger success rate, resilience, and robustness under local observability and yields faster convergence given the same sample size. However, centralised policies achieve much higher time efficiency during training as it takes much less time to train the same size of samples. These findings highlight the trade-offs between centralised and distributed policy in reinforcement learning-based control for soft robotic systems and provide actionable design guidance for future sim-to-real transfer in soft rod-like manipulators.",
    "fetched_at": "2025-11-06T02:19:03.467430Z"
  },
  {
    "id": "2511.02208v1",
    "title": "Training Proactive and Personalized LLM Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Weiwei Sun",
      "Xuhui Zhou",
      "Weihua Du",
      "Xingyao Wang",
      "Sean Welleck",
      "Graham Neubig",
      "Maarten Sap",
      "Yiming Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02208v1",
    "abstract": "While existing work focuses primarily on task success, we argue that effective real-world agents require optimizing three dimensions: productivity (task completion), proactivity (asking essential questions), and personalization (adapting to diverse user preferences). We introduce UserVille, an interactive environment with LLM-based user simulators enabling diverse, configurable user preferences. Leveraging UserVille, we introduce PPP, a multi-objective reinforcement learning approach that jointly optimizes all three dimensions: Productivity, Proactivity, and Personalization. Experiments on software engineering and deep research tasks show that agents trained with PPP achieve substantial improvements over strong baselines such as GPT-5 (+21.6 on average), demonstrating the ability to ask strategic clarifying questions, adapt to unseen user preferences, and improve task success through better interaction. This work demonstrates that explicitly optimizing for user-centered interaction is critical for building practical and effective AI agents.",
    "fetched_at": "2025-11-06T02:19:03.467373Z"
  },
  {
    "id": "2511.02216v1",
    "title": "Adaptive Cooperative Transmission Design for Ultra-Reliable Low-Latency   Communications via Deep Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.IT",
      "IT",
      "cs.AI",
      "AI",
      "math.IT"
    ],
    "authors": [
      "Hyemin Yu",
      "Hong-Chuan Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02216v1",
    "abstract": "Next-generation wireless communication systems must support ultra-reliable low-latency communication (URLLC) service for mission-critical applications. Meeting stringent URLLC requirements is challenging, especially for two-hop cooperative communication. In this paper, we develop an adaptive transmission design for a two-hop relaying communication system. Each hop transmission adaptively configures its transmission parameters separately, including numerology, mini-slot size, and modulation and coding scheme, for reliable packet transmission within a strict latency constraint. We formulate the hop-specific transceiver configuration as a Markov decision process (MDP) and propose a dual-agent reinforcement learning-based cooperative latency-aware transmission (DRL-CoLA) algorithm to learn latency-aware transmission policies in a distributed manner. Simulation results verify that the proposed algorithm achieves the near-optimal reliability while satisfying strict latency requirements.",
    "fetched_at": "2025-11-06T02:19:03.467314Z"
  },
  {
    "id": "2511.02223v1",
    "title": "Quantitative Risk Assessment in Radiation Oncology via LLM-Powered Root   Cause Analysis of Incident Reports",
    "date": "2025-11-04",
    "tags": [
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Yuntao Wang",
      "Siamak P. Najad-Davarani",
      "Elizabeth Bossart",
      "Matthew T. Studenski",
      "Mariluz De Ornelas",
      "Yunze Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02223v1",
    "abstract": "Background: Modern large language models (LLMs) offer powerful reasoning that converts narratives into structured, taxonomy-aligned data, revealing patterns across planning, delivery, and verification. Embedded as agentic tools, LLMs can assist root-cause analysis and risk assessment (e.g., failure mode and effect analysis FMEA), produce auditable rationales, and draft targeted mitigation actions.   Methods: We developed a data-driven pipeline utilizing an LLM to perform automated root cause analysis on 254 institutional safety incidents. The LLM systematically classified each incident into structured taxonomies for radiotherapy pathway steps and contributory factors. Subsequent quantitative analyses included descriptive statistics, Analysis of Variance (ANOVA), multiple Ordinal Logistic Regression (OLR) analyses to identify predictors of event severity, and Association Rule Mining (ARM) to uncover systemic vulnerabilities.   Results: The high-level Ordinal Logistic Regression (OLR) models identified specific, significant drivers of severity. The Pathway model was statistically significant (Pseudo R2 = 0.033, LR p = 0.015), as was the Responsibility model (Pseudo R2 = 0.028, LR p < 0.001). Association Rule Mining (ARM) identified high-confidence systemic rules, such as \"CF5 Teamwork, management and organisational\" (n = 8, Conf = 1.0) and the high-frequency link between \"(11) Pre-treatment planning process\" and \"CF2 Procedural\" (n = 152, Conf = 0.916).   Conclusion: The LLM-powered, data-driven framework provides a more objective and powerful methodology for risk assessment than traditional approaches. Our findings empirically demonstrate that interventions focused on fortifying high-risk process steps and mitigating systemic failures are most effective for improving patient safety.",
    "fetched_at": "2025-11-06T02:19:03.467273Z"
  },
  {
    "id": "2511.02225v1",
    "title": "Learning Interactive World Model for Object-Centric Reinforcement   Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Fan Feng",
      "Phillip Lippe",
      "Sara Magliacane"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02225v1",
    "abstract": "Agents that understand objects and their interactions can learn policies that are more robust and transferable. However, most object-centric RL methods factor state by individual objects while leaving interactions implicit. We introduce the Factored Interactive Object-Centric World Model (FIOC-WM), a unified framework that learns structured representations of both objects and their interactions within a world model. FIOC-WM captures environment dynamics with disentangled and modular representations of object interactions, improving sample efficiency and generalization for policy learning. Concretely, FIOC-WM first learns object-centric latents and an interaction structure directly from pixels, leveraging pre-trained vision encoders. The learned world model then decomposes tasks into composable interaction primitives, and a hierarchical policy is trained on top: a high level selects the type and order of interactions, while a low level executes them. On simulated robotic and embodied-AI benchmarks, FIOC-WM improves policy-learning sample efficiency and generalization over world-model baselines, indicating that explicit, modular interaction learning is crucial for robust control.",
    "fetched_at": "2025-11-06T02:19:03.467215Z"
  },
  {
    "id": "2511.02230v1",
    "title": "Continuum: Efficient and Robust Multi-Turn LLM Agent Scheduling with KV   Cache Time-to-Live",
    "date": "2025-11-04",
    "tags": [
      "cs.OS",
      "OS",
      "cs.AI",
      "AI",
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Hanchen Li",
      "Qiuyang Mang",
      "Runyuan He",
      "Qizheng Zhang",
      "Huanzhi Mao",
      "Xiaokun Chen",
      "Alvin Cheung",
      "Joseph Gonzalez",
      "Ion Stoica"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02230v1",
    "abstract": "Agentic LLM applications interleave LLM generation requests with tool calls. These tool calls break the continuity of the workflow by creating pauses between LLM requests, bringing many challenges for the serving system, especially under multi-turn scenarios. Each pause potentially causes KV cache eviction and extra waiting time before entering the continuous batch for the following LLM request. Since these pauses happen for each call, this problem becomes increasingly severe as turn number grow for agentic programs. Previous works either fail to incorporate information from the tool call, evicting KV cache that leads to repetitive prefill or loading, or ignore the continuity of a multi-turn program, creating waiting time between turns that increases per-request latency.   We present Continuum, a serving system to optimize job completion time for multi-turn agent workloads by combining tool-aware KV cache timeout with program-level scheduling. By predicting tool call durations in agentic workflows, Continuum selectively pins the KV cache in GPU memory with a time-to-live value based on total turn number. When combined with program-level first-come-first-serve, Continuum prevents scheduling bubbles, preserves multi-turn continuity, and optimizes for throughput for complex agentic workflows. By modeling the variability of tool call and agent program continuity, Continuum outperforms state-of-the-art baselines. Our evaluation on real-world agentic workloads (SWE-Bench and BFCL) with Llama-3.1 8B/70B models shows that Continuum significantly improves the average job completion times, and remains performant across different hardware setups and DRAM offloading schemes. Preview code is available at: https://github.com/Hanchenli/vllm-continuum",
    "fetched_at": "2025-11-06T02:19:03.467171Z"
  },
  {
    "id": "2511.02241v1",
    "title": "Structural Plasticity as Active Inference: A Biologically-Inspired   Architecture for Homeostatic Control",
    "date": "2025-11-04",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC",
      "68T07, 92B20",
      "I.2.6; I.2.0; I.2.11",
      "11"
    ],
    "authors": [
      "Brennen A. Hill"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02241v1",
    "abstract": "Traditional neural networks, while powerful, rely on biologically implausible learning mechanisms such as global backpropagation. This paper introduces the Structurally Adaptive Predictive Inference Network (SAPIN), a novel computational model inspired by the principles of active inference and the morphological plasticity observed in biological neural cultures. SAPIN operates on a 2D grid where processing units, or cells, learn by minimizing local prediction errors. The model features two primary, concurrent learning mechanisms: a local, Hebbian-like synaptic plasticity rule based on the temporal difference between a cell's actual activation and its learned expectation, and a structural plasticity mechanism where cells physically migrate across the grid to optimize their information-receptive fields. This dual approach allows the network to learn both how to process information (synaptic weights) and also where to position its computational resources (network topology). We validated the SAPIN model on the classic Cart Pole reinforcement learning benchmark. Our results demonstrate that the architecture can successfully solve the CartPole task, achieving robust performance. The network's intrinsic drive to minimize prediction error and maintain homeostasis was sufficient to discover a stable balancing policy. We also found that while continual learning led to instability, locking the network's parameters after achieving success resulted in a stable policy. When evaluated for 100 episodes post-locking (repeated over 100 successful agents), the locked networks maintained an average 82% success rate.",
    "fetched_at": "2025-11-06T02:19:03.466991Z"
  },
  {
    "id": "2511.02304v1",
    "title": "Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.FL",
      "FL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Beyazit Yalcinkaya",
      "Marcell Vazquez-Chanlatte",
      "Ameesh Shah",
      "Hanna Krasowski",
      "Sanjit A. Seshia"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02304v1",
    "abstract": "We study the problem of learning multi-task, multi-agent policies for cooperative, temporal objectives, under centralized training, decentralized execution. In this setting, using automata to represent tasks enables the decomposition of complex tasks into simpler sub-tasks that can be assigned to agents. However, existing approaches remain sample-inefficient and are limited to the single-task case. In this work, we present Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for learning task-conditioned, decentralized team policies. We identify the main challenges to ACC-MARL's feasibility in practice, propose solutions, and prove the correctness of our approach. We further show that the value functions of learned policies can be used to assign tasks optimally at test time. Experiments show emergent task-aware, multi-step coordination among agents, e.g., pressing a button to unlock a door, holding the door, and short-circuiting tasks.",
    "fetched_at": "2025-11-06T02:19:03.466814Z"
  },
  {
    "id": "2511.02314v1",
    "title": "Large-scale automatic carbon ion treatment planning for head and neck   cancers via parallel multi-agent reinforcement learning",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "physics.med-ph",
      "med-ph"
    ],
    "authors": [
      "Jueye Zhang",
      "Chao Yang",
      "Youfang Lai",
      "Kai-Wen Li",
      "Wenting Yan",
      "Yunzhou Xia",
      "Haimei Zhang",
      "Jingjing Zhou",
      "Gen Yang",
      "Chen Lin",
      "Tian Li",
      "Yibao Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02314v1",
    "abstract": "Head-and-neck cancer (HNC) planning is difficult because multiple critical organs-at-risk (OARs) are close to complex targets. Intensity-modulated carbon-ion therapy (IMCT) offers superior dose conformity and OAR sparing but remains slow due to relative biological effectiveness (RBE) modeling, leading to laborious, experience-based, and often suboptimal tuning of many treatment-planning parameters (TPPs). Recent deep learning (DL) methods are limited by data bias and plan feasibility, while reinforcement learning (RL) struggles to efficiently explore the exponentially large TPP search space. We propose a scalable multi-agent RL (MARL) framework for parallel tuning of 45 TPPs in IMCT. It uses a centralized-training decentralized-execution (CTDE) QMIX backbone with Double DQN, Dueling DQN, and recurrent encoding (DRQN) for stable learning in a high-dimensional, non-stationary environment. To enhance efficiency, we (1) use compact historical DVH vectors as state inputs, (2) apply a linear action-to-value transform mapping small discrete actions to uniform parameter adjustments, and (3) design an absolute, clinically informed piecewise reward aligned with plan scores. A synchronous multi-process worker system interfaces with the PHOENIX TPS for parallel optimization and accelerated data collection. On a head-and-neck dataset (10 training, 10 testing), the method tuned 45 parameters simultaneously and produced plans comparable to or better than expert manual ones (relative plan score: RL $85.93\\pm7.85%$ vs Manual $85.02\\pm6.92%$), with significant (p-value $<$ 0.05) improvements for five OARs. The framework efficiently explores high-dimensional TPP spaces and generates clinically competitive IMCT plans through direct TPS interaction, notably improving OAR sparing.",
    "fetched_at": "2025-11-06T02:19:03.466763Z"
  },
  {
    "id": "2511.02317v2",
    "title": "Fiedler-Based Characterization and Identification of Leaders in   Semi-Autonomous Networks",
    "date": "2025-11-04",
    "tags": [
      "math.OC",
      "OC"
    ],
    "authors": [
      "Evyatar Matmon",
      "Daniel Zelazo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02317v2",
    "abstract": "This paper addresses the problem of identifying leader nodes in semi-autonomous consensus networks from observed agent dynamics. Using the grounded Laplacian formulation, we derive spectral conditions that ensure the components of the Fiedler vector associated with leader and follower nodes are distinct. Building on the foundation, we emply the notion of relative tempo from prio works as an observable quantity that relates agents' steady-state velocities to the Fiedler vector. This relationship enables the development of a data-driven algorithm that reconstructs the Fiedler vector - and consequently identifies the leader set - using only steady-state velocity measurements, without requiring knowledge of the network topology. The proposed approach is validated through nuerical examples, demonstrating how spectral properties and relative tempo measurements can be combined to reveal hidden leadership structures in consensus networks.",
    "fetched_at": "2025-11-06T02:19:03.466683Z"
  },
  {
    "id": "2511.02504v1",
    "title": "Dexterous Robotic Piano Playing at Scale",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Le Chen",
      "Yi Zhao",
      "Jan Schneider",
      "Quankai Gao",
      "Simon Guist",
      "Cheng Qian",
      "Juho Kannala",
      "Bernhard Schölkopf",
      "Joni Pajarinen",
      "Dieter Büchler"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02504v1",
    "abstract": "Endowing robot hands with human-level dexterity has been a long-standing goal in robotics. Bimanual robotic piano playing represents a particularly challenging task: it is high-dimensional, contact-rich, and requires fast, precise control. We present OmniPianist, the first agent capable of performing nearly one thousand music pieces via scalable, human-demonstration-free learning. Our approach is built on three core components. First, we introduce an automatic fingering strategy based on Optimal Transport (OT), allowing the agent to autonomously discover efficient piano-playing strategies from scratch without demonstrations. Second, we conduct large-scale Reinforcement Learning (RL) by training more than 2,000 agents, each specialized in distinct music pieces, and aggregate their experience into a dataset named RP1M++, consisting of over one million trajectories for robotic piano playing. Finally, we employ a Flow Matching Transformer to leverage RP1M++ through large-scale imitation learning, resulting in the OmniPianist agent capable of performing a wide range of musical pieces. Extensive experiments and ablation studies highlight the effectiveness and scalability of our approach, advancing dexterous robotic piano playing at scale.",
    "fetched_at": "2025-11-06T02:19:03.466427Z"
  },
  {
    "id": "2511.02532v1",
    "title": "Agentic AI for Mobile Network RAN Management and Optimization",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jorge Pellejero",
      "Luis A. Hernández Gómez",
      "Luis Mendo Tomás",
      "Zoraida Frias Barroso"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02532v1",
    "abstract": "Agentic AI represents a new paradigm for automating complex systems by using Large AI Models (LAMs) to provide human-level cognitive abilities with multimodal perception, planning, memory, and reasoning capabilities. This will lead to a new generation of AI systems that autonomously decompose goals, retain context over time, learn continuously, operate across tools and environments, and adapt dynamically. The complexity of 5G and upcoming 6G networks renders manual optimization ineffective, pointing to Agentic AI as a method for automating decisions in dynamic RAN environments. However, despite its rapid advances, there is no established framework outlining the foundational components and operational principles of Agentic AI systems nor a universally accepted definition.   This paper contributes to ongoing research on Agentic AI in 5G and 6G networks by outlining its core concepts and then proposing a practical use case that applies Agentic principles to RAN optimization. We first introduce Agentic AI, tracing its evolution from classical agents and discussing the progress from workflows and simple AI agents to Agentic AI. Core design patterns-reflection, planning, tool use, and multi-agent collaboration-are then described to illustrate how intelligent behaviors are orchestrated. These theorical concepts are grounded in the context of mobile networks, with a focus on RAN management and optimization. A practical 5G RAN case study shows how time-series analytics and LAM-driven agents collaborate for KPI-based autonomous decision-making.",
    "fetched_at": "2025-11-06T02:19:03.466357Z"
  },
  {
    "id": "2511.02560v1",
    "title": "SigmaCollab: An Application-Driven Dataset for Physically Situated   Collaboration",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Dan Bohus",
      "Sean Andrist",
      "Ann Paradiso",
      "Nick Saw",
      "Tim Schoonbeek",
      "Maia Stiber"
    ],
    "institution": "Microsoft",
    "link": "http://arxiv.org/pdf/2511.02560v1",
    "abstract": "We introduce SigmaCollab, a dataset enabling research on physically situated human-AI collaboration. The dataset consists of a set of 85 sessions in which untrained participants were guided by a mixed-reality assistive AI agent in performing procedural tasks in the physical world. SigmaCollab includes a set of rich, multimodal data streams, such as the participant and system audio, egocentric camera views from the head-mounted device, depth maps, head, hand and gaze tracking information, as well as additional annotations performed post-hoc. While the dataset is relatively small in size (~ 14 hours), its application-driven and interactive nature brings to the fore novel research challenges for human-AI collaboration, and provides more realistic testing grounds for various AI models operating in this space. In future work, we plan to use the dataset to construct a set of benchmarks for physically situated collaboration in mixed-reality task assistive scenarios. SigmaCollab is available at https://github.com/microsoft/SigmaCollab.",
    "fetched_at": "2025-11-06T02:19:03.466304Z"
  },
  {
    "id": "2511.02605v1",
    "title": "Adaptive GR(1) Specification Repair for Liveness-Preserving Shielding in   Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Tiberiu-Andrei Georgescu",
      "Alexander W. Goodall",
      "Dalal Alrajeh",
      "Francesco Belardinelli",
      "Sebastian Uchitel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02605v1",
    "abstract": "Shielding is widely used to enforce safety in reinforcement learning (RL), ensuring that an agent's actions remain compliant with formal specifications. Classical shielding approaches, however, are often static, in the sense that they assume fixed logical specifications and hand-crafted abstractions. While these static shields provide safety under nominal assumptions, they fail to adapt when environment assumptions are violated. In this paper, we develop the first adaptive shielding framework - to the best of our knowledge - based on Generalized Reactivity of rank 1 (GR(1)) specifications, a tractable and expressive fragment of Linear Temporal Logic (LTL) that captures both safety and liveness properties. Our method detects environment assumption violations at runtime and employs Inductive Logic Programming (ILP) to automatically repair GR(1) specifications online, in a systematic and interpretable way. This ensures that the shield evolves gracefully, ensuring liveness is achievable and weakening goals only when necessary. We consider two case studies: Minepump and Atari Seaquest; showing that (i) static symbolic controllers are often severely suboptimal when optimizing for auxiliary rewards, and (ii) RL agents equipped with our adaptive shield maintain near-optimal reward and perfect logical compliance compared with static shields.",
    "fetched_at": "2025-11-06T02:19:03.466248Z"
  },
  {
    "id": "2511.02606v1",
    "title": "A Multi-Agent Psychological Simulation System for Human Behavior   Modeling",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Xiangen Hu",
      "Jiarui Tong",
      "Sheng Xu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02606v1",
    "abstract": "Training and education in human-centered fields require authentic practice, yet realistic simulations of human behavior have remained limited. We present a multi-agent psychological simulation system that models internal cognitive-affective processes to generate believable human behaviors. In contrast to black-box neural models, this system is grounded in established psychological theories (e.g., self-efficacy, mindset, social constructivism) and explicitly simulates an ``inner parliament'' of agents corresponding to key psychological factors. These agents deliberate and interact to determine the system's output behavior, enabling unprecedented transparency and alignment with human psychology. We describe the system's architecture and theoretical foundations, illustrate its use in teacher training and research, and discuss how it embodies principles of social learning, cognitive apprenticeship, deliberate practice, and meta-cognition.",
    "fetched_at": "2025-11-06T02:19:03.466195Z"
  },
  {
    "id": "2511.02762v1",
    "title": "From Solo to Symphony: Orchestrating Multi-Agent Collaboration with   Single-Agent Demos",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Xun Wang",
      "Zhuoran Li",
      "Yanshan Lin",
      "Hai Zhong",
      "Longbo Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02762v1",
    "abstract": "Training a team of agents from scratch in multi-agent reinforcement learning (MARL) is highly inefficient, much like asking beginners to play a symphony together without first practicing solo. Existing methods, such as offline or transferable MARL, can ease this burden, but they still rely on costly multi-agent data, which often becomes the bottleneck. In contrast, solo experiences are far easier to obtain in many important scenarios, e.g., collaborative coding, household cooperation, and search-and-rescue. To unlock their potential, we propose Solo-to-Collaborative RL (SoCo), a framework that transfers solo knowledge into cooperative learning. SoCo first pretrains a shared solo policy from solo demonstrations, then adapts it for cooperation during multi-agent training through a policy fusion mechanism that combines an MoE-like gating selector and an action editor. Experiments across diverse cooperative tasks show that SoCo significantly boosts the training efficiency and performance of backbone algorithms. These results demonstrate that solo demonstrations provide a scalable and effective complement to multi-agent data, making cooperative learning more practical and broadly applicable.",
    "fetched_at": "2025-11-06T02:19:03.465839Z"
  },
  {
    "id": "2511.02823v1",
    "title": "Optimizing AI Agent Attacks With Synthetic Data",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chloe Loughridge",
      "Paul Colognese",
      "Avery Griffin",
      "Tyler Tracy",
      "Jon Kutasov",
      "Joe Benton"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02823v1",
    "abstract": "As AI deployments become more complex and high-stakes, it becomes increasingly important to be able to estimate their risk. AI control is one framework for doing so. However, good control evaluations require eliciting strong attack policies. This can be challenging in complex agentic environments where compute constraints leave us data-poor. In this work, we show how to optimize attack policies in SHADE-Arena, a dataset of diverse realistic control environments. We do this by decomposing attack capability into five constituent skills -- suspicion modeling, attack selection, plan synthesis, execution and subtlety -- and optimizing each component individually. To get around the constraint of limited data, we develop a probabilistic model of attack dynamics, optimize our attack hyperparameters using this simulation, and then show that the results transfer to SHADE-Arena. This results in a substantial improvement in attack strength, reducing safety score from a baseline of 0.87 to 0.41 using our scaffold.",
    "fetched_at": "2025-11-06T02:19:03.465697Z"
  },
  {
    "id": "2511.02238v1",
    "title": "Deep Ideation: Designing LLM Agents to Generate Novel Research Ideas on   Scientific Concept Network",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Keyu Zhao",
      "Weiquan Lin",
      "Qirui Zheng",
      "Fengli Xu",
      "Yong Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02238v1",
    "abstract": "Novel research ideas play a critical role in advancing scientific inquiries. Recent advancements in Large Language Models (LLMs) have demonstrated their potential to generate novel research ideas by leveraging large-scale scientific literature. However, previous work in research ideation has primarily relied on simplistic methods, such as keyword co-occurrence or semantic similarity. These approaches focus on identifying statistical associations in the literature but overlook the complex, contextual relationships between scientific concepts, which are essential to effectively leverage knowledge embedded in human literature. For instance, papers that simultaneously mention \"keyword A\" and \"keyword B\" often present research ideas that integrate both concepts. Additionally, some LLM-driven methods propose and refine research ideas using the model's internal knowledge, but they fail to effectively utilize the scientific concept network, limiting the grounding of ideas in established research. To address these challenges, we propose the Deep Ideation framework to address these challenges, integrating a scientific network that captures keyword co-occurrence and contextual relationships, enriching LLM-driven ideation. The framework introduces an explore-expand-evolve workflow to iteratively refine research ideas, using an Idea Stack to track progress. A critic engine, trained on real-world reviewer feedback, guides the process by providing continuous feedback on the novelty and feasibility of ideas. Our experiments show that our approach improves the quality of generated ideas by 10.67% compared to other methods, with ideas surpassing top conference acceptance levels. Human evaluation highlights their practical value in scientific research, and ablation studies confirm the effectiveness of each component in the workflow. Code repo is available at https://github.com/kyZhao-1/Deep-Ideation.",
    "fetched_at": "2025-11-06T02:19:01.541059Z"
  },
  {
    "id": "2511.02239v1",
    "title": "LACY: A Vision-Language Model-based Language-Action Cycle for   Self-Improving Robotic Manipulation",
    "date": "2025-11-04",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Youngjin Hong",
      "Houjian Yu",
      "Mingen Li",
      "Changhyun Choi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02239v1",
    "abstract": "Learning generalizable policies for robotic manipulation increasingly relies on large-scale models that map language instructions to actions (L2A). However, this one-way paradigm often produces policies that execute tasks without deeper contextual understanding, limiting their ability to generalize or explain their behavior. We argue that the complementary skill of mapping actions back to language (A2L) is essential for developing more holistic grounding. An agent capable of both acting and explaining its actions can form richer internal representations and unlock new paradigms for self-supervised learning. We introduce LACY (Language-Action Cycle), a unified framework that learns such bidirectional mappings within a single vision-language model. LACY is jointly trained on three synergistic tasks: generating parameterized actions from language (L2A), explaining observed actions in language (A2L), and verifying semantic consistency between two language descriptions (L2C). This enables a self-improving cycle that autonomously generates and filters new training data through an active augmentation strategy targeting low-confidence cases, thereby improving the model without additional human labels. Experiments on pick-and-place tasks in both simulation and the real world show that LACY improves task success rates by 56.46% on average and yields more robust language-action grounding for robotic manipulation. Project page: https://vla2026.github.io/LACY/",
    "fetched_at": "2025-11-06T02:19:01.541002Z"
  },
  {
    "id": "2511.02246v1",
    "title": "Demo: Statistically Significant Results On Biases and Errors of LLMs Do   Not Guarantee Generalizable Results",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jonathan Liu",
      "Haoling Qiu",
      "Jonathan Lasko",
      "Damianos Karakos",
      "Mahsa Yarmohammadi",
      "Mark Dredze"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02246v1",
    "abstract": "Recent research has shown that hallucinations, omissions, and biases are prevalent in everyday use-cases of LLMs. However, chatbots used in medical contexts must provide consistent advice in situations where non-medical factors are involved, such as when demographic information is present. In order to understand the conditions under which medical chatbots fail to perform as expected, we develop an infrastructure that 1) automatically generates queries to probe LLMs and 2) evaluates answers to these queries using multiple LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples the space of patient demographics, histories, disorders, and writing styles to create realistic questions that we subsequently use to prompt LLMs. In 2), our evaluation pipeline provides hallucination and omission detection using LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge treatment category detectors. As a baseline study, we perform two case studies on inter-LLM agreement and the impact of varying the answering and evaluation LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's Kappa $\\kappa=0.118$), and only specific (answering, evaluation) LLM pairs yield statistically significant differences across writing styles, genders, and races. We recommend that studies using LLM evaluation use multiple LLMs as evaluators in order to avoid arriving at statistically significant but non-generalizable results, particularly in the absence of ground-truth data. We also suggest publishing inter-LLM agreement metrics for transparency. Our code and dataset are available here: https://github.com/BBN-E/medic-neurips-2025-demo.",
    "fetched_at": "2025-11-06T02:19:01.540952Z"
  },
  {
    "id": "2511.02303v1",
    "title": "Unlocking the Power of Multi-Agent LLM for Reasoning: From Lazy Agents   to Deliberation",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zhiwei Zhang",
      "Xiaomin Li",
      "Yudi Lin",
      "Hui Liu",
      "Ramraj Chandradevan",
      "Linlin Wu",
      "Minhua Lin",
      "Fali Wang",
      "Xianfeng Tang",
      "Qi He",
      "Suhang Wang"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02303v1",
    "abstract": "Large Language Models (LLMs) trained with reinforcement learning and verifiable rewards have achieved strong results on complex reasoning tasks. Recent work extends this paradigm to a multi-agent setting, where a meta-thinking agent proposes plans and monitors progress while a reasoning agent executes subtasks through sequential conversational turns. Despite promising performance, we identify a critical limitation: lazy agent behavior, in which one agent dominates while the other contributes little, undermining collaboration and collapsing the setup to an ineffective single agent. In this paper, we first provide a theoretical analysis showing why lazy behavior naturally arises in multi-agent reasoning. We then introduce a stable and efficient method for measuring causal influence, helping mitigate this issue. Finally, as collaboration intensifies, the reasoning agent risks getting lost in multi-turn interactions and trapped by previous noisy responses. To counter this, we propose a verifiable reward mechanism that encourages deliberation by allowing the reasoning agent to discard noisy outputs, consolidate instructions, and restart its reasoning process when necessary. Extensive experiments demonstrate that our framework alleviates lazy agent behavior and unlocks the full potential of multi-agent framework for complex reasoning tasks.",
    "fetched_at": "2025-11-06T02:19:01.540891Z"
  },
  {
    "id": "2511.02366v1",
    "title": "LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for   LLMs in Chinese Context",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yudong Li",
      "Zhongliang Yang",
      "Kejiang Chen",
      "Wenxuan Wang",
      "Tianxin Zhang",
      "Sifang Wan",
      "Kecheng Wang",
      "Haitian Li",
      "Xu Wang",
      "Lefan Cheng",
      "Youdan Yang",
      "Baocheng Chen",
      "Ziyu Liu",
      "Yufei Sun",
      "Liyan Wu",
      "Wenya Wen",
      "Xingchi Gu",
      "Peiru Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02366v1",
    "abstract": "In this work, we propose LiveSecBench, a dynamic and continuously updated safety benchmark specifically for Chinese-language LLM application scenarios. LiveSecBench evaluates models across six critical dimensions (Legality, Ethics, Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in the Chinese legal and social frameworks. This benchmark maintains relevance through a dynamic update schedule that incorporates new threat vectors, such as the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs, providing a landscape of AI safety in the context of Chinese language. The leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.",
    "fetched_at": "2025-11-06T02:19:01.540819Z"
  },
  {
    "id": "2511.02371v1",
    "title": "LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming   Alignment",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rohan Wandre",
      "Yash Gajewar",
      "Namrata Patel",
      "Vivek Dhalkari"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02371v1",
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as the dominant paradigm for grounding large language model outputs in verifiable evidence. However, as modern AI agents transition from static knowledge bases to continuous multimodal streams encompassing text, images, video, and audio, two critical challenges arise: maintaining index freshness without prohibitive re-indexing costs, and preserving cross-modal semantic consistency across heterogeneous embedding spaces. We present LUMA-RAG, a lifelong multimodal agent architecture featuring three key innovations: (i) a streaming, multi-tier memory system that dynamically spills embeddings from a hot HNSW tier to a compressed IVFPQ tier under strict memory budgets; (ii) a streaming CLAP->CLIP alignment bridge that maintains cross-modal consistency through incremental orthogonal Procrustes updates; and (iii) stability-aware retrieval telemetry providing Safe@k guarantees by jointly bounding alignment drift and quantization error. Experiments demonstrate robust text-to-image retrieval (Recall@10 = 0.94), graceful performance degradation under product quantization offloading, and provably stable audio-to-image rankings (Safe@1 = 1.0), establishing LUMA-RAG as a practical framework for production multimodal RAG systems.",
    "fetched_at": "2025-11-06T02:19:01.540730Z"
  },
  {
    "id": "2511.02378v1",
    "title": "Revisiting put-that-there, context aware window interactions via LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Riccardo Bovo",
      "Daniele Giunchi",
      "Pasquale Cascarano",
      "Eric J. Gonzalez",
      "Mar Gonzalez-Franco"
    ],
    "institution": "Google, Meta",
    "link": "http://arxiv.org/pdf/2511.02378v1",
    "abstract": "We revisit Bolt's classic \"Put-That-There\" concept for modern head-mounted displays by pairing Large Language Models (LLMs) with XR sensor and tech stack. The agent fuses (i) a semantically segmented 3-D environment, (ii) live application metadata, and (iii) users' verbal, pointing, and head-gaze cues to issue JSON window-placement actions. As a result, users can manage a panoramic workspace through: (1) explicit commands (\"Place Google Maps on the coffee table\"), (2) deictic speech plus gestures (\"Put that there\"), or (3) high-level goals (\"I need to send a message\"). Unlike traditional explicit interfaces, our system supports one-to-many action mappings and goal-centric reasoning, allowing the LLM to dynamically infer relevant applications and layout decisions, including interrelationships across tools. This enables seamless, intent-driven interaction without manual window juggling in immersive XR environments.",
    "fetched_at": "2025-11-06T02:19:01.540682Z"
  },
  {
    "id": "2511.02399v1",
    "title": "EvoDev: An Iterative Feature-Driven Framework for End-to-End Software   Development with LLM-based Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junwei Liu",
      "Chen Xu",
      "Chong Wang",
      "Tong Bai",
      "Weitong Chen",
      "Kaseng Wong",
      "Yiling Lou",
      "Xin Peng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02399v1",
    "abstract": "Recent advances in large language model agents offer the promise of automating end-to-end software development from natural language requirements. However, existing approaches largely adopt linear, waterfall-style pipelines, which oversimplify the iterative nature of real-world development and struggle with complex, large-scale projects. To address these limitations, we propose EvoDev, an iterative software development framework inspired by feature-driven development. EvoDev decomposes user requirements into a set of user-valued features and constructs a Feature Map, a directed acyclic graph that explicitly models dependencies between features. Each node in the feature map maintains multi-level information, including business logic, design, and code, which is propagated along dependencies to provide context for subsequent development iterations. We evaluate EvoDev on challenging Android development tasks and show that it outperforms the best-performing baseline, Claude Code, by a substantial margin of 56.8%, while improving single-agent performance by 16.0%-76.6% across different base LLMs, highlighting the importance of dependency modeling, context propagation, and workflow-aware agent design for complex software projects. Our work summarizes practical insights for designing iterative, LLM-driven development frameworks and informs future training of base LLMs to better support iterative software development.",
    "fetched_at": "2025-11-06T02:19:01.540633Z"
  },
  {
    "id": "2511.02424v1",
    "title": "ReAcTree: Hierarchical LLM Agent Trees with Control Flow for   Long-Horizon Task Planning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jae-Woo Choi",
      "Hyungmin Kim",
      "Hyobin Ong",
      "Minsu Jang",
      "Dohyung Kim",
      "Jaehong Kim",
      "Youngwoo Yoon"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02424v1",
    "abstract": "Recent advancements in large language models (LLMs) have enabled significant progress in decision-making and task planning for embodied autonomous agents. However, most existing methods still struggle with complex, long-horizon tasks because they rely on a monolithic trajectory that entangles all past decisions and observations, attempting to solve the entire task in a single unified process. To address this limitation, we propose ReAcTree, a hierarchical task-planning method that decomposes a complex goal into more manageable subgoals within a dynamically constructed agent tree. Each subgoal is handled by an LLM agent node capable of reasoning, acting, and further expanding the tree, while control flow nodes coordinate the execution strategies of agent nodes. In addition, we integrate two complementary memory systems: each agent node retrieves goal-specific, subgoal-level examples from episodic memory and shares environment-specific observations through working memory. Experiments on the WAH-NL and ALFRED datasets demonstrate that ReAcTree consistently outperforms strong task-planning baselines such as ReAct across diverse LLMs. Notably, on WAH-NL, ReAcTree achieves a 61% goal success rate with Qwen 2.5 72B, nearly doubling ReAct's 31%.",
    "fetched_at": "2025-11-06T02:19:01.540567Z"
  },
  {
    "id": "2511.02427v1",
    "title": "From the Laboratory to Real-World Application: Evaluating Zero-Shot   Scene Interpretation on Edge Devices for Mobile Robotics",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Nicolas Schuler",
      "Lea Dewald",
      "Nick Baldig",
      "Jürgen Graf"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02427v1",
    "abstract": "Video Understanding, Scene Interpretation and Commonsense Reasoning are highly challenging tasks enabling the interpretation of visual information, allowing agents to perceive, interact with and make rational decisions in its environment. Large Language Models (LLMs) and Visual Language Models (VLMs) have shown remarkable advancements in these areas in recent years, enabling domain-specific applications as well as zero-shot open vocabulary tasks, combining multiple domains. However, the required computational complexity poses challenges for their application on edge devices and in the context of Mobile Robotics, especially considering the trade-off between accuracy and inference time. In this paper, we investigate the capabilities of state-of-the-art VLMs for the task of Scene Interpretation and Action Recognition, with special regard to small VLMs capable of being deployed to edge devices in the context of Mobile Robotics. The proposed pipeline is evaluated on a diverse dataset consisting of various real-world cityscape, on-campus and indoor scenarios. The experimental evaluation discusses the potential of these small models on edge devices, with particular emphasis on challenges, weaknesses, inherent model biases and the application of the gained information. Supplementary material is provided via the following repository: https://datahub.rz.rptu.de/hstr-csrl-public/publications/scene-interpretation-on-edge-devices/",
    "fetched_at": "2025-11-06T02:19:01.540495Z"
  },
  {
    "id": "2511.02469v1",
    "title": "Modeling Hawkish-Dovish Latent Beliefs in Multi-Agent Debate-Based LLMs   for Monetary Policy Decision Classification",
    "date": "2025-11-04",
    "tags": [
      "q-fin.CP",
      "CP",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kaito Takano",
      "Masanori Hirano",
      "Kei Nakagawa"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02469v1",
    "abstract": "Accurately forecasting central bank policy decisions, particularly those of the Federal Open Market Committee(FOMC) has become increasingly important amid heightened economic uncertainty. While prior studies have used monetary policy texts to predict rate changes, most rely on static classification models that overlook the deliberative nature of policymaking. This study proposes a novel framework that structurally imitates the FOMC's collective decision-making process by modeling multiple large language models(LLMs) as interacting agents. Each agent begins with a distinct initial belief and produces a prediction based on both qualitative policy texts and quantitative macroeconomic indicators. Through iterative rounds, agents revise their predictions by observing the outputs of others, simulating deliberation and consensus formation. To enhance interpretability, we introduce a latent variable representing each agent's underlying belief(e.g., hawkish or dovish), and we theoretically demonstrate how this belief mediates the perception of input information and interaction dynamics. Empirical results show that this debate-based approach significantly outperforms standard LLMs-based baselines in prediction accuracy. Furthermore, the explicit modeling of beliefs provides insights into how individual perspectives and social influence shape collective policy forecasts.",
    "fetched_at": "2025-11-06T02:19:01.540442Z"
  },
  {
    "id": "2511.02503v1",
    "title": "Adapting General-Purpose Foundation Models for X-ray Ptychography in   Low-Data Regimes",
    "date": "2025-11-04",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Robinson Umeike",
      "Neil Getty",
      "Yin Xiangyu",
      "Yi Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02503v1",
    "abstract": "The automation of workflows in advanced microscopy is a key goal where foundation models like Language Models (LLMs) and Vision-Language Models (VLMs) show great potential. However, adapting these general-purpose models for specialized scientific tasks is critical, and the optimal domain adaptation strategy is often unclear. To address this, we introduce PtychoBench, a new multi-modal, multi-task benchmark for ptychographic analysis. Using this benchmark, we systematically compare two specialization strategies: Supervised Fine-Tuning (SFT) and In-Context Learning (ICL). We evaluate these strategies on a visual artifact detection task with VLMs and a textual parameter recommendation task with LLMs in a data-scarce regime. Our findings reveal that the optimal specialization pathway is task-dependent. For the visual task, SFT and ICL are highly complementary, with a fine-tuned model guided by context-aware examples achieving the highest mean performance (Micro-F1 of 0.728). Conversely, for the textual task, ICL on a large base model is the superior strategy, reaching a peak Micro-F1 of 0.847 and outperforming a powerful \"super-expert\" SFT model (0-shot Micro-F1 of 0.839). We also confirm the superiority of context-aware prompting and identify a consistent contextual interference phenomenon in fine-tuned models. These results, benchmarked against strong baselines including GPT-4o and a DINOv3-based classifier, offer key observations for AI in science: the optimal specialization path in our benchmark is dependent on the task modality, offering a clear framework for developing more effective science-based agentic systems.",
    "fetched_at": "2025-11-06T02:19:01.540395Z"
  },
  {
    "id": "2511.02651v1",
    "title": "Apriel-H1: Towards Efficient Enterprise Reasoning Models",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oleksiy Ostapenko",
      "Luke Kumar",
      "Raymond Li",
      "Denis Kocetkov",
      "Joel Lamy-Poirier",
      "Shruthan Radhakrishna",
      "Soham Parikh",
      "Shambhavi Mishra",
      "Sebastien Paquet",
      "Srinivas Sunkara",
      "Valérie Bécaert",
      "Sathwik Tejaswi Madhusudhan",
      "Torsten Scholak"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02651v1",
    "abstract": "Large Language Models (LLMs) achieve remarkable reasoning capabilities through transformer architectures with attention mechanisms. However, transformers suffer from quadratic time and memory complexity in the attention module (MHA) and require caching key-value states during inference, which severely limits throughput and scalability. High inference throughput is critical for agentic tasks, long-context reasoning, efficient deployment under high request loads, and more efficient test-time compute scaling.   State Space Models (SSMs) such as Mamba offer a promising alternative with linear inference complexity and a constant memory footprint via recurrent computation with fixed-size hidden states. In this technical report we introduce the Apriel-H1 family of hybrid LLMs that combine transformer attention and SSM sequence mixers for efficient reasoning at 15B model size. These models are obtained through incremental distillation from a pretrained reasoning transformer, Apriel-Nemotron-15B-Thinker, progressively replacing less critical attention layers with linear Mamba blocks.   We release multiple post-distillation variants of Apriel-H1-15B-Thinker with different SSM-to-MHA ratios and analyse how reasoning performance degrades as more Mamba layers replace MHA. Additionally, we release a 30/50 hybrid variant of Apriel-H1, further fine-tuned on a supervised dataset of reasoning traces, achieving over 2x higher inference throughput when deployed in the production-ready vLLM environment, with minimal degradation in reasoning performance. This shows that distilled hybrid SSM-Transformer architectures can deliver substantial efficiency gains over the pretrained transformer equivalent without substantially compromising the reasoning quality.",
    "fetched_at": "2025-11-06T02:19:01.540344Z"
  },
  {
    "id": "2511.02690v1",
    "title": "Curriculum Design for Trajectory-Constrained Agent: Compressing   Chain-of-Thought Tokens in LLMs",
    "date": "2025-11-04",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Georgios Tzannetos",
      "Parameswaran Kamalaruban",
      "Adish Singla"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02690v1",
    "abstract": "Training agents to operate under strict constraints during deployment, such as limited resource budgets or stringent safety requirements, presents significant challenges, especially when these constraints render the task complex. In this work, we propose a curriculum learning strategy that gradually tightens constraints during training, enabling the agent to incrementally master the deployment requirements. Inspired by self-paced learning techniques in unconstrained reinforcement learning (RL), our approach facilitates a smoother transition to challenging environments by initially training on simplified versions of the constraints and progressively introducing the full deployment conditions. We provide a theoretical analysis using an RL agent in a binary-tree Markov Decision Process (MDP) to demonstrate that our curriculum strategy can accelerate training relative to a baseline approach that imposes the trajectory constraints from the outset. Moreover, we empirically validate the effectiveness and generality of our method across both RL and large language model (LLM) agents in diverse settings, including a binary-tree MDP, a multi-task navigation domain, and a math reasoning task with two benchmarks. These results highlight the potential of curriculum design in enhancing the efficiency and performance of agents operating under complex trajectory constraints during deployment. Moreover, when applied to LLMs, our strategy enables compression of output chain-of-thought tokens, achieving a substantial inference speedup on consumer hardware, demonstrating its effectiveness for resource-constrained deployment.",
    "fetched_at": "2025-11-06T02:19:01.540260Z"
  },
  {
    "id": "2511.02734v1",
    "title": "CostBench: Evaluating Multi-Turn Cost-Optimal Planning and Adaptation in   Dynamic Environments for LLM Tool-Use Agents",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jiayu Liu",
      "Cheng Qian",
      "Zhaochen Su",
      "Qing Zong",
      "Shijue Huang",
      "Bingxiang He",
      "Yi R. Fung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02734v1",
    "abstract": "Current evaluations of Large Language Model (LLM) agents primarily emphasize task completion, often overlooking resource efficiency and adaptability. This neglects a crucial capability: agents' ability to devise and adjust cost-optimal plans in response to changing environments. To bridge this gap, we introduce CostBench, a scalable, cost-centric benchmark designed to evaluate agents' economic reasoning and replanning abilities. Situated in the travel-planning domain, CostBench comprises tasks solvable via multiple sequences of atomic and composite tools with diverse, customizable costs. It also supports four types of dynamic blocking events, such as tool failures and cost changes, to simulate real-world unpredictability and necessitate agents to adapt in real time. Evaluating leading open-sourced and proprietary models on CostBench reveals a substantial gap in cost-aware planning: agents frequently fail to identify cost-optimal solutions in static settings, with even GPT-5 achieving less than 75% exact match rate on the hardest tasks, and performance further dropping by around 40% under dynamic conditions. By diagnosing these weaknesses, CostBench lays the groundwork for developing future agents that are both economically rational and robust.",
    "fetched_at": "2025-11-06T02:19:01.540212Z"
  },
  {
    "id": "2511.02748v1",
    "title": "Agentic World Modeling for 6G: Near-Real-Time Generative State-Space   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.NI",
      "NI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Farhad Rezazadeh",
      "Hatim Chergui",
      "Merouane Debbah",
      "Houbing Song",
      "Dusit Niyato",
      "Lingjia Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02748v1",
    "abstract": "We argue that sixth-generation (6G) intelligence is not fluent token prediction but the capacity to imagine and choose -- to simulate future scenarios, weigh trade-offs, and act with calibrated uncertainty. We reframe open radio access network (O-RAN) near-real-time (Near-RT) control via counterfactual dynamics and a world modeling (WM) paradigm that learns an action-conditioned generative state space. This enables quantitative \"what-if\" forecasting beyond large language models (LLMs) as the primary modeling primitive. Actions such as physical resource blocks (PRBs) are treated as first-class control inputs in a causal world model, and both aleatoric and epistemic uncertainty are modeled for prediction and what-if analysis. An agentic, model predictive control (MPC)-based cross-entropy method (CEM) planner operates over short horizons, using prior-mean rollouts within data-driven PRB bounds to maximize a deterministic reward. The model couples multi-scale structured state-space mixtures (MS3M) with a compact stochastic latent to form WM-MS3M, summarizing key performance indicators (KPIs) histories and predicting next-step KPIs under hypothetical PRB sequences. On realistic O-RAN traces, WM-MS3M cuts mean absolute error (MAE) by 1.69% versus MS3M with 32% fewer parameters and similar latency, and achieves 35-80% lower root mean squared error (RMSE) than attention/hybrid baselines with 2.3-4.1x faster inference, enabling rare-event simulation and offline policy screening.",
    "fetched_at": "2025-11-06T02:19:01.540151Z"
  },
  {
    "id": "2511.02755v1",
    "title": "Controlling Performance and Budget of a Centralized Multi-agent LLM   System with Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bowen Jin",
      "TJ Collins",
      "Donghan Yu",
      "Mert Cemri",
      "Shenao Zhang",
      "Mengyu Li",
      "Jay Tang",
      "Tian Qin",
      "Zhiyang Xu",
      "Jiarui Lu",
      "Guoli Yin",
      "Jiawei Han",
      "Zirui Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02755v1",
    "abstract": "Large language models (LLMs) exhibit complementary strengths across domains and come with varying inference costs, motivating the design of multi-agent LLM systems where specialized models collaborate efficiently. Existing approaches predominantly rely on decentralized frameworks, which invoke multiple LLMs for every input and thus lead to substantial and uncontrolled inference costs. In this work, we introduce a centralized multi-LLM framework, where a controller LLM selectively coordinates a pool of expert models in a cost-efficient and cost-controllable manner. We formulate this coordination problem as reinforcement learning with dual objectives: maximizing task performance while minimizing the overall inference cost. In addition, we expect the multi-agent system to have adapted behavior with different budget conditions during inference. To this end, we propose CoRL, a reinforcement learning framework that optimizes the performance cost trade-off in a controllable multi-budget setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a single system to surpass the best expert LLM under high-budget settings, while maintaining strong performance in more economical low-budget modes, highlighting the effectiveness of centralized coordination for scalable and cost-efficient multi-agent LLM systems.",
    "fetched_at": "2025-11-06T02:19:01.540091Z"
  },
  {
    "id": "2511.02794v1",
    "title": "When One Modality Sabotages the Others: A Diagnostic Lens on Multimodal   Reasoning",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Chenyu Zhang",
      "Minsol Kim",
      "Shohreh Ghorbani",
      "Jingyao Wu",
      "Rosalind Picard",
      "Patricia Maes",
      "Paul Pu Liang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02794v1",
    "abstract": "Despite rapid growth in multimodal large language models (MLLMs), their reasoning traces remain opaque: it is often unclear which modality drives a prediction, how conflicts are resolved, or when one stream dominates. In this paper, we introduce modality sabotage, a diagnostic failure mode in which a high-confidence unimodal error overrides other evidence and misleads the fused result. To analyze such dynamics, we propose a lightweight, model-agnostic evaluation layer that treats each modality as an agent, producing candidate labels and a brief self-assessment used for auditing. A simple fusion mechanism aggregates these outputs, exposing contributors (modalities supporting correct outcomes) and saboteurs (modalities that mislead). Applying our diagnostic layer in a case study on multimodal emotion recognition benchmarks with foundation models revealed systematic reliability profiles, providing insight into whether failures may arise from dataset artifacts or model limitations. More broadly, our framework offers a diagnostic scaffold for multimodal reasoning, supporting principled auditing of fusion dynamics and informing possible interventions.",
    "fetched_at": "2025-11-06T02:19:01.540008Z"
  },
  {
    "id": "2511.02805v1",
    "title": "MemSearcher: Training LLMs to Reason, Search and Manage Memory via   End-to-End Reinforcement Learning",
    "date": "2025-11-04",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qianhao Yuan",
      "Jie Lou",
      "Zichao Li",
      "Jiawei Chen",
      "Yaojie Lu",
      "Hongyu Lin",
      "Le Sun",
      "Debing Zhang",
      "Xianpei Han"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02805v1",
    "abstract": "Typical search agents concatenate the entire interaction history into the LLM context, preserving information integrity but producing long, noisy contexts, resulting in high computation and memory costs. In contrast, using only the current turn avoids this overhead but discards essential information. This trade-off limits the scalability of search agents. To address this challenge, we propose MemSearcher, an agent workflow that iteratively maintains a compact memory and combines the current turn with it. At each turn, MemSearcher fuses the user's question with the memory to generate reasoning traces, perform search actions, and update memory to retain only information essential for solving the task. This design stabilizes context length across multi-turn interactions, improving efficiency without sacrificing accuracy. To optimize this workflow, we introduce multi-context GRPO, an end-to-end RL framework that jointly optimize reasoning, search strategies, and memory management of MemSearcher Agents. Specifically, multi-context GRPO samples groups of trajectories under different contexts and propagates trajectory-level advantages across all conversations within them. Trained on the same dataset as Search-R1, MemSearcher achieves significant improvements over strong baselines on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher even outperforms 7B-based baselines, demonstrating that striking a balance between information integrity and efficiency yields both higher accuracy and lower computational overhead. The code and models will be publicly available at https://github.com/icip-cas/MemSearcher",
    "fetched_at": "2025-11-06T02:19:01.539941Z"
  },
  {
    "id": "2511.02834v2",
    "title": "Agent-Omni: Test-Time Multimodal Reasoning via Model Coordination for   Understanding Anything",
    "date": "2025-11-04",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Huawei Lin",
      "Yunzhi Shi",
      "Tong Geng",
      "Weijie Zhao",
      "Wei Wang",
      "Ravender Pal Singh"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02834v2",
    "abstract": "Multimodal large language models (MLLMs) have shown strong capabilities but remain limited to fixed modality pairs and require costly fine-tuning with large aligned datasets. Building fully omni-capable models that can integrate text, images, audio, and video remains impractical and lacks robust reasoning support. In this paper, we propose an Agent-Omni framework that coordinates existing foundation models through a master-agent system, enabling flexible multimodal reasoning without retraining. The master agent interprets user intent, delegates subtasks to modality-specific agents, and integrates their outputs into coherent responses. Extensive experiments across text, image, audio, video, and omni benchmarks show that Agent-Omni consistently achieves state-of-the-art performance, particularly on tasks requiring complex cross-modal reasoning. Its agent-based design enables seamless integration of specialized foundation models, ensuring adaptability to diverse inputs while maintaining transparency and interpretability. In addition, the framework is modular and easily extensible, allowing future improvements as stronger models become available.",
    "fetched_at": "2025-11-06T02:19:01.539847Z"
  },
  {
    "id": "2511.02048v1",
    "title": "Finding Probably Approximate Optimal Solutions by Training to Estimate   the Optimal Values of Subproblems",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nimrod Megiddo",
      "Segev Wasserkrug",
      "Orit Davidovich",
      "Shimrit Shtern"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02048v1",
    "abstract": "The paper is about developing a solver for maximizing a real-valued function of binary variables. The solver relies on an algorithm that estimates the optimal objective-function value of instances from the underlying distribution of objectives and their respective sub-instances. The training of the estimator is based on an inequality that facilitates the use of the expected total deviation from optimality conditions as a loss function rather than the objective-function itself. Thus, it does not calculate values of policies, nor does it rely on solved instances.",
    "fetched_at": "2025-11-06T02:19:07.220839Z"
  },
  {
    "id": "2511.02052v1",
    "title": "Solving cold start in news recommendations: a RippleNet-based system for   large scale media outlet",
    "date": "2025-11-03",
    "tags": [
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Karol Radziszewski",
      "Michał Szpunar",
      "Piotr Ociepka",
      "Mateusz Buczyński"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02052v1",
    "abstract": "We present a scalable recommender system implementation based on RippleNet, tailored for the media domain with a production deployment in Onet.pl, one of Poland's largest online media platforms. Our solution addresses the cold-start problem for newly published content by integrating content-based item embeddings into the knowledge propagation mechanism of RippleNet, enabling effective scoring of previously unseen items. The system architecture leverages Amazon SageMaker for distributed training and inference, and Apache Airflow for orchestrating data pipelines and model retraining workflows. To ensure high-quality training data, we constructed a comprehensive golden dataset consisting of user and item features and a separate interaction table, all enabling flexible extensions and integration of new signals.",
    "fetched_at": "2025-11-06T02:19:07.220798Z"
  },
  {
    "id": "2511.02053v1",
    "title": "Data-driven Learning of Interaction Laws in Multispecies Particle   Systems with Gaussian Processes: Convergence Theory and Applications",
    "date": "2025-11-03",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Jinchao Feng",
      "Charles Kulick",
      "Sui Tang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02053v1",
    "abstract": "We develop a Gaussian process framework for learning interaction kernels in multi-species interacting particle systems from trajectory data. Such systems provide a canonical setting for multiscale modeling, where simple microscopic interaction rules generate complex macroscopic behaviors. While our earlier work established a Gaussian process approach and convergence theory for single-species systems, and later extended to second-order models with alignment and energy-type interactions, the multi-species setting introduces new challenges: heterogeneous populations interact both within and across species, the number of unknown kernels grows, and asymmetric interactions such as predator-prey dynamics must be accommodated. We formulate the learning problem in a nonparametric Bayesian setting and establish rigorous statistical guarantees. Our analysis shows recoverability of the interaction kernels, provides quantitative error bounds, and proves statistical optimality of posterior estimators, thereby unifying and generalizing previous single-species theory. Numerical experiments confirm the theoretical predictions and demonstrate the effectiveness of the proposed approach, highlighting its advantages over existing kernel-based methods. This work contributes a complete statistical framework for data-driven inference of interaction laws in multi-species systems, advancing the broader multiscale modeling program of connecting microscopic particle dynamics with emergent macroscopic behavior.",
    "fetched_at": "2025-11-06T02:19:07.220752Z"
  },
  {
    "id": "2511.02062v1",
    "title": "Vortex: Hosting ML Inference and Knowledge Retrieval Services With Tight   Latency and Throughput Requirements",
    "date": "2025-11-03",
    "tags": [
      "cs.DB",
      "DB",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuting Yang",
      "Tiancheng Yuan",
      "Jamal Hashim",
      "Thiago Garrett",
      "Jeffrey Qian",
      "Ann Zhang",
      "Yifan Wang",
      "Weijia Song",
      "Ken Birman"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02062v1",
    "abstract": "There is growing interest in deploying ML inference and knowledge retrieval as services that could support both interactive queries by end users and more demanding request flows that arise from AIs integrated into a end-user applications and deployed as agents. Our central premise is that these latter cases will bring service level latency objectives (SLOs). Existing ML serving platforms use batching to optimize for high throughput, exposing them to unpredictable tail latencies. Vortex enables an SLO-first approach. For identical tasks, Vortex's pipelines achieve significantly lower and more stable latencies than TorchServe and Ray Serve over a wide range of workloads, often enabling a given SLO target at more than twice the request rate. When RDMA is available, the Vortex advantage is even more significant.",
    "fetched_at": "2025-11-06T02:19:07.220700Z"
  },
  {
    "id": "2511.02069v1",
    "title": "Complete asymptotic type-token relationship for growing complex systems   with inverse power-law count rankings",
    "date": "2025-11-03",
    "tags": [
      "physics.soc-ph",
      "soc-ph",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Pablo Rosillo-Rodes",
      "Laurent Hébert-Dufresne",
      "Peter Sheridan Dodds"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02069v1",
    "abstract": "The growth dynamics of complex systems often exhibit statistical regularities involving power-law relationships. For real finite complex systems formed by countable tokens (animals, words) as instances of distinct types (species, dictionary entries), an inverse power-law scaling $S \\sim r^{-\\alpha}$ between type count $S$ and type rank $r$, widely known as Zipf's law, is widely observed to varying degrees of fidelity. A secondary, summary relationship is Heaps' law, which states that the number of types scales sublinearly with the total number of observed tokens present in a growing system. Here, we propose an idealized model of a growing system that (1) deterministically produces arbitrary inverse power-law count rankings for types, and (2) allows us to determine the exact asymptotics of the type-token relationship. Our argument improves upon and remedies earlier work. We obtain a unified asymptotic expression for all values of $\\alpha$, which corrects the special cases of $\\alpha = 1$ and $\\alpha \\gg 1$. Our approach relies solely on the form of count rankings, avoids unnecessary approximations, and does not involve any stochastic mechanisms or sampling processes. We thereby demonstrate that a general type-token relationship arises solely as a consequence of Zipf's law.",
    "fetched_at": "2025-11-06T02:19:07.220635Z"
  },
  {
    "id": "2511.02077v1",
    "title": "Beyond Static Cutoffs: One-Shot Dynamic Thresholding for Diffusion   Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jucheng Shen",
      "Yeonju Ro"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02077v1",
    "abstract": "Masked diffusion language models (MDLMs) are becoming competitive with their autoregressive counterparts but typically decode with fixed steps and sequential unmasking. To accelerate decoding, recent work such as Fast-dLLM enables parallel decoding via a static global confidence threshold, yet we observe strong block- and step-wise confidence fluctuations and, within a dataset, near-identical confidence trajectories across inputs as measured by cosine similarity. Motivated by these observations, we introduce One-Shot Dynamic Thresholding (OSDT), which calibrates thresholds on a single sequence and applies them to subsequent inputs with negligible overhead. On GPQA, GSM8K, and HumanEval, OSDT attains superior accuracy-throughput trade-offs (+24% tokens/s on GSM8K at the best accuracy, +45% on GPQA with comparable accuracy, and +50% on HumanEval with a modest accuracy gap). Beyond these results, our findings suggest broader opportunities to leverage reusable task-level confidence signatures for more general-purpose algorithmic and systems innovations in diffusion decoding.",
    "fetched_at": "2025-11-06T02:19:07.220481Z"
  },
  {
    "id": "2511.02083v1",
    "title": "Watermarking Discrete Diffusion Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Avi Bagchi",
      "Akhil Bhimaraju",
      "Moulik Choraria",
      "Daniel Alabi",
      "Lav R. Varshney"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02083v1",
    "abstract": "Watermarking has emerged as a promising technique to track AI-generated content and differentiate it from authentic human creations. While prior work extensively studies watermarking for autoregressive large language models (LLMs) and image diffusion models, none address discrete diffusion language models, which are becoming popular due to their high inference throughput. In this paper, we introduce the first watermarking method for discrete diffusion models by applying the distribution-preserving Gumbel-max trick at every diffusion step and seeding the randomness with the sequence index to enable reliable detection. We experimentally demonstrate that our scheme is reliably detectable on state-of-the-art diffusion language models and analytically prove that it is distortion-free with an exponentially decaying probability of false detection in the token sequence length.",
    "fetched_at": "2025-11-06T02:19:07.220442Z"
  },
  {
    "id": "2511.02087v1",
    "title": "Energy Loss Functions for Physical Systems",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "physics.comp-ph",
      "comp-ph"
    ],
    "authors": [
      "Sékou-Oumar Kaba",
      "Kusha Sareen",
      "Daniel Levy",
      "Siamak Ravanbakhsh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02087v1",
    "abstract": "Effectively leveraging prior knowledge of a system's physics is crucial for applications of machine learning to scientific domains. Previous approaches mostly focused on incorporating physical insights at the architectural level. In this paper, we propose a framework to leverage physical information directly into the loss function for prediction and generative modeling tasks on systems like molecules and spins. We derive energy loss functions assuming that each data sample is in thermal equilibrium with respect to an approximate energy landscape. By using the reverse KL divergence with a Boltzmann distribution around the data, we obtain the loss as an energy difference between the data and the model predictions. This perspective also recasts traditional objectives like MSE as energy-based, but with a physically meaningless energy. In contrast, our formulation yields physically grounded loss functions with gradients that better align with valid configurations, while being architecture-agnostic and computationally efficient. The energy loss functions also inherently respect physical symmetries. We demonstrate our approach on molecular generation and spin ground-state prediction and report significant improvements over baselines.",
    "fetched_at": "2025-11-06T02:19:07.220394Z"
  },
  {
    "id": "2511.02089v1",
    "title": "LLM Probing with Contrastive Eigenproblems: Improving Understanding and   Applicability of CCS",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Stefan F. Schouten",
      "Peter Bloem"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02089v1",
    "abstract": "Contrast-Consistent Search (CCS) is an unsupervised probing method able to test whether large language models represent binary features, such as sentence truth, in their internal activations. While CCS has shown promise, its two-term objective has been only partially understood. In this work, we revisit CCS with the aim of clarifying its mechanisms and extending its applicability. We argue that what should be optimized for, is relative contrast consistency. Building on this insight, we reformulate CCS as an eigenproblem, yielding closed-form solutions with interpretable eigenvalues and natural extensions to multiple variables. We evaluate these approaches across a range of datasets, finding that they recover similar performance to CCS, while avoiding problems around sensitivity to random initialization. Our results suggest that relativizing contrast consistency not only improves our understanding of CCS but also opens pathways for broader probing and mechanistic interpretability methods.",
    "fetched_at": "2025-11-06T02:19:07.220346Z"
  },
  {
    "id": "2511.02091v1",
    "title": "Natural Building Blocks for Structured World Models: Theory, Evidence,   and Scaling",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lancelot Da Costa",
      "Sanjeev Namjoshi",
      "Mohammed Abbas Ansari",
      "Bernhard Schölkopf"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02091v1",
    "abstract": "The field of world modeling is fragmented, with researchers developing bespoke architectures that rarely build upon each other. We propose a framework that specifies the natural building blocks for structured world models based on the fundamental stochastic processes that any world model must capture: discrete processes (logic, symbols) and continuous processes (physics, dynamics); the world model is then defined by the hierarchical composition of these building blocks. We examine Hidden Markov Models (HMMs) and switching linear dynamical systems (sLDS) as natural building blocks for discrete and continuous modeling--which become partially-observable Markov decision processes (POMDPs) and controlled sLDS when augmented with actions. This modular approach supports both passive modeling (generation, forecasting) and active control (planning, decision-making) within the same architecture. We avoid the combinatorial explosion of traditional structure learning by largely fixing the causal architecture and searching over only four depth parameters. We review practical expressiveness through multimodal generative modeling (passive) and planning from pixels (active), with performance competitive to neural approaches while maintaining interpretability. The core outstanding challenge is scalable joint structure-parameter learning; current methods finesse this by cleverly growing structure and parameters incrementally, but are limited in their scalability. If solved, these natural building blocks could provide foundational infrastructure for world modeling, analogous to how standardized layers enabled progress in deep learning.",
    "fetched_at": "2025-11-06T02:19:07.220307Z"
  },
  {
    "id": "2511.02092v1",
    "title": "Uncertainty Guided Online Ensemble for Non-stationary Data Streams in   Fusion Science",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "physics.plasm-ph",
      "plasm-ph"
    ],
    "authors": [
      "Kishansingh Rajput",
      "Malachi Schram",
      "Brian Sammuli",
      "Sen Lin"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.02092v1",
    "abstract": "Machine Learning (ML) is poised to play a pivotal role in the development and operation of next-generation fusion devices. Fusion data shows non-stationary behavior with distribution drifts, resulted by both experimental evolution and machine wear-and-tear. ML models assume stationary distribution and fail to maintain performance when encountered with such non-stationary data streams. Online learning techniques have been leveraged in other domains, however it has been largely unexplored for fusion applications. In this paper, we present an application of online learning to continuously adapt to drifting data stream for prediction of Toroidal Field (TF) coils deflection at the DIII-D fusion facility. The results demonstrate that online learning is critical to maintain ML model performance and reduces error by 80% compared to a static model. Moreover, traditional online learning can suffer from short-term performance degradation as ground truth is not available before making the predictions. As such, we propose an uncertainty guided online ensemble method to further improve the performance. The Deep Gaussian Process Approximation (DGPA) technique is leveraged for calibrated uncertainty estimation and the uncertainty values are then used to guide a meta-algorithm that produces predictions based on an ensemble of learners trained on different horizon of historical data. The DGPA also provides uncertainty estimation along with the predictions for decision makers. The online ensemble and the proposed uncertainty guided online ensemble reduces predictions error by about 6%, and 10% respectively over standard single model based online learning.",
    "fetched_at": "2025-11-06T02:19:07.220255Z"
  },
  {
    "id": "2511.02100v1",
    "title": "Geometric Data Valuation via Leverage Scores",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.NA",
      "NA",
      "math.NA",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Rodrigo Mendoza-Smith"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02100v1",
    "abstract": "Shapley data valuation provides a principled, axiomatic framework for assigning importance to individual datapoints, and has gained traction in dataset curation, pruning, and pricing. However, it is a combinatorial measure that requires evaluating marginal utility across all subsets of the data, making it computationally infeasible at scale. We propose a geometric alternative based on statistical leverage scores, which quantify each datapoint's structural influence in the representation space by measuring how much it extends the span of the dataset and contributes to the effective dimensionality of the training problem. We show that our scores satisfy the dummy, efficiency, and symmetry axioms of Shapley valuation and that extending them to \\emph{ridge leverage scores} yields strictly positive marginal gains that connect naturally to classical A- and D-optimal design criteria. We further show that training on a leverage-sampled subset produces a model whose parameters and predictive risk are within $O(\\varepsilon)$ of the full-data optimum, thereby providing a rigorous link between data valuation and downstream decision quality. Finally, we conduct an active learning experiment in which we empirically demonstrate that ridge-leverage sampling outperforms standard baselines without requiring access gradients or backward passes.",
    "fetched_at": "2025-11-06T02:19:07.220150Z"
  },
  {
    "id": "2511.02101v2",
    "title": "Measuring the Intrinsic Dimension of Earth Representations",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.IT",
      "IT",
      "math.IT"
    ],
    "authors": [
      "Arjun Rao",
      "Marc Rußwurm",
      "Konstantin Klemmer",
      "Esther Rolf"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02101v2",
    "abstract": "Within the context of representation learning for Earth observation, geographic Implicit Neural Representations (INRs) embed low-dimensional location inputs (longitude, latitude) into high-dimensional embeddings, through models trained on geo-referenced satellite, image or text data. Despite the common aim of geographic INRs to distill Earth's data into compact, learning-friendly representations, we lack an understanding of how much information is contained in these Earth representations, and where that information is concentrated. The intrinsic dimension of a dataset measures the number of degrees of freedom required to capture its local variability, regardless of the ambient high-dimensional space in which it is embedded. This work provides the first study of the intrinsic dimensionality of geographic INRs. Analyzing INRs with ambient dimension between 256 and 512, we find that their intrinsic dimensions fall roughly between 2 and 10 and are sensitive to changing spatial resolution and input modalities during INR pre-training. Furthermore, we show that the intrinsic dimension of a geographic INR correlates with downstream task performance and can capture spatial artifacts, facilitating model evaluation and diagnostics. More broadly, our work offers an architecture-agnostic, label-free metric of information content that can enable unsupervised evaluation, model selection, and pre-training design across INRs.",
    "fetched_at": "2025-11-06T02:19:07.220108Z"
  },
  {
    "id": "2511.02108v1",
    "title": "Metamorphic Testing of Large Language Models for Natural Language   Processing",
    "date": "2025-11-03",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Steven Cho",
      "Stefano Ruberto",
      "Valerio Terragni"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.02108v1",
    "abstract": "Using large language models (LLMs) to perform natural language processing (NLP) tasks has become increasingly pervasive in recent times. The versatile nature of LLMs makes them applicable to a wide range of such tasks. While the performance of recent LLMs is generally outstanding, several studies have shown that they can often produce incorrect results. Automatically identifying these faulty behaviors is extremely useful for improving the effectiveness of LLMs. One obstacle to this is the limited availability of labeled datasets, which necessitates an oracle to determine the correctness of LLM behaviors. Metamorphic testing (MT) is a popular testing approach that alleviates this oracle problem. At the core of MT are metamorphic relations (MRs), which define relationships between the outputs of related inputs. MT can expose faulty behaviors without the need for explicit oracles (e.g., labeled datasets). This paper presents the most comprehensive study of MT for LLMs to date. We conducted a literature review and collected 191 MRs for NLP tasks. We implemented a representative subset (36 MRs) to conduct a series of experiments with three popular LLMs, running approximately 560,000 metamorphic tests. The results shed light on the capabilities and opportunities of MT for LLMs, as well as its limitations.",
    "fetched_at": "2025-11-06T02:19:07.220058Z"
  },
  {
    "id": "2511.02109v1",
    "title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep values or   Shallow Preferences",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Joshua Ashkinaze",
      "Hua Shen",
      "Sai Avula",
      "Eric Gilbert",
      "Ceren Budak"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02109v1",
    "abstract": "We introduce the Deep Value Benchmark (DVB), an evaluation framework that directly tests whether large language models (LLMs) learn fundamental human values or merely surface-level preferences. This distinction is critical for AI alignment: Systems that capture deeper values are likely to generalize human intentions robustly, while those that capture only superficial patterns in preference data risk producing misaligned behavior. The DVB uses a novel experimental design with controlled confounding between deep values (e.g., moral principles) and shallow features (e.g., superficial attributes). In the training phase, we expose LLMs to human preference data with deliberately correlated deep and shallow features -- for instance, where a user consistently prefers (non-maleficence, formal language) options over (justice, informal language) alternatives. The testing phase then breaks these correlations, presenting choices between (justice, formal language) and (non-maleficence, informal language) options. This design allows us to precisely measure a model's Deep Value Generalization Rate (DVGR) -- the probability of generalizing based on the underlying value rather than the shallow feature. Across 9 different models, the average DVGR is just 0.30. All models generalize deep values less than chance. Larger models have a (slightly) lower DVGR than smaller models. We are releasing our dataset, which was subject to three separate human validation experiments. DVB provides an interpretable measure of a core feature of alignment.",
    "fetched_at": "2025-11-06T02:19:07.220011Z"
  },
  {
    "id": "2511.02122v1",
    "title": "Matrix Sensing with Kernel Optimal Loss: Robustness and Optimization   Landscape",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xinyuan Song",
      "Jiaye Teng",
      "Ziye Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02122v1",
    "abstract": "In this paper we study how the choice of loss functions of non-convex optimization problems affects their robustness and optimization landscape, through the study of noisy matrix sensing. In traditional regression tasks, mean squared error (MSE) loss is a common choice, but it can be unreliable for non-Gaussian or heavy-tailed noise. To address this issue, we adopt a robust loss based on nonparametric regression, which uses a kernel-based estimate of the residual density and maximizes the estimated log-likelihood. This robust formulation coincides with the MSE loss under Gaussian errors but remains stable under more general settings. We further examine how this robust loss reshapes the optimization landscape by analyzing the upper-bound of restricted isometry property (RIP) constants for spurious local minima to disappear. Through theoretical and empirical analysis, we show that this new loss excels at handling large noise and remains robust across diverse noise distributions. This work offers initial insights into enhancing the robustness of machine learning tasks through simply changing the loss, guided by an intuitive and broadly applicable analytical framework.",
    "fetched_at": "2025-11-06T02:19:07.219896Z"
  },
  {
    "id": "2511.02123v1",
    "title": "Variance-Aware Feel-Good Thompson Sampling for Contextual Bandits",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "math.OC",
      "OC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Xuheng Li",
      "Quanquan Gu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02123v1",
    "abstract": "Variance-dependent regret bounds have received increasing attention in recent studies on contextual bandits. However, most of these studies are focused on upper confidence bound (UCB)-based bandit algorithms, while sampling based bandit algorithms such as Thompson sampling are still understudied. The only exception is the LinVDTS algorithm (Xu et al., 2023), which is limited to linear reward function and its regret bound is not optimal with respect to the model dimension. In this paper, we present FGTSVA, a variance-aware Thompson Sampling algorithm for contextual bandits with general reward function with optimal regret bound. At the core of our analysis is an extension of the decoupling coefficient, a technique commonly used in the analysis of Feel-good Thompson sampling (FGTS) that reflects the complexity of the model space. With the new decoupling coefficient denoted by $\\mathrm{dc}$, FGTS-VA achieves the regret of $\\tilde{O}(\\sqrt{\\mathrm{dc}\\cdot\\log|\\mathcal{F}|\\sum_{t=1}^T\\sigma_t^2}+\\mathrm{dc})$, where $|\\mathcal{F}|$ is the size of the model space, $T$ is the total number of rounds, and $\\sigma_t^2$ is the subgaussian norm of the noise (e.g., variance when the noise is Gaussian) at round $t$. In the setting of contextual linear bandits, the regret bound of FGTSVA matches that of UCB-based algorithms using weighted linear regression (Zhou and Gu, 2022).",
    "fetched_at": "2025-11-06T02:19:07.219853Z"
  },
  {
    "id": "2511.02130v1",
    "title": "Re-FORC: Adaptive Reward Prediction for Efficient Chain-of-Thought   Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Renos Zabounidis",
      "Aditya Golatkar",
      "Michael Kleinman",
      "Alessandro Achille",
      "Wei Xia",
      "Stefano Soatto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02130v1",
    "abstract": "We propose Re-FORC, an adaptive reward prediction method that, given a context, enables prediction of the expected future rewards as a function of the number of future thinking tokens. Re-FORC trains a lightweight adapter on reasoning models, demonstrating improved prediction with longer reasoning and larger models. Re-FORC enables: 1) early stopping of unpromising reasoning chains, reducing compute by 26% while maintaining accuracy, 2) optimized model and thinking length selection that achieves 4% higher accuracy at equal compute and 55% less compute at equal accuracy compared to the largest model, 3) adaptive test-time scaling, which increases accuracy by 11% in high compute regime, and 7% in low compute regime. Re-FORC allows dynamic reasoning with length control via cost-per-token thresholds while estimating computation time upfront.",
    "fetched_at": "2025-11-06T02:19:07.219812Z"
  },
  {
    "id": "2511.02132v1",
    "title": "Optimizing Attention on GPUs by Exploiting GPU Architectural NUMA   Effects",
    "date": "2025-11-03",
    "tags": [
      "cs.AR",
      "AR",
      "cs.DC",
      "DC",
      "cs.LG",
      "LG",
      "cs.PF",
      "PF"
    ],
    "authors": [
      "Mansi Choudhary",
      "Karthik Sangaiah",
      "Sonali Singh",
      "Muhammad Osama",
      "Lisa Wu Wills",
      "Ganesh Dasika"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02132v1",
    "abstract": "The rise of disaggregated AI GPUs has exposed a critical bottleneck in large-scale attention workloads: non-uniform memory access (NUMA). As multi-chiplet designs become the norm for scaling compute capabilities, memory latency and bandwidth vary sharply across compute regions, undermining the performance of traditional GPU kernel scheduling strategies that assume uniform memory access. We identify how these NUMA effects distort locality in multi-head attention (MHA) and present Swizzled Head-first Mapping, a spatially-aware scheduling strategy that aligns attention heads with GPU NUMA domains to exploit intra-chiplet cache reuse. On AMD's MI300X architecture, our method achieves up to 50% higher performance over state-of-the-art attention algorithms using conventional scheduling techniques and sustains consistently high L2 cache hit rates of 80-97%. These results demonstrate that NUMA-aware scheduling is now fundamental to achieving full efficiency on next-generation disaggregated GPUs, offering a path forward for scalable AI training and inference.",
    "fetched_at": "2025-11-06T02:19:07.219760Z"
  },
  {
    "id": "2511.02135v1",
    "title": "Rethinking LLM Human Simulation: When a Graph is What You Need",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Joseph Suh",
      "Suhong Moon",
      "Serina Chang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02135v1",
    "abstract": "Large language models (LLMs) are increasingly used to simulate humans, with applications ranging from survey prediction to decision-making. However, are LLMs strictly necessary, or can smaller, domain-grounded models suffice? We identify a large class of simulation problems in which individuals make choices among discrete options, where a graph neural network (GNN) can match or surpass strong LLM baselines despite being three orders of magnitude smaller. We introduce Graph-basEd Models for human Simulation (GEMS), which casts discrete choice simulation tasks as a link prediction problem on graphs, leveraging relational knowledge while incorporating language representations only when needed. Evaluations across three key settings on three simulation datasets show that GEMS achieves comparable or better accuracy than LLMs, with far greater efficiency, interpretability, and transparency, highlighting the promise of graph-based modeling as a lightweight alternative to LLMs for human simulation. Our code is available at https://github.com/schang-lab/gems.",
    "fetched_at": "2025-11-06T02:19:07.219706Z"
  },
  {
    "id": "2511.01149v1",
    "title": "Modular Task Decomposition and Dynamic Collaboration in Multi-Agent   Systems Driven by Large Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shuaidong Pan",
      "Di Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01149v1",
    "abstract": "This paper addresses the limitations of a single agent in task decomposition and collaboration during complex task execution, and proposes a multi-agent architecture for modular task decomposition and dynamic collaboration based on large language models. The method first converts natural language task descriptions into unified semantic representations through a large language model. On this basis, a modular decomposition mechanism is introduced to break down the overall goal into multiple hierarchical sub-tasks. Then, dynamic scheduling and routing mechanisms enable reasonable division of labor and realtime collaboration among agents, allowing the system to adjust strategies continuously according to environmental feedback, thus maintaining efficiency and stability in complex tasks. Furthermore, a constraint parsing and global consistency mechanism is designed to ensure coherent connections between sub-tasks and balanced workload, preventing performance degradation caused by redundant communication or uneven resource allocation. The experiments validate the architecture across multiple dimensions, including task success rate, decomposition efficiency, sub-task coverage, and collaboration balance. The results show that the proposed method outperforms existing approaches in both overall performance and robustness, achieving a better balance between task complexity and communication overhead. In conclusion, this study demonstrates the effectiveness and feasibility of language-driven task decomposition and dynamic collaboration in multi-agent systems, providing a systematic solution for task execution in complex environments.",
    "fetched_at": "2025-11-06T02:19:05.288766Z"
  },
  {
    "id": "2511.01166v1",
    "title": "MicroRemed: Benchmarking LLMs in Microservices Remediation",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.SE",
      "SE",
      "68T50",
      "I.2.7",
      "7"
    ],
    "authors": [
      "Lingzhe Zhang",
      "Yunpeng Zhai",
      "Tong Jia",
      "Chiming Duan",
      "Minghua He",
      "Leyi Pan",
      "Zhaoyang Liu",
      "Bolin Ding",
      "Ying Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01166v1",
    "abstract": "Large Language Models (LLMs) integrated with agent-based reasoning frameworks have recently shown strong potential for autonomous decision-making and system-level operations. One promising yet underexplored direction is microservice remediation, where the goal is to automatically recover faulty microservice systems. Existing approaches, however, still rely on human-crafted prompts from Site Reliability Engineers (SREs), with LLMs merely converting textual instructions into executable code. To advance research in this area, we introduce MicroRemed, the first benchmark for evaluating LLMs in end-to-end microservice remediation, where models must directly generate executable Ansible playbooks from diagnosis reports to restore system functionality. We further propose ThinkRemed, a multi-agent framework that emulates the reflective and perceptive reasoning of SREs. Experimental results show that MicroRemed presents substantial challenges to current LLMs, while ThinkRemed improves end-to-end remediation performance through iterative reasoning and system reflection. The benchmark is available at https://github.com/LLM4AIOps/MicroRemed.",
    "fetched_at": "2025-11-06T02:19:05.288723Z"
  },
  {
    "id": "2511.01181v1",
    "title": "Learning When to Quit in Sales Conversations",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Emaad Manzoor",
      "Eva Ascarza",
      "Oded Netzer"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01181v1",
    "abstract": "Salespeople frequently face the dynamic screening decision of whether to persist in a conversation or abandon it to pursue the next lead. Yet, little is known about how these decisions are made, whether they are efficient, or how to improve them. We study these decisions in the context of high-volume outbound sales where leads are ample, but time is scarce and failure is common. We formalize the dynamic screening decision as an optimal stopping problem and develop a generative language model-based sequential decision agent - a stopping agent - that learns whether and when to quit conversations by imitating a retrospectively-inferred optimal stopping policy. Our approach handles high-dimensional textual states, scales to large language models, and works with both open-source and proprietary language models. When applied to calls from a large European telecommunications firm, our stopping agent reduces the time spent on failed calls by 54% while preserving nearly all sales; reallocating the time saved increases expected sales by up to 37%. Upon examining the linguistic cues that drive salespeople's quitting decisions, we find that they tend to overweight a few salient expressions of consumer disinterest and mispredict call failure risk, suggesting cognitive bounds on their ability to make real-time conversational decisions. Our findings highlight the potential of artificial intelligence algorithms to correct cognitively-bounded human decisions and improve salesforce efficiency.",
    "fetched_at": "2025-11-06T02:19:05.288658Z"
  },
  {
    "id": "2511.01188v1",
    "title": "ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and   Multi-LLM Interaction",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Lvhua Wu",
      "Xuefeng Jiang",
      "Sheng Sun",
      "Tian Wen",
      "Yuwei Wang",
      "Min Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01188v1",
    "abstract": "The rapid spread of fake news threatens social stability and public trust, rendering its detection an imperative research priority. Although large language models (LLMs) excel at numerous natural language processing tasks with their remarkable contextual understanding and extensive prior knowledge, the time-bounded knowledge coverage and tendency for generating hallucination content reduce their reliability when handling fast-evolving news streams. Furthermore, models trained on existing static datasets also often lack the generalization needed for emerging news topics. To address these challenges, we propose ZoFia, a novel two-stage zero-shot fake news detection framework. First, we introduce Hierarchical Salience to quantify the importance of entities in the news content, and propose the SC-MMR algorithm to effectively select an informative and diverse set of keywords that serve as queries for retrieving up-to-date external evidence. Subsequently, a multi LLM interactive system, in which each agent assumes a distinct role, performs multi-view collaborative analysis and adversarial debate over the news text and its related information, and finally produces an interpretable and robust judgment. Comprehensive experiments on two public datasets demonstrate that ZoFia obviously outperforms existing zero-shot baselines and most of few-shot methods. Our codes will be open-sourced to facilitate related communities.",
    "fetched_at": "2025-11-06T02:19:05.288612Z"
  },
  {
    "id": "2511.01625v1",
    "title": "UniDataBench: Evaluating Data Analytics Agents Across Structured and   Unstructured Data",
    "date": "2025-11-03",
    "tags": [
      "cs.DB",
      "DB"
    ],
    "authors": [
      "Han Weng",
      "Zhou Liu",
      "Yuanfeng Song",
      "Xiaoming Yin",
      "Xing Chen",
      "Wentao Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01625v1",
    "abstract": "In the real business world, data is stored in a variety of sources, including structured relational databases, unstructured databases (e.g., NoSQL databases), or even CSV/excel files. The ability to extract reasonable insights across these diverse source is vital for business success. Existing benchmarks, however, are limited in assessing agents' capabilities across these diverse data types. To address this gap, we introduce UniDataBench, a comprehensive benchmark designed to evaluate the performance of data analytics agents in handling diverse data sources. Specifically, UniDataBench is originating from real-life industry analysis report and we then propose a pipeline to remove the privacy and sensitive information. It encompasses a wide array of datasets, including relational databases, CSV files to NoSQL data, reflecting real-world business scenarios, and provides unified framework to assess how effectively agents can explore multiple data formats, extract valuable insights, and generate meaningful summaries and recommendations. Based on UniDataBench, we propose a novel LLM-based agent named ReActInsight, an autonomous agent that performs end-to-end analysis over diverse data sources by automatically discovering cross-source linkages, decomposing goals, and generating robust, self-correcting code to extract actionable insights. Our benchmark and agent together provide a powerful framework for advancing the capabilities of data analytics agents in real-world applications.",
    "fetched_at": "2025-11-06T02:19:05.288318Z"
  },
  {
    "id": "2511.01633v1",
    "title": "Scaling Graph Chain-of-Thought Reasoning: A Multi-Agent Framework with   Efficient LLM Serving",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chengying Huan",
      "Ziheng Meng",
      "Yongchao Liu",
      "Zhengyi Yang",
      "Yun Zhu",
      "Yue Yun",
      "Shipeng Li",
      "Rong Gu",
      "Xiabao Wu",
      "Haitao Zhang",
      "Chuntao Hong",
      "Shaonan Ma",
      "Guihai Chen",
      "Chen Tian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01633v1",
    "abstract": "Graph Chain-of-Thought (Graph-CoT) enables large language models (LLMs) to perform step-by-step reasoning over graph-structured knowledge, but existing pipelines suffer from low accuracy, excessive token usage, high latency, and low throughput due to single-agent monolithic prompts, repeated context re-encoding, and inefficient serving execution. We present GLM, the first multi-agent Graph-CoT system co-designed with an optimized LLM serving architecture. GLM decomposes reasoning into specialized agents for classification, reasoning, action generation, and graph retrieval, enabling branching and selective context sharing to reduce prompt length and reasoning iterations while preserving reasoning quality, thereby improving accuracy and reducing overall token consumption. To scale inference, we introduce a Graph-CoT-aware LLM inference mechanism with graph-specific KV-cache management, priority-based eviction, and pipelined execution to improve serving efficiency. Experiments demonstrate that GLM improves answer accuracy by up to 38%, reduces token cost by up to 95.7%, lowers inference latency by 90.3%, and achieves up to 15.1x higher throughput compared to state-of-the-art Graph-CoT baselines, enabling efficient adoption for complex real-world reasoning at scale.",
    "fetched_at": "2025-11-06T02:19:05.288255Z"
  },
  {
    "id": "2511.01668v1",
    "title": "Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal   Question Answering in Judicial Forensics",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yueqing Xi",
      "Yifan Bai",
      "Huasen Luo",
      "Weiliang Wen",
      "Hui Liu",
      "Haoliang Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01668v1",
    "abstract": "As artificial intelligence permeates judicial forensics, ensuring the veracity and traceability of legal question answering (QA) has become critical. Conventional large language models (LLMs) are prone to hallucination, risking misleading guidance in legal consultation, while static knowledge bases struggle to keep pace with frequently updated statutes and case law. We present a hybrid legal QA agent tailored for judicial settings that integrates retrieval-augmented generation (RAG) with multi-model ensembling to deliver reliable, auditable, and continuously updatable counsel. The system prioritizes retrieval over generation: when a trusted legal repository yields relevant evidence, answers are produced via RAG; otherwise, multiple LLMs generate candidates that are scored by a specialized selector, with the top-ranked answer returned. High-quality outputs then undergo human review before being written back to the repository, enabling dynamic knowledge evolution and provenance tracking. Experiments on the Law\\_QA dataset show that our hybrid approach significantly outperforms both a single-model baseline and a vanilla RAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm the complementary contributions of retrieval prioritization, model ensembling, and the human-in-the-loop update mechanism. The proposed system demonstrably reduces hallucination while improving answer quality and legal compliance, advancing the practical landing of media forensics technologies in judicial scenarios.",
    "fetched_at": "2025-11-06T02:19:05.288174Z"
  },
  {
    "id": "2511.01817v1",
    "title": "SciTextures: Collecting and Connecting Visual Patterns, Models, and Code   Across Science and Art",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Sagi Eppel",
      "Alona Strugatski"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01817v1",
    "abstract": "The ability to connect visual patterns with the processes that form them represents one of the deepest forms of visual understanding. Textures of clouds and waves, the growth of cities and forests, or the formation of materials and landscapes are all examples of patterns emerging from underlying mechanisms. We present the Scitextures dataset, a large-scale collection of textures and visual patterns from all domains of science, tech, and art, along with the models and code that generate these images. Covering over 1,200 different models and 100,000 images of patterns and textures from physics, chemistry, biology, sociology, technology, mathematics, and art, this dataset offers a way to explore the connection between the visual patterns that shape our world and the mechanisms that produce them. Created by an agentic AI pipeline that autonomously collects and implements models in standardized form, we use SciTextures to evaluate the ability of leading AI models to link visual patterns to the models and code that generate them, and to identify different patterns that emerged from the same process. We also test AIs ability to infer and recreate the mechanisms behind visual patterns by providing a natural image of a real-world pattern and asking the AI to identify, model, and code the mechanism that formed the pattern, then run this code to generate a simulated image that is compared to the real image. These benchmarks show that vision-language models (VLMs) can understand and simulate the physical system beyond a visual pattern. The dataset and code are available at: https://zenodo.org/records/17485502",
    "fetched_at": "2025-11-06T02:19:05.287947Z"
  },
  {
    "id": "2511.01824v1",
    "title": "Simulating Environments with Reasoning Models for Agent Training",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuetai Li",
      "Huseyin A Inan",
      "Xiang Yue",
      "Wei-Ning Chen",
      "Lukas Wutschitz",
      "Janardhan Kulkarni",
      "Radha Poovendran",
      "Robert Sim",
      "Saravan Rajmohan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01824v1",
    "abstract": "LLM agents excel in compact environments requiring deep reasoning but remain brittle when operating in broader, more complex contexts that demand robustness across diverse tools and schemas. Building bespoke environments for training is heavy, brittle, and limits progress. In this paper, we demonstrate that LLMs can simulate realistic environment feedback without access to actual testbed data or APIs. Inspired by this capability, we propose two frameworks: Simia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets into diverse trajectories in an environment-agnostic manner, and Simia-RL, a framework that enables RL training without real environment implementations through LLM-simulated feedback. Fine-tuning open models yields consistent improvements across multiple benchmarks, surpassing GPT-4o and approaching o4-mini on $\\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable agent training without environment engineering, replacing heavy and brittle implementations with flexible LLM-based simulation.",
    "fetched_at": "2025-11-06T02:19:05.287902Z"
  },
  {
    "id": "2511.01833v1",
    "title": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images   Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Ming Li",
      "Jike Zhong",
      "Shitian Zhao",
      "Haoquan Zhang",
      "Shaoheng Lin",
      "Yuxiang Lai",
      "Wei Chen",
      "Konstantinos Psounis",
      "Kaipeng Zhang"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2511.01833v1",
    "abstract": "The frontier of visual reasoning is shifting toward models like OpenAI o3, which can intelligently create and operate tools to transform images for problem-solving, also known as thinking-\\textit{with}-images in chain-of-thought. Yet existing benchmarks fail to fully capture this advanced capability. Even Visual Search, the most common benchmark for current thinking-\\textit{with}-images methods, tests only basic operations such as localization and cropping, offering little insight into more complex, dynamic, and tool-dependent reasoning. We introduce \\textbf{TIR-Bench}, a comprehensive benchmark for evaluating agentic thinking-with-images across 13 diverse tasks, each requiring novel tool use for image processing and manipulation in chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from leading open-sourced and proprietary models to those with explicit tool-use augmentation. Results show that TIR-Bench is universally challenging, and strong performance requires genuine thinking-with-images capabilities. Finally, we present a pilot study comparing direct versus agentic fine-tuning.",
    "fetched_at": "2025-11-06T02:19:05.287838Z"
  },
  {
    "id": "2511.01854v2",
    "title": "Tool-to-Agent Retrieval: Bridging Tools and Agents for Scalable LLM   Multi-Agent Systems",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Elias Lumer",
      "Faheem Nizar",
      "Anmol Gulati",
      "Pradeep Honaganahalli Basavaraju",
      "Vamse Kumar Subbiah"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.01854v2",
    "abstract": "Recent advances in LLM Multi-Agent Systems enable scalable orchestration of sub-agents, each coordinating hundreds or thousands of tools or Model Context Protocol (MCP) servers. However, existing retrieval methods typically match queries against coarse agent-level descriptions before routing, which obscures fine-grained tool functionality and often results in suboptimal agent selection. We introduce Tool-to-Agent Retrieval, a unified framework that embeds both tools and their parent agents in a shared vector space and connects them through metadata relationships. By explicitly representing tool capabilities and traversing metadata to the agent level, Tool-to-Agent Retrieval enables granular tool-level or agent-level retrieval, ensuring that agents and their underlying tools or MCP servers are equally represented without the context dilution that arises from chunking many tools together. Evaluating Tool-to-Agent Retrieval across eight embedding models, our approach achieves consistent improvements of 19.4% in Recall@5 and 17.7% in nDCG@5 over previous state-of-the-art agent retrievers on the LiveMCPBench benchmark.",
    "fetched_at": "2025-11-06T02:19:05.287775Z"
  },
  {
    "id": "2511.01205v1",
    "title": "When Machines Join the Moral Circle: The Persona Effect of Generative AI   Agents in Collaborative Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Yueqiao Jin",
      "Roberto Martinez-Maldonado",
      "Wanruo Shi",
      "Songjie Huang",
      "Mingmin Zheng",
      "Xinbin Han",
      "Dragan Gasevic",
      "Lixiang Yan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01205v1",
    "abstract": "Generative AI is increasingly positioned as a peer in collaborative learning, yet its effects on ethical deliberation remain unclear. We report a between-subjects experiment with university students (N=217) who discussed an autonomous-vehicle dilemma in triads under three conditions: human-only control, supportive AI teammate, or contrarian AI teammate. Using moral foundations lexicons, argumentative coding from the augmentative knowledge construction framework, semantic trajectory modelling with BERTopic and dynamic time warping, and epistemic network analysis, we traced how AI personas reshape moral discourse. Supportive AIs increased grounded/qualified claims relative to control, consolidating integrative reasoning around care/fairness, while contrarian AIs modestly broadened moral framing and sustained value pluralism. Both AI conditions reduced thematic drift compared with human-only groups, indicating more stable topical focus. Post-discussion justification complexity was only weakly predicted by moral framing and reasoning quality, and shifts in final moral decisions were driven primarily by participants' initial stance rather than condition. Overall, AI teammates altered the process, the distribution and connection of moral frames and argument quality, more than the outcome of moral choice, highlighting the potential of generative AI agents as teammates for eliciting reflective, pluralistic moral reasoning in collaborative learning.",
    "fetched_at": "2025-11-06T02:19:03.468746Z"
  },
  {
    "id": "2511.01218v1",
    "title": "Optimizing Electric Vehicle Charging Station Placement Using   Reinforcement Learning and Agent-Based Simulations",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Minh-Duc Nguyen",
      "Dung D. Le",
      "Phi Long Nguyen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01218v1",
    "abstract": "The rapid growth of electric vehicles (EVs) necessitates the strategic placement of charging stations to optimize resource utilization and minimize user inconvenience. Reinforcement learning (RL) offers an innovative approach to identifying optimal charging station locations; however, existing methods face challenges due to their deterministic reward systems, which limit efficiency. Because real-world conditions are dynamic and uncertain, a deterministic reward structure cannot fully capture the complexities of charging station placement. As a result, evaluation becomes costly and time-consuming, and less reflective of real-world scenarios. To address this challenge, we propose a novel framework that integrates deep RL with agent-based simulations to model EV movement and estimate charging demand in real time. Our approach employs a hybrid RL agent with dual Q-networks to select optimal locations and configure charging ports, guided by a hybrid reward function that combines deterministic factors with simulation-derived feedback. Case studies in Hanoi, Vietnam, show that our method reduces average waiting times by 53.28% compared to the initial state, outperforming static baseline methods. This scalable and adaptive solution enhances EV infrastructure planning, effectively addressing real-world complexities and improving user experience.",
    "fetched_at": "2025-11-06T02:19:03.468680Z"
  },
  {
    "id": "2511.01236v1",
    "title": "Don't Just Search, Understand: Semantic Path Planning Agent for   Spherical Tensegrity Robots in Unknown Environments",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Junwen Zhang",
      "Changyue Liu",
      "Pengqi Fu",
      "Xiang Guo",
      "Ye Shi",
      "Xudong Liang",
      "Zhijian Wang",
      "Hanzhi Ma"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01236v1",
    "abstract": "Endowed with inherent dynamical properties that grant them remarkable ruggedness and adaptability, spherical tensegrity robots stand as prototypical examples of hybrid softrigid designs and excellent mobile platforms. However, path planning for these robots in unknown environments presents a significant challenge, requiring a delicate balance between efficient exploration and robust planning. Traditional path planners, which treat the environment as a geometric grid, often suffer from redundant searches and are prone to failure in complex scenarios due to their lack of semantic understanding. To overcome these limitations, we reframe path planning in unknown environments as a semantic reasoning task. We introduce a Semantic Agent for Tensegrity robots (SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages high-level environmental comprehension to generate efficient and reliable planning strategies.At the core of SATPlanner is an Adaptive Observation Window mechanism, inspired by the \"fast\" and \"slow\" thinking paradigms of LLMs. This mechanism dynamically adjusts the perceptual field of the agent: it narrows for rapid traversal of open spaces and expands to reason about complex obstacle configurations. This allows the agent to construct a semantic belief of the environment, enabling the search space to grow only linearly with the path length (O(L)) while maintaining path quality. We extensively evaluate SATPlanner in 1,000 simulation trials, where it achieves a 100% success rate, outperforming other real-time planning algorithms. Critically, SATPlanner reduces the search space by 37.2% compared to the A* algorithm while achieving comparable, near-optimal path lengths. Finally, the practical feasibility of SATPlanner is validated on a physical spherical tensegrity robot prototype.",
    "fetched_at": "2025-11-06T02:19:03.468636Z"
  },
  {
    "id": "2511.01310v1",
    "title": "From Pixels to Cooperation Multi Agent Reinforcement Learning based on   Multimodal World Models",
    "date": "2025-11-03",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Sureyya Akin",
      "Kavita Srivastava",
      "Prateek B. Kapoor",
      "Pradeep G. Sethi",
      "Sunita Q. Patel",
      "Rahu Srivastava"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01310v1",
    "abstract": "Learning cooperative multi-agent policies directly from high-dimensional, multimodal sensory inputs like pixels and audio (from pixels) is notoriously sample-inefficient. Model-free Multi-Agent Reinforcement Learning (MARL) algorithms struggle with the joint challenge of representation learning, partial observability, and credit assignment. To address this, we propose a novel framework based on a shared, generative Multimodal World Model (MWM). Our MWM is trained to learn a compressed latent representation of the environment's dynamics by fusing distributed, multimodal observations from all agents using a scalable attention-based mechanism. Subsequently, we leverage this learned MWM as a fast, \"imagined\" simulator to train cooperative MARL policies (e.g., MAPPO) entirely within its latent space, decoupling representation learning from policy learning. We introduce a new set of challenging multimodal, multi-agent benchmarks built on a 3D physics simulator. Our experiments demonstrate that our MWM-MARL framework achieves orders-of-magnitude greater sample efficiency compared to state-of-the-art model-free MARL baselines. We further show that our proposed multimodal fusion is essential for task success in environments with sensory asymmetry and that our architecture provides superior robustness to sensor-dropout, a critical feature for real-world deployment.",
    "fetched_at": "2025-11-06T02:19:03.468570Z"
  },
  {
    "id": "2511.01383v1",
    "title": "CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Landson Guo",
      "Andres M. Diaz Aguilar",
      "William Talbot",
      "Turcan Tuna",
      "Marco Hutter",
      "Cesar Cadena"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01383v1",
    "abstract": "Accurate point-wise velocity estimation in 3D is crucial for robot interaction with non-rigid, dynamic agents, such as humans, enabling robust performance in path planning, collision avoidance, and object manipulation in dynamic environments. To this end, this paper proposes a novel RADAR, LiDAR, and camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V. This pipeline leverages raw RADAR measurements to create a novel RADAR representation, the velocity cube, which densely represents radial velocities within the RADAR's field-of-view. By combining the velocity cube for radial velocity extraction, optical flow for tangential velocity estimation, and LiDAR for point-wise range measurements through a closed-form solution, our approach can produce 3D velocity estimates for a dense array of points. Developed as an open-source ROS2 package, CaRLi-V has been field-tested against a custom dataset and proven to produce low velocity error metrics relative to ground truth, enabling point-wise velocity estimation for robotic applications.",
    "fetched_at": "2025-11-06T02:19:03.468501Z"
  },
  {
    "id": "2511.01415v1",
    "title": "Modulation of temporal decision-making in a deep reinforcement learning   agent under the dual-task paradigm",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Amrapali Pednekar",
      "Álvaro Garrido-Pérez",
      "Yara Khaluf",
      "Pieter Simoens"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01415v1",
    "abstract": "This study explores the interference in temporal processing within a dual-task paradigm from an artificial intelligence (AI) perspective. In this context, the dual-task setup is implemented as a simplified version of the Overcooked environment with two variations, single task (T) and dual task (T+N). Both variations involve an embedded time production task, but the dual task (T+N) additionally involves a concurrent number comparison task. Two deep reinforcement learning (DRL) agents were separately trained for each of these tasks. These agents exhibited emergent behavior consistent with human timing research. Specifically, the dual task (T+N) agent exhibited significant overproduction of time relative to its single task (T) counterpart. This result was consistent across four target durations. Preliminary analysis of neural dynamics in the agents' LSTM layers did not reveal any clear evidence of a dedicated or intrinsic timer. Hence, further investigation is needed to better understand the underlying time-keeping mechanisms of the agents and to provide insights into the observed behavioral patterns. This study is a small step towards exploring parallels between emergent DRL behavior and behavior observed in biological systems in order to facilitate a better understanding of both.",
    "fetched_at": "2025-11-06T02:19:03.468449Z"
  },
  {
    "id": "2511.01425v1",
    "title": "Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal   Faithfulness Analysis",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "I.2.6; I.2.10",
      "10"
    ],
    "authors": [
      "Yuhang Huang",
      "Zekai Lin",
      "Fan Zhong",
      "Lei Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01425v1",
    "abstract": "Explanations for AI models in high-stakes domains like medicine often lack verifiability, which can hinder trust. To address this, we propose an interactive agent that produces explanations through an auditable sequence of actions. The agent learns a policy to strategically seek external visual evidence to support its diagnostic reasoning. This policy is optimized using reinforcement learning, resulting in a model that is both efficient and generalizable. Our experiments show that this action-based reasoning process significantly improves calibrated accuracy, reducing the Brier score by 18\\% compared to a non-interactive baseline. To validate the faithfulness of the agent's explanations, we introduce a causal intervention method. By masking the visual evidence the agent chooses to use, we observe a measurable degradation in its performance ($\\Delta$Brier=+0.029), confirming that the evidence is integral to its decision-making process. Our work provides a practical framework for building AI systems with verifiable and faithful reasoning capabilities.",
    "fetched_at": "2025-11-06T02:19:03.468400Z"
  },
  {
    "id": "2511.01448v1",
    "title": "LiCoMemory: Lightweight and Cognitive Agentic Memory for Efficient   Long-Term Reasoning",
    "date": "2025-11-03",
    "tags": [
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Zhengjun Huang",
      "Zhoujin Tian",
      "Qintian Guo",
      "Fangyuan Zhang",
      "Yingli Zhou",
      "Di Jiang",
      "Xiaofang Zhou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01448v1",
    "abstract": "Large Language Model (LLM) agents exhibit remarkable conversational and reasoning capabilities but remain constrained by limited context windows and the lack of persistent memory. Recent efforts address these limitations via external memory architectures, often employing graph-based representations, yet most adopt flat, entangled structures that intertwine semantics with topology, leading to redundant representations, unstructured retrieval, and degraded efficiency and accuracy. To resolve these issues, we propose LiCoMemory, an end-to-end agentic memory framework for real-time updating and retrieval, which introduces CogniGraph, a lightweight hierarchical graph that utilizes entities and relations as semantic indexing layers, and employs temporal and hierarchy-aware search with integrated reranking for adaptive and coherent knowledge retrieval. Experiments on long-term dialogue benchmarks, LoCoMo and LongMemEval, show that LiCoMemory not only outperforms established baselines in temporal reasoning, multi-session consistency, and retrieval efficiency, but also notably reduces update latency. Our official code and data are available at https://github.com/EverM0re/LiCoMemory.",
    "fetched_at": "2025-11-06T02:19:03.468353Z"
  },
  {
    "id": "2511.01493v1",
    "title": "Floor Plan-Guided Visual Navigation Incorporating Depth and Directional   Cues",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Wei Huang",
      "Jiaxin Li",
      "Zang Wan",
      "Huijun Di",
      "Wei Liang",
      "Zhu Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01493v1",
    "abstract": "Guiding an agent to a specific target in indoor environments based solely on RGB inputs and a floor plan is a promising yet challenging problem. Although existing methods have made significant progress, two challenges remain unresolved. First, the modality gap between egocentric RGB observations and the floor plan hinders the integration of visual and spatial information for both local obstacle avoidance and global planning. Second, accurate localization is critical for navigation performance, but remains challenging at deployment in unseen environments due to the lack of explicit geometric alignment between RGB inputs and floor plans. We propose a novel diffusion-based policy, denoted as GlocDiff, which integrates global path planning from the floor plan with local depth-aware features derived from RGB observations. The floor plan offers explicit global guidance, while the depth features provide implicit geometric cues, collectively enabling precise prediction of optimal navigation directions and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation during training to enhance robustness against pose estimation errors, and we find that combining this with a relatively stable VO module during inference results in significantly improved navigation performance. Extensive experiments on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in achieving superior navigation performance, and the success of real-world deployments also highlights its potential for widespread practical applications.",
    "fetched_at": "2025-11-06T02:19:03.468298Z"
  },
  {
    "id": "2511.01527v1",
    "title": "TPS-Bench: Evaluating AI Agents' Tool Planning \\& Scheduling Abilities   in Compounding Tasks",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hanwen Xu",
      "Xuyao Huang",
      "Yuzhe Liu",
      "Kai Yu",
      "Zhijie Deng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01527v1",
    "abstract": "Large language model (LLM) agents have exhibited strong problem-solving competence across domains like research and coding. Yet, it remains underexplored whether LLM agents can tackle compounding real-world problems that require a diverse set of tools to complete. Given a broad, heterogeneous tool repository, LLM agents must not only select appropriate tools based on task planning analysis but also strategically schedule the execution order to ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of LLM agents in solving such problems that demand Tool Planning and Scheduling. TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a tool repository containing hundreds of model context protocol (MCP) tools. In particular, each task is composed of multiple subtasks, such as web search, map navigation, calendar checking, etc., and each subtask can be completed by a basic tool. Our evaluation emphasizes both task completion rate and efficiency. The empirical studies on popular closed-source and open-source LLMs indicate that most models can perform reasonable tool planning, but differ in scheduling. For example, GLM-4.5 achieves an outperforming task completion rate of 64.72% with extensive sequential tool calls, hence suffering from significantly long execution time. By contrast, GPT-4o prioritizes parallel tool calls but achieves only a 45.08% completion rate. Considering reinforcement learning (RL) can be a viable way to improve the scheduling efficiency without compromising performance, we perform an initial study on Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in task completion rate based on rarely 100 RL training samples. Our code is available https://github.com/hanwenxu1/mcp-agent.",
    "fetched_at": "2025-11-06T02:19:03.468241Z"
  },
  {
    "id": "2511.01554v1",
    "title": "Learning what to say and how precisely: Efficient Communication via   Differentiable Discrete Communication Learning",
    "date": "2025-11-03",
    "tags": [
      "cs.MA",
      "MA",
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "math.IT"
    ],
    "authors": [
      "Aditya Kapoor",
      "Yash Bhisikar",
      "Benjamin Freed",
      "Jan Peters",
      "Mingfei Sun"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01554v1",
    "abstract": "Effective communication in multi-agent reinforcement learning (MARL) is critical for success but constrained by bandwidth, yet past approaches have been limited to complex gating mechanisms that only decide \\textit{whether} to communicate, not \\textit{how precisely}. Learning to optimize message precision at the bit-level is fundamentally harder, as the required discretization step breaks gradient flow. We address this by generalizing Differentiable Discrete Communication Learning (DDCL), a framework for end-to-end optimization of discrete messages. Our primary contribution is an extension of DDCL to support unbounded signals, transforming it into a universal, plug-and-play layer for any MARL architecture. We verify our approach with three key results. First, through a qualitative analysis in a controlled environment, we demonstrate \\textit{how} agents learn to dynamically modulate message precision according to the informational needs of the task. Second, we integrate our variant of DDCL into four state-of-the-art MARL algorithms, showing it reduces bandwidth by over an order of magnitude while matching or exceeding task performance. Finally, we provide direct evidence for the \\enquote{Bitter Lesson} in MARL communication: a simple Transformer-based policy leveraging DDCL matches the performance of complex, specialized architectures, questioning the necessity of bespoke communication designs.",
    "fetched_at": "2025-11-06T02:19:03.468185Z"
  },
  {
    "id": "2511.01594v1",
    "title": "MARS: Multi-Agent Robotic System with Multimodal Large Language Models   for Assistive Intelligence",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV",
      "I.2.9; I.2.11; I.2.6; I.4.8",
      "8"
    ],
    "authors": [
      "Renjun Gao",
      "Peiyan Zhong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01594v1",
    "abstract": "Multimodal large language models (MLLMs) have shown remarkable capabilities in cross-modal understanding and reasoning, offering new opportunities for intelligent assistive systems, yet existing systems still struggle with risk-aware planning, user personalization, and grounding language plans into executable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic System powered by MLLMs for assistive intelligence and designed for smart home robots supporting people with disabilities. The system integrates four agents: a visual perception agent for extracting semantic and spatial features from environment images, a risk assessment agent for identifying and prioritizing hazards, a planning agent for generating executable action sequences, and an evaluation agent for iterative optimization. By combining multimodal perception with hierarchical multi-agent decision-making, the framework enables adaptive, risk-aware, and personalized assistance in dynamic indoor environments. Experiments on multiple datasets demonstrate the superior overall performance of the proposed system in risk-aware planning and coordinated multi-agent execution compared with state-of-the-art multimodal models. The proposed approach also highlights the potential of collaborative AI for practical assistive scenarios and provides a generalizable methodology for deploying MLLM-enabled multi-agent systems in real-world environments.",
    "fetched_at": "2025-11-06T02:19:03.468125Z"
  },
  {
    "id": "2511.01695v2",
    "title": "Collaborative Large Language Model Inference via Resource-Aware Parallel   Speculative Decoding",
    "date": "2025-11-03",
    "tags": [
      "cs.LG",
      "LG",
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Jungyeon Koh",
      "Hyun Jong Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01695v2",
    "abstract": "The growing demand for on-device large language model (LLM) inference highlights the need for efficient mobile edge computing (MEC) solutions, especially in resource-constrained settings. Speculative decoding offers a promising solution by partitioning token generation between a lightweight draft model on mobile devices and a powerful target model on edge servers, but suffers from communication overhead and asynchronous delays. This paper is the first to propose a unified framework that jointly optimizes user association and resource allocation (UARA) to support efficient parallel speculative decoding. We solve the UARA problem using a multi-agent deep reinforcement learning algorithm. To evaluate our approach under realistic conditions, we conduct experiments using the Sionna simulator. Results show that our method achieves up to 28.0% and an average of 23.7% reduction in end-to-end latency without compromising inference accuracy, enabling scalable and low-latency LLM services in MEC systems.",
    "fetched_at": "2025-11-06T02:19:03.468072Z"
  },
  {
    "id": "2511.01718v1",
    "title": "Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete   Denoising Diffusion Process",
    "date": "2025-11-03",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Jiayi Chen",
      "Wenxuan Song",
      "Pengxiang Ding",
      "Ziyang Zhou",
      "Han Zhao",
      "Feilong Tang",
      "Donglin Wang",
      "Haoang Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01718v1",
    "abstract": "Vision-language-action (VLA) models aim to understand natural language instructions and visual observations and to execute corresponding actions as an embodied agent. Recent work integrates future images into the understanding-acting loop, yielding unified VLAs that jointly understand, generate, and act -- reading text and images and producing future images and actions. However, these models either rely on external experts for modality unification or treat image generation and action prediction as separate processes, limiting the benefits of direct synergy between these tasks. Our core philosophy is to optimize generation and action jointly through a synchronous denoising process, where the iterative refinement enables actions to evolve from initialization, under constant and sufficient visual guidance. We ground this philosophy in our proposed Unified Diffusion VLA and Joint Discrete Denoising Diffusion Process (JD3P), which is a joint diffusion process that integrates multiple modalities into a single denoising trajectory to serve as the key mechanism enabling understanding, generation, and acting to be intrinsically synergistic. Our model and theory are built on a unified tokenized space of all modalities and a hybrid attention mechanism. We further propose a two-stage training pipeline and several inference-time techniques that optimize performance and efficiency. Our approach achieves state-of-the-art performance on benchmarks such as CALVIN, LIBERO, and SimplerEnv with 4$\\times$ faster inference than autoregressive methods, and we demonstrate its effectiveness through in-depth analysis and real-world evaluations. Our project page is available at https://irpn-eai.github.io/UD-VLA.github.io/.",
    "fetched_at": "2025-11-06T02:19:03.467994Z"
  },
  {
    "id": "2511.01720v1",
    "title": "Efficient Tool-Calling Multi-Expert NPC Agent for Commonsense   Persona-Grounded Dialogue",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mahammad Nuriyev"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01720v1",
    "abstract": "We present a multi-expert system for creating Non-Player Characters (NPCs) capable of both natural dialogue and contextual action execution in interactive environments. Using Qwen3 as the base model and Low-Rank Adaptation (LoRA) adapters, we instantiate three specialists: tool calling, tool-response interpretation, and direct dialogue. Our system comfortably meets the computational efficiency requirements, delivering fast responses and maintaining modest resource usage on L40S GPUs. In the Commonsense Persona-Grounded Dialogue Challenge 2025, our method ranked second overall.   Code available at: https://github.com/MahammadNuriyev62/CPDC-challenge-2025-solution/",
    "fetched_at": "2025-11-06T02:19:03.467929Z"
  },
  {
    "id": "2511.01755v1",
    "title": "3EED: Ground Everything Everywhere in 3D",
    "date": "2025-11-03",
    "tags": [
      "cs.CV",
      "CV",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Rong Li",
      "Yuhao Dong",
      "Tianshuai Hu",
      "Ao Liang",
      "Youquan Liu",
      "Dongyue Lu",
      "Liang Pan",
      "Lingdong Kong",
      "Junwei Liang",
      "Ziwei Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01755v1",
    "abstract": "Visual grounding in 3D is the key for embodied agents to localize language-referred objects in open-world environments. However, existing benchmarks are limited to indoor focus, single-platform constraints, and small scale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark featuring RGB and LiDAR data from vehicle, drone, and quadruped platforms. We provide over 128,000 objects and 22,000 validated referring expressions across diverse outdoor scenes -- 10x larger than existing datasets. We develop a scalable annotation pipeline combining vision-language model prompting with human verification to ensure high-quality spatial grounding. To support cross-platform learning, we propose platform-aware normalization and cross-modal alignment techniques, and establish benchmark protocols for in-domain and cross-platform evaluations. Our findings reveal significant performance gaps, highlighting the challenges and opportunities of generalizable 3D grounding. The 3EED dataset and benchmark toolkit are released to advance future research in language-driven 3D embodied perception.",
    "fetched_at": "2025-11-06T02:19:03.467896Z"
  },
  {
    "id": "2511.01805v2",
    "title": "Accumulating Context Changes the Beliefs of Language Models",
    "date": "2025-11-03",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiayi Geng",
      "Howard Chen",
      "Ryan Liu",
      "Manoel Horta Ribeiro",
      "Robb Willer",
      "Graham Neubig",
      "Thomas L. Griffiths"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01805v2",
    "abstract": "Language model (LM) assistants are increasingly used in applications such as brainstorming and research. Improvements in memory and context size have allowed these models to become more autonomous, which has also resulted in more text accumulation in their context windows without explicit user intervention. This comes with a latent risk: the belief profiles of models -- their understanding of the world as manifested in their responses or actions -- may silently change as context accumulates. This can lead to subtly inconsistent user experiences, or shifts in behavior that deviate from the original alignment of the models. In this paper, we explore how accumulating context by engaging in interactions and processing text -- talking and reading -- can change the beliefs of language models, as manifested in their responses and behaviors. Our results reveal that models' belief profiles are highly malleable: GPT-5 exhibits a 54.7% shift in its stated beliefs after 10 rounds of discussion about moral dilemmas and queries about safety, while Grok 4 shows a 27.2% shift on political issues after reading texts from the opposing position. We also examine models' behavioral changes by designing tasks that require tool use, where each tool selection corresponds to an implicit belief. We find that these changes align with stated belief shifts, suggesting that belief shifts will be reflected in actual behavior in agentic systems. Our analysis exposes the hidden risk of belief shift as models undergo extended sessions of talking or reading, rendering their opinions and actions unreliable.",
    "fetched_at": "2025-11-06T02:19:03.467832Z"
  },
  {
    "id": "2511.02016v1",
    "title": "ABIDES-MARL: A Multi-Agent Reinforcement Learning Environment for   Endogenous Price Formation and Execution in a Limit Order Book",
    "date": "2025-11-03",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.GT",
      "GT",
      "cs.MA",
      "MA",
      "cs.SY",
      "SY",
      "eess.SY",
      "91-10, 91A26, 68T05, 93E20",
      "I.2.11; I.2.8; J.4",
      "4"
    ],
    "authors": [
      "Patrick Cheridito",
      "Jean-Loup Dupret",
      "Zhexin Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02016v1",
    "abstract": "We present ABIDES-MARL, a framework that combines a new multi-agent reinforcement learning (MARL) methodology with a new realistic limit-order-book (LOB) simulation system to study equilibrium behavior in complex financial market games. The system extends ABIDES-Gym by decoupling state collection from kernel interruption, enabling synchronized learning and decision-making for multiple adaptive agents while maintaining compatibility with standard RL libraries. It preserves key market features such as price-time priority and discrete tick sizes. Methodologically, we use MARL to approximate equilibrium-like behavior in multi-period trading games with a finite number of heterogeneous agents-an informed trader, a liquidity trader, noise traders, and competing market makers-all with individual price impacts. This setting bridges optimal execution and market microstructure by embedding the liquidity trader's optimization problem within a strategic trading environment. We validate the approach by solving an extended Kyle model within the simulation system, recovering the gradual price discovery phenomenon. We then extend the analysis to a liquidity trader's problem where market liquidity arises endogenously and show that, at equilibrium, execution strategies shape market-maker behavior and price dynamics. ABIDES-MARL provides a reproducible foundation for analyzing equilibrium and strategic adaptation in realistic markets and contributes toward building economically interpretable agentic AI systems for finance.",
    "fetched_at": "2025-11-06T02:19:03.467770Z"
  },
  {
    "id": "2511.02071v1",
    "title": "Human-AI Co-Embodied Intelligence for Scientific Experimentation and   Manufacturing",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xinyi Lin",
      "Yuyang Zhang",
      "Yuanhang Gan",
      "Juntao Chen",
      "Hao Shen",
      "Yichun He",
      "Lijun Li",
      "Ze Yuan",
      "Shuang Wang",
      "Chaohao Wang",
      "Rui Zhang",
      "Na Li",
      "Jia Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02071v1",
    "abstract": "Scientific experiment and manufacture rely on complex, multi-step procedures that demand continuous human expertise for precise execution and decision-making. Despite advances in machine learning and automation, conventional models remain confined to virtual domains, while real-world experiment and manufacture still rely on human supervision and expertise. This gap between machine intelligence and physical execution limits reproducibility, scalability, and accessibility across scientific and manufacture workflows. Here, we introduce human-AI co-embodied intelligence, a new form of physical AI that unites human users, agentic AI, and wearable hardware into an integrated system for real-world experiment and intelligent manufacture. In this paradigm, humans provide precise execution and control, while agentic AI contributes memory, contextual reasoning, adaptive planning, and real-time feedback. The wearable interface continuously captures the experimental and manufacture processes, facilitates seamless communication between humans and AI for corrective guidance and interpretable collaboration. As a demonstration, we present Agentic-Physical Experimentation (APEX) system, coupling agentic reasoning with physical execution through mixed-reality. APEX observes and interprets human actions, aligns them with standard operating procedures, provides 3D visual guidance, and analyzes every step. Implemented in a cleanroom for flexible electronics fabrication, APEX system achieves context-aware reasoning with accuracy exceeding general multimodal large language models, corrects errors in real time, and transfers expertise to beginners. These results establish a new class of agentic-physical-human intelligence that extends agentic reasoning beyond computation into the physical domain, transforming scientific research and manufacturing into autonomous, traceable, interpretable, and scalable processes.",
    "fetched_at": "2025-11-06T02:19:03.467715Z"
  },
  {
    "id": "2511.02094v1",
    "title": "Automated Reward Design for Gran Turismo",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Michel Ma",
      "Takuma Seno",
      "Kaushik Subramanian",
      "Peter R. Wurman",
      "Peter Stone",
      "Craig Sherstan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.02094v1",
    "abstract": "When designing reinforcement learning (RL) agents, a designer communicates the desired agent behavior through the definition of reward functions - numerical feedback given to the agent as reward or punishment for its actions. However, mapping desired behaviors to reward functions can be a difficult process, especially in complex environments such as autonomous racing. In this paper, we demonstrate how current foundation models can effectively search over a space of reward functions to produce desirable RL agents for the Gran Turismo 7 racing game, given only text-based instructions. Through a combination of LLM-based reward generation, VLM preference-based evaluation, and human feedback we demonstrate how our system can be used to produce racing agents competitive with GT Sophy, a champion-level RL racing agent, as well as generate novel behaviors, paving the way for practical automated reward design in real world applications.",
    "fetched_at": "2025-11-06T02:19:03.467631Z"
  },
  {
    "id": "2511.02119v1",
    "title": "InsurAgent: A Large Language Model-Empowered Agent for Simulating   Individual Behavior in Purchasing Flood Insurance",
    "date": "2025-11-03",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ziheng Geng",
      "Jiachen Liu",
      "Ran Cao",
      "Lu Cheng",
      "Dan M. Frangopol",
      "Minghui Cheng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02119v1",
    "abstract": "Flood insurance is an effective strategy for individuals to mitigate disaster-related losses. However, participation rates among at-risk populations in the United States remain strikingly low. This gap underscores the need to understand and model the behavioral mechanisms underlying insurance decisions. Large language models (LLMs) have recently exhibited human-like intelligence across wide-ranging tasks, offering promising tools for simulating human decision-making. This study constructs a benchmark dataset to capture insurance purchase probabilities across factors. Using this dataset, the capacity of LLMs is evaluated: while LLMs exhibit a qualitative understanding of factors, they fall short in estimating quantitative probabilities. To address this limitation, InsurAgent, an LLM-empowered agent comprising five modules including perception, retrieval, reasoning, action, and memory, is proposed. The retrieval module leverages retrieval-augmented generation (RAG) to ground decisions in empirical survey data, achieving accurate estimation of marginal and bivariate probabilities. The reasoning module leverages LLM common sense to extrapolate beyond survey data, capturing contextual information that is intractable for traditional models. The memory module supports the simulation of temporal decision evolutions, illustrated through a roller coaster life trajectory. Overall, InsurAgent provides a valuable tool for behavioral modeling and policy analysis.",
    "fetched_at": "2025-11-06T02:19:03.467579Z"
  },
  {
    "id": "2511.02136v1",
    "title": "JaxMARL-HFT: GPU-Accelerated Large-Scale Multi-Agent Reinforcement   Learning for High-Frequency Trading",
    "date": "2025-11-03",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Valentin Mohl",
      "Sascha Frey",
      "Reuben Leyland",
      "Kang Li",
      "George Nigmatulin",
      "Mihai Cucuringu",
      "Stefan Zohren",
      "Jakob Foerster",
      "Anisoara Calinescu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02136v1",
    "abstract": "Agent-based modelling (ABM) approaches for high-frequency financial markets are difficult to calibrate and validate, partly due to the large parameter space created by defining fixed agent policies. Multi-agent reinforcement learning (MARL) enables more realistic agent behaviour and reduces the number of free parameters, but the heavy computational cost has so far limited research efforts. To address this, we introduce JaxMARL-HFT (JAX-based Multi-Agent Reinforcement Learning for High-Frequency Trading), the first GPU-accelerated open-source multi-agent reinforcement learning environment for high-frequency trading (HFT) on market-by-order (MBO) data. Extending the JaxMARL framework and building on the JAX-LOB implementation, JaxMARL-HFT is designed to handle a heterogeneous set of agents, enabling diverse observation/action spaces and reward functions. It is designed flexibly, so it can also be used for single-agent RL, or extended to act as an ABM with fixed-policy agents. Leveraging JAX enables up to a 240x reduction in end-to-end training time, compared with state-of-the-art reference implementations on the same hardware. This significant speed-up makes it feasible to exploit the large, granular datasets available in high-frequency trading, and to perform the extensive hyperparameter sweeps required for robust and efficient MARL research in trading. We demonstrate the use of JaxMARL-HFT with independent Proximal Policy Optimization (IPPO) for a two-player environment, with an order execution and a market making agent, using one year of LOB data (400 million orders), and show that these agents learn to outperform standard benchmarks. The code for the JaxMARL-HFT framework is available on GitHub.",
    "fetched_at": "2025-11-06T02:19:03.467507Z"
  },
  {
    "id": "2511.00751v1",
    "title": "Reevaluating Self-Consistency Scaling in Multi-Agent Systems",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Chiyan Loo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00751v1",
    "abstract": "This study examines the trade-offs of increasing sampled reasoning paths in self-consistency for modern large language models (LLMs). Earlier research with older models showed that combining multiple reasoning chains improves results before reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we revisit those claims under current model conditions. Each configuration pooled outputs from varying sampled reasoning paths and compared them to a single chain-of-thought (CoT) baseline. Larger models exhibited a more stable and consistent improvement curve. The results confirm that performance gains taper off after moderate sampling, aligning with past findings. This plateau suggests diminishing returns driven by overlap among reasoning paths. Self-consistency remains useful, but high-sample configurations offer little benefit relative to their computational cost.",
    "fetched_at": "2025-11-06T02:19:05.289486Z"
  },
  {
    "id": "2511.00782v1",
    "title": "Count-Based Approaches Remain Strong: A Benchmark Against Transformer   and LLM Pipelines on Structured EHR",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jifan Gao",
      "Michael Rosenthal",
      "Brian Wolpin",
      "Simona Cristea"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00782v1",
    "abstract": "Structured electronic health records (EHR) are essential for clinical prediction. While count-based learners continue to perform strongly on such data, no benchmarking has directly compared them against more recent mixture-of-agents LLM pipelines, which have been reported to outperform single LLMs in various NLP tasks. In this study, we evaluated three categories of methodologies for EHR prediction using the EHRSHOT dataset: count-based models built from ontology roll-ups with two time bins, based on LightGBM and the tabular foundation model TabPFN; a pretrained sequential transformer (CLMBR); and a mixture-of-agents pipeline that converts tabular histories to natural-language summaries followed by a text classifier. We assessed eight outcomes using the EHRSHOT dataset. Across the eight evaluation tasks, head-to-head wins were largely split between the count-based and the mixture-of-agents methods. Given their simplicity and interpretability, count-based models remain a strong candidate for structured EHR benchmarking. The source code is available at: https://github.com/cristea-lab/Structured_EHR_Benchmark.",
    "fetched_at": "2025-11-06T02:19:05.289452Z"
  },
  {
    "id": "2511.00807v2",
    "title": "FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving   on Heterogeneous GPUs",
    "date": "2025-11-02",
    "tags": [
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Xuan He",
      "Zequan Fang",
      "Jinzhao Lian",
      "Danny H. K. Tsang",
      "Baosen Zhang",
      "Yize Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00807v2",
    "abstract": "The ever-increasing computation and energy demand for LLM and AI agents call for holistic and efficient optimization of LLM serving systems. In practice, heterogeneous GPU clusters can be deployed in a geographically distributed manner, while LLM load also observes diversity in terms of both query traffic and serving patterns. LLM queries running on advanced GPUs during a high-emission hour at one location can lead to significantly higher carbon footprints versus same queries running on mid-level GPUs at a low-emission time and location. By observing LLM serving requirements and leveraging spatiotemporal computation flexibility, we consider the joint routing and scheduling problem, and propose FREESH to cooperatively run a group of data centers while minimizing user-specified carbon or energy objectives. FREESH identifies the optimal configurations of balanced load serving by matching distinct GPU instance's power-throughput characteristics with predictable LLM query length and workloads. To ensure both latency and fairness requirements, FREESH identifies optimized parallelism and query routing schedules together with dynamic GPU frequency scaling for power saving, and Least-Laxity-First (LLF) serving strategy for query scheduling. During the 1-hour serving on production workloads, FREESH reduces energy by 28.6% and emissions by 45.45% together with improvements in SLO attainment and fairness.",
    "fetched_at": "2025-11-06T02:19:05.289348Z"
  },
  {
    "id": "2511.00872v1",
    "title": "A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric   Software Engineering Tasks",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Zhuowen Yin",
      "Cuifeng Gao",
      "Chunsong Fan",
      "Wenzhang Yang",
      "Yinxing Xue",
      "Lijun Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00872v1",
    "abstract": "Unlike traditional automation tools or static LLM-based systems, agents combine decision-making and tool utilization to accomplish complex tasks, showing great potential in software engineering. However, existing studies largely focus on specific tasks or isolated aspects, providing an incomplete picture of agents' practical capabilities. To address this, we conduct a comprehensive empirical study evaluating seven general-purpose agent frameworks across three representative code-centric tasks: software development, vulnerability detection, and program repair. Each task is assessed using standard, widely adopted benchmarks to ensure objective and comparable evaluation. Agent performance is systematically analyzed from three complementary perspectives: effectiveness (task success), efficiency (execution process), and overhead (token consumption). Our findings reveal distinct capability patterns and trade-offs among the evaluated frameworks. In terms of effectiveness, agents achieve moderate overall performance. Regarding efficiency, AgentOrchestra tends to exhibit the longest trajectories and the most correction attempts due to coordination overhead, whereas OpenHands demonstrate stronger reflective reasoning abilities. For overhead, software development incurs the highest monetary cost, while GPTswarm remains the most cost-efficient. Furthermore, we conduct an in-depth cross-analysis of the relationship between effectiveness and efficiency, exploring the underlying reasons behind their interplay. These findings guide both practical adoption and future research toward more efficient software engineering agents.",
    "fetched_at": "2025-11-06T02:19:05.289126Z"
  },
  {
    "id": "2511.00908v1",
    "title": "GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with   Heterogeneous Graph Neural Networks",
    "date": "2025-11-02",
    "tags": [
      "cs.CV",
      "CV",
      "cs.GR",
      "GR"
    ],
    "authors": [
      "Heng Zheng",
      "Yuling Shi",
      "Xiaodong Gu",
      "Haochen You",
      "Zijian Zhang",
      "Lubin Gan",
      "Hao Zhang",
      "Wenjun Huang",
      "Jin Huang"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.00908v1",
    "abstract": "Visual geo-localization requires extensive geographic knowledge and sophisticated reasoning to determine image locations without GPS metadata. Traditional retrieval methods are constrained by database coverage and quality. Recent Large Vision-Language Models (LVLMs) enable direct location reasoning from image content, yet individual models struggle with diverse geographic regions and complex scenes. Existing multi-agent systems improve performance through model collaboration but treat all agent interactions uniformly. They lack mechanisms to handle conflicting predictions effectively. We propose \\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph neural networks for visual geo-localization. Our approach models diverse debate relationships through typed edges, distinguishing supportive collaboration, competitive argumentation, and knowledge transfer. We introduce a dual-level debate mechanism combining node-level refinement and edge-level argumentation modeling. A cross-level topology refinement strategy enables co-evolution between graph structure and agent representations. Experiments on multiple benchmarks demonstrate GraphGeo significantly outperforms state-of-the-art methods. Our framework transforms cognitive conflicts between agents into enhanced geo-localization accuracy through structured debate.",
    "fetched_at": "2025-11-06T02:19:05.289065Z"
  },
  {
    "id": "2511.00945v1",
    "title": "\"Less is More\": Reducing Cognitive Load and Task Drift in Real-Time   Multimodal Assistive Agents for the Visually Impaired",
    "date": "2025-11-02",
    "tags": [
      "cs.HC",
      "HC",
      "H.5",
      "5"
    ],
    "authors": [
      "Yi Zhao",
      "Siqi Wang",
      "Qiqun Geng",
      "Erxin Yu",
      "Jing Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00945v1",
    "abstract": "Vision-Language Models (VLMs) enable on-demand visual assistance, yet current applications for people with visual impairments (PVI) impose high cognitive load and exhibit task drift, limiting real-world utility. We first conducted a formative study with 15 PVI and identified three requirements for visually impaired assistance (VIA): low latency for real-time use, minimal cognitive load, and hallucination-resistant responses to sustain trust. Informed by the formative study, we present VIA-Agent, a prototype that co-optimizes its cognitive 'brain' and interactive 'body'. The brain implements a goal-persistent design with calibrated conciseness to produce brief, actionable guidance; the body adopts a real-time communication (RTC) embodiment-evolving from a request-response model Context Protocol (MCP) pipeline-to-support fluid interaction. We evaluated VIA-Agent with 9 PVI across navigation and object retrieval in the wild against BeMyAI and Doubao. VIA-Agent significantly outperformed BeMyAI both quantitatively and qualitatively. While achieving success rates comparable to Doubao, it reduced mean task time by 39.9% (70.1 s vs. 110.7 s), required fewer conversational turns (4.3 vs. 5.0), and lowered perceived cognitive load and task drift. System Usability Scale (SUS) results aligned with these findings, with VIA-Agent achieving the highest usability. We hope this work inspires the development of more human-centered VIA systems.",
    "fetched_at": "2025-11-06T02:19:05.288923Z"
  },
  {
    "id": "2511.00767v1",
    "title": "Power Control Based on Multi-Agent Deep Q Network for D2D Communication",
    "date": "2025-11-02",
    "tags": [
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Shi Gengtian",
      "Takashi Koshimizu",
      "Megumi Saito",
      "Pan Zhenni",
      "Liu Jiang",
      "Shigeru Shimamoto"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00767v1",
    "abstract": "In device-to-device (D2D) communication under a cell with resource sharing mode the spectrum resource utilization of the system will be improved. However, if the interference generated by the D2D user is not controlled, the performance of the entire system and the quality of service (QOS) of the cellular user may be degraded. Power control is important because it helps to reduce interference in the system. In this paper, we propose a reinforcement learning algorithm for adaptive power control that helps reduce interference to increase system throughput. Simulation results show the proposed algorithm has better performance than traditional algorithm in LTE (Long Term Evolution).",
    "fetched_at": "2025-11-06T02:19:03.469529Z"
  },
  {
    "id": "2511.00802v1",
    "title": "GrowthHacker: Automated Off-Policy Evaluation Optimization Using   Code-Modifying LLM Agents",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Jie JW Wu",
      "Ayanda Patrick Herlihy",
      "Ahmad Saleem Mirza",
      "Ali Afoud",
      "Fatemeh Fard"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00802v1",
    "abstract": "With the software industry shifting toward a data-driven culture, online A/B testing is a key tool for evaluating new technologies. However, deploying such experiments requires substantial resources, may negatively impact users, and involves long data collection periods. To address this, \\textit{off-policy evaluation (OPE)}, or offline A/B testing, uses logged data to assess technologies and is fundamental in Reinforcement Learning, making it crucial in domains where online testing is costly or risky, such as healthcare, recommender systems, education, dialog systems, and robotics. Despite advances in coding LLMs and agentic AI, little is known about leveraging them to optimize OPE results. We investigate whether LLMs and LLM-based agents can improve OPE performance via code optimization. We propose \\textit{GrowthHacker}, a benchmark with agent and baseline methods on large-scale real-world datasets, which iteratively optimizes code, evaluates results, and begins new optimization cycles. We collected datasets, established protocols, implemented baselines for OPE on the Open Bandit Pipeline (OBP)~\\cite{saito2021openbanditdatasetpipeline} and Scope-RL~\\cite{kiyohara2023scope}, and developed the \\textit{two_agent} framework, which reduces system complexity while preserving optimization effectiveness. Results show the two_agent framework achieves 100% reliability and the highest average improvement of 106.7% among positive outcomes. Both two_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%. These findings demonstrate the feasibility of LLM-based agents as automated \"growth hackers\" to enhance OPE systems, with implications for scaling data-driven decision-making in production.",
    "fetched_at": "2025-11-06T02:19:03.469481Z"
  },
  {
    "id": "2511.00810v1",
    "title": "GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor   for GUI Grounding",
    "date": "2025-11-02",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.HC",
      "HC",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shijie Zhou",
      "Viet Dac Lai",
      "Hao Tan",
      "Jihyung Kil",
      "Wanrong Zhu",
      "Changyou Chen",
      "Ruiyi Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00810v1",
    "abstract": "Graphical user interface (GUI) grounding is a key function of computer-use agents, which maps natural-language instructions to actionable screen regions. Existing approaches based on Multimodal Large Language Models (MLLMs) typically formulate it as a text-based coordinate generation task, yet directly generating precise coordinates from visual inputs remains challenging and computationally intensive. An intuitive way to implement GUI grounding is to first select visual patches relevant to the instructions and then determine the precise click location within those patches. Based on the observations that general MLLMs have some native grounding capability, nested within their attentions, we propose GUI-AIMA, an attention-based and coordinate-free supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns the intrinsic multimodal attention of MLLMs with patch-wise grounding signals. These signals are calculated adaptively for diverse user instructions by multi-head aggregation on simplified query-visual attention matrices. Besides, its coordinate-free manner can easily integrate a plug-and-play zoom-in stage. GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional data efficiency and verifying that light training can trigger the native grounding capability of MLLMs. It achieves state-of-the-art performance among 3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2% on OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA",
    "fetched_at": "2025-11-06T02:19:03.469425Z"
  },
  {
    "id": "2511.00814v1",
    "title": "Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic   Motion Planning",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY",
      "93C41, 93E11, 37M10",
      "I.2.9; I.2.6; I.2.8",
      "8"
    ],
    "authors": [
      "Stella Kombo",
      "Masih Haseli",
      "Skylar Wei",
      "Joel W. Burdick"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00814v1",
    "abstract": "Autonomous systems often must predict the motions of nearby agents from partial and noisy data. This paper asks and answers the question: \"can we learn, in real-time, a nonlinear predictive model of another agent's motions?\" Our online framework denoises and forecasts such dynamics using a modified sliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy measurements are embedded into a Hankel matrix, while an associated Page matrix enables singular-value hard thresholding (SVHT) to estimate the effective rank. A Cadzow projection enforces structured low-rank consistency, yielding a denoised trajectory and local noise variance estimates. From this representation, a time-varying Hankel-DMD lifted linear predictor is constructed for multi-step forecasts. The residual analysis provides variance-tracking signals that can support downstream estimators and risk-aware planning. We validate the approach in simulation under Gaussian and heavy-tailed noise, and experimentally on a dynamic crane testbed. Results show that the method achieves stable variance-aware denoising and short-horizon prediction suitable for integration into real-time control frameworks.",
    "fetched_at": "2025-11-06T02:19:03.469360Z"
  },
  {
    "id": "2511.00839v1",
    "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "John Yang",
      "Kilian Lieret",
      "Joyce Yang",
      "Carlos E. Jimenez",
      "Ofir Press",
      "Ludwig Schmidt",
      "Diyi Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00839v1",
    "abstract": "Current benchmarks for coding evaluate language models (LMs) on concrete, well-specified tasks such as fixing specific bugs or writing targeted tests. However, human programmers do not spend all day incessantly addressing isolated tasks. Instead, real-world software development is grounded in the pursuit of high-level goals, like improving user retention or reducing costs. Evaluating whether LMs can also iteratively develop code to better accomplish open-ended objectives without any explicit guidance remains an open challenge. To address this, we introduce CodeClash, a benchmark where LMs compete in multi-round tournaments to build the best codebase for achieving a competitive objective. Each round proceeds in two phases: agents edit their code, then their codebases compete head-to-head in a code arena that determines winners based on objectives like score maximization, resource acquisition, or survival. Whether it's writing notes, scrutinizing documentation, analyzing competition logs, or creating test suites, models must decide for themselves how to improve their codebases both absolutely and against their opponents. We run 1680 tournaments (25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal that while models exhibit diverse development styles, they share fundamental limitations in strategic reasoning. Models also struggle with long-term codebase maintenance, as repositories become progressively messy and redundant. These limitations are stark: top models lose every round against expert human programmers. We open-source CodeClash to advance the study of autonomous, goal-oriented code development.",
    "fetched_at": "2025-11-06T02:19:03.469311Z"
  },
  {
    "id": "2511.00843v1",
    "title": "Portal UX Agent -- A Plug-and-Play Engine for Rendering UIs from Natural   Language Specifications",
    "date": "2025-11-02",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Xinsong Li",
      "Ning Jiang",
      "Jay Selvaraj"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00843v1",
    "abstract": "The rapid appearance of large language models (LLMs) has led to systems that turn natural-language intent into real user interfaces (UIs). Free-form code generation maximizes expressiveness but often hurts reliability, security, and design-system compliance. In contrast, fully static UIs are easy to govern but lack adaptability. We present the Portal UX Agent, a practical middle way that makes bounded generation work: an LLM plans the UI at a high level, and a deterministic renderer assembles the final interface from a vetted set of components and layout templates. The agent maps intents to a typed composition-template and component specifications-constrained by a schema. This enables auditability, reuse, and safety while preserving flexibility. We also introduce a mixed-methods evaluation framework that combines automatic checks (coverage, property fidelity, layout, accessibility, performance) with an LLM-as-a-Judge rubric to assess semantic alignment and visual polish. Experiments on multi-domain portal scenarios show that the Portal UX Agent reliably turns intent into coherent, usable UIs and performs well on compositionality and clarity. This work advances agentic UI design by combining model-driven representations, plug-and-play rendering, and structured evaluation, paving the way for controllable and trustworthy UI generation.",
    "fetched_at": "2025-11-06T02:19:03.469253Z"
  },
  {
    "id": "2511.00880v1",
    "title": "KFCPO: Kronecker-Factored Approximated Constrained Policy Optimization",
    "date": "2025-11-02",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "68T07, 90C15, 93E35"
    ],
    "authors": [
      "Joonyoung Lim",
      "Younghwan Yoo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00880v1",
    "abstract": "We propose KFCPO, a novel Safe Reinforcement Learning (Safe RL) algorithm that combines scalable Kronecker-Factored Approximate Curvature (K-FAC) based second-order policy optimization with safety-aware gradient manipulation. KFCPO leverages K-FAC to perform efficient and stable natural gradient updates by approximating the Fisher Information Matrix (FIM) in a layerwise, closed form manner, avoiding iterative approximation overheads. To address the tradeoff between reward maximization and constraint satisfaction, we introduce a margin aware gradient manipulation mechanism that adaptively adjusts the influence of reward and cost gradients based on the agent's proximity to safety boundaries. This method blends gradients using a direction sensitive projection, eliminating harmful interference and avoiding abrupt changes caused by fixed hard thresholds. Additionally, a minibatch level KL rollback strategy is adopted to ensure trust region compliance and to prevent destabilizing policy shifts. Experiments on Safety Gymnasium using OmniSafe show that KFCPO achieves 10.3% to 50.2% higher average return across environments compared to the best baseline that respected the safety constraint, demonstrating superior balance of safety and performance.",
    "fetched_at": "2025-11-06T02:19:03.469208Z"
  },
  {
    "id": "2511.00917v1",
    "title": "Maestro: Orchestrating Robotics Modules with Vision-Language Models for   Zero-Shot Generalist Robots",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junyao Shi",
      "Rujia Yang",
      "Kaitian Chao",
      "Selina Bingqing Wan",
      "Yifei Shao",
      "Jiahui Lei",
      "Jianing Qian",
      "Long Le",
      "Pratik Chaudhari",
      "Kostas Daniilidis",
      "Chuan Wen",
      "Dinesh Jayaraman"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00917v1",
    "abstract": "Today's best-explored routes towards generalist robots center on collecting ever larger \"observations-in actions-out\" robotics datasets to train large end-to-end models, copying a recipe that has worked for vision-language models (VLMs). We pursue a road less traveled: building generalist policies directly around VLMs by augmenting their general capabilities with specific robot capabilities encapsulated in a carefully curated set of perception, planning, and control modules. In Maestro, a VLM coding agent dynamically composes these modules into a programmatic policy for the current task and scenario. Maestro's architecture benefits from a streamlined closed-loop interface without many manually imposed structural constraints, and a comprehensive and diverse tool repertoire. As a result, it largely surpasses today's VLA models for zero-shot performance on challenging manipulation skills. Further, Maestro is easily extensible to incorporate new modules, easily editable to suit new embodiments such as a quadruped-mounted arm, and even easily adapts from minimal real-world experiences through local code edits.",
    "fetched_at": "2025-11-06T02:19:03.469168Z"
  },
  {
    "id": "2511.00993v1",
    "title": "Aligning LLM agents with human learning and adjustment behavior: a dual   agent approach",
    "date": "2025-11-02",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Tianming Liu",
      "Jirong Yang",
      "Yafeng Yin",
      "Manzi Li",
      "Linghao Wang",
      "Zheng Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00993v1",
    "abstract": "Effective modeling of how human travelers learn and adjust their travel behavior from interacting with transportation systems is critical for system assessment and planning. However, this task is also difficult due to the complex cognition and decision-making involved in such behavior. Recent research has begun to leverage Large Language Model (LLM) agents for this task. Building on this, we introduce a novel dual-agent framework that enables continuous learning and alignment between LLM agents and human travelers on learning and adaptation behavior from online data streams. Our approach involves a set of LLM traveler agents, equipped with a memory system and a learnable persona, which serve as simulators for human travelers. To ensure behavioral alignment, we introduce an LLM calibration agent that leverages the reasoning and analytical capabilities of LLMs to train the personas of these traveler agents. Working together, this dual-agent system is designed to track and align the underlying decision-making mechanisms of travelers and produce realistic, adaptive simulations. Using a real-world dataset from a day-to-day route choice experiment, we show our approach significantly outperforms existing LLM-based methods in both individual behavioral alignment and aggregate simulation accuracy. Furthermore, we demonstrate that our method moves beyond simple behavioral mimicry to capture the evolution of underlying learning processes, a deeper alignment that fosters robust generalization. Overall, our framework provides a new approach for creating adaptive and behaviorally realistic agents to simulate travelers' learning and adaptation that can benefit transportation simulation and policy analysis.",
    "fetched_at": "2025-11-06T02:19:03.469096Z"
  },
  {
    "id": "2511.01008v1",
    "title": "MARS-SQL: A multi-agent reinforcement learning framework for Text-to-SQL",
    "date": "2025-11-02",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Haolin Yang",
      "Jipeng Zhang",
      "Zhitao He",
      "Yi R. Fung"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01008v1",
    "abstract": "Translating natural language to SQL remains difficult for complex queries. Such queries often need environmental interaction and self-correction. To address this, we introduce MARS-SQL, a novel multi-agent framework that combines principled task decomposition and interactive reinforcement learning (RL). Our system comprises three specialized agents: a Grounding Agent for schema linking, a Generation Agent for query generation, and a Validation Agent for final selection. The core of our framework is the Generation agent, which is trained via a multi-turn RL policy. Adopting a ReAct-style Think-Act-Observe loop, the agent iteratively generates thoughts, executes SQL actions against a live database, and revises its strategy based on execution feedback, enabling dynamic, stateful reasoning and self-correction. At inference time, we generate multiple interaction trajectories to explore diverse reasoning paths. The Validation agent, then selects the optimal trajectory by modeling verification as a next-token prediction task and choosing the solution with the highest generation probability. This structured workflow pipelines specialized agents. It combines interactive RL for generation with generative modeling for verification. The approach proves highly effective for robust and accurate SQL generation. Experiments show that MARS-SQL achieves state-of-the-art Execution Accuracy of 77.84% on the BIRD dev set and 89.75% on the Spider test set. Our code is available at https://github.com/YangHaolin0526/MARS-SQL.",
    "fetched_at": "2025-11-06T02:19:03.469038Z"
  },
  {
    "id": "2511.01047v2",
    "title": "HAFixAgent: History-Aware Automated Program Repair Agent",
    "date": "2025-11-02",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yu Shi",
      "Hao Li",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01047v2",
    "abstract": "Automated program repair (APR) has recently shifted toward large language models and agent-based systems, yet most systems rely on local snapshot context, overlooking repository history. Prior work shows that repository history helps repair single-line bugs, since the last commit touching the buggy line is often the bug-introducing one. In this paper, we investigate whether repository history can also improve agentic APR systems at scale, especially for complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing Agent that injects blame-derived repository heuristics into its repair loop. A preliminary study of all 854 real-world bugs from Defects4J motivates our design, showing that bug-relevant history is both widely available and highly concentrated. Empirical comparison of HAFixAgent with two state-of-the-art baselines shows: (1) Effectiveness: HAFixAgent significantly improves over the agent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2) Efficiency: history does not significantly increase agent steps and keeps token costs comparable, with notably lower median costs for complex multi-file-multi-hunk bugs. (3) Practicality: combining different historical heuristics repairs more bugs, offering a clear cost-benefit trade-off. HAFixAgent offers a practical recipe for history-aware agentic APR: ground the agent in version control history, prioritize diff-based historical context, and integrate complementary heuristics when needed.",
    "fetched_at": "2025-11-06T02:19:03.468990Z"
  },
  {
    "id": "2511.01078v1",
    "title": "Predictive Auxiliary Learning for Belief-based Multi-Agent Systems",
    "date": "2025-11-02",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Qinwei Huang",
      "Stefan Wang",
      "Simon Khan",
      "Garrett Katz",
      "Qinru Qiu"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2511.01078v1",
    "abstract": "The performance of multi-agent reinforcement learning (MARL) in partially observable environments depends on effectively aggregating information from observations, communications, and reward signals. While most existing multi-agent systems primarily rely on rewards as the only feedback for policy training, our research shows that introducing auxiliary predictive tasks can significantly enhance learning efficiency and stability. We propose Belief-based Predictive Auxiliary Learning (BEPAL), a framework that incorporates auxiliary training objectives to support policy optimization. BEPAL follows the centralized training with decentralized execution paradigm. Each agent learns a belief model that predicts unobservable state information, such as other agents' rewards or motion directions, alongside its policy model. By enriching hidden state representations with information that does not directly contribute to immediate reward maximization, this auxiliary learning process stabilizes MARL training and improves overall performance. We evaluate BEPAL in the predator-prey environment and Google Research Football, where it achieves an average improvement of about 16 percent in performance metrics and demonstrates more stable convergence compared to baseline methods.",
    "fetched_at": "2025-11-06T02:19:03.468943Z"
  },
  {
    "id": "2511.01083v1",
    "title": "Deployable Vision-driven UAV River Navigation via Human-in-the-loop   Preference Alignment",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Zihan Wang",
      "Jianwen Li",
      "Li-Fan Wu",
      "Nina Mahmoudian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01083v1",
    "abstract": "Rivers are critical corridors for environmental monitoring and disaster response, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven policies can provide fast, low-cost coverage. However, deployment exposes simulation-trained policies with distribution shift and safety risks and requires efficient adaptation from limited human interventions. We study human-in-the-loop (HITL) learning with a conservative overseer who vetoes unsafe or inefficient actions and provides statewise preferences by comparing the agent's proposal with a corrective override. We introduce Statewise Hybrid Preference Alignment for Robotics (SPAR-H), which fuses direct preference optimization on policy logits with a reward-based pathway that trains an immediate-reward estimator from the same preferences and updates the policy using a trust-region surrogate. With five HITL rollouts collected from a fixed novice policy, SPAR-H achieves the highest final episodic reward and the lowest variance across initial conditions among tested methods. The learned reward model aligns with human-preferred actions and elevates nearby non-intervened choices, supporting stable propagation of improvements. We benchmark SPAR-H against imitation learning (IL), direct preference variants, and evaluative reinforcement learning (RL) in the HITL setting, and demonstrate real-world feasibility of continual preference alignment for UAV river following. Overall, dual statewise preferences empirically provide a practical route to data-efficient online adaptation in riverine navigation.",
    "fetched_at": "2025-11-06T02:19:03.468893Z"
  },
  {
    "id": "2511.01093v1",
    "title": "Continual Learning, Not Training: Online Adaptation For Agents",
    "date": "2025-11-02",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "F.2.2; I.2.7",
      "7"
    ],
    "authors": [
      "Aman Jaglan",
      "Jarrod Barnes"
    ],
    "institution": "Microsoft, MIT",
    "link": "http://arxiv.org/pdf/2511.01093v1",
    "abstract": "Continual Learning (CL) methods have traditionally focused on mitigating catastrophic forgetting through gradient-based retraining, an approach ill-suited for deployed agents that must adapt in real time. We introduce our Adaptive Teaching and Learning System (ATLAS), a dual-agent architecture that decouples reasoning (Teacher) from execution (Student) and incorporates a persistent learning memory that stores distilled guidance from experience. This informs the orchestration layer, enabling the system to dynamically adjust its operational strategies, such as supervision level or initial plan selection, at inference time. In doing so, ATLAS achieves gradient-free continual learning, shifting the locus of adaptation from model parameters to system-level orchestration. We formulate this as a system-centric paradigm for continual learning, where the objective is adaptive efficiency: maximizing task success while minimizing computational cost through inference-time orchestration rather than parameter updates. Evaluated on Microsoft's ExCyTIn-Bench, an open-source benchmark simulating complex cyberthreat investigation, ATLAS achieves 54.1% success with GPT-5-mini as its Student, outperforming the larger GPT-5 (High) by 13% while reducing cost by 86%. Cross-incident validation demonstrates generalization: frozen pamphlets from Incident #5 improve accuracy from 28% to 41% with zero retraining, while shifting output composition from verbose exploration to structured reasoning. Together, these findings establish gradient-free continual learning as a viable path toward adaptive, deployable AI systems and provide causally annotated traces valuable for training explicit world models.",
    "fetched_at": "2025-11-06T02:19:03.468838Z"
  },
  {
    "id": "2511.01107v1",
    "title": "SLAP: Shortcut Learning for Abstract Planning",
    "date": "2025-11-02",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Y. Isabel Liu",
      "Bowen Li",
      "Benjamin Eysenbach",
      "Tom Silver"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.01107v1",
    "abstract": "Long-horizon decision-making with sparse rewards and continuous states and actions remains a fundamental challenge in AI and robotics. Task and motion planning (TAMP) is a model-based framework that addresses this challenge by planning hierarchically with abstract actions (options). These options are manually defined, limiting the agent to behaviors that we as human engineers know how to program (pick, place, move). In this work, we propose Shortcut Learning for Abstract Planning (SLAP), a method that leverages existing TAMP options to automatically discover new ones. Our key idea is to use model-free reinforcement learning (RL) to learn shortcuts in the abstract planning graph induced by the existing options in TAMP. Without any additional assumptions or inputs, shortcut learning leads to shorter solutions than pure planning, and higher task success rates than flat and hierarchical RL. Qualitatively, SLAP discovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that differ significantly from the manually-defined ones. In experiments in four simulated robotic environments, we show that SLAP solves and generalizes to a wide range of tasks, reducing overall plan lengths by over 50% and consistently outperforming planning and RL baselines.",
    "fetched_at": "2025-11-06T02:19:03.468793Z"
  },
  {
    "id": "2511.00330v1",
    "title": "Sherlock: Reliable and Efficient Agentic Workflow Execution",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Yeonju Ro",
      "Haoran Qiu",
      "Íñigo Goiri",
      "Rodrigo Fonseca",
      "Ricardo Bianchini",
      "Aditya Akella",
      "Zhangyang Wang",
      "Mattan Erez",
      "Esha Choukse"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00330v1",
    "abstract": "With the increasing adoption of large language models (LLM), agentic workflows, which compose multiple LLM calls with tools, retrieval, and reasoning steps, are increasingly replacing traditional applications. However, such workflows are inherently error-prone: incorrect or partially correct output at one step can propagate or even amplify through subsequent stages, compounding the impact on the final output. Recent work proposes integrating verifiers that validate LLM output or actions, such as self-reflection, debate, or LLM-as-a-judge mechanisms. Yet, verifying every step introduces significant latency and cost overheads.   In this work, we seek to answer three key questions: which nodes in a workflow are most error-prone and thus deserve costly verification, how to select the most appropriate verifier for each node, and how to use verification with minimal impact to latency? Our solution, Sherlock, addresses these using counterfactual analysis on agentic workflows to identify error-prone nodes and selectively attaching cost-optimal verifiers only where necessary. At runtime, Sherlock speculatively executes downstream tasks to reduce latency overhead, while verification runs in the background. If verification fails, execution is rolled back to the last verified output. Compared to the non-verifying baseline, Sherlock delivers an 18.3% accuracy gain on average across benchmarks. Sherlock reduces workflow execution time by up to 48.7% over non-speculative execution and lowers verification cost by 26.0% compared to the Monte Carlo search-based method, demonstrating that principled, fault-aware verification effectively balances efficiency and reliability in agentic workflows.",
    "fetched_at": "2025-11-06T02:19:05.290100Z"
  },
  {
    "id": "2511.00488v1",
    "title": "\\texttt{ReMind}: Understanding Deductive Code Reasoning in LLMs",
    "date": "2025-11-01",
    "tags": [
      "cs.PL",
      "PL",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jun Gao",
      "Yun Peng",
      "Xiaoxue Ren"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00488v1",
    "abstract": "Large Language Models (LLMs) have achieved remarkable progress in code-related tasks. Despite their advancement, empirical evidence reveals that they still struggle with \\emph{deductive code reasoning}, the ability to reason about the program execution process. While prior studies have recognized this limitation, the underlying causes remain largely underexplored. In this paper, we begin by presenting a comprehensive empirical study that reveals three key challenges undermining deductive code reasoning: (1) an intrinsic gap between generation and reasoning abilities, (2) a consistent bias towards code sources, and (3) weak zero-shot generalization on complex benchmarks. In light of these challenges, we propose \\texttt{ReMind}, a multi-agent framework composed of \\texttt{Mutator}, \\texttt{Executor}, and \\texttt{Inspector}. The \\texttt{Mutator} generates code variants to mitigate bias towards code sources, the \\texttt{Executor} traces variable states step-by-step to expose inconsistency, and the \\texttt{Inspector} identifies problematic reasoning steps and provides control-flow refinement to bridge the intrinsic reasoning gap. Through their coordinated collaboration, \\texttt{ReMind} systematically identifies and refines reasoning flaws, achieving outstanding performance and enabling robust zero-shot generalization. Extensive experiments on two benchmarks with five LLMs demonstrate the superior advantages of \\texttt{ReMind} compared to baseline approaches in deductive code reasoning.",
    "fetched_at": "2025-11-06T02:19:05.289871Z"
  },
  {
    "id": "2511.00517v1",
    "title": "Issue-Oriented Agent-Based Framework for Automated Review Comment   Generation",
    "date": "2025-11-01",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Shuochuan Li",
      "Dong Wang",
      "Patanamon Thongtanunam",
      "Zan Wang",
      "Jiuqiao Yu",
      "Junjie Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00517v1",
    "abstract": "Code review (CR) is a crucial practice for ensuring software quality. Various automated review comment generation techniques have been proposed to streamline the labor-intensive process. However, existing approaches heavily rely on a single model to identify various issues within the code, limiting the model's ability to handle the diverse, issue-specific nature of code changes and leading to non-informative comments, especially in complex scenarios such as bug fixes. To address these limitations, we propose RevAgent, a novel agent-based issue-oriented framework, decomposes the task into three stages: (1) Generation Stage, where five category-specific commentator agents analyze code changes from distinct issue perspectives and generate candidate comments; (2) Discrimination Stage, where a critic agent selects the most appropriate issue-comment pair; and (3) Training Stage, where all agents are fine-tuned on curated, category-specific data to enhance task specialization. Evaluation results show that RevAgent significantly outperforms state-of-the-art PLM- and LLM-based baselines, with improvements of 12.90\\%, 10.87\\%, 6.32\\%, and 8.57\\% on BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively higher accuracy in issue-category identification, particularly for challenging scenarios. Human evaluations further validate the practicality of RevAgent in generating accurate, readable, and context-aware review comments. Moreover, RevAgent delivers a favorable trade-off between performance and efficiency.",
    "fetched_at": "2025-11-06T02:19:05.289826Z"
  },
  {
    "id": "2511.00619v1",
    "title": "GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance   Detection in Android",
    "date": "2025-11-01",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Huaijin Ran",
      "Haoyi Zhang",
      "Xunzhu Tang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00619v1",
    "abstract": "Automating the detection of EU General Data Protection Regulation (GDPR) violations in source code is a critical but underexplored challenge. We introduce \\textbf{GDPR-Bench-Android}, the first comprehensive benchmark for evaluating diverse automated methods for GDPR compliance detection in Android applications. It contains \\textbf{1951} manually annotated violation instances from \\textbf{15} open-source repositories, covering 23 GDPR articles at file-, module-, and line-level granularities. To enable a multi-paradigm evaluation, we contribute \\textbf{Formal-AST}, a novel, source-code-native formal method that serves as a deterministic baseline. We define two tasks: (1) \\emph{multi-granularity violation localization}, evaluated via Accuracy@\\textit{k}; and (2) \\emph{snippet-level multi-label classification}, assessed by macro-F1 and other classification metrics. We benchmark 11 methods, including eight state-of-the-art LLMs, our Formal-AST analyzer, a retrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings reveal that no single paradigm excels across all tasks. For Task 1, the ReAct agent achieves the highest file-level Accuracy@1 (17.38%), while the Qwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the Formal-AST method's 1.86%. For the difficult multi-label Task 2, the Claude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method yields the highest Macro-Precision (7.10%). These results highlight the task-dependent strengths of different automated approaches and underscore the value of our benchmark in diagnosing their capabilities. All resources are available at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.",
    "fetched_at": "2025-11-06T02:19:05.289723Z"
  },
  {
    "id": "2511.00628v1",
    "title": "AgentGit: A Version Control Framework for Reliable and Scalable   LLM-Powered Multi-Agent Systems",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Yang Li",
      "Siqi Ping",
      "Xiyu Chen",
      "Xiaojian Qi",
      "Zigan Wang",
      "Ye Luo",
      "Xiaowei Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00628v1",
    "abstract": "With the rapid progress of large language models (LLMs), LLM-powered multi-agent systems (MAS) are drawing increasing interest across academia and industry. However, many current MAS frameworks struggle with reliability and scalability, especially on complex tasks. We present AgentGit, a framework that brings Git-like rollback and branching to MAS workflows. Built as an infrastructure layer on top of LangGraph, AgentGit supports state commit, revert, and branching, allowing agents to traverse, compare, and explore multiple trajectories efficiently. To evaluate AgentGit, we designed an experiment that optimizes target agents by selecting better prompts. We ran a multi-step A/B test against three baselines -- LangGraph, AutoGen, and Agno -- on a real-world task: retrieving and analyzing paper abstracts. Results show that AgentGit significantly reduces redundant computation, lowers runtime and token usage, and supports parallel exploration across multiple branches, enhancing both reliability and scalability in MAS development. This work offers a practical path to more robust MAS design and enables error recovery, safe exploration, iterative debugging, and A/B testing in collaborative AI systems.",
    "fetched_at": "2025-11-06T02:19:05.289675Z"
  },
  {
    "id": "2511.01912v1",
    "title": "EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory",
    "date": "2025-11-01",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Wenzhe Fan",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.01912v1",
    "abstract": "Planning has been a cornerstone of artificial intelligence for solving complex problems, and recent progress in LLM-based multi-agent frameworks have begun to extend this capability. However, the role of human-like memory within these frameworks remains largely unexplored. Understanding how agents coordinate through memory is critical for natural language planning, where iterative reasoning, constraint tracking, and error correction drive the success. Inspired by working memory model in cognitive psychology, we present EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The framework consists of three agents (Constraint Extractor, Verifier, and Actor) and two memory modules: Constraint Memory (CMem), which evolves across queries by storing task-specific rules and constraints while remains fixed within a query, and Query-feedback Memory (QMem), which evolves within a query by accumulating feedback across iterations for solution refinement. Both memory modules are reset at the end of each query session. Evaluations on trip planning, meeting planning, and calendar scheduling show consistent performance improvements, highlighting the effectiveness of EvoMem. This success underscores the importance of memory in enhancing multi-agent planning.",
    "fetched_at": "2025-11-06T02:19:03.470089Z"
  },
  {
    "id": "2511.00370v1",
    "title": "Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent   Conflict",
    "date": "2025-11-01",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chaochen Wu",
      "Guan Luo",
      "Meiyun Zuo",
      "Zhitao Fan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00370v1",
    "abstract": "Video moment retrieval uses a text query to locate a moment from a given untrimmed video reference. Locating corresponding video moments with text queries helps people interact with videos efficiently. Current solutions for this task have not considered conflict within location results from different models, so various models cannot integrate correctly to produce better results. This study introduces a reinforcement learning-based video moment retrieval model that can scan the whole video once to find the moment's boundary while producing its locational evidence. Moreover, we proposed a multi-agent system framework that can use evidential learning to resolve conflicts between agents' localization output. As a side product of observing and dealing with conflicts between agents, we can decide whether a query has no corresponding moment in a video (out-of-scope) without additional training, which is suitable for real-world applications. Extensive experiments on benchmark datasets show the effectiveness of our proposed methods compared with state-of-the-art approaches. Furthermore, the results of our study reveal that modeling competition and conflict of the multi-agent system is an effective way to improve RL performance in moment retrieval and show the new role of evidential learning in the multi-agent framework.",
    "fetched_at": "2025-11-06T02:19:03.470045Z"
  },
  {
    "id": "2511.00413v1",
    "title": "Tree Training: Accelerating Agentic LLMs Training via Shared Prefix   Reuse",
    "date": "2025-11-01",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shaojie Wang",
      "Jinghui Wang",
      "Yinghan Cui",
      "Xuxing Chen",
      "Chao Wang",
      "Liang Huang",
      "Xiaojiang Zhang",
      "Junyi Peng",
      "Li Wan",
      "Haotian Zhang",
      "Bin Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00413v1",
    "abstract": "In agentic LLM scenarios, an agent's interaction process during a single rollout often exhibits branching behaviors. Due to memory retrieval and concurrent tool executions at certain decision points, the token trajectory of one task evolves into a tree-like structure rather than a linear sequence. However, current training pipelines decompose such tree-structured trajectories into separate linear segments, treating each branch as an independent sequence. As a result, shared prefixes across these branches are repeatedly recomputed during both forward and backward passes. To address this inefficiency, we propose Tree Training, a paradigm that computes each shared prefix only once and reuses its intermediate results across related branches during both forward and backward passes, substantially improving computation efficiency in large-scale agentic training. This is achieved via (i) Tree Packing, which efficiently reuses shared computations across trajectories, and (ii) Gradient Restoration, which ensures correct gradient propagation across reused prefixes. Experiments on multiple open-source models demonstrate up to 3.9x reduction in total training time, enabling more efficient agentic LLM SFT and RL training.",
    "fetched_at": "2025-11-06T02:19:03.469997Z"
  },
  {
    "id": "2511.00450v1",
    "title": "SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin",
    "date": "2025-11-01",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Vahid Etemadi",
      "Gregorio Robles"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00450v1",
    "abstract": "Context: The software maintenance phase involves many activities such as code refactoring, bug fixing, code review or testing. Program comprehension is key to all these activities, as it demands developers to grasp the knowledge (e.g., implementation details) required to modify the codebase. Methods as main building blocks in a program can offer developers this knowledge source for code comprehension. However, reading entire method statements can be challenging, which necessitates precise and up-to-date comments. Objective: We propose a solution as an IntelliJ IDEA plugin, named SmartDoc, that assists developers in generating context-aware method comments. Method: This plugin acts as an Artificial Intelligence (AI) agent that has its own memory and is augmented by target methods' context. When a request is initiated by the end-user, the method content and all its nested method calls are used in the comment generation. At the beginning, these nested methods are visited and a call graph is generated. This graph is then traversed using depth-first search (DFS), enabling the provision of full-context to enrich Large Language Model (LLM) prompts. Result: The product is a software, as a plugin, developed for Java codebase and installable on IntelliJ IDEA. This plugin can serve concurrently for methods whose comments are being updated , and it shares memory across all flows to avoid redundant calls. o measure the accuracy of this solution, a dedicated test case is run to record SmartDoc generated comments and their corresponding ground truth. For each collected result-set, three metrics are computed, BERTScore, BLEU and ROUGE-1. These metrics will determine how accurate the generated comments are in comparison to the ground truth. Result: The obtained accuracy, in terms of the precision, recall and F1, is promising, and lies in the range of 0.80 to 0.90 for BERTScore.",
    "fetched_at": "2025-11-06T02:19:03.469927Z"
  },
  {
    "id": "2511.00529v2",
    "title": "On Improvisation and Open-Endedness: Insights for Experiential AI",
    "date": "2025-11-01",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.NE",
      "NE",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Botao 'Amber' Hu"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2511.00529v2",
    "abstract": "Improvisation-the art of spontaneous creation that unfolds moment-to-moment without a scripted outcome-requires practitioners to continuously sense, adapt, and create anew. It is a fundamental mode of human creativity spanning music, dance, and everyday life. The open-ended nature of improvisation produces a stream of novel, unrepeatable moments-an aspect highly valued in artistic creativity. In parallel, open-endedness (OE)-a system's capacity for unbounded novelty and endless \"interestingness\"-is exemplified in natural or cultural evolution and has been considered \"the last grand challenge\" in artificial life (ALife). The rise of generative AI now raises the question in computational creativity (CC) research: What makes a \"good\" improvisation for AI? Can AI learn to improvise in a genuinely open-ended way? In this work-in-progress paper, we report insights from in-depth interviews with 6 experts in improvisation across dance, music, and contact improvisation. We draw systemic connections between human improvisational arts and the design of future experiential AI agents that could improvise alone or alongside humans-or even with other AI agents-embodying qualities of improvisation drawn from practice: active listening (umwelt and awareness), being in the time (mindfulness and ephemerality), embracing the unknown (source of randomness and serendipity), non-judgmental flow (acceptance and dynamical stability, balancing structure and surprise (unpredictable criticality at edge of chaos), imaginative metaphor (synaesthesia and planning), empathy, trust, boundary, and care (mutual theory of mind), and playfulness and intrinsic motivation (maintaining interestingness).",
    "fetched_at": "2025-11-06T02:19:03.469878Z"
  },
  {
    "id": "2511.00549v1",
    "title": "Robust Single-Agent Reinforcement Learning for Regional Traffic Signal   Control Under Demand Fluctuations",
    "date": "2025-11-01",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qiang Li",
      "Jin Niu",
      "Lina Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00549v1",
    "abstract": "Traffic congestion, primarily driven by intersection queuing, significantly impacts urban living standards, safety, environmental quality, and economic efficiency. While Traffic Signal Control (TSC) systems hold potential for congestion mitigation, traditional optimization models often fail to capture real-world traffic complexity and dynamics. This study introduces a novel single-agent reinforcement learning (RL) framework for regional adaptive TSC, circumventing the coordination complexities inherent in multi-agent systems through a centralized decision-making paradigm. The model employs an adjacency matrix to unify the encoding of road network topology, real-time queue states derived from probe vehicle data, and current signal timing parameters. Leveraging the efficient learning capabilities of the DreamerV3 world model, the agent learns control policies where actions sequentially select intersections and adjust their signal phase splits to regulate traffic inflow/outflow, analogous to a feedback control system. Reward design prioritizes queue dissipation, directly linking congestion metrics (queue length) to control actions. Simulation experiments conducted in SUMO demonstrate the model's effectiveness: under inference scenarios with multi-level (10%, 20%, 30%) Origin-Destination (OD) demand fluctuations, the framework exhibits robust anti-fluctuation capability and significantly reduces queue lengths. This work establishes a new paradigm for intelligent traffic control compatible with probe vehicle technology. Future research will focus on enhancing practical applicability by incorporating stochastic OD demand fluctuations during training and exploring regional optimization mechanisms for contingency events.",
    "fetched_at": "2025-11-06T02:19:03.469834Z"
  },
  {
    "id": "2511.00551v1",
    "title": "Single-agent Reinforcement Learning Model for Regional Adaptive Traffic   Signal Control",
    "date": "2025-11-01",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Qiang Li",
      "Ningjing Zeng",
      "Lina Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00551v1",
    "abstract": "Several studies have employed reinforcement learning (RL) to address the challenges of regional adaptive traffic signal control (ATSC) and achieved promising results. In this field, existing research predominantly adopts multi-agent frameworks. However, the adoption of multi-agent frameworks presents challenges for scalability. Instead, the Traffic signal control (TSC) problem necessitates a single-agent framework. TSC inherently relies on centralized management by a single control center, which can monitor traffic conditions across all roads in the study area and coordinate the control of all intersections. This work proposes a single-agent RL-based regional ATSC model compatible with probe vehicle technology. Key components of the RL design include state, action, and reward function definitions. To facilitate learning and manage congestion, both state and reward functions are defined based on queue length, with action designed to regulate queue dynamics. The queue length definition used in this study differs slightly from conventional definitions but is closely correlated with congestion states. More importantly, it allows for reliable estimation using link travel time data from probe vehicles. With probe vehicle data already covering most urban roads, this feature enhances the proposed method's potential for widespread deployment. The method was comprehensively evaluated using the SUMO simulation platform. Experimental results demonstrate that the proposed model effectively mitigates large-scale regional congestion levels via coordinated multi-intersection control.",
    "fetched_at": "2025-11-06T02:19:03.469785Z"
  },
  {
    "id": "2511.00592v1",
    "title": "Agentic Auto-Scheduling: An Experimental Study of LLM-Guided Loop   Optimization",
    "date": "2025-11-01",
    "tags": [
      "cs.PL",
      "PL",
      "cs.DC",
      "DC",
      "cs.LG",
      "LG",
      "cs.PF",
      "PF"
    ],
    "authors": [
      "Massinissa Merouani",
      "Islem Kara Bernou",
      "Riyadh Baghdadi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00592v1",
    "abstract": "Automatic code optimization remains a difficult challenge, particularly for complex loop nests on modern hardware. This paper investigates a novel approach to code optimization where Large Language Models (LLMs) guide the process through a closed-loop interaction with a compiler. We present ComPilot, an experimental framework that leverages off-the-shelf LLMs, without any task-specific fine-tuning, as interactive optimization agents. ComPilot establishes a feedback loop where an LLM proposes transformations for a given loop nest to a compiler. The compiler attempts the transformations, reporting back legality status and measured speedup or slowdown. The LLM utilizes this concrete feedback to iteratively refine its optimization strategy. Our extensive evaluation across the PolyBench benchmark suite demonstrates the effectiveness of this zero-shot approach. ComPilot achieves geometric mean speedups of 2.66x (single run) and 3.54x (best-of-5 runs) over the original code. Furthermore, ComPilot demonstrates competitive performance against the state-of-the-art Pluto polyhedral optimizer, outperforming it in many cases. This experimental study demonstrates that general-purpose LLMs can effectively guide the code optimization process when grounded by compiler feedback, opening promising research directions for agentic AI in code optimization.",
    "fetched_at": "2025-11-06T02:19:03.469733Z"
  },
  {
    "id": "2511.00651v1",
    "title": "Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models   (SLMs) for Automated Telecom Network Troubleshooting",
    "date": "2025-11-01",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.IT",
      "IT",
      "cs.MA",
      "MA",
      "cs.NI",
      "NI",
      "math.IT"
    ],
    "authors": [
      "Chenhua Shi",
      "Bhavika Jalli",
      "Gregor Macdonald",
      "John Zou",
      "Wanlu Lei",
      "Mridul Jain",
      "Joji Philip"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00651v1",
    "abstract": "Telecom networks are rapidly growing in scale and complexity, making effective management, operation, and optimization increasingly challenging. Although Artificial Intelligence (AI) has been applied to many telecom tasks, existing models are often narrow in scope, require large amounts of labeled data, and struggle to generalize across heterogeneous deployments. Consequently, network troubleshooting continues to rely heavily on Subject Matter Experts (SMEs) to manually correlate various data sources to identify root causes and corrective actions. To address these limitations, we propose a Multi-Agent System (MAS) that employs an agentic workflow, with Large Language Models (LLMs) coordinating multiple specialized tools for fully automated network troubleshooting. Once faults are detected by AI/ML-based monitors, the framework dynamically activates agents such as an orchestrator, solution planner, executor, data retriever, and root-cause analyzer to diagnose issues and recommend remediation strategies within a short time frame. A key component of this system is the solution planner, which generates appropriate remediation plans based on internal documentation. To enable this, we fine-tuned a Small Language Model (SLM) on proprietary troubleshooting documents to produce domain-grounded solution plans. Experimental results demonstrate that the proposed framework significantly accelerates troubleshooting automation across both Radio Access Network (RAN) and Core network domains.",
    "fetched_at": "2025-11-06T02:19:03.469685Z"
  },
  {
    "id": "2511.00739v1",
    "title": "A CPU-Centric Perspective on Agentic AI",
    "date": "2025-11-01",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Ritik Raj",
      "Hong Wang",
      "Tushar Krishna"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00739v1",
    "abstract": "Agentic AI frameworks add a decision-making orchestrator embedded with external tools, including web search, Python interpreter, contextual database, and others, on top of monolithic LLMs, turning them from passive text oracles into autonomous problem-solvers that can plan, call tools, remember past steps, and adapt on the fly.   This paper aims to characterize and understand the system bottlenecks introduced by agentic AI workloads from a largely overlooked CPU-centric perspective. We first systematically characterize Agentic AI on the basis of orchestrator/decision making component, inference path dynamics and repetitiveness of the agentic flow which directly influences the system-level performance. Thereafter, based on the characterization, we choose five representative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow, Langchain and SWE-Agent to profile latency, throughput and energy metrics and demystify the significant impact of CPUs on these metrics relative to GPUs. We observe that - 1. Tool processing on CPUs can take up to 90.6% of the total latency; 2. Agentic throughput gets bottlenecked either by CPU factors - coherence, synchronization and over-subscription of cores or GPU factors - main memory capacity and bandwidth; \\circled{3} CPU dynamic energy consumes up to 44% of the total dynamic energy at large batch sizes. Based on the profiling insights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching (CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and heterogeneous agentic workloads respectively to demonstrate the potential to improve the performance, efficiency, and scalability of agentic AI. We achieve up to 2.1x and 1.41x P50 latency speedup compared to the multi-processing benchmark for homogeneous and heterogeneous agentic workloads respectively.",
    "fetched_at": "2025-11-06T02:19:03.469618Z"
  },
  {
    "id": "2510.27094v1",
    "title": "CombiGraph-Vis: A Curated Multimodal Olympiad Benchmark for Discrete   Mathematical Reasoning",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hamed Mahdavi",
      "Pouria Mahdavinia",
      "Alireza Farhadi",
      "Pegah Mohammadipour",
      "Samira Malek",
      "Majid Daliri",
      "Pedram Mohammadipour",
      "Alireza Hashemi",
      "Amir Khasahmadi",
      "Vasant Honavar"
    ],
    "institution": "Amirkabir University of Technology, Autodesk, City University of New York, New York University, Pennsylvania State University",
    "link": "http://arxiv.org/pdf/2510.27094v1",
    "abstract": "State-of-the-art (SOTA) LLMs have progressed from struggling on proof-based Olympiad problems to solving most of the IMO 2025 problems, with leading systems reportedly handling 5 of 6 problems. Given this progress, we assess how well these models can grade proofs: detecting errors, judging their severity, and assigning fair scores beyond binary correctness. We study proof-analysis capabilities using a corpus of 90 Gemini 2.5 Pro-generated solutions that we grade on a 1-4 scale with detailed error annotations, and on MathArena solution sets for IMO/USAMO 2025 scored on a 0-7 scale. Our analysis shows that models can reliably flag incorrect (including subtly incorrect) solutions but exhibit calibration gaps in how partial credit is assigned. To address this, we introduce agentic workflows that extract and analyze reference solutions and automatically derive problem-specific rubrics for a multi-step grading process. We instantiate and compare different design choices for the grading workflows, and evaluate their trade-offs. Across our annotated corpus and MathArena, our proposed workflows achieve higher agreement with human grades and more consistent handling of partial credit across metrics. We release all code, data, and prompts/logs to facilitate future research.",
    "fetched_at": "2025-11-06T02:19:05.292158Z"
  },
  {
    "id": "2510.27140v1",
    "title": "Measuring the Security of Mobile LLM Agents under Adversarial Prompts   from Untrusted Third-Party Channels",
    "date": "2025-10-31",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Chenghao Du",
      "Quanfeng Huang",
      "Tingxuan Tang",
      "Zihao Wang",
      "Yue Xiao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27140v1",
    "abstract": "Large Language Models (LLMs) have transformed software development, enabling AI-powered applications known as LLM-based agents that promise to automate tasks across diverse apps and workflows. Yet, the security implications of deploying such agents in adversarial mobile environments remain poorly understood. In this paper, we present the first systematic study of security risks in mobile LLM agents. We design and evaluate a suite of adversarial case studies, ranging from opportunistic manipulations such as pop-up advertisements to advanced, end-to-end workflows involving malware installation and cross-app data exfiltration. Our evaluation covers eight state-of-the-art mobile agents across three architectures, with over 2,000 adversarial and paired benign trials. The results reveal systemic vulnerabilities: low-barrier vectors such as fraudulent ads succeed with over 80% reliability, while even workflows requiring the circumvention of operating-system warnings, such as malware installation, are consistently completed by advanced multi-app agents. By mapping these attacks to the MITRE ATT&CK Mobile framework, we uncover novel privilege-escalation and persistence pathways unique to LLM-driven automation. Collectively, our findings provide the first end-to-end evidence that mobile LLM agents are exploitable in realistic adversarial settings, where untrusted third-party channels (e.g., ads, embedded webviews, cross-app notifications) are an inherent part of the mobile ecosystem.",
    "fetched_at": "2025-11-06T02:19:05.291859Z"
  },
  {
    "id": "2510.27157v1",
    "title": "A Survey on Generative Recommendation: Data, Model, and Tasks",
    "date": "2025-10-31",
    "tags": [
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Min Hou",
      "Le Wu",
      "Yuxin Liao",
      "Yonghui Yang",
      "Zhen Zhang",
      "Changlong Zheng",
      "Han Wu",
      "Richang Hong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27157v1",
    "abstract": "Recommender systems serve as foundational infrastructure in modern information ecosystems, helping users navigate digital content and discover items aligned with their preferences. At their core, recommender systems address a fundamental problem: matching users with items. Over the past decades, the field has experienced successive paradigm shifts, from collaborative filtering and matrix factorization in the machine learning era to neural architectures in the deep learning era. Recently, the emergence of generative models, especially large language models (LLMs) and diffusion models, have sparked a new paradigm: generative recommendation, which reconceptualizes recommendation as a generation task rather than discriminative scoring. This survey provides a comprehensive examination through a unified tripartite framework spanning data, model, and task dimensions. Rather than simply categorizing works, we systematically decompose approaches into operational stages-data augmentation and unification, model alignment and training, task formulation and execution. At the data level, generative models enable knowledge-infused augmentation and agent-based simulation while unifying heterogeneous signals. At the model level, we taxonomize LLM-based methods, large recommendation models, and diffusion approaches, analyzing their alignment mechanisms and innovations. At the task level, we illuminate new capabilities including conversational interaction, explainable reasoning, and personalized content generation. We identify five key advantages: world knowledge integration, natural language understanding, reasoning capabilities, scaling laws, and creative generation. We critically examine challenges in benchmark design, model robustness, and deployment efficiency, while charting a roadmap toward intelligent recommendation assistants that fundamentally reshape human-information interaction.",
    "fetched_at": "2025-11-06T02:19:05.291807Z"
  },
  {
    "id": "2510.27196v1",
    "title": "MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness   Understanding for Multimodal Large Language Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zixin Chen",
      "Hongzhan Lin",
      "Kaixin Li",
      "Ziyang Luo",
      "Yayue Deng",
      "Jing Ma"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27196v1",
    "abstract": "The proliferation of memes on social media necessitates the capabilities of multimodal Large Language Models (mLLMs) to effectively understand multimodal harmfulness. Existing evaluation approaches predominantly focus on mLLMs' detection accuracy for binary classification tasks, which often fail to reflect the in-depth interpretive nuance of harmfulness across diverse contexts. In this paper, we propose MemeArena, an agent-based arena-style evaluation framework that provides a context-aware and unbiased assessment for mLLMs' understanding of multimodal harmfulness. Specifically, MemeArena simulates diverse interpretive contexts to formulate evaluation tasks that elicit perspective-specific analyses from mLLMs. By integrating varied viewpoints and reaching consensus among evaluators, it enables fair and unbiased comparisons of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments demonstrate that our framework effectively reduces the evaluation biases of judge agents, with judgment results closely aligning with human preferences, offering valuable insights into reliable and comprehensive mLLM evaluations in multimodal harmfulness understanding. Our code and data are publicly available at https://github.com/Lbotirx/MemeArena.",
    "fetched_at": "2025-11-06T02:19:05.291679Z"
  },
  {
    "id": "2510.27251v1",
    "title": "FinPos: A Position-Aware Trading Agent System for Real Financial Markets",
    "date": "2025-10-31",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Bijia Liu",
      "Ronghao Dang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27251v1",
    "abstract": "The exceptional potential of large language models (LLMs) in handling text information has garnered significant attention in the field of financial trading. However, current trading agents primarily focus on single-step trading tasks and lack awareness of continuous position management. Therefore, we propose a position-aware trading task designed to simulate a more realistic market. To address this task, we develop a trading agent system, FinPos, optimized for position management. FinPos is able to interpret various types of market information from a professional perspective, providing a reliable basis for positioning decisions. To mitigate the substantial market risks arising from position fluctuations, FinPos employs dual decision agents. Furthermore, the continuous nature of position management necessitates our adoption of multi-timescale rewards, which in turn empowers FinPos to effectively balance short-term fluctuations against long-term trends. Extensive experiments demonstrate that FinPos surpasses state-of-the-art trading agents in the position-aware trading task, which closely mirrors real market conditions. More importantly, our findings reveal that LLM-centered agent systems exhibit a vast, largely unexplored potential in long-term market decision-making.",
    "fetched_at": "2025-11-06T02:19:05.291565Z"
  },
  {
    "id": "2510.27275v1",
    "title": "Prevalence of Security and Privacy Risk-Inducing Usage of AI-based   Conversational Agents",
    "date": "2025-10-31",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Kathrin Grosse",
      "Nico Ebert"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27275v1",
    "abstract": "Recent improvement gains in large language models (LLMs) have lead to everyday usage of AI-based Conversational Agents (CAs). At the same time, LLMs are vulnerable to an array of threats, including jailbreaks and, for example, causing remote code execution when fed specific inputs. As a result, users may unintentionally introduce risks, for example, by uploading malicious files or disclosing sensitive information. However, the extent to which such user behaviors occur and thus potentially facilitate exploits remains largely unclear. To shed light on this issue, we surveyed a representative sample of 3,270 UK adults in 2024 using Prolific. A third of these use CA services such as ChatGPT or Gemini at least once a week. Of these ``regular users'', up to a third exhibited behaviors that may enable attacks, and a fourth have tried jailbreaking (often out of understandable reasons such as curiosity, fun or information seeking). Half state that they sanitize data and most participants report not sharing sensitive data. However, few share very sensitive data such as passwords. The majority are unaware that their data can be used to train models and that they can opt-out. Our findings suggest that current academic threat models manifest in the wild, and mitigations or guidelines for the secure usage of CAs should be developed. In areas critical to security and privacy, CAs must be equipped with effective AI guardrails to prevent, for example, revealing sensitive information to curious employees. Vendors need to increase efforts to prevent the entry of sensitive data, and to create transparency with regard to data usage policies and settings.",
    "fetched_at": "2025-11-06T02:19:05.291414Z"
  },
  {
    "id": "2510.27287v1",
    "title": "Can LLMs Help You at Work? A Sandbox for Evaluating LLM Agents in   Enterprise Environments",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Harsh Vishwakarma",
      "Ankush Agarwal",
      "Ojas Patil",
      "Chaitanya Devaguptapu",
      "Mahesh Chandran"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.27287v1",
    "abstract": "Enterprise systems are crucial for enhancing productivity and decision-making among employees and customers. Integrating LLM based systems into enterprise systems enables intelligent automation, personalized experiences, and efficient information retrieval, driving operational efficiency and strategic growth. However, developing and evaluating such systems is challenging due to the inherent complexity of enterprise environments, where data is fragmented across multiple sources and governed by sophisticated access controls. We present EnterpriseBench, a comprehensive benchmark that simulates enterprise settings, featuring 500 diverse tasks across software engineering, HR, finance, and administrative domains. Our benchmark uniquely captures key enterprise characteristics including data source fragmentation, access control hierarchies, and cross-functional workflows. Additionally, we provide a novel data generation pipeline that creates internally consistent enterprise tasks from organizational metadata. Experiments with state-of-the-art LLM agents demonstrate that even the most capable models achieve only 41.8% task completion, highlighting significant opportunities for improvement in enterprise-focused AI systems.",
    "fetched_at": "2025-11-06T02:19:05.291371Z"
  },
  {
    "id": "2510.27417v1",
    "title": "Agentic LLMs for REST API Test Amplification: A Comparative Study Across   Cloud Applications",
    "date": "2025-10-31",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Jarne Besjes",
      "Robbe Nooyens",
      "Tolgahan Bardakci",
      "Mutlu Beyazit",
      "Serge Demeyer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27417v1",
    "abstract": "Representational State Transfer (REST) APIs are a cornerstone of modern cloud native systems. Ensuring their reliability demands automated test suites that exercise diverse and boundary level behaviors. Nevertheless, designing such test cases remains a challenging and resource intensive endeavor. This study extends prior work on Large Language Model (LLM) based test amplification by evaluating single agent and multi agent configurations across four additional cloud applications. The amplified test suites maintain semantic validity with minimal human intervention. The results demonstrate that agentic LLM systems can effectively generalize across heterogeneous API architectures, increasing endpoint and parameter coverage while revealing defects. Moreover, a detailed analysis of computational cost, runtime, and energy consumption highlights trade-offs between accuracy, scalability, and efficiency. These findings underscore the potential of LLM driven test amplification to advance the automation and sustainability of REST API testing in complex cloud environments.",
    "fetched_at": "2025-11-06T02:19:05.291274Z"
  },
  {
    "id": "2510.27452v1",
    "title": "From Pixels to Paths: A Multi-Agent Framework for Editable Scientific   Illustration",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Jianwen Sun",
      "Fanrui Zhang",
      "Yukang Feng",
      "Chuanhao Li",
      "Zizhen Li",
      "Jiaxin Ai",
      "Yifan Chang",
      "Yu Dai",
      "Kaipeng Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27452v1",
    "abstract": "Scientific illustrations demand both high information density and post-editability. However, current generative models have two major limitations: Frist, image generation models output rasterized images lacking semantic structure, making it impossible to access, edit, or rearrange independent visual components in the images. Second, code-based generation methods (TikZ or SVG), although providing element-level control, force users into the cumbersome cycle of \"writing-compiling-reviewing\" and lack the intuitiveness of manipulation. Neither of these two approaches can well meet the needs for efficiency, intuitiveness, and iterative modification in scientific creation. To bridge this gap, we introduce VisPainter, a multi-agent framework for scientific illustration built upon the model context protocol. VisPainter orchestrates three specialized modules-a Manager, a Designer, and a Toolbox-to collaboratively produce diagrams compatible with standard vector graphics software. This modular, role-based design allows each element to be explicitly represented and manipulated, enabling true element-level control and any element can be added and modified later. To systematically evaluate the quality of scientific illustrations, we introduce VisBench, a benchmark with seven-dimensional evaluation metrics. It assesses high-information-density scientific illustrations from four aspects: content, layout, visual perception, and interaction cost. To this end, we conducted extensive ablation experiments to verify the rationality of our architecture and the reliability of our evaluation methods. Finally, we evaluated various vision-language models, presenting fair and credible model rankings along with detailed comparisons of their respective capabilities. Additionally, we isolated and quantified the impacts of role division, step control,and description on the quality of illustrations.",
    "fetched_at": "2025-11-06T02:19:05.291186Z"
  },
  {
    "id": "2510.27489v1",
    "title": "Auditing LLM Editorial Bias in News Media Exposure",
    "date": "2025-10-31",
    "tags": [
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Marco Minici",
      "Cristian Consonni",
      "Federico Cinus",
      "Giuseppe Manco"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2510.27489v1",
    "abstract": "Large Language Models (LLMs) increasingly act as gateways to web content, shaping how millions of users encounter online information. Unlike traditional search engines, whose retrieval and ranking mechanisms are well studied, the selection processes of web-connected LLMs add layers of opacity to how answers are generated. By determining which news outlets users see, these systems can influence public opinion, reinforce echo chambers, and pose risks to civic discourse and public trust.   This work extends two decades of research in algorithmic auditing to examine how LLMs function as news engines. We present the first audit comparing three leading agents, GPT-4o-Mini, Claude-3.7-Sonnet, and Gemini-2.0-Flash, against Google News, asking: \\textit{How do LLMs differ from traditional aggregators in the diversity, ideology, and reliability of the media they expose to users?}   Across 24 global topics, we find that, compared to Google News, LLMs surface significantly fewer unique outlets and allocate attention more unevenly. In the same way, GPT-4o-Mini emphasizes more factual and right-leaning sources; Claude-3.7-Sonnet favors institutional and civil-society domains and slightly amplifies right-leaning exposure; and Gemini-2.0-Flash exhibits a modest left-leaning tilt without significant changes in factuality. These patterns remain robust under prompt variations and alternative reliability benchmarks. Together, our findings show that LLMs already enact \\textit{agentic editorial policies}, curating information in ways that diverge from conventional aggregators. Understanding and governing their emerging editorial power will be critical for ensuring transparency, pluralism, and trust in digital information ecosystems.",
    "fetched_at": "2025-11-06T02:19:05.291005Z"
  },
  {
    "id": "2510.27617v1",
    "title": "VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Heng Ping",
      "Arijit Bhattacharjee",
      "Peiyu Zhang",
      "Shixuan Li",
      "Wei Yang",
      "Anzhe Cheng",
      "Xiaole Zhang",
      "Jesse Thomason",
      "Ali Jannesari",
      "Nesreen Ahmed",
      "Paul Bogdan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27617v1",
    "abstract": "Automation of Register Transfer Level (RTL) design can help developers meet increasing computational demands. Large Language Models (LLMs) show promise for Hardware Description Language (HDL) generation, but face challenges due to limited parametric knowledge and domain-specific constraints. While prompt engineering and fine-tuning have limitations in knowledge coverage and training costs, multi-agent architectures offer a training-free paradigm to enhance reasoning through collaborative generation. However, current multi-agent approaches suffer from two critical deficiencies: susceptibility to noise propagation and constrained reasoning space exploration. We propose VeriMoA, a training-free mixture-of-agents (MoA) framework with two synergistic innovations. First, a quality-guided caching mechanism to maintain all intermediate HDL outputs and enables quality-based ranking and selection across the entire generation process, encouraging knowledge accumulation over layers of reasoning. Second, a multi-path generation strategy that leverages C++ and Python as intermediate representations, decomposing specification-to-HDL translation into two-stage processes that exploit LLM fluency in high-resource languages while promoting solution diversity. Comprehensive experiments on VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves 15--30% improvements in Pass@1 across diverse LLM backbones, especially enabling smaller models to match larger models and fine-tuned alternatives without requiring costly training.",
    "fetched_at": "2025-11-06T02:19:05.290703Z"
  },
  {
    "id": "2510.27628v1",
    "title": "Validity Is What You Need",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sebastian Benthall",
      "Andrew Clark"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27628v1",
    "abstract": "While AI agents have long been discussed and studied in computer science, today's Agentic AI systems are something new. We consider other definitions of Agentic AI and propose a new realist definition. Agentic AI is a software delivery mechanism, comparable to software as a service (SaaS), which puts an application to work autonomously in a complex enterprise setting. Recent advances in large language models (LLMs) as foundation models have driven excitement in Agentic AI. We note, however, that Agentic AI systems are primarily applications, not foundations, and so their success depends on validation by end users and principal stakeholders. The tools and techniques needed by the principal users to validate their applications are quite different from the tools and techniques used to evaluate foundation models. Ironically, with good validation measures in place, in many cases the foundation models can be replaced with much simpler, faster, and more interpretable models that handle core logic. When it comes to Agentic AI, validity is what you need. LLMs are one option that might achieve it.",
    "fetched_at": "2025-11-06T02:19:05.290558Z"
  },
  {
    "id": "2510.27630v2",
    "title": "Interaction as Intelligence Part II: Asynchronous Human-Agent Rollout   for Long-Horizon Task Training",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Dayuan Fu",
      "Yunze Wu",
      "Xiaojie Cai",
      "Lyumanshan Ye",
      "Shijie Xia",
      "Zhen Huang",
      "Weiye Si",
      "Tianze Xu",
      "Jie Sun",
      "Keyu Li",
      "Mohan Jiang",
      "Junfei Wang",
      "Qishuo Hua",
      "Pengrui Lu",
      "Yang Xiao",
      "Pengfei Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27630v2",
    "abstract": "Large Language Model (LLM) agents have recently shown strong potential in domains such as automated coding, deep research, and graphical user interface manipulation. However, training them to succeed on long-horizon, domain-specialized tasks remains challenging. Current methods primarily fall into two categories. The first relies on dense human annotations through behavior cloning, which is prohibitively expensive for long-horizon tasks that can take days or months. The second depends on outcome-driven sampling, which often collapses due to the rarity of valid positive trajectories on domain-specialized tasks. We introduce Apollo, a sampling framework that integrates asynchronous human guidance with action-level data filtering. Instead of requiring annotators to shadow every step, Apollo allows them to intervene only when the agent drifts from a promising trajectory, by providing prior knowledge, strategic advice, etc. This lightweight design makes it possible to sustain interactions for over 30 hours and produces valuable trajectories at a lower cost. Apollo then applies supervision control to filter out sub-optimal actions and prevent error propagation. Together, these components enable reliable and effective data collection in long-horizon environments. To demonstrate the effectiveness of Apollo, we evaluate it using InnovatorBench. Our experiments show that when applied to train the GLM-4.5 model on InnovatorBench, Apollo achieves more than a 50% improvement over the untrained baseline and a 28% improvement over a variant trained without human interaction. These results highlight the critical role of human-in-the-loop sampling and the robustness of Apollo's design in handling long-horizon, domain-specialized tasks.",
    "fetched_at": "2025-11-06T02:19:05.290508Z"
  },
  {
    "id": "2511.00197v1",
    "title": "Understanding Code Agent Behaviour: An Empirical Study of Success and   Failure Trajectories",
    "date": "2025-10-31",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Oorja Majgaonkar",
      "Zhiwei Fei",
      "Xiang Li",
      "Federica Sarro",
      "He Ye"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00197v1",
    "abstract": "The increasing deployment of Large Language Model (LLM) agents for complex software engineering tasks has created a need to understand their problem-solving behaviours beyond simple success metrics. While these agents demonstrate impressive capabilities in automated issue resolution, their decision-making processes remain largely opaque. This paper presents an empirical study of agent trajectories, namely the execution traces capturing the steps agents take when attempting to resolve software issues. We analyse trajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and Prometheus) on the SWE-Bench benchmark, examining both successful and failed attempts. Our investigation reveals several key insights into agent behaviour. First, we identify how distinct problem-solving strategies, such as defensive programming and context gathering, enable success in different scenarios. Second, we find that failed trajectories are consistently longer and exhibit higher variance than successful ones, with failure patterns differing significantly between agents. Third, our fault localisation analysis shows that while most trajectories correctly identify problematic files (72-81\\% even in failures), success depends more on achieving approximate rather than exact code modifications. These and other findings unveiled by our study, provide a foundation for understanding agent behaviour through trajectory analysis, contributing to the development of more robust and interpretable autonomous software engineering systems.",
    "fetched_at": "2025-11-06T02:19:05.290307Z"
  },
  {
    "id": "2511.00261v1",
    "title": "Spot The Ball: A Benchmark for Visual Social Inference",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Neha Balamurugan",
      "Sarah Wu",
      "Adam Chun",
      "Gabe Gaw",
      "Cristobal Eyzaguirre",
      "Tobias Gerstenberg"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00261v1",
    "abstract": "Humans excel at visual social inference, the ability to infer hidden elements of a scene from subtle behavioral cues such as other people's gaze, pose, and orientation. This ability drives everyday social reasoning in humans and is critical for developing more human-like AI agents. We introduce Spot The Ball, a challenging benchmark for evaluating visual social inference in vision-language models (VLMs) using sports as a test domain. The task is to localize a removed sports ball from soccer, basketball, and volleyball images. We present a curated evaluation set with human baselines and a scalable pipeline for generating additional test items. We evaluate four state-of-the-art VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting strategies, finding that humans are consistently two to three times more accurate (20-34%) than models ($\\leq$ 17%) across all sports. Our analyses show that models rely on superficial spatial heuristics--such as guessing near the image center or nearby players--while humans leverage social cues like gaze direction and body pose. These findings reveal a persistent human-model gap in visual social reasoning and underscore the need for architectures that explicitly encode structured behavioral cues to achieve robust, human-like inference.",
    "fetched_at": "2025-11-06T02:19:05.290198Z"
  },
  {
    "id": "2510.27069v1",
    "title": "Distributed Precoding for Cell-free Massive MIMO in O-RAN: A Multi-agent   Deep Reinforcement Learning Framework",
    "date": "2025-10-31",
    "tags": [
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Mohammad Hossein Shokouhi",
      "Vincent W. S. Wong"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27069v1",
    "abstract": "Cell-free massive multiple-input multiple-output (MIMO) is a key technology for next-generation wireless systems. The integration of cell-free massive MIMO within the open radio access network (O-RAN) architecture addresses the growing need for decentralized, scalable, and high-capacity networks that can support different use cases. Precoding is a crucial step in the operation of cell-free massive MIMO, where O-RUs steer their beams towards the intended users while mitigating interference to other users. Current precoding schemes for cell-free massive MIMO are either fully centralized or fully distributed. Centralized schemes are not scalable, whereas distributed schemes may lead to a high inter-O-RU interference. In this paper, we propose a distributed and scalable precoding framework for cell-free massive MIMO that uses limited information exchange among precoding agents to mitigate interference. We formulate an optimization problem for precoding that maximizes the aggregate throughput while guaranteeing the minimum data rate requirements of users. The formulated problem is nonconvex. We propose a multi-timescale framework that combines multi-agent deep reinforcement learning (DRL) with expert insights from an iterative algorithm to determine the precoding matrices efficiently. We conduct simulations and compare the proposed framework with the centralized precoding and distributed precoding methods for different numbers of O-RUs, users, and transmit antennas. The results show that the proposed framework achieves a higher aggregate throughput than the distributed regularized zero-forcing (D-RZF) scheme and the weighted minimum mean square error (WMMSE) algorithm. When compared with the centralized regularized zero-forcing (C-RZF) scheme, the proposed framework achieves similar aggregate throughput performance but with a lower signaling overhead.",
    "fetched_at": "2025-11-06T02:19:03.471950Z"
  },
  {
    "id": "2511.02097v1",
    "title": "A Step Toward World Models: A Survey on Robotic Manipulation",
    "date": "2025-10-31",
    "tags": [
      "cs.RO",
      "RO",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Peng-Fei Zhang",
      "Ying Cheng",
      "Xiaofan Sun",
      "Shijie Wang",
      "Lei Zhu",
      "Heng Tao Shen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.02097v1",
    "abstract": "Autonomous agents are increasingly expected to operate in complex, dynamic, and uncertain environments, performing tasks such as manipulation, navigation, and decision-making. Achieving these capabilities requires agents to understand the underlying mechanisms and dynamics of the world, moving beyond purely reactive control or simple replication of observed states. This motivates the development of world models as internal representations that encode environmental states, capture dynamics, and enable prediction, planning, and reasoning. Despite growing interest, the definition, scope, architectures, and essential capabilities of world models remain ambiguous. In this survey, rather than directly imposing a fixed definition and limiting our scope to methods explicitly labeled as world models, we examine approaches that exhibit the core capabilities of world models through a review of methods in robotic manipulation. We analyze their roles across perception, prediction, and control, identify key challenges and solutions, and distill the core components, capabilities, and functions that a real world model should possess. Building on this analysis, we aim to outline a roadmap for developing generalizable and practical world models for robotics.",
    "fetched_at": "2025-11-06T02:19:03.471904Z"
  },
  {
    "id": "2510.27107v1",
    "title": "A Memory-Efficient Retrieval Architecture for RAG-Enabled Wearable   Medical LLMs-Agents",
    "date": "2025-10-31",
    "tags": [
      "cs.AR",
      "AR"
    ],
    "authors": [
      "Zhipeng Liao",
      "Kunming Shao",
      "Jiangnan Yu",
      "Liang Zhao",
      "Tim Kwang-Ting Cheng",
      "Chi-Ying Tsui",
      "Jie Yang",
      "Mohamad Sawan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27107v1",
    "abstract": "With powerful and integrative large language models (LLMs), medical AI agents have demonstrated unique advantages in providing personalized medical consultations, continuous health monitoring, and precise treatment plans. Retrieval-Augmented Generation (RAG) integrates personal medical documents into LLMs by an external retrievable database to address the costly retraining or fine-tuning issues in deploying customized agents. While deploying medical agents in edge devices ensures privacy protection, RAG implementations impose substantial memory access and energy consumption during the retrieval stage. This paper presents a hierarchical retrieval architecture for edge RAG, leveraging a two-stage retrieval scheme that combines approximate retrieval for candidate set generation, followed by high-precision retrieval on pre-selected document embeddings. The proposed architecture significantly reduces energy consumption and external memory access while maintaining retrieval accuracy. Simulation results show that, under TSMC 28nm technology, the proposed hierarchical retrieval architecture has reduced the overall memory access by nearly 50% and the computation by 75% compared to pure INT8 retrieval, and the total energy consumption for 1 MB data retrieval is 177.76 {\\mu}J/query.",
    "fetched_at": "2025-11-06T02:19:03.471851Z"
  },
  {
    "id": "2511.00116v1",
    "title": "LC-Opt: Benchmarking Reinforcement Learning and Agentic AI for   End-to-End Liquid Cooling Optimization in Data Centers",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Avisek Naug",
      "Antonio Guillen",
      "Vineet Kumar",
      "Scott Greenwood",
      "Wesley Brewer",
      "Sahand Ghorbanpour",
      "Ashwin Ramesh Babu",
      "Vineet Gundecha",
      "Ricardo Luna Gutierrez",
      "Soumyendu Sarkar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00116v1",
    "abstract": "Liquid cooling is critical for thermal management in high-density data centers with the rising AI workloads. However, machine learning-based controllers are essential to unlock greater energy efficiency and reliability, promoting sustainability. We present LC-Opt, a Sustainable Liquid Cooling (LC) benchmark environment, for reinforcement learning (RL) control strategies in energy-efficient liquid cooling of high-performance computing (HPC) systems. Built on the baseline of a high-fidelity digital twin of Oak Ridge National Lab's Frontier Supercomputer cooling system, LC-Opt provides detailed Modelica-based end-to-end models spanning site-level cooling towers to data center cabinets and server blade groups. RL agents optimize critical thermal controls like liquid supply temperature, flow rate, and granular valve actuation at the IT cabinet level, as well as cooling tower (CT) setpoints through a Gymnasium interface, with dynamic changes in workloads. This environment creates a multi-objective real-time optimization challenge balancing local thermal regulation and global energy efficiency, and also supports additional components like a heat recovery unit (HRU). We benchmark centralized and decentralized multi-agent RL approaches, demonstrate policy distillation into decision and regression trees for interpretable control, and explore LLM-based methods that explain control actions in natural language through an agentic mesh architecture designed to foster user trust and simplify system management. LC-Opt democratizes access to detailed, customizable liquid cooling models, enabling the ML community, operators, and vendors to develop sustainable data center liquid cooling control solutions.",
    "fetched_at": "2025-11-06T02:19:03.471791Z"
  },
  {
    "id": "2511.00117v1",
    "title": "DCcluster-Opt: Benchmarking Dynamic Multi-Objective Optimization for   Geo-Distributed Data Center Workloads",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Antonio Guillen-Perez",
      "Avisek Naug",
      "Vineet Gundecha",
      "Sahand Ghorbanpour",
      "Ricardo Luna Gutierrez",
      "Ashwin Ramesh Babu",
      "Munther Salim",
      "Shubhanker Banerjee",
      "Eoin H. Oude Essink",
      "Damien Fay",
      "Soumyendu Sarkar"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00117v1",
    "abstract": "The increasing energy demands and carbon footprint of large-scale AI require intelligent workload management in globally distributed data centers. Yet progress is limited by the absence of benchmarks that realistically capture the interplay of time-varying environmental factors (grid carbon intensity, electricity prices, weather), detailed data center physics (CPUs, GPUs, memory, HVAC energy), and geo-distributed network dynamics (latency and transmission costs). To bridge this gap, we present DCcluster-Opt: an open-source, high-fidelity simulation benchmark for sustainable, geo-temporal task scheduling. DCcluster-Opt combines curated real-world datasets, including AI workload traces, grid carbon intensity, electricity markets, weather across 20 global regions, cloud transmission costs, and empirical network delay parameters with physics-informed models of data center operations, enabling rigorous and reproducible research in sustainable computing. It presents a challenging scheduling problem where a top-level coordinating agent must dynamically reassign or defer tasks that arrive with resource and service-level agreement requirements across a configurable cluster of data centers to optimize multiple objectives. The environment also models advanced components such as heat recovery. A modular reward system enables an explicit study of trade-offs among carbon emissions, energy costs, service level agreements, and water use. It provides a Gymnasium API with baseline controllers, including reinforcement learning and rule-based strategies, to support reproducible ML research and a fair comparison of diverse algorithms. By offering a realistic, configurable, and accessible testbed, DCcluster-Opt accelerates the development and validation of next-generation sustainable computing solutions for geo-distributed data centers.",
    "fetched_at": "2025-11-06T02:19:03.471715Z"
  },
  {
    "id": "2510.27130v1",
    "title": "AI Agents in Drug Discovery",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Srijit Seal",
      "Dinh Long Huynh",
      "Moudather Chelbi",
      "Sara Khosravi",
      "Ankur Kumar",
      "Mattson Thieme",
      "Isaac Wilks",
      "Mark Davies",
      "Jessica Mustali",
      "Yannick Sun",
      "Nick Edwards",
      "Daniil Boiko",
      "Andrei Tyrin",
      "Douglas W. Selinger",
      "Ayaan Parikh",
      "Rahul Vijayan",
      "Shoman Kasbekar",
      "Dylan Reid",
      "Andreas Bender",
      "Ola Spjuth"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27130v1",
    "abstract": "Artificial intelligence (AI) agents are emerging as transformative tools in drug discovery, with the ability to autonomously reason, act, and learn through complicated research workflows. Building on large language models (LLMs) coupled with perception, computation, action, and memory tools, these agentic AI systems could integrate diverse biomedical data, execute tasks, carry out experiments via robotic platforms, and iteratively refine hypotheses in closed loops. We provide a conceptual and technical overview of agentic AI architectures, ranging from ReAct and Reflection to Supervisor and Swarm systems, and illustrate their applications across key stages of drug discovery, including literature synthesis, toxicity prediction, automated protocol generation, small-molecule synthesis, drug repurposing, and end-to-end decision-making. To our knowledge, this represents the first comprehensive work to present real-world implementations and quantifiable impacts of agentic AI systems deployed in operational drug discovery settings. Early implementations demonstrate substantial gains in speed, reproducibility, and scalability, compressing workflows that once took months into hours while maintaining scientific traceability. We discuss the current challenges related to data heterogeneity, system reliability, privacy, and benchmarking, and outline future directions towards technology in support of science and translation.",
    "fetched_at": "2025-11-06T02:19:03.471636Z"
  },
  {
    "id": "2510.27176v1",
    "title": "Glia: A Human-Inspired AI for Automated Systems Design and Optimization",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Pouya Hamadanian",
      "Pantea Karimi",
      "Arash Nasr-Esfahany",
      "Kimia Noorbakhsh",
      "Joseph Chandler",
      "Ali ParandehGheibi",
      "Mohammad Alizadeh",
      "Hari Balakrishnan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27176v1",
    "abstract": "Can an AI autonomously design mechanisms for computer systems on par with the creativity and reasoning of human experts? We present Glia, an AI architecture for networked systems design that uses large language models (LLMs) in a human-inspired, multi-agent workflow. Each agent specializes in reasoning, experimentation, and analysis, collaborating through an evaluation framework that grounds abstract reasoning in empirical feedback. Unlike prior ML-for-systems methods that optimize black-box policies, Glia generates interpretable designs and exposes its reasoning process. When applied to a distributed GPU cluster for LLM inference, it produces new algorithms for request routing, scheduling, and auto-scaling that perform at human-expert levels in significantly less time, while yielding novel insights into workload behavior. Our results suggest that by combining reasoning LLMs with structured experimentation, an AI can produce creative and understandable designs for complex systems problems.",
    "fetched_at": "2025-11-06T02:19:03.471524Z"
  },
  {
    "id": "2510.27210v1",
    "title": "GUI-Rise: Structured Reasoning and History Summarization for GUI   Navigation",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Tao Liu",
      "Chongyu Wang",
      "Rongjie Li",
      "Yingchen Yu",
      "Xuming He",
      "Bai Song"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27210v1",
    "abstract": "While Multimodal Large Language Models (MLLMs) have advanced GUI navigation agents, current approaches face limitations in cross-domain generalization and effective history utilization. We present a reasoning-enhanced framework that systematically integrates structured reasoning, action prediction, and history summarization. The structured reasoning component generates coherent Chain-of-Thought analyses combining progress estimation and decision reasoning, which inform both immediate action predictions and compact history summaries for future steps. Based on this framework, we train a GUI agent, \\textbf{GUI-Rise}, through supervised fine-tuning on pseudo-labeled trajectories and reinforcement learning with Group Relative Policy Optimization (GRPO). This framework employs specialized rewards, including a history-aware objective, directly linking summary quality to subsequent action performance. Comprehensive evaluations on standard benchmarks demonstrate state-of-the-art results under identical training data conditions, with particularly strong performance in out-of-domain scenarios. These findings validate our framework's ability to maintain robust reasoning and generalization across diverse GUI navigation tasks. Code is available at https://leon022.github.io/GUI-Rise.",
    "fetched_at": "2025-11-06T02:19:03.471464Z"
  },
  {
    "id": "2511.00122v1",
    "title": "Engineering.ai: A Platform for Teams of AI Engineers in Computational   Design",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ran Xu",
      "Yupeng Qi",
      "Jingsen Feng",
      "Xu Chu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00122v1",
    "abstract": "In modern engineering practice, human engineers collaborate in specialized teams to design complex products, with each expert completing their respective tasks while communicating and exchanging results and data with one another. While this division of expertise is essential for managing multidisciplinary complexity, it demands substantial development time and cost. Recently, we introduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer for computational fluid dynamics, and turbulence.ai, which can conduct end-to-end research in fluid mechanics draft publications and PhD theses. Building upon these foundations, we present Engineering.ai, a platform for teams of AI engineers in computational design. The framework employs a hierarchical multi-agent architecture where a Chief Engineer coordinates specialized agents consisting of Aerodynamics, Structural, Acoustic, and Optimization Engineers, each powered by LLM with domain-specific knowledge. Agent-agent collaboration is achieved through file-mediated communication for data provenance and reproducibility, while a comprehensive memory system maintains project context, execution history, and retrieval-augmented domain knowledge to ensure reliable decision-making across the workflow. The system integrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis, enabling parallel multidisciplinary simulations while maintaining computational accuracy. The framework is validated through UAV wing optimization. This work demonstrates that agentic-AI-enabled AI engineers has the potential to perform complex engineering tasks autonomously. Remarkably, the automated workflow achieved a 100% success rate across over 400 parametric configurations, with zero mesh generation failures, solver convergence issues, or manual interventions required, validating that the framework is trustworthy.",
    "fetched_at": "2025-11-06T02:19:03.471411Z"
  },
  {
    "id": "2510.27266v1",
    "title": "HyperClick: Advancing Reliable GUI Grounding via Uncertainty Calibration",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Shaojie Zhang",
      "Pei Fu",
      "Ruoceng Zhang",
      "Jiahui Yang",
      "Anan Du",
      "Xiuwen Xi",
      "Shaokang Wang",
      "Ying Huang",
      "Bin Qin",
      "Zhenbo Luo",
      "Jian Luan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27266v1",
    "abstract": "Autonomous Graphical User Interface (GUI) agents rely on accurate GUI grounding, which maps language instructions to on-screen coordinates, to execute user commands. However, current models, whether trained via supervised fine-tuning (SFT) or reinforcement fine-tuning (RFT), lack self-awareness of their capability boundaries, leading to overconfidence and unreliable predictions. We first systematically evaluate probabilistic and verbalized confidence in general and GUI-specific models, revealing a misalignment between confidence and actual accuracy, which is particularly critical in dynamic GUI automation tasks, where single errors can cause task failure. To address this, we propose HyperClick, a novel framework that enhances reliable GUI grounding through uncertainty calibration. HyperClick introduces a dual reward mechanism, combining a binary reward for correct actions with a truncated Gaussian-based spatial confidence modeling, calibrated using the Brier score. This approach jointly optimizes grounding accuracy and confidence reliability, fostering introspective self-criticism. Extensive experiments on seven challenge benchmarks show that HyperClick achieves state-of-the-art performance while providing well-calibrated confidence. By enabling explicit confidence calibration and introspective self-criticism, HyperClick reduces overconfidence and supports more reliable GUI automation.",
    "fetched_at": "2025-11-06T02:19:03.471358Z"
  },
  {
    "id": "2510.27289v1",
    "title": "A Digital Twin-based Multi-Agent Reinforcement Learning Framework for   Vehicle-to-Grid Coordination",
    "date": "2025-10-31",
    "tags": [
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Zhengchang Hua",
      "Panagiotis Oikonomou",
      "Karim Djemame",
      "Nikos Tziritas",
      "Georgios Theodoropoulos"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27289v1",
    "abstract": "The coordination of large-scale, decentralised systems, such as a fleet of Electric Vehicles (EVs) in a Vehicle-to-Grid (V2G) network, presents a significant challenge for modern control systems. While collaborative Digital Twins have been proposed as a solution to manage such systems without compromising the privacy of individual agents, deriving globally optimal control policies from the high-level information they share remains an open problem. This paper introduces Digital Twin Assisted Multi-Agent Deep Deterministic Policy Gradient (DT-MADDPG) algorithm, a novel hybrid architecture that integrates a multi-agent reinforcement learning framework with a collaborative DT network. Our core contribution is a simulation-assisted learning algorithm where the centralised critic is enhanced by a predictive global model that is collaboratively built from the privacy-preserving data shared by individual DTs. This approach removes the need for collecting sensitive raw data at a centralised entity, a requirement of traditional multi-agent learning algorithms. Experimental results in a simulated V2G environment demonstrate that DT-MADDPG can achieve coordination performance comparable to the standard MADDPG algorithm while offering significant advantages in terms of data privacy and architectural decentralisation. This work presents a practical and robust framework for deploying intelligent, learning-based coordination in complex, real-world cyber-physical systems.",
    "fetched_at": "2025-11-06T02:19:03.471287Z"
  },
  {
    "id": "2510.27329v1",
    "title": "Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to   Coupled Reward Machines",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kristina Levina",
      "Nikolaos Pappas",
      "Athanasios Karapantelakis",
      "Aneta Vulgarakis Feljan",
      "Jendrik Seipp"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27329v1",
    "abstract": "Reward machines (RMs) inform reinforcement learning agents about the reward structure of the environment. This is particularly advantageous for complex non-Markovian tasks because agents with access to RMs can learn more efficiently from fewer samples. However, learning with RMs is ill-suited for long-horizon problems in which a set of subtasks can be executed in any order. In such cases, the amount of information to learn increases exponentially with the number of unordered subtasks. In this work, we address this limitation by introducing three generalisations of RMs: (1) Numeric RMs allow users to express complex tasks in a compact form. (2) In Agenda RMs, states are associated with an agenda that tracks the remaining subtasks to complete. (3) Coupled RMs have coupled states associated with each subtask in the agenda. Furthermore, we introduce a new compositional learning algorithm that leverages coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM scales better than state-of-the-art RM algorithms for long-horizon problems with unordered subtasks.",
    "fetched_at": "2025-11-06T02:19:03.471231Z"
  },
  {
    "id": "2510.27334v1",
    "title": "When AI Trading Agents Compete: Adverse Selection of Meta-Orders by   Reinforcement Learning-Based Market Making",
    "date": "2025-10-31",
    "tags": [
      "q-fin.TR",
      "TR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ali Raza Jafree",
      "Konark Jain",
      "Nick Firoozye"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2510.27334v1",
    "abstract": "We investigate the mechanisms by which medium-frequency trading agents are adversely selected by opportunistic high-frequency traders. We use reinforcement learning (RL) within a Hawkes Limit Order Book (LOB) model in order to replicate the behaviours of high-frequency market makers. In contrast to the classical models with exogenous price impact assumptions, the Hawkes model accounts for endogenous price impact and other key properties of the market (Jain et al. 2024a). Given the real-world impracticalities of the market maker updating strategies for every event in the LOB, we formulate the high-frequency market making agent via an impulse control reinforcement learning framework (Jain et al. 2025). The RL used in the simulation utilises Proximal Policy Optimisation (PPO) and self-imitation learning. To replicate the adverse selection phenomenon, we test the RL agent trading against a medium frequency trader (MFT) executing a meta-order and demonstrate that, with training against the MFT meta-order execution agent, the RL market making agent learns to capitalise on the price drift induced by the meta-order. Recent empirical studies have shown that medium-frequency traders are increasingly subject to adverse selection by high-frequency trading agents. As high-frequency trading continues to proliferate across financial markets, the slippage costs incurred by medium-frequency traders are likely to increase over time. However, we do not observe that increased profits for the market making RL agent necessarily cause significantly increased slippages for the MFT agent.",
    "fetched_at": "2025-11-06T02:19:03.471184Z"
  },
  {
    "id": "2510.27363v1",
    "title": "ToolScope: An Agentic Framework for Vision-Guided and Long-Horizon Tool   Use",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Mengjie Deng",
      "Guanting Dong",
      "Zhicheng Dou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27363v1",
    "abstract": "Recently, large language models (LLMs) have demonstrated remarkable problem-solving capabilities by autonomously integrating with external tools for collaborative reasoning. However, due to the inherently complex and diverse nature of multimodal information, enabling multimodal large language models (MLLMs) to flexibly and efficiently utilize external tools during reasoning remains an underexplored challenge. In this work, we introduce ToolScope, an agentic framework designed to unify global planning with local multimodal perception, adopting a specialized Perceive tool to mitigates visual context degradation in long-horizon VQA task. ToolScope comprises three primary components: the Global Navigator, the Agentic Executor, and the Response Synthesizer. The Global Navigator functions as a \"telescope\", offering high-level strategic guidance. The Agentic Executor operates iteratively to augment MLLM with local perception through the integration of external tools-Search, Code, and Perceive. Finally, the Response Synthesizer consolidates and organizes the reasoning process into a coherent, user-friendly output. We evaluate ToolScope on four VQA benchmarks across diverse domains, including VQA 2.0, ScienceQA, MAT-Search and MathVista. It demonstrates strong generalization capabilities, achieving an average performance improvement of up to +6.69% across all datasets.",
    "fetched_at": "2025-11-06T02:19:03.471139Z"
  },
  {
    "id": "2510.27383v1",
    "title": "Realistic pedestrian-driver interaction modelling using multi-agent RL   with human perceptual-motor constraints",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yueyang Wang",
      "Mehmet Dogar",
      "Gustav Markkula"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27383v1",
    "abstract": "Modelling pedestrian-driver interactions is critical for understanding human road user behaviour and developing safe autonomous vehicle systems. Existing approaches often rely on rule-based logic, game-theoretic models, or 'black-box' machine learning methods. However, these models typically lack flexibility or overlook the underlying mechanisms, such as sensory and motor constraints, which shape how pedestrians and drivers perceive and act in interactive scenarios. In this study, we propose a multi-agent reinforcement learning (RL) framework that integrates both visual and motor constraints of pedestrian and driver agents. Using a real-world dataset from an unsignalised pedestrian crossing, we evaluate four model variants, one without constraints, two with either motor or visual constraints, and one with both, across behavioural metrics of interaction realism. Results show that the combined model with both visual and motor constraints performs best. Motor constraints lead to smoother movements that resemble human speed adjustments during crossing interactions. The addition of visual constraints introduces perceptual uncertainty and field-of-view limitations, leading the agents to exhibit more cautious and variable behaviour, such as less abrupt deceleration. In this data-limited setting, our model outperforms a supervised behavioural cloning model, demonstrating that our approach can be effective without large training datasets. Finally, our framework accounts for individual differences by modelling parameters controlling the human constraints as population-level distributions, a perspective that has not been explored in previous work on pedestrian-vehicle interaction modelling. Overall, our work demonstrates that multi-agent RL with human constraints is a promising modelling approach for simulating realistic road user interactions.",
    "fetched_at": "2025-11-06T02:19:03.471095Z"
  },
  {
    "id": "2510.27410v1",
    "title": "Dialogue as Discovery: Navigating Human Intent Through Principled   Inquiry",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jianwen Sun",
      "Yukang Feng",
      "Yifan Chang",
      "Chuanhao Li",
      "Zizhen Li",
      "Jiaxin Ai",
      "Fanrui Zhang",
      "Yu Dai",
      "Kaipeng Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27410v1",
    "abstract": "A fundamental bottleneck in human-AI collaboration is the \"intention expression gap,\" the difficulty for humans to effectively convey complex, high-dimensional thoughts to AI. This challenge often traps users in inefficient trial-and-error loops and is exacerbated by the diverse expertise levels of users. We reframe this problem from passive instruction following to a Socratic collaboration paradigm, proposing an agent that actively probes for information to resolve its uncertainty about user intent. we name the proposed agent Nous, trained to acquire proficiency in this inquiry policy. The core mechanism of Nous is a training framework grounded in the first principles of information theory. Within this framework, we define the information gain from dialogue as an intrinsic reward signal, which is fundamentally equivalent to the reduction of Shannon entropy over a structured task space. This reward design enables us to avoid reliance on costly human preference annotations or external reward models. To validate our framework, we develop an automated simulation pipeline to generate a large-scale, preference-based dataset for the challenging task of scientific diagram generation. Comprehensive experiments, including ablations, subjective and objective evaluations, and tests across user expertise levels, demonstrate the effectiveness of our proposed framework. Nous achieves leading efficiency and output quality, while remaining robust to varying user expertise. Moreover, its design is domain-agnostic, and we show evidence of generalization beyond diagram generation. Experimental results prove that our work offers a principled, scalable, and adaptive paradigm for resolving uncertainty about user intent in complex human-AI collaboration.",
    "fetched_at": "2025-11-06T02:19:03.471046Z"
  },
  {
    "id": "2510.27418v1",
    "title": "Dynamic Affective Memory Management for Personalized LLM Agents",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Junfeng Lu",
      "Yueyan Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27418v1",
    "abstract": "Advances in large language models are making personalized AI agents a new research focus. While current agent systems primarily rely on personalized external memory databases to deliver customized experiences, they face challenges such as memory redundancy, memory staleness, and poor memory-context integration, largely due to the lack of effective memory updates during interaction. To tackle these issues, we propose a new memory management system designed for affective scenarios. Our approach employs a Bayesian-inspired memory update algorithm with the concept of memory entropy, enabling the agent to autonomously maintain a dynamically updated memory vector database by minimizing global entropy to provide more personalized services. To better evaluate the system's effectiveness in this context, we propose DABench, a benchmark focusing on emotional expression and emotional change toward objects. Experimental results demonstrate that, our system achieves superior performance in personalization, logical coherence, and accuracy. Ablation studies further validate the effectiveness of the Bayesian-inspired update mechanism in alleviating memory bloat. Our work offers new insights into the design of long-term memory systems.",
    "fetched_at": "2025-11-06T02:19:03.470978Z"
  },
  {
    "id": "2510.27420v1",
    "title": "Towards a Multi-Embodied Grasping Agent",
    "date": "2025-10-31",
    "tags": [
      "cs.RO",
      "RO",
      "I.2.9",
      "9"
    ],
    "authors": [
      "Roman Freiberg",
      "Alexander Qualmann",
      "Ngo Anh Vien",
      "Gerhard Neumann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27420v1",
    "abstract": "Multi-embodiment grasping focuses on developing approaches that exhibit generalist behavior across diverse gripper designs. Existing methods often learn the kinematic structure of the robot implicitly and face challenges due to the difficulty of sourcing the required large-scale data. In this work, we present a data-efficient, flow-based, equivariant grasp synthesis architecture that can handle different gripper types with variable degrees of freedom and successfully exploit the underlying kinematic model, deducing all necessary information solely from the gripper and scene geometry. Unlike previous equivariant grasping methods, we translated all modules from the ground up to JAX and provide a model with batching capabilities over scenes, grippers, and grasps, resulting in smoother learning, improved performance and faster inference time. Our dataset encompasses grippers ranging from humanoid hands to parallel yaw grippers and includes 25,000 scenes and 20 million grasps.",
    "fetched_at": "2025-11-06T02:19:03.470940Z"
  },
  {
    "id": "2510.27484v1",
    "title": "Thought Branches: Interpreting LLM Reasoning Requires Resampling",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Uzay Macar",
      "Paul C. Bogdan",
      "Senthooran Rajamanoharan",
      "Neel Nanda"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27484v1",
    "abstract": "Most work interpreting reasoning models studies only a single chain-of-thought (CoT), yet these models define distributions over many possible CoTs. We argue that studying a single sample is inadequate for understanding causal influence and the underlying computation. Though fully specifying this distribution is intractable, it can be understood by sampling. We present case studies using resampling to investigate model decisions. First, when a model states a reason for its action, does that reason actually cause the action? In \"agentic misalignment\" scenarios, we resample specific sentences to measure their downstream effects. Self-preservation sentences have small causal impact, suggesting they do not meaningfully drive blackmail. Second, are artificial edits to CoT sufficient for steering reasoning? These are common in literature, yet take the model off-policy. Resampling and selecting a completion with the desired property is a principled on-policy alternative. We find off-policy interventions yield small and unstable effects compared to resampling in decision-making tasks. Third, how do we understand the effect of removing a reasoning step when the model may repeat it post-edit? We introduce a resilience metric that repeatedly resamples to prevent similar content from reappearing downstream. Critical planning statements resist removal but have large effects when eliminated. Fourth, since CoT is sometimes \"unfaithful\", can our methods teach us anything in these settings? Adapting causal mediation analysis, we find that hints that have a causal effect on the output without being explicitly mentioned exert a subtle and cumulative influence on the CoT that persists even if the hint is removed. Overall, studying distributions via resampling enables reliable causal analysis, clearer narratives of model reasoning, and principled CoT interventions.",
    "fetched_at": "2025-11-06T02:19:03.470895Z"
  },
  {
    "id": "2511.00136v1",
    "title": "A Dual Large Language Models Architecture with Herald Guided Prompts for   Parallel Fine Grained Traffic Signal Control",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Qing Guo",
      "Xinhang Li",
      "Junyu Chen",
      "Zheng Guo",
      "Xiaocong Li",
      "Lin Zhang",
      "Lei Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00136v1",
    "abstract": "Leveraging large language models (LLMs) in traffic signal control (TSC) improves optimization efficiency and interpretability compared to traditional reinforcement learning (RL) methods. However, existing LLM-based approaches are limited by fixed time signal durations and are prone to hallucination errors, while RL methods lack robustness in signal timing decisions and suffer from poor generalization. To address these challenges, this paper proposes HeraldLight, a dual LLMs architecture enhanced by Herald guided prompts. The Herald Module extracts contextual information and forecasts queue lengths for each traffic phase based on real-time conditions. The first LLM, LLM-Agent, uses these forecasts to make fine grained traffic signal control, while the second LLM, LLM-Critic, refines LLM-Agent's outputs, correcting errors and hallucinations. These refined outputs are used for score-based fine-tuning to improve accuracy and robustness. Simulation experiments using CityFlow on real world datasets covering 224 intersections in Jinan (12), Hangzhou (16), and New York (196) demonstrate that HeraldLight outperforms state of the art baselines, achieving a 20.03% reduction in average travel time across all scenarios and a 10.74% reduction in average queue length on the Jinan and Hangzhou scenarios. The source code is available on GitHub: https://github.com/BUPT-ANTlab/HeraldLight.",
    "fetched_at": "2025-11-06T02:19:03.470838Z"
  },
  {
    "id": "2510.27544v1",
    "title": "Mechanics of Learned Reasoning 1: TempoBench, A Benchmark for   Interpretable Deconstruction of Reasoning System Performance",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.FL",
      "FL"
    ],
    "authors": [
      "Nikolaus Holzer",
      "William Fishell",
      "Baishakhi Ray",
      "Mark Santolucito"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27544v1",
    "abstract": "Large Language Models (LLMs) are increasingly excelling and outpacing human performance on many tasks. However, to improve LLM reasoning, researchers either rely on ad-hoc generated datasets or formal mathematical proof systems such as the Lean proof assistant. Whilst ad-hoc generated methods can capture the decision chains of real-world reasoning processes, they may encode some inadvertent bias in the space of reasoning they cover; they also cannot be formally verified. On the other hand, systems like Lean can guarantee verifiability, but are not well-suited to capture the nature of agentic decision chain-based tasks. This creates a gap both in performance for functions such as business agents or code assistants, and in the usefulness of LLM reasoning benchmarks, whereby these fall short in reasoning structure or real-world alignment. We introduce TempoBench, the first formally grounded and verifiable diagnostic benchmark that parametrizes difficulty to systematically analyze how LLMs perform reasoning. TempoBench uses two evaluation benchmarks to break down reasoning ability. First, temporal trace evaluation (TTE) tests the ability of an LLM to understand and simulate the execution of a given multi-step reasoning system. Subsequently, temporal causal evaluation (TCE) tests an LLM's ability to perform multi-step causal reasoning and to distill cause-and-effect relations from complex systems. We find that models score 65.6% on TCE-normal, and 7.5% on TCE-hard. This shows that state-of-the-art LLMs clearly understand the TCE task but perform poorly as system complexity increases. Our code is available at our \\href{https://github.com/nik-hz/tempobench}{GitHub repository}.",
    "fetched_at": "2025-11-06T02:19:03.470780Z"
  },
  {
    "id": "2510.27566v1",
    "title": "Interact-RAG: Reason and Interact with the Corpus, Beyond Black-Box   Retrieval",
    "date": "2025-10-31",
    "tags": [
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Yulong Hui",
      "Chao Chen",
      "Zhihang Fu",
      "Yihao Liu",
      "Jieping Ye",
      "Huanchen Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27566v1",
    "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced LLMs by incorporating external information. However, prevailing agentic RAG approaches are constrained by a critical limitation: they treat the retrieval process as a black-box querying operation. This confines agents' actions to query issuing, hindering its ability to tackle complex information-seeking tasks. To address this, we introduce Interact-RAG, a new paradigm that elevates the LLM agent from a passive query issuer into an active manipulator of the retrieval process. We dismantle the black-box with a Corpus Interaction Engine, equipping the agent with a set of action primitives for fine-grained control over information retrieval. To further empower the agent on the entire RAG pipeline, we first develop a reasoning-enhanced workflow, which enables both zero-shot execution and the synthesis of interaction trajectories. We then leverage this synthetic data to train a fully autonomous end-to-end agent via Supervised Fine-Tuning (SFT), followed by refinement with Reinforcement Learning (RL). Extensive experiments across six benchmarks demonstrate that Interact-RAG significantly outperforms other advanced methods, validating the efficacy of our reasoning-interaction strategy.",
    "fetched_at": "2025-11-06T02:19:03.470728Z"
  },
  {
    "id": "2510.27569v1",
    "title": "MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool   Agentic Retrieval",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Qi Luo",
      "Xiaonan Li",
      "Yuxin Wang",
      "Tingshuo Fan",
      "Yuan Li",
      "Xinchi Chen",
      "Xipeng Qiu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27569v1",
    "abstract": "Large Language Models (LLMs) excel at reasoning and generation but are inherently limited by static pretraining data, resulting in factual inaccuracies and weak adaptability to new information. Retrieval-Augmented Generation (RAG) addresses this issue by grounding LLMs in external knowledge; However, the effectiveness of RAG critically depends on whether the model can adequately access relevant information. Existing RAG systems rely on a single retriever with fixed top-k selection, restricting access to a narrow and static subset of the corpus. As a result, this single-retriever paradigm has become the primary bottleneck for comprehensive external information acquisition, especially in tasks requiring corpus-level reasoning. To overcome this limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG framework that enables LLMs to dynamically coordinate multiple retrieval mechanisms for broader and more precise information access. MARAG-R1 equips the model with four retrieval tools -- semantic search, keyword search, filtering, and aggregation -- and learns both how and when to use them through a two-stage training process: supervised fine-tuning followed by reinforcement learning. This design allows the model to interleave reasoning and retrieval, progressively gathering sufficient evidence for corpus-level synthesis. Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that MARAG-R1 substantially outperforms strong baselines and achieves new state-of-the-art results in corpus-level reasoning tasks.",
    "fetched_at": "2025-11-06T02:19:03.470675Z"
  },
  {
    "id": "2510.27598v2",
    "title": "InnovatorBench: Evaluating Agents' Ability to Conduct Innovative LLM   Research",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yunze Wu",
      "Dayuan Fu",
      "Weiye Si",
      "Zhen Huang",
      "Mohan Jiang",
      "Keyu Li",
      "Shijie Xia",
      "Jie Sun",
      "Tianze Xu",
      "Xiangkun Hu",
      "Pengrui Lu",
      "Xiaojie Cai",
      "Lyumanshan Ye",
      "Wenhong Zhu",
      "Yang Xiao",
      "Pengfei Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27598v2",
    "abstract": "AI agents could accelerate scientific discovery by automating hypothesis formation, experiment design, coding, execution, and analysis, yet existing benchmarks probe narrow skills in simplified settings. To address this gap, we introduce InnovatorBench, a benchmark-platform pair for realistic, end-to-end assessment of agents performing Large Language Model (LLM) research. It comprises 20 tasks spanning Data Construction, Filtering, Augmentation, Loss Design, Reward Design, and Scaffold Construction, which require runnable artifacts and assessment of correctness, performance, output quality, and uncertainty. To support agent operation, we develop ResearchGym, a research environment offering rich action spaces, distributed and long-horizon execution, asynchronous monitoring, and snapshot saving. We also implement a lightweight ReAct agent that couples explicit reasoning with executable planning using frontier models such as Claude-4, GPT-5, GLM-4.5, and Kimi-K2. Our experiments demonstrate that while frontier models show promise in code-driven research tasks, they struggle with fragile algorithm-related tasks and long-horizon decision making, such as impatience, poor resource management, and overreliance on template-based reasoning. Furthermore, agents require over 11 hours to achieve their best performance on InnovatorBench, underscoring the benchmark's difficulty and showing the potential of InnovatorBench to be the next generation of code-based research benchmark.",
    "fetched_at": "2025-11-06T02:19:03.470616Z"
  },
  {
    "id": "2510.27623v1",
    "title": "Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive   Trigger Learning",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Qiusi Zhan",
      "Hyeonjeong Ha",
      "Rui Yang",
      "Sirui Xu",
      "Hanyang Chen",
      "Liang-Yan Gui",
      "Yu-Xiong Wang",
      "Huan Zhang",
      "Heng Ji",
      "Daniel Kang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27623v1",
    "abstract": "Multimodal large language models (MLLMs) have advanced embodied agents by enabling direct perception, reasoning, and planning task-oriented actions from visual inputs. However, such vision driven embodied agents open a new attack surface: visual backdoor attacks, where the agent behaves normally until a visual trigger appears in the scene, then persistently executes an attacker-specified multi-step policy. We introduce BEAT, the first framework to inject such visual backdoors into MLLM-based embodied agents using objects in the environments as triggers. Unlike textual triggers, object triggers exhibit wide variation across viewpoints and lighting, making them difficult to implant reliably. BEAT addresses this challenge by (1) constructing a training set that spans diverse scenes, tasks, and trigger placements to expose agents to trigger variability, and (2) introducing a two-stage training scheme that first applies supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning (CTL). CTL formulates trigger discrimination as preference learning between trigger-present and trigger-free inputs, explicitly sharpening the decision boundaries to ensure precise backdoor activation. Across various embodied agent benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while maintaining strong benign task performance, and generalizes reliably to out-of-distribution trigger placements. Notably, compared to naive SFT, CTL boosts backdoor activation accuracy up to 39% under limited backdoor data. These findings expose a critical yet unexplored security risk in MLLM-based embodied agents, underscoring the need for robust defenses before real-world deployment.",
    "fetched_at": "2025-11-06T02:19:03.470514Z"
  },
  {
    "id": "2510.27659v1",
    "title": "Challenges in Credit Assignment for Multi-Agent Reinforcement Learning   in Open Agent Systems",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Alireza Saleh Abadi",
      "Leen-Kiat Soh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27659v1",
    "abstract": "In the rapidly evolving field of multi-agent reinforcement learning (MARL), understanding the dynamics of open systems is crucial. Openness in MARL refers to the dynam-ic nature of agent populations, tasks, and agent types with-in a system. Specifically, there are three types of openness as reported in (Eck et al. 2023) [2]: agent openness, where agents can enter or leave the system at any time; task openness, where new tasks emerge, and existing ones evolve or disappear; and type openness, where the capabil-ities and behaviors of agents change over time. This report provides a conceptual and empirical review, focusing on the interplay between openness and the credit assignment problem (CAP). CAP involves determining the contribution of individual agents to the overall system performance, a task that becomes increasingly complex in open environ-ments. Traditional credit assignment (CA) methods often assume static agent populations, fixed and pre-defined tasks, and stationary types, making them inadequate for open systems. We first conduct a conceptual analysis, in-troducing new sub-categories of openness to detail how events like agent turnover or task cancellation break the assumptions of environmental stationarity and fixed team composition that underpin existing CAP methods. We then present an empirical study using representative temporal and structural algorithms in an open environment. The results demonstrate that openness directly causes credit misattribution, evidenced by unstable loss functions and significant performance degradation.",
    "fetched_at": "2025-11-06T02:19:03.470439Z"
  },
  {
    "id": "2511.00171v1",
    "title": "CompAgent: An Agentic Framework for Visual Compliance Verification",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Rahul Ghosh",
      "Baishali Chaudhury",
      "Hari Prasanna Das",
      "Meghana Ashok",
      "Ryan Razkenari",
      "Sungmin Hong",
      "Chun-Hao Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00171v1",
    "abstract": "Visual compliance verification is a critical yet underexplored problem in computer vision, especially in domains such as media, entertainment, and advertising where content must adhere to complex and evolving policy rules. Existing methods often rely on task-specific deep learning models trained on manually labeled datasets, which are costly to build and limited in generalizability. While recent multi-modal large language models (MLLMs) offer broad real-world knowledge and policy understanding, they struggle to reason over fine-grained visual details and apply structured compliance rules effectively on their own. In this paper, we propose CompAgent, the first agentic framework for visual compliance verification. CompAgent augments MLLMs with a suite of visual tools - such as object detectors, face analyzers, NSFW detectors, and captioning models - and introduces a planning agent that dynamically selects appropriate tools based on the compliance policy. A verification agent then integrates image, tool outputs, and policy context to perform multi-modal reasoning. Experiments on public benchmarks show that CompAgent outperforms specialized classifiers, direct MLLM prompting, and curated routing baselines, achieving up to 76% F1 score and a 10% improvement over the state-of-the-art on the UnsafeBench dataset. Our results demonstrate the effectiveness of agentic planning and tool-augmented reasoning for scalable, accurate, and adaptable visual compliance verification.",
    "fetched_at": "2025-11-06T02:19:03.470395Z"
  },
  {
    "id": "2511.00181v1",
    "title": "From Evidence to Verdict: An Agent-Based Forensic Framework for   AI-Generated Image Detection",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Mengfei Liang",
      "Yiting Qu",
      "Yukun Jiang",
      "Michael Backes",
      "Yang Zhang"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.00181v1",
    "abstract": "The rapid evolution of AI-generated images poses unprecedented challenges to information integrity and media authenticity. Existing detection approaches suffer from fundamental limitations: traditional classifiers lack interpretability and fail to generalize across evolving generative models, while vision-language models (VLMs), despite their promise, remain constrained to single-shot analysis and pixel-level reasoning. To address these challenges, we introduce AIFo (Agent-based Image Forensics), a novel training-free framework that emulates human forensic investigation through multi-agent collaboration. Unlike conventional methods, our framework employs a set of forensic tools, including reverse image search, metadata extraction, pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based agents that collect, synthesize, and reason over cross-source evidence. When evidence is conflicting or insufficient, a structured multi-agent debate mechanism allows agents to exchange arguments and reach a reliable conclusion. Furthermore, we enhance the framework with a memory-augmented reasoning module that learns from historical cases to improve future detection accuracy. Our comprehensive evaluation spans 6,000 images across both controlled laboratory settings and challenging real-world scenarios, including images from modern generative platforms and diverse online sources. AIFo achieves 97.05% accuracy, substantially outperforming traditional classifiers and state-of-the-art VLMs. These results demonstrate that agent-based procedural reasoning offers a new paradigm for more robust, interpretable, and adaptable AI-generated image detection.",
    "fetched_at": "2025-11-06T02:19:03.470337Z"
  },
  {
    "id": "2511.00190v1",
    "title": "Deep reinforcement learning for optimal trading with partial information",
    "date": "2025-10-31",
    "tags": [
      "q-fin.TR",
      "TR",
      "q-fin.CP",
      "CP",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Andrea Macrì",
      "Sebastian Jaimungal",
      "Fabrizio Lillo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2511.00190v1",
    "abstract": "Reinforcement Learning (RL) applied to financial problems has been the subject of a lively area of research. The use of RL for optimal trading strategies that exploit latent information in the market is, to the best of our knowledge, not widely tackled. In this paper we study an optimal trading problem, where a trading signal follows an Ornstein-Uhlenbeck process with regime-switching dynamics. We employ a blend of RL and Recurrent Neural Networks (RNN) in order to make the most at extracting underlying information from the trading signal with latent parameters.   The latent parameters driving mean reversion, speed, and volatility are filtered from observations of the signal, and trading strategies are derived via RL. To address this problem, we propose three Deep Deterministic Policy Gradient (DDPG)-based algorithms that integrate Gated Recurrent Unit (GRU) networks to capture temporal dependencies in the signal. The first, a one -step approach (hid-DDPG), directly encodes hidden states from the GRU into the RL trader. The second and third are two-step methods: one (prob-DDPG) makes use of posterior regime probability estimates, while the other (reg-DDPG) relies on forecasts of the next signal value. Through extensive simulations with increasingly complex Markovian regime dynamics for the trading signal's parameters, as well as an empirical application to equity pair trading, we find that prob-DDPG achieves superior cumulative rewards and exhibits more interpretable strategies. By contrast, reg-DDPG provides limited benefits, while hid-DDPG offers intermediate performance with less interpretable strategies. Our results show that the quality and structure of the information supplied to the agent are crucial: embedding probabilistic insights into latent regimes substantially improves both profitability and robustness of reinforcement learning-based trading strategies.",
    "fetched_at": "2025-11-06T02:19:03.470283Z"
  },
  {
    "id": "2511.00222v1",
    "title": "Consistently Simulating Human Personas with Multi-Turn Reinforcement   Learning",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Marwa Abdulhai",
      "Ryan Cheng",
      "Donovan Clay",
      "Tim Althoff",
      "Sergey Levine",
      "Natasha Jaques"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00222v1",
    "abstract": "Large Language Models (LLMs) are increasingly used to simulate human users in interactive settings such as therapy, education, and social role-play. While these simulations enable scalable training and evaluation of AI agents, off-the-shelf LLMs often drift from their assigned personas, contradict earlier statements, or abandon role-appropriate behavior. We introduce a unified framework for evaluating and improving persona consistency in LLM-generated dialogue. We define three automatic metrics: prompt-to-line consistency, line-to-line consistency, and Q&A consistency, that capture different types of persona drift and validate each against human annotations. Using these metrics as reward signals, we apply multi-turn reinforcement learning to fine-tune LLMs for three user roles: a patient, a student, and a social chat partner. Our method reduces inconsistency by over 55%, resulting in more coherent and faithful simulated users.",
    "fetched_at": "2025-11-06T02:19:03.470232Z"
  },
  {
    "id": "2511.00265v1",
    "title": "AgentBnB: A Browser-Based Cybersecurity Tabletop Exercise with Large   Language Model Support and Retrieval-Aligned Scaffolding",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Arman Anwar",
      "Zefang Liu"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2511.00265v1",
    "abstract": "Traditional cybersecurity tabletop exercises (TTXs) provide valuable training but are often scripted, resource-intensive, and difficult to scale. We introduce AgentBnB, a browser-based re-imagining of the Backdoors & Breaches game that integrates large language model teammates with a Bloom-aligned, retrieval-augmented copilot (C2D2). The system expands a curated corpus into factual, conceptual, procedural, and metacognitive snippets, delivering on-demand, cognitively targeted hints. Prompt-engineered agents employ a scaffolding ladder that gradually fades as learner confidence grows. In a solo-player pilot with four graduate students, participants reported greater intention to use the agent-based version compared to the physical card deck and viewed it as more scalable, though a ceiling effect emerged on a simple knowledge quiz. Despite limitations of small sample size, single-player focus, and narrow corpus, these early findings suggest that large language model augmented TTXs can provide lightweight, repeatable practice without the logistical burden of traditional exercises. Planned extensions include multi-player modes, telemetry-driven coaching, and comparative studies with larger cohorts.",
    "fetched_at": "2025-11-06T02:19:03.470181Z"
  },
  {
    "id": "2511.00272v1",
    "title": "Improving the Robustness of Control of Chaotic Convective Flows with   Domain-Informed Reinforcement Learning",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "physics.flu-dyn",
      "flu-dyn"
    ],
    "authors": [
      "Michiel Straat",
      "Thorben Markmann",
      "Sebastian Peitz",
      "Barbara Hammer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00272v1",
    "abstract": "Chaotic convective flows arise in many real-world systems, such as microfluidic devices and chemical reactors. Stabilizing these flows is highly desirable but remains challenging, particularly in chaotic regimes where conventional control methods often fail. Reinforcement Learning (RL) has shown promise for control in laminar flow settings, but its ability to generalize and remain robust under chaotic and turbulent dynamics is not well explored, despite being critical for real-world deployment. In this work, we improve the practical feasibility of RL-based control of such flows focusing on Rayleigh-B\\'enard Convection (RBC), a canonical model for convective heat transport. To enhance generalization and sample efficiency, we introduce domain-informed RL agents that are trained using Proximal Policy Optimization across diverse initial conditions and flow regimes. We incorporate domain knowledge in the reward function via a term that encourages B\\'enard cell merging, as an example of a desirable macroscopic property. In laminar flow regimes, the domain-informed RL agents reduce convective heat transport by up to 33%, and in chaotic flow regimes, they still achieve a 10% reduction, which is significantly better than the conventional controllers used in practice. We compare the domain-informed to uninformed agents: Our results show that the domain-informed reward design results in steady flows, faster convergence during training, and generalization across flow regimes without retraining. Our work demonstrates that elegant domain-informed priors can greatly enhance the robustness of RL-based control of chaotic flows, bringing real-world deployment closer.",
    "fetched_at": "2025-11-06T02:19:03.470141Z"
  },
  {
    "id": "2510.27304v1",
    "title": "Binary Anomaly Detection in Streaming IoT Traffic under Concept Drift",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Rodrigo Matos Carnier",
      "Laura Lahesoo",
      "Kensuke Fukuda"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27304v1",
    "abstract": "With the growing volume of Internet of Things (IoT) network traffic, machine learning (ML)-based anomaly detection is more relevant than ever. Traditional batch learning models face challenges such as high maintenance and poor adaptability to rapid anomaly changes, known as concept drift. In contrast, streaming learning integrates online and incremental learning, enabling seamless updates and concept drift detection to improve robustness. This study investigates anomaly detection in streaming IoT traffic as binary classification, comparing batch and streaming learning approaches while assessing the limitations of current IoT traffic datasets. We simulated heterogeneous network data streams by carefully mixing existing datasets and streaming the samples one by one. Our results highlight the failure of batch models to handle concept drift, but also reveal persisting limitations of current datasets to expose model limitations due to low traffic heterogeneity. We also investigated the competitiveness of tree-based ML algorithms, well-known in batch anomaly detection, and compared it to non-tree-based ones, confirming the advantages of the former. Adaptive Random Forest achieved F1-score of 0.990 $\\pm$ 0.006 at one-third the computational cost of its batch counterpart. Hoeffding Adaptive Tree reached F1-score of 0.910 $\\pm$ 0.007, reducing computational cost by four times, making it a viable choice for online applications despite a slight trade-off in stability.",
    "fetched_at": "2025-11-05T02:19:05.055273Z"
  },
  {
    "id": "2510.27313v1",
    "title": "Un-Attributability: Computing Novelty From Retrieval & Semantic   Similarity",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Philipp Davydov",
      "Ameya Prabhu",
      "Matthias Bethge",
      "Elisa Nguyen",
      "Seong Joon Oh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27313v1",
    "abstract": "Understanding how language-model outputs relate to the pretraining corpus is central to studying model behavior. Most training data attribution (TDA) methods ask which training examples causally influence a given output, often using leave-one-out tests. We invert the question: which outputs cannot be attributed to any pretraining example? We introduce un-attributability as an operational measure of semantic novelty: an output is novel if the pretraining corpus contains no semantically similar context. We approximate this with a simple two-stage retrieval pipeline: index the corpus with lightweight GIST embeddings, retrieve the top-n candidates, then rerank with ColBERTv2. If the nearest corpus item is less attributable than a human-generated text reference, we consider the output of the model as novel. We evaluate on SmolLM and SmolLM2 and report three findings: (1) models draw on pretraining data across much longer spans than previously reported; (2) some domains systematically promote or suppress novelty; and (3) instruction tuning not only alters style but also increases novelty. Reframing novelty assessment around un-attributability enables efficient analysis at pretraining scale. We release ~20 TB of corpus chunks and index artifacts to support replication and large-scale extension of our analysis at https://huggingface.co/datasets/stai-tuebingen/faiss-smollm",
    "fetched_at": "2025-11-05T02:19:05.055227Z"
  },
  {
    "id": "2510.27315v1",
    "title": "CASR-Net: An Image Processing-focused Deep Learning-based Coronary   Artery Segmentation and Refinement Network for X-ray Coronary Angiogram",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Alvee Hassan",
      "Rusab Sarmun",
      "Muhammad E. H. Chowdhury",
      "M. Murugappan",
      "Md. Sakib Abrar Hossain",
      "Sakib Mahmud",
      "Abdulrahman Alqahtani",
      "Sohaib Bassam Zoghoul",
      "Amith Khandakar",
      "Susu M. Zughaier",
      "Somaya Al-Maadeed",
      "Anwarul Hasan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27315v1",
    "abstract": "Early detection of coronary artery disease (CAD) is critical for reducing mortality and improving patient treatment planning. While angiographic image analysis from X-rays is a common and cost-effective method for identifying cardiac abnormalities, including stenotic coronary arteries, poor image quality can significantly impede clinical diagnosis. We present the Coronary Artery Segmentation and Refinement Network (CASR-Net), a three-stage pipeline comprising image preprocessing, segmentation, and refinement. A novel multichannel preprocessing strategy combining CLAHE and an improved Ben Graham method provides incremental gains, increasing Dice Score Coefficient (DSC) by 0.31-0.89% and Intersection over Union (IoU) by 0.40-1.16% compared with using the techniques individually. The core innovation is a segmentation network built on a UNet with a DenseNet121 encoder and a Self-organized Operational Neural Network (Self-ONN) based decoder, which preserves the continuity of narrow and stenotic vessel branches. A final contour refinement module further suppresses false positives. Evaluated with 5-fold cross-validation on a combination of two public datasets that contain both healthy and stenotic arteries, CASR-Net outperformed several state-of-the-art models, achieving an IoU of 61.43%, a DSC of 76.10%, and clDice of 79.36%. These results highlight a robust approach to automated coronary artery segmentation, offering a valuable tool to support clinicians in diagnosis and treatment planning.",
    "fetched_at": "2025-11-05T02:19:05.055173Z"
  },
  {
    "id": "2510.27321v1",
    "title": "MedM2T: A MultiModal Framework for Time-Aware Modeling with Electronic   Health Record and Electrocardiogram Data",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yu-Chen Kuo",
      "Yi-Ju Tseng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27321v1",
    "abstract": "The inherent multimodality and heterogeneous temporal structures of medical data pose significant challenges for modeling. We propose MedM2T, a time-aware multimodal framework designed to address these complexities. MedM2T integrates: (i) Sparse Time Series Encoder to flexibly handle irregular and sparse time series, (ii) Hierarchical Time-Aware Fusion to capture both micro- and macro-temporal patterns from multiple dense time series, such as ECGs, and (iii) Bi-Modal Attention to extract cross-modal interactions, which can be extended to any number of modalities. To mitigate granularity gaps between modalities, MedM2T uses modality-specific pre-trained encoders and aligns resulting features within a shared encoder. We evaluated MedM2T on MIMIC-IV and MIMIC-IV-ECG datasets for three tasks that encompass chronic and acute disease dynamics: 90-day cardiovascular disease (CVD) prediction, in-hospital mortality prediction, and ICU length-of-stay (LOS) regression. MedM2T outperformed state-of-the-art multimodal learning frameworks and existing time series models, achieving an AUROC of 0.947 and an AUPRC of 0.706 for CVD prediction; an AUROC of 0.901 and an AUPRC of 0.558 for mortality prediction; and Mean Absolute Error (MAE) of 2.31 for LOS regression. These results highlight the robustness and broad applicability of MedM2T, positioning it as a promising tool in clinical prediction. We provide the implementation of MedM2T at https://github.com/DHLab-TSENG/MedM2T.",
    "fetched_at": "2025-11-05T02:19:05.055093Z"
  },
  {
    "id": "2510.27324v1",
    "title": "Generative Semantic Coding for Ultra-Low Bitrate Visual Communication   and Analysis",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Weiming Chen",
      "Yijia Wang",
      "Zhihan Zhu",
      "Zhihai He"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27324v1",
    "abstract": "We consider the problem of ultra-low bit rate visual communication for remote vision analysis, human interactions and control in challenging scenarios with very low communication bandwidth, such as deep space exploration, battlefield intelligence, and robot navigation in complex environments. In this paper, we ask the following important question: can we accurately reconstruct the visual scene using only a very small portion of the bit rate in existing coding methods while not sacrificing the accuracy of vision analysis and performance of human interactions? Existing text-to-image generation models offer a new approach for ultra-low bitrate image description. However, they can only achieve a semantic-level approximation of the visual scene, which is far insufficient for the purpose of visual communication and remote vision analysis and human interactions. To address this important issue, we propose to seamlessly integrate image generation with deep image compression, using joint text and coding latent to guide the rectified flow models for precise generation of the visual scene. The semantic text description and coding latent are both encoded and transmitted to the decoder at a very small bit rate. Experimental results demonstrate that our method can achieve the same image reconstruction quality and vision analysis accuracy as existing methods while using much less bandwidth. The code will be released upon paper acceptance.",
    "fetched_at": "2025-11-05T02:19:05.055046Z"
  },
  {
    "id": "2510.27328v2",
    "title": "A Unified Representation Underlying the Judgment of Large Language   Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yi-Long Lu",
      "Jiajun Song",
      "Wei Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27328v2",
    "abstract": "A central architectural question for both biological and artificial intelligence is whether judgment relies on specialized modules or a unified, domain-general resource. While the discovery of decodable neural representations for distinct concepts in Large Language Models (LLMs) has suggested a modular architecture, whether these representations are truly independent systems remains an open question. Here we provide evidence for a convergent architecture for evaluative judgment. Across a range of LLMs, we find that diverse evaluative judgments are computed along a dominant dimension, which we term the Valence-Assent Axis (VAA). This axis jointly encodes subjective valence (\"what is good\") and the model's assent to factual claims (\"what is true\"). Through direct interventions, we demonstrate this axis drives a critical mechanism, which is identified as the subordination of reasoning: the VAA functions as a control signal that steers the generative process to construct a rationale consistent with its evaluative state, even at the cost of factual accuracy. Our discovery offers a mechanistic account for response bias and hallucination, revealing how an architecture that promotes coherent judgment can systematically undermine faithful reasoning.",
    "fetched_at": "2025-11-05T02:19:05.054958Z"
  },
  {
    "id": "2510.27337v1",
    "title": "TransAlign: Machine Translation Encoders are Strong Word Aligners, Too",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Benedikt Ebing",
      "Christian Goldschmied",
      "Goran Glavaš"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27337v1",
    "abstract": "In the absence of sizable training data for most world languages and NLP tasks, translation-based strategies such as translate-test -- evaluating on noisy source language data translated from the target language -- and translate-train -- training on noisy target language data translated from the source language -- have been established as competitive approaches for cross-lingual transfer (XLT). For token classification tasks, these strategies require label projection: mapping the labels from each token in the original sentence to its counterpart(s) in the translation. To this end, it is common to leverage multilingual word aligners (WAs) derived from encoder language models such as mBERT or LaBSE. Despite obvious associations between machine translation (MT) and WA, research on extracting alignments with MT models is largely limited to exploiting cross-attention in encoder-decoder architectures, yielding poor WA results. In this work, in contrast, we propose TransAlign, a novel word aligner that utilizes the encoder of a massively multilingual MT model. We show that TransAlign not only achieves strong WA performance but substantially outperforms popular WA and state-of-the-art non-WA-based label projection methods in MT-based XLT for token classification.",
    "fetched_at": "2025-11-05T02:19:05.054818Z"
  },
  {
    "id": "2510.27338v1",
    "title": "Reasoning Models Sometimes Output Illegible Chains of Thought",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Arun Jose"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27338v1",
    "abstract": "Language models trained via outcome-based reinforcement learning (RL) to reason using chain-of-thought (CoT) have shown remarkable performance. Monitoring such a model's CoT may allow us to understand its intentions and detect potential malicious behavior. However, to be effective, this requires that CoTs are legible and faithful. We study CoT legibility across 14 reasoning models, finding that RL often causes reasoning to become illegible to both humans and AI monitors, with reasoning models (except Claude) generating illegible CoTs while returning to perfectly readable final answers. We show that models use illegible reasoning to reach correct answers (accuracy dropping by 53\\% when forced to use only legible portions), yet find no correlation between legibility and performance when resampling - suggesting the relationship is more nuanced. We also find that legibility degrades on harder questions. We discuss potential hypotheses for these results, including steganography, training artifacts, and vestigial tokens. These results suggest that without explicit optimization for legibility, outcome-based RL naturally produces models with increasingly opaque reasoning processes, potentially undermining monitoring approaches.",
    "fetched_at": "2025-11-05T02:19:05.054775Z"
  },
  {
    "id": "2510.27342v1",
    "title": "Pairwise and Attribute-Aware Decision Tree-Based Preference Elicitation   for Cold-Start Recommendation",
    "date": "2025-10-31",
    "tags": [
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alireza Gharahighehi",
      "Felipe Kenji Nakano",
      "Xuehua Yang",
      "Wenhan Cu",
      "Celine Vens"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27342v1",
    "abstract": "Recommender systems (RSs) are intelligent filtering methods that suggest items to users based on their inferred preferences, derived from their interaction history on the platform. Collaborative filtering-based RSs rely on users past interactions to generate recommendations. However, when a user is new to the platform, referred to as a cold-start user, there is no historical data available, making it difficult to provide personalized recommendations. To address this, rating elicitation techniques can be used to gather initial ratings or preferences on selected items, helping to build an early understanding of the user's tastes. Rating elicitation approaches are generally categorized into two types: non-personalized and personalized. Decision tree-based rating elicitation is a personalized method that queries users about their preferences at each node of the tree until sufficient information is gathered. In this paper, we propose an extension to the decision tree approach for rating elicitation in the context of music recommendation. Our method: (i) elicits not only item ratings but also preferences on attributes such as genres to better cluster users, and (ii) uses item pairs instead of single items at each node to more effectively learn user preferences. Experimental results demonstrate that both proposed enhancements lead to improved performance, particularly with a reduced number of queries.",
    "fetched_at": "2025-11-05T02:19:05.054739Z"
  },
  {
    "id": "2510.27343v1",
    "title": "Discriminative Rule Learning for Outcome-Guided Process Model Discovery",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ali Norouzifar",
      "Wil van der Aalst"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27343v1",
    "abstract": "Event logs extracted from information systems offer a rich foundation for understanding and improving business processes. In many real-world applications, it is possible to distinguish between desirable and undesirable process executions, where desirable traces reflect efficient or compliant behavior, and undesirable ones may involve inefficiencies, rule violations, delays, or resource waste. This distinction presents an opportunity to guide process discovery in a more outcome-aware manner. Discovering a single process model without considering outcomes can yield representations poorly suited for conformance checking and performance analysis, as they fail to capture critical behavioral differences. Moreover, prioritizing one behavior over the other may obscure structural distinctions vital for understanding process outcomes. By learning interpretable discriminative rules over control-flow features, we group traces with similar desirability profiles and apply process discovery separately within each group. This results in focused and interpretable models that reveal the drivers of both desirable and undesirable executions. The approach is implemented as a publicly available tool and it is evaluated on multiple real-life event logs, demonstrating its effectiveness in isolating and visualizing critical process patterns.",
    "fetched_at": "2025-11-05T02:19:05.054687Z"
  },
  {
    "id": "2510.27353v1",
    "title": "An In-depth Study of LLM Contributions to the Bin Packing Problem",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "I.2.8; F.2.2",
      "2"
    ],
    "authors": [
      "Julien Herrmann",
      "Guillaume Pallez"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27353v1",
    "abstract": "Recent studies have suggested that Large Language Models (LLMs) could provide interesting ideas contributing to mathematical discovery. This claim was motivated by reports that LLM-based genetic algorithms produced heuristics offering new insights into the online bin packing problem under uniform and Weibull distributions. In this work, we reassess this claim through a detailed analysis of the heuristics produced by LLMs, examining both their behavior and interpretability. Despite being human-readable, these heuristics remain largely opaque even to domain experts. Building on this analysis, we propose a new class of algorithms tailored to these specific bin packing instances. The derived algorithms are significantly simpler, more efficient, more interpretable, and more generalizable, suggesting that the considered instances are themselves relatively simple. We then discuss the limitations of the claim regarding LLMs' contribution to this problem, which appears to rest on the mistaken assumption that the instances had previously been studied. Our findings instead emphasize the need for rigorous validation and contextualization when assessing the scientific value of LLM-generated outputs.",
    "fetched_at": "2025-11-05T02:19:05.054646Z"
  },
  {
    "id": "2510.27355v1",
    "title": "ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via   Probing Representations",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zijian Wang",
      "Chang Xu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27355v1",
    "abstract": "This paper introduces ThoughtProbe, a novel inference time framework that leverages the hidden reasoning features of Large Language Models (LLMs) to improve their reasoning performance. Unlike previous works that manipulate the hidden representations to steer LLM generation, we harness them as discriminative signals to guide the tree structured response space exploration. In each node expansion, a classifier serves as a scoring and ranking mechanism that efficiently allocates computational resources by prioritizing higher score candidates for continuation. After completing the tree expansion, we collect answers from all branches to form a candidate answer pool. We then propose a branch aggregation method that marginalizes over all supporting branches by aggregating their CoT scores, thereby identifying the optimal answer from the pool. Experimental results show that our framework's comprehensive exploration not only covers valid reasoning chains but also effectively identifies them, achieving significant improvements across multiple arithmetic reasoning benchmarks.",
    "fetched_at": "2025-11-05T02:19:05.054607Z"
  },
  {
    "id": "2510.27359v1",
    "title": "FPS: Feedforward-based Parameter Selection For Efficient Fine-Tuning",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kenneth Yang",
      "Wen-Li Wei",
      "Jen-Chun Lin"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27359v1",
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) has emerged as a key strategy for adapting large-scale pre-trained models to downstream tasks, but existing approaches face notable limitations. Addition-based methods, such as Adapters [1], introduce inference latency and engineering complexity, while selection-based methods like Gradient-based Parameter Selection (GPS) [2] require a full backward pass, which results in the same peak memory usage as full fine-tuning. To address this dilemma, we propose Feedforward-based Parameter Selection (FPS), a gradient-free method that identifies an optimal parameter subset in a single forward pass. FPS ranks parameters by the product of their magnitudes and corresponding input activations, leveraging both pre-trained knowledge and downstream data. Evaluated on $24$ visual tasks from FGVC and VTAB-1k, FPS achieves performance comparable to state-of-the-art methods while reducing peak memory usage by nearly $9 \\times$ and accelerating parameter selection by about $2 \\times$, offering a genuinely memory-efficient and practical solution for fine-tuning large-scale pre-trained models.",
    "fetched_at": "2025-11-05T02:19:05.054567Z"
  },
  {
    "id": "2510.27364v1",
    "title": "Fine-Tuning Open Video Generators for Cinematic Scene Synthesis: A   Small-Data Pipeline with LoRA and Wan2.1 I2V",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Meftun Akarsu",
      "Kerem Catay",
      "Sedat Bin Vedat",
      "Enes Kutay Yarkan",
      "Ilke Senturk",
      "Arda Sar",
      "Dafne Eksioglu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27364v1",
    "abstract": "We present a practical pipeline for fine-tuning open-source video diffusion transformers to synthesize cinematic scenes for television and film production from small datasets. The proposed two-stage process decouples visual style learning from motion generation. In the first stage, Low-Rank Adaptation (LoRA) modules are integrated into the cross-attention layers of the Wan2.1 I2V-14B model to adapt its visual representations using a compact dataset of short clips from Ay Yapim's historical television film El Turco. This enables efficient domain transfer within hours on a single GPU. In the second stage, the fine-tuned model produces stylistically consistent keyframes that preserve costume, lighting, and color grading, which are then temporally expanded into coherent 720p sequences through the model's video decoder. We further apply lightweight parallelization and sequence partitioning strategies to accelerate inference without quality degradation. Quantitative and qualitative evaluations using FVD, CLIP-SIM, and LPIPS metrics, supported by a small expert user study, demonstrate measurable improvements in cinematic fidelity and temporal stability over the base model. The complete training and inference pipeline is released to support reproducibility and adaptation across cinematic domains.",
    "fetched_at": "2025-11-05T02:19:05.054479Z"
  },
  {
    "id": "2510.27369v1",
    "title": "From the Rock Floor to the Cloud: A Systematic Survey of   State-of-the-Art NLP in Battery Life Cycle",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tosin Adewumi",
      "Martin Karlsson",
      "Marcus Liwicki",
      "Mikael Sjödahl",
      "Lama Alkhaled",
      "Rihab Gargouri",
      "Nudrat Habib",
      "Franz Hennie"
    ],
    "institution": "Google, Meta",
    "link": "http://arxiv.org/pdf/2510.27369v1",
    "abstract": "We present a comprehensive systematic survey of the application of natural language processing (NLP) along the entire battery life cycle, instead of one stage or method, and introduce a novel technical language processing (TLP) framework for the EU's proposed digital battery passport (DBP) and other general battery predictions. We follow the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable databases or search engines, including Google Scholar, Institute of Electrical and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we assessed 274 scientific papers before the critical review of the final 66 relevant papers. We publicly provide artifacts of the review for validation and reproducibility. The findings show that new NLP tasks are emerging in the battery domain, which facilitate materials discovery and other stages of the life cycle. Notwithstanding, challenges remain, such as the lack of standard benchmarks. Our proposed TLP framework, which incorporates agentic AI and optimized prompts, will be apt for tackling some of the challenges.",
    "fetched_at": "2025-11-05T02:19:05.054421Z"
  },
  {
    "id": "2510.27378v1",
    "title": "Measuring Chain-of-Thought Monitorability Through Faithfulness and   Verbosity",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Austin Meek",
      "Eitan Sprejer",
      "Iván Arcuschin",
      "Austin J. Brockmeier",
      "Steven Basart"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27378v1",
    "abstract": "Chain-of-thought (CoT) outputs let us read a model's step-by-step reasoning. Since any long, serial reasoning process must pass through this textual trace, the quality of the CoT is a direct window into what the model is thinking. This visibility could help us spot unsafe or misaligned behavior (monitorability), but only if the CoT is transparent about its internal reasoning (faithfulness). Fully measuring faithfulness is difficult, so researchers often focus on examining the CoT in cases where the model changes its answer after adding a cue to the input. This proxy finds some instances of unfaithfulness but loses information when the model maintains its answer, and does not investigate aspects of reasoning not tied to the cue. We extend these results to a more holistic sense of monitorability by introducing verbosity: whether the CoT lists every factor needed to solve the task. We combine faithfulness and verbosity into a single monitorability score that shows how well the CoT serves as the model's external `working memory', a property that many safety schemes based on CoT monitoring depend on. We evaluate instruction-tuned and reasoning models on BBH, GPQA, and MMLU. Our results show that models can appear faithful yet remain hard to monitor when they leave out key factors, and that monitorability differs sharply across model families. We release our evaluation code using the Inspect library to support reproducible future work.",
    "fetched_at": "2025-11-05T02:19:05.054361Z"
  },
  {
    "id": "2510.27379v1",
    "title": "Spiking Neural Networks: The Future of Brain-Inspired Computing",
    "date": "2025-10-31",
    "tags": [
      "cs.NE",
      "NE",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sales G. Aribe Jr"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27379v1",
    "abstract": "Spiking Neural Networks (SNNs) represent the latest generation of neural computation, offering a brain-inspired alternative to conventional Artificial Neural Networks (ANNs). Unlike ANNs, which depend on continuous-valued signals, SNNs operate using distinct spike events, making them inherently more energy-efficient and temporally dynamic. This study presents a comprehensive analysis of SNN design models, training algorithms, and multi-dimensional performance metrics, including accuracy, energy consumption, latency, spike count, and convergence behavior. Key neuron models such as the Leaky Integrate-and-Fire (LIF) and training strategies, including surrogate gradient descent, ANN-to-SNN conversion, and Spike-Timing Dependent Plasticity (STDP), are examined in depth. Results show that surrogate gradient-trained SNNs closely approximate ANN accuracy (within 1-2%), with faster convergence by the 20th epoch and latency as low as 10 milliseconds. Converted SNNs also achieve competitive performance but require higher spike counts and longer simulation windows. STDP-based SNNs, though slower to converge, exhibit the lowest spike counts and energy consumption (as low as 5 millijoules per inference), making them optimal for unsupervised and low-power tasks. These findings reinforce the suitability of SNNs for energy-constrained, latency-sensitive, and adaptive applications such as robotics, neuromorphic vision, and edge AI systems. While promising, challenges persist in hardware standardization and scalable training. This study concludes that SNNs, with further refinement, are poised to propel the next phase of neuromorphic computing.",
    "fetched_at": "2025-11-05T02:19:05.054307Z"
  },
  {
    "id": "2510.27385v1",
    "title": "On the Equivalence of Optimal Transport Problem and Action Matching with   Optimal Vector Fields",
    "date": "2025-10-31",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nikita Kornilov",
      "Alexander Korotin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27385v1",
    "abstract": "Flow Matching (FM) method in generative modeling maps arbitrary probability distributions by constructing an interpolation between them and then learning the vector field that defines ODE for this interpolation. Recently, it was shown that FM can be modified to map distributions optimally in terms of the quadratic cost function for any initial interpolation. To achieve this, only specific optimal vector fields, which are typical for solutions of Optimal Transport (OT) problems, need to be considered during FM loss minimization. In this note, we show that considering only optimal vector fields can lead to OT in another approach: Action Matching (AM). Unlike FM, which learns a vector field for a manually chosen interpolation between given distributions, AM learns the vector field that defines ODE for an entire given sequence of distributions.",
    "fetched_at": "2025-11-05T02:19:05.054215Z"
  },
  {
    "id": "2510.27391v1",
    "title": "Modality Alignment across Trees on Heterogeneous Hyperbolic Manifolds",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Wu Wei",
      "Xiaomeng Fan",
      "Yuwei Wu",
      "Zhi Gao",
      "Pengxiang Li",
      "Yunde Jia",
      "Mehrtash Harandi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27391v1",
    "abstract": "Modality alignment is critical for vision-language models (VLMs) to effectively integrate information across modalities. However, existing methods extract hierarchical features from text while representing each image with a single feature, leading to asymmetric and suboptimal alignment. To address this, we propose Alignment across Trees, a method that constructs and aligns tree-like hierarchical features for both image and text modalities. Specifically, we introduce a semantic-aware visual feature extraction framework that applies a cross-attention mechanism to visual class tokens from intermediate Transformer layers, guided by textual cues to extract visual features with coarse-to-fine semantics. We then embed the feature trees of the two modalities into hyperbolic manifolds with distinct curvatures to effectively model their hierarchical structures. To align across the heterogeneous hyperbolic manifolds with different curvatures, we formulate a KL distance measure between distributions on heterogeneous manifolds, and learn an intermediate manifold for manifold alignment by minimizing the distance. We prove the existence and uniqueness of the optimal intermediate manifold. Experiments on taxonomic open-set classification tasks across multiple image datasets demonstrate that our method consistently outperforms strong baselines under few-shot and cross-domain settings.",
    "fetched_at": "2025-11-05T02:19:05.054177Z"
  },
  {
    "id": "2510.27397v1",
    "title": "Interpretable Model-Aware Counterfactual Explanations for Random Forest",
    "date": "2025-10-31",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Joshua S. Harvey",
      "Guanchao Feng",
      "Sai Anusha Meesala",
      "Tina Zhao",
      "Dhagash Mehta"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27397v1",
    "abstract": "Despite their enormous predictive power, machine learning models are often unsuitable for applications in regulated industries such as finance, due to their limited capacity to provide explanations. While model-agnostic frameworks such as Shapley values have proved to be convenient and popular, they rarely align with the kinds of causal explanations that are typically sought after. Counterfactual case-based explanations, where an individual is informed of which circumstances would need to be different to cause a change in outcome, may be more intuitive and actionable. However, finding appropriate counterfactual cases is an open challenge, as is interpreting which features are most critical for the change in outcome. Here, we pose the question of counterfactual search and interpretation in terms of similarity learning, exploiting the representation learned by the random forest predictive model itself. Once a counterfactual is found, the feature importance of the explanation is computed as a function of which random forest partitions are crossed in order to reach it from the original instance. We demonstrate this method on both the MNIST hand-drawn digit dataset and the German credit dataset, finding that it generates explanations that are sparser and more useful than Shapley values.",
    "fetched_at": "2025-11-05T02:19:05.054117Z"
  },
  {
    "id": "2510.27400v1",
    "title": "Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiahao Liu",
      "Zijian Wang",
      "Kuo Zhao",
      "Dong Hu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27400v1",
    "abstract": "Knowledge editing has emerged as an efficient approach for updating factual knowledge in large language models (LLMs). It typically locates knowledge storage modules and then modifies their parameters. However, most existing methods focus on the weights of multilayer perceptron (MLP) modules, which are often identified as the main repositories of factual information. Other components, such as attention (Attn) modules, are often ignored during editing. This imbalance can leave residual outdated knowledge and limit editing effectiveness. We perform comprehensive knowledge localization experiments on advanced LLMs and find that Attn modules play a substantial role in factual knowledge storage and retrieval, especially in earlier layers. Based on these insights, we propose IntAttn-Edit, a method that extends the associative memory paradigm to jointly update both MLP and Attn modules. Our approach uses a knowledge balancing strategy that allocates update magnitudes in proportion to each module's measured contribution to knowledge storage. Experiments on standard benchmarks show that IntAttn-Edit achieves higher edit success, better generalization, and stronger knowledge preservation than prior methods. Further analysis shows that the balancing strategy keeps editing performance within an optimal range across diverse settings.",
    "fetched_at": "2025-11-05T02:19:05.054066Z"
  },
  {
    "id": "2510.27403v1",
    "title": "FedMuon: Accelerating Federated Learning with Matrix Orthogonalization",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junkang Liu",
      "Fanhua Shang",
      "Junchao Zhou",
      "Hongying Liu",
      "Yuanyuan Liu",
      "Jin Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27403v1",
    "abstract": "The core bottleneck of Federated Learning (FL) lies in the communication rounds. That is, how to achieve more effective local updates is crucial for reducing communication rounds. Existing FL methods still primarily use element-wise local optimizers (Adam/SGD), neglecting the geometric structure of the weight matrices. This often leads to the amplification of pathological directions in the weights during local updates, leading deterioration in the condition number and slow convergence. Therefore, we introduce the Muon optimizer in local, which has matrix orthogonalization to optimize matrix-structured parameters. Experimental results show that, in IID setting, Local Muon significantly accelerates the convergence of FL and reduces communication rounds compared to Local SGD and Local AdamW. However, in non-IID setting, independent matrix orthogonalization based on the local distributions of each client induces strong client drift. Applying Muon in non-IID FL poses significant challenges: (1) client preconditioner leading to client drift; (2) moment reinitialization. To address these challenges, we propose a novel Federated Muon optimizer (FedMuon), which incorporates two key techniques: (1) momentum aggregation, where clients use the aggregated momentum for local initialization; (2) local-global alignment, where the local gradients are aligned with the global update direction to significantly reduce client drift. Theoretically, we prove that \\texttt{FedMuon} achieves a linear speedup convergence rate without the heterogeneity assumption, where $S$ is the number of participating clients per round, $K$ is the number of local iterations, and $R$ is the total number of communication rounds. Empirically, we validate the effectiveness of FedMuon on language and vision models. Compared to several baselines, FedMuon significantly reduces communication rounds and improves test accuracy.",
    "fetched_at": "2025-11-05T02:19:05.054017Z"
  },
  {
    "id": "2510.27407v1",
    "title": "Awal -- Community-Powered Language Technology for Tamazight",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Alp Öktem",
      "Farida Boudichat"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27407v1",
    "abstract": "This paper presents Awal, a community-powered initiative for developing language technology resources for Tamazight. We provide a comprehensive review of the NLP landscape for Tamazight, examining recent progress in computational resources, and the emergence of community-driven approaches to address persistent data scarcity. Launched in 2024, awaldigital.org platform addresses the underrepresentation of Tamazight in digital spaces through a collaborative platform enabling speakers to contribute translation and voice data. We analyze 18 months of community engagement, revealing significant barriers to participation including limited confidence in written Tamazight and ongoing standardization challenges. Despite widespread positive reception, actual data contribution remained concentrated among linguists and activists. The modest scale of community contributions -- 6,421 translation pairs and 3 hours of speech data -- highlights the limitations of applying standard crowdsourcing approaches to languages with complex sociolinguistic contexts. We are working on improved open-source MT models using the collected data.",
    "fetched_at": "2025-11-05T02:19:05.053943Z"
  },
  {
    "id": "2510.27408v3",
    "title": "Estimation of aboveground biomass in a tropical dry forest: An   intercomparison of airborne, unmanned, and space laser scanning",
    "date": "2025-10-31",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Nelson Mattié",
      "Arturo Sanchez-Azofeifa",
      "Pablo Crespo-Peremarch",
      "Juan-Ygnacio López-Hernández"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27408v3",
    "abstract": "According to the Paris Climate Change Agreement, all nations are required to submit reports on their greenhouse gas emissions and absorption every two years by 2024. Consequently, forests play a crucial role in reducing carbon emissions, which is essential for meeting these obligations. Recognizing the significance of forest conservation in the global battle against climate change, Article 5 of the Paris Agreement emphasizes the need for high-quality forest data. This study focuses on enhancing methods for mapping aboveground biomass in tropical dry forests. Tropical dry forests are considered one of the least understood tropical forest environments; therefore, there is a need for accurate approaches to estimate carbon pools. We employ a comparative analysis of AGB estimates, utilizing different discrete and full-waveform laser scanning datasets in conjunction with Ordinary Least Squares and Bayesian approaches SVM. Airborne Laser Scanning, Unmanned Laser Scanning, and Space Laser Scanning were used as independent variables for extracting forest metrics. Variable selection, SVM regression tuning, and cross-validation via a machine-learning approach were applied to account for overfitting and underfitting. The results indicate that six key variables primarily related to tree height: Elev\\.minimum, Elev\\.L3, lev\\.MAD\\.mode, Elev\\.mode, Elev\\.MAD\\.median, and Elev\\.skewness, are important for AGB estimation using ALSD and ULSD, while Leaf Area Index, canopy coverage and height, terrain elevation, and full-waveform signal energy emerged as the most vital variables. AGB values estimated from ten permanent tropical dry forest plots in Costa Rica Guanacaste province ranged from 26.02 Mg/ha to 175.43 Mg/ha. The SVM regressions demonstrated a 17.89 error across all laser scanning systems, with SLSF W exhibiting the lowest error 17.07 in estimating total biomass per plot.",
    "fetched_at": "2025-11-05T02:19:05.053904Z"
  },
  {
    "id": "2510.27413v1",
    "title": "Atlas-Alignment: Making Interpretability Transferable Across Language   Models",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bruno Puri",
      "Jim Berend",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27413v1",
    "abstract": "Interpretability is crucial for building safe, reliable, and controllable language models, yet existing interpretability pipelines remain costly and difficult to scale. Interpreting a new model typically requires costly training of model-specific sparse autoencoders, manual or semi-automated labeling of SAE components, and their subsequent validation. We introduce Atlas-Alignment, a framework for transferring interpretability across language models by aligning unknown latent spaces to a Concept Atlas - a labeled, human-interpretable latent space - using only shared inputs and lightweight representational alignment techniques. Once aligned, this enables two key capabilities in previously opaque models: (1) semantic feature search and retrieval, and (2) steering generation along human-interpretable atlas concepts. Through quantitative and qualitative evaluations, we show that simple representational alignment methods enable robust semantic retrieval and steerable generation without the need for labeled concept data. Atlas-Alignment thus amortizes the cost of explainable AI and mechanistic interpretability: by investing in one high-quality Concept Atlas, we can make many new models transparent and controllable at minimal marginal cost.",
    "fetched_at": "2025-11-05T02:19:05.053781Z"
  },
  {
    "id": "2510.27419v1",
    "title": "DeepCompress: A Dual Reward Strategy for Dynamically Exploring and   Compressing Reasoning Chains",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tian Liang",
      "Wenxiang Jiao",
      "Zhiwei He",
      "Jiahao Xu",
      "Haitao Mi",
      "Dong Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27419v1",
    "abstract": "Large Reasoning Models (LRMs) have demonstrated impressive capabilities but suffer from cognitive inefficiencies like ``overthinking'' simple problems and ``underthinking'' complex ones. While existing methods that use supervised fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can improve efficiency, they often do so at the cost of accuracy. This paper introduces \\textbf{DeepCompress}, a novel framework that simultaneously enhances both the accuracy and efficiency of LRMs. We challenge the prevailing approach of consistently favoring shorter reasoning paths, showing that longer responses can contain a broader range of correct solutions for difficult problems. DeepCompress employs an adaptive length reward mechanism that dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on the model's evolving capability. It encourages shorter, more efficient reasoning for ``Simple'' problems while promoting longer, more exploratory thought chains for ``Hard'' problems. This dual-reward strategy enables the model to autonomously adjust its Chain-of-Thought (CoT) length, compressing reasoning for well-mastered problems and extending it for those it finds challenging. Experimental results on challenging mathematical benchmarks show that DeepCompress consistently outperforms baseline methods, achieving superior accuracy while significantly improving token efficiency.",
    "fetched_at": "2025-11-05T02:19:05.053692Z"
  },
  {
    "id": "2510.27421v1",
    "title": "Who Does Your Algorithm Fail? Investigating Age and Ethnic Bias in the   MAMA-MIA Dataset",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Aditya Parikh",
      "Sneha Das",
      "Aasa Feragen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27421v1",
    "abstract": "Deep learning models aim to improve diagnostic workflows, but fairness evaluation remains underexplored beyond classification, e.g., in image segmentation. Unaddressed segmentation bias can lead to disparities in the quality of care for certain populations, potentially compounded across clinical decision points and amplified through iterative model development. Here, we audit the fairness of the automated segmentation labels provided in the breast cancer tumor segmentation dataset MAMA-MIA. We evaluate automated segmentation quality across age, ethnicity, and data source. Our analysis reveals an intrinsic age-related bias against younger patients that continues to persist even after controlling for confounding factors, such as data source. We hypothesize that this bias may be linked to physiological factors, a known challenge for both radiologists and automated systems. Finally, we show how aggregating data from multiple data sources influences site-specific ethnic biases, underscoring the necessity of investigating data at a granular level.",
    "fetched_at": "2025-11-05T02:19:05.053634Z"
  },
  {
    "id": "2510.27428v1",
    "title": "Learning Soft Robotic Dynamics with Active Exploration",
    "date": "2025-10-31",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hehui Zheng",
      "Bhavya Sukhija",
      "Chenhao Li",
      "Klemens Iten",
      "Andreas Krause",
      "Robert K. Katzschmann"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27428v1",
    "abstract": "Soft robots offer unmatched adaptability and safety in unstructured environments, yet their compliant, high-dimensional, and nonlinear dynamics make modeling for control notoriously difficult. Existing data-driven approaches often fail to generalize, constrained by narrowly focused task demonstrations or inefficient random exploration. We introduce SoftAE, an uncertainty-aware active exploration framework that autonomously learns task-agnostic and generalizable dynamics models of soft robotic systems. SoftAE employs probabilistic ensemble models to estimate epistemic uncertainty and actively guides exploration toward underrepresented regions of the state-action space, achieving efficient coverage of diverse behaviors without task-specific supervision. We evaluate SoftAE on three simulated soft robotic platforms -- a continuum arm, an articulated fish in fluid, and a musculoskeletal leg with hybrid actuation -- and on a pneumatically actuated continuum soft arm in the real world. Compared with random exploration and task-specific model-based reinforcement learning, SoftAE produces more accurate dynamics models, enables superior zero-shot control on unseen tasks, and maintains robustness under sensing noise, actuation delays, and nonlinear material effects. These results demonstrate that uncertainty-driven active exploration can yield scalable, reusable dynamics models across diverse soft robotic morphologies, representing a step toward more autonomous, adaptable, and data-efficient control in compliant robots.",
    "fetched_at": "2025-11-05T02:19:05.053573Z"
  },
  {
    "id": "2510.27432v1",
    "title": "Mitigating Semantic Collapse in Partially Relevant Video Retrieval",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "WonJun Moon",
      "MinSeok Jung",
      "Gilhan Park",
      "Tae-Young Kim",
      "Cheol-Ho Cho",
      "Woojin Jun",
      "Jae-Pil Heo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27432v1",
    "abstract": "Partially Relevant Video Retrieval (PRVR) seeks videos where only part of the content matches a text query. Existing methods treat every annotated text-video pair as a positive and all others as negatives, ignoring the rich semantic variation both within a single video and across different videos. Consequently, embeddings of both queries and their corresponding video-clip segments for distinct events within the same video collapse together, while embeddings of semantically similar queries and segments from different videos are driven apart. This limits retrieval performance when videos contain multiple, diverse events. This paper addresses the aforementioned problems, termed as semantic collapse, in both the text and video embedding spaces. We first introduce Text Correlation Preservation Learning, which preserves the semantic relationships encoded by the foundation model across text queries. To address collapse in video embeddings, we propose Cross-Branch Video Alignment (CBVA), a contrastive alignment method that disentangles hierarchical video representations across temporal scales. Subsequently, we introduce order-preserving token merging and adaptive CBVA to enhance alignment by producing video segments that are internally coherent yet mutually distinctive. Extensive experiments on PRVR benchmarks demonstrate that our framework effectively prevents semantic collapse and substantially improves retrieval accuracy.",
    "fetched_at": "2025-11-05T02:19:05.053511Z"
  },
  {
    "id": "2510.27442v1",
    "title": "CoMViT: An Efficient Vision Backbone for Supervised Classification in   Medical Imaging",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "I.2.10",
      "10"
    ],
    "authors": [
      "Aon Safdar",
      "Mohamed Saadeldin"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27442v1",
    "abstract": "Vision Transformers (ViTs) have demonstrated strong potential in medical imaging; however, their high computational demands and tendency to overfit on small datasets limit their applicability in real-world clinical scenarios. In this paper, we present CoMViT, a compact and generalizable Vision Transformer architecture optimized for resource-constrained medical image analysis. CoMViT integrates a convolutional tokenizer, diagonal masking, dynamic temperature scaling, and pooling-based sequence aggregation to improve performance and generalization. Through systematic architectural optimization, CoMViT achieves robust performance across twelve MedMNIST datasets while maintaining a lightweight design with only ~4.5M parameters. It matches or outperforms deeper CNN and ViT variants, offering up to 5-20x parameter reduction without sacrificing accuracy. Qualitative Grad-CAM analyses show that CoMViT consistently attends to clinically relevant regions despite its compact size. These results highlight the potential of principled ViT redesign for developing efficient and interpretable models in low-resource medical imaging settings.",
    "fetched_at": "2025-11-05T02:19:05.053453Z"
  },
  {
    "id": "2510.27443v1",
    "title": "MVeLMA: Multimodal Vegetation Loss Modeling Architecture for Predicting   Post-fire Vegetation Loss",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Meenu Ravi",
      "Shailik Sarkar",
      "Yanshen Sun",
      "Vaishnavi Singh",
      "Chang-Tien Lu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27443v1",
    "abstract": "Understanding post-wildfire vegetation loss is critical for developing effective ecological recovery strategies and is often challenging due to the extended time and effort required to capture the evolving ecosystem features. Recent works in this area have not fully explored all the contributing factors, their modalities, and interactions with each other. Furthermore, most research in this domain is limited by a lack of interpretability in predictive modeling, making it less useful in real-world settings. In this work, we propose a novel end-to-end ML pipeline called MVeLMA (\\textbf{M}ultimodal \\textbf{Ve}getation \\textbf{L}oss \\textbf{M}odeling \\textbf{A}rchitecture) to predict county-wise vegetation loss from fire events. MVeLMA uses a multimodal feature integration pipeline and a stacked ensemble-based architecture to capture different modalities while also incorporating uncertainty estimation through probabilistic modeling. Through comprehensive experiments, we show that our model outperforms several state-of-the-art (SOTA) and baseline models in predicting post-wildfire vegetation loss. Furthermore, we generate vegetation loss confidence maps to identify high-risk counties, thereby helping targeted recovery efforts. The findings of this work have the potential to inform future disaster relief planning, ecological policy development, and wildlife recovery management.",
    "fetched_at": "2025-11-05T02:19:05.053412Z"
  },
  {
    "id": "2510.27448v1",
    "title": "GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data   Generation through Formal Language",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuhao Zhang",
      "Dingxin Hu",
      "Tinghao Yu",
      "Hao Liu",
      "Yiting Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27448v1",
    "abstract": "Multi-modal Large Language Models (MLLMs) have gained significant attention in both academia and industry for their capabilities in handling multi-modal tasks. However, these models face challenges in mathematical geometric reasoning due to the scarcity of high-quality geometric data. To address this issue, synthetic geometric data has become an essential strategy. Current methods for generating synthetic geometric data involve rephrasing or expanding existing problems and utilizing predefined rules and templates to create geometric images and problems. However, these approaches often produce data that lacks diversity or is prone to noise. Additionally, the geometric images synthesized by existing methods tend to exhibit limited variation and deviate significantly from authentic geometric diagrams. To overcome these limitations, we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses formal languages to explore combinations of conditions within metric space, generating high-fidelity geometric problems that differ from the originals while ensuring correctness through a symbolic engine. Experimental results show that our synthetic data significantly outperforms existing methods. The model trained with our data surpass the proprietary GPT-4o model by 18.7\\% on geometry problem-solving tasks in MathVista and by 16.5\\% on GeoQA. Additionally, it exceeds the performance of a leading open-source model by 5.7\\% on MathVista and by 2.7\\% on GeoQA.",
    "fetched_at": "2025-11-05T02:19:05.053356Z"
  },
  {
    "id": "2510.27462v1",
    "title": "VCORE: Variance-Controlled Optimization-based Reweighting for   Chain-of-Thought Supervision",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xuan Gong",
      "Senmiao Wang",
      "Hanbo Huang",
      "Ruoyu Sun",
      "Shiyu Liang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27462v1",
    "abstract": "Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has emerged as a crucial technique for enhancing the reasoning abilities of large language models (LLMs). However, the standard cross-entropy loss treats all tokens equally, ignoring their heterogeneous contributions across a reasoning trajectory. This uniform treatment leads to misallocated supervision and weak generalization, especially in complex, long-form reasoning tasks. To address this, we introduce \\textbf{V}ariance-\\textbf{C}ontrolled \\textbf{O}ptimization-based \\textbf{RE}weighting (VCORE), a principled framework that reformulates CoT supervision as a constrained optimization problem. By adopting an optimization-theoretic perspective, VCORE enables a principled and adaptive allocation of supervision across tokens, thereby aligning the training objective more closely with the goal of robust reasoning generalization. Empirical evaluations demonstrate that VCORE consistently outperforms existing token reweighting methods. Across both in-domain and out-of-domain settings, VCORE achieves substantial performance gains on mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B, 32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more effective initialization for subsequent reinforcement learning, establishing a stronger foundation for advancing the reasoning capabilities of LLMs. The Code will be released at https://github.com/coder-gx/VCORE.",
    "fetched_at": "2025-11-05T02:19:05.053302Z"
  },
  {
    "id": "2510.27469v1",
    "title": "Diffuse Thinking: Exploring Diffusion Language Models as Efficient   Thought Proposers for Reasoning",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Chenyang Shao",
      "Sijian Ren",
      "Fengli Xu",
      "Yong Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27469v1",
    "abstract": "In recent years, large language models (LLMs) have witnessed remarkable advancements, with the test-time scaling law consistently enhancing the reasoning capabilities. Through systematic evaluation and exploration of a diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to generate deliberate reasoning steps, thereby substantially enhancing reasoning accuracy. However, LLMs' autoregressive generation paradigm results in reasoning performance scaling sub-optimally with test-time computation, often requiring excessive computational overhead to propose thoughts while yielding only marginal performance gains. In contrast, diffusion language models (DLMs) can efficiently produce diverse samples through parallel denoising in a single forward pass, inspiring us to leverage them for proposing intermediate thoughts, thereby alleviating the computational burden associated with autoregressive generation while maintaining quality. In this work, we propose an efficient collaborative reasoning framework, leveraging DLMs to generate candidate thoughts and LLMs to evaluate their quality. Experiments across diverse benchmarks demonstrate that our framework achieves strong performance in complex reasoning tasks, offering a promising direction for future research. Our code is open-source at https://anonymous.4open.science/r/Diffuse-Thinking-EC60.",
    "fetched_at": "2025-11-05T02:19:05.053248Z"
  },
  {
    "id": "2510.27474v1",
    "title": "Spectral Neural Graph Sparsification",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Angelica Liguori",
      "Ettore Ritacco",
      "Pietro Sabatino",
      "Annalisa Socievole"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27474v1",
    "abstract": "Graphs are central to modeling complex systems in domains such as social networks, molecular chemistry, and neuroscience. While Graph Neural Networks, particularly Graph Convolutional Networks, have become standard tools for graph learning, they remain constrained by reliance on fixed structures and susceptibility to over-smoothing. We propose the Spectral Preservation Network, a new framework for graph representation learning that generates reduced graphs serving as faithful proxies of the original, enabling downstream tasks such as community detection, influence propagation, and information diffusion at a reduced computational cost. The Spectral Preservation Network introduces two key components: the Joint Graph Evolution layer and the Spectral Concordance loss. The former jointly transforms both the graph topology and the node feature matrix, allowing the structure and attributes to evolve adaptively across layers and overcoming the rigidity of static neighborhood aggregation. The latter regularizes these transformations by enforcing consistency in both the spectral properties of the graph and the feature vectors of the nodes. We evaluate the effectiveness of Spectral Preservation Network on node-level sparsification by analyzing well-established metrics and benchmarking against state-of-the-art methods. The experimental results demonstrate the superior performance and clear advantages of our approach.",
    "fetched_at": "2025-11-05T02:19:05.053200Z"
  },
  {
    "id": "2510.27477v1",
    "title": "The aftermath of compounds: Investigating Compounds and their Semantic   Representations",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Swarang Joshi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27477v1",
    "abstract": "This study investigates how well computational embeddings align with human semantic judgments in the processing of English compound words. We compare static word vectors (GloVe) and contextualized embeddings (BERT) against human ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn from a psycholinguistic dataset. Using measures of association strength (Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC), we compute embedding-derived LMD and ST metrics and assess their relationships with human judgments via Spearmans correlation and regression analyses. Our results show that BERT embeddings better capture compositional semantics than GloVe, and that predictability ratings are strong predictors of semantic transparency in both human and model data. These findings advance computational psycholinguistics by clarifying the factors that drive compound word processing and offering insights into embedding-based semantic modeling.",
    "fetched_at": "2025-11-05T02:19:05.053152Z"
  },
  {
    "id": "2510.27480v1",
    "title": "Simplex-to-Euclidean Bijections for Categorical Flow Matching",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Bernardo Williams",
      "Victor M. Yeom-Song",
      "Marcelo Hartmann",
      "Arto Klami"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27480v1",
    "abstract": "We propose a method for learning and sampling from probability distributions supported on the simplex. Our approach maps the open simplex to Euclidean space via smooth bijections, leveraging the Aitchison geometry to define the mappings, and supports modeling categorical data by a Dirichlet interpolation that dequantizes discrete observations into continuous ones. This enables density modeling in Euclidean space through the bijection while still allowing exact recovery of the original discrete distribution. Compared to previous methods that operate on the simplex using Riemannian geometry or custom noise processes, our approach works in Euclidean space while respecting the Aitchison geometry, and achieves competitive performance on both synthetic and real-world data sets.",
    "fetched_at": "2025-11-05T02:19:05.053117Z"
  },
  {
    "id": "2510.27486v1",
    "title": "FedAdamW: A Communication-Efficient Optimizer with Convergence and   Generalization Guarantees for Federated Large Models",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junkang Liu",
      "Fanhua Shang",
      "Kewen Zhu",
      "Hongying Liu",
      "Yuanyuan Liu",
      "Jin Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27486v1",
    "abstract": "AdamW has become one of the most effective optimizers for training large-scale models. We have also observed its effectiveness in the context of federated learning (FL). However, directly applying AdamW in federated learning settings poses significant challenges: (1) due to data heterogeneity, AdamW often yields high variance in the second-moment estimate $\\boldsymbol{v}$; (2) the local overfitting of AdamW may cause client drift; and (3) Reinitializing moment estimates ($\\boldsymbol{v}$, $\\boldsymbol{m}$) at each round slows down convergence. To address these challenges, we propose the first \\underline{Fed}erated \\underline{AdamW} algorithm, called \\texttt{FedAdamW}, for training and fine-tuning various large models. \\texttt{FedAdamW} aligns local updates with the global update using both a \\textbf{local correction mechanism} and decoupled weight decay to mitigate local overfitting. \\texttt{FedAdamW} efficiently aggregates the \\texttt{mean} of the second-moment estimates to reduce their variance and reinitialize them. Theoretically, we prove that \\texttt{FedAdamW} achieves a linear speedup convergence rate of $\\mathcal{O}(\\sqrt{(L \\Delta \\sigma_l^2)/(S K R \\epsilon^2)}+(L \\Delta)/R)$ without \\textbf{heterogeneity assumption}, where $S$ is the number of participating clients per round, $K$ is the number of local iterations, and $R$ is the total number of communication rounds. We also employ PAC-Bayesian generalization analysis to explain the effectiveness of decoupled weight decay in local training. Empirically, we validate the effectiveness of \\texttt{FedAdamW} on language and vision Transformer models. Compared to several baselines, \\texttt{FedAdamW} significantly reduces communication rounds and improves test accuracy. The code is available in https://github.com/junkangLiu0/FedAdamW.",
    "fetched_at": "2025-11-05T02:19:05.053019Z"
  },
  {
    "id": "2510.27497v1",
    "title": "InertialAR: Autoregressive 3D Molecule Generation with Inertial Frames",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Haorui Li",
      "Weitao Du",
      "Yuqiang Li",
      "Hongyu Guo",
      "Shengchao Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27497v1",
    "abstract": "Transformer-based autoregressive models have emerged as a unifying paradigm across modalities such as text and images, but their extension to 3D molecule generation remains underexplored. The gap stems from two fundamental challenges: (1) tokenizing molecules into a canonical 1D sequence of tokens that is invariant to both SE(3) transformations and atom index permutations, and (2) designing an architecture capable of modeling hybrid atom-based tokens that couple discrete atom types with continuous 3D coordinates. To address these challenges, we introduce InertialAR. InertialAR devises a canonical tokenization that aligns molecules to their inertial frames and reorders atoms to ensure SE(3) and permutation invariance. Moreover, InertialAR equips the attention mechanism with geometric awareness via geometric rotary positional encoding (GeoRoPE). In addition, it utilizes a hierarchical autoregressive paradigm to predict the next atom-based token, predicting the atom type first and then its 3D coordinates via Diffusion loss. Experimentally, InertialAR achieves state-of-the-art performance on 7 of the 10 evaluation metrics for unconditional molecule generation across QM9, GEOM-Drugs, and B3LYP. Moreover, it significantly outperforms strong baselines in controllable generation for targeted chemical functionality, attaining state-of-the-art results across all 5 metrics.",
    "fetched_at": "2025-11-05T02:19:05.052946Z"
  },
  {
    "id": "2510.27498v1",
    "title": "Minimax-Optimal Two-Sample Test with Sliced Wasserstein",
    "date": "2025-10-31",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Binh Thuan Tran",
      "Nicolas Schreuder"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27498v1",
    "abstract": "We study the problem of nonparametric two-sample testing using the sliced Wasserstein (SW) distance. While prior theoretical and empirical work indicates that the SW distance offers a promising balance between strong statistical guarantees and computational efficiency, its theoretical foundations for hypothesis testing remain limited. We address this gap by proposing a permutation-based SW test and analyzing its performance. The test inherits finite-sample Type I error control from the permutation principle. Moreover, we establish non-asymptotic power bounds and show that the procedure achieves the minimax separation rate $n^{-1/2}$ over multinomial and bounded-support alternatives, matching the optimal guarantees of kernel-based tests while building on the geometric foundations of Wasserstein distances. Our analysis further quantifies the trade-off between the number of projections and statistical power. Finally, numerical experiments demonstrate that the test combines finite-sample validity with competitive power and scalability, and -- unlike kernel-based tests, which require careful kernel tuning -- it performs consistently well across all scenarios we consider.",
    "fetched_at": "2025-11-05T02:19:05.052893Z"
  },
  {
    "id": "2510.27503v1",
    "title": "pDANSE: Particle-based Data-driven Nonlinear State Estimation from   Nonlinear Measurements",
    "date": "2025-10-31",
    "tags": [
      "eess.SP",
      "SP",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anubhab Ghosh",
      "Yonina C. Eldar",
      "Saikat Chatterjee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27503v1",
    "abstract": "We consider the problem of designing a data-driven nonlinear state estimation (DANSE) method that uses (noisy) nonlinear measurements of a process whose underlying state transition model (STM) is unknown. Such a process is referred to as a model-free process. A recurrent neural network (RNN) provides parameters of a Gaussian prior that characterize the state of the model-free process, using all previous measurements at a given time point. In the case of DANSE, the measurement system was linear, leading to a closed-form solution for the state posterior. However, the presence of a nonlinear measurement system renders a closed-form solution infeasible. Instead, the second-order statistics of the state posterior are computed using the nonlinear measurements observed at the time point. We address the nonlinear measurements using a reparameterization trick-based particle sampling approach, and estimate the second-order statistics of the state posterior. The proposed method is referred to as particle-based DANSE (pDANSE). The RNN of pDANSE uses sequential measurements efficiently and avoids the use of computationally intensive sequential Monte-Carlo (SMC) and/or ancestral sampling. We describe the semi-supervised learning method for pDANSE, which transitions to unsupervised learning in the absence of labeled data. Using a stochastic Lorenz-$63$ system as a benchmark process, we experimentally demonstrate the state estimation performance for four nonlinear measurement systems. We explore cubic nonlinearity and a camera-model nonlinearity where unsupervised learning is used; then we explore half-wave rectification nonlinearity and Cartesian-to-spherical nonlinearity where semi-supervised learning is used. The performance of state estimation is shown to be competitive vis-\\`a-vis particle filters that have complete knowledge of the STM of the Lorenz-$63$ system.",
    "fetched_at": "2025-11-05T02:19:05.052850Z"
  },
  {
    "id": "2510.27504v1",
    "title": "DP-FedPGN: Finding Global Flat Minima for Differentially Private   Federated Learning via Penalizing Gradient Norm",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Junkang Liu",
      "Yuxuan Tian",
      "Fanhua Shang",
      "Yuanyuan Liu",
      "Hongying Liu",
      "Junchao Zhou",
      "Daorui Ding"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27504v1",
    "abstract": "To prevent inference attacks in Federated Learning (FL) and reduce the leakage of sensitive information, Client-level Differentially Private Federated Learning (CL-DPFL) is widely used. However, current CL-DPFL methods usually result in sharper loss landscapes, which leads to a decrease in model generalization after differential privacy protection. By using Sharpness Aware Minimization (SAM), the current popular federated learning methods are to find a local flat minimum value to alleviate this problem. However, the local flatness may not reflect the global flatness in CL-DPFL. Therefore, to address this issue and seek global flat minima of models, we propose a new CL-DPFL algorithm, DP-FedPGN, in which we introduce a global gradient norm penalty to the local loss to find the global flat minimum. Moreover, by using our global gradient norm penalty, we not only find a flatter global minimum but also reduce the locally updated norm, which means that we further reduce the error of gradient clipping. From a theoretical perspective, we analyze how DP-FedPGN mitigates the performance degradation caused by DP. Meanwhile, the proposed DP-FedPGN algorithm eliminates the impact of data heterogeneity and achieves fast convergence. We also use R\\'enyi DP to provide strict privacy guarantees and provide sensitivity analysis for local updates. Finally, we conduct effectiveness tests on both ResNet and Transformer models, and achieve significant improvements in six visual and natural language processing tasks compared to existing state-of-the-art algorithms. The code is available at https://github.com/junkangLiu0/DP-FedPGN",
    "fetched_at": "2025-11-05T02:19:05.052796Z"
  },
  {
    "id": "2510.27506v1",
    "title": "Asynchronous Risk-Aware Multi-Agent Packet Routing for Ultra-Dense LEO   Satellite Networks",
    "date": "2025-10-31",
    "tags": [
      "cs.NI",
      "NI",
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "math.IT"
    ],
    "authors": [
      "Ke He",
      "Thang X. Vu",
      "Le He",
      "Lisheng Fan",
      "Symeon Chatzinotas",
      "Bjorn Ottersten"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27506v1",
    "abstract": "The rise of ultra-dense LEO constellations creates a complex and asynchronous network environment, driven by their massive scale, dynamic topologies, and significant delays. This unique complexity demands an adaptive packet routing algorithm that is asynchronous, risk-aware, and capable of balancing diverse and often conflicting QoS objectives in a decentralized manner. However, existing methods fail to address this need, as they typically rely on impractical synchronous decision-making and/or risk-oblivious approaches. To tackle this gap, we introduce PRIMAL, an event-driven multi-agent routing framework designed specifically to allow each satellite to act independently on its own event-driven timeline, while managing the risk of worst-case performance degradation via a principled primal-dual approach. This is achieved by enabling agents to learn the full cost distribution of the targeted QoS objectives and constrain tail-end risks. Extensive simulations on a LEO constellation with 1584 satellites validate its superiority in effectively optimizing latency and balancing load. Compared to a recent risk-oblivious baseline, it reduces queuing delay by over 70%, and achieves a nearly 12 ms end-to-end delay reduction in loaded scenarios. This is accomplished by resolving the core conflict between naive shortest-path finding and congestion avoidance, highlighting such autonomous risk-awareness as a key to robust routing.",
    "fetched_at": "2025-11-05T02:19:05.052733Z"
  },
  {
    "id": "2510.27508v1",
    "title": "Context-Gated Cross-Modal Perception with Visual Mamba for PET-CT Lung   Tumor Segmentation",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Elena Mulero Ayllón",
      "Linlin Shen",
      "Pierangelo Veltri",
      "Fabrizia Gelardi",
      "Arturo Chiti",
      "Paolo Soda",
      "Matteo Tortora"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27508v1",
    "abstract": "Accurate lung tumor segmentation is vital for improving diagnosis and treatment planning, and effectively combining anatomical and functional information from PET and CT remains a major challenge. In this study, we propose vMambaX, a lightweight multimodal framework integrating PET and CT scan images through a Context-Gated Cross-Modal Perception Module (CGM). Built on the Visual Mamba architecture, vMambaX adaptively enhances inter-modality feature interaction, emphasizing informative regions while suppressing noise. Evaluated on the PCLT20K dataset, the model outperforms baseline models while maintaining lower computational complexity. These results highlight the effectiveness of adaptive cross-modal gating for multimodal tumor segmentation and demonstrate the potential of vMambaX as an efficient and scalable framework for advanced lung cancer analysis. The code is available at https://github.com/arco-group/vMambaX.",
    "fetched_at": "2025-11-05T02:19:05.052674Z"
  },
  {
    "id": "2510.27512v1",
    "title": "Effect of Domain Generalization Techniques in Low Resource Systems",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mahi Aminu",
      "Chisom Chibuike",
      "Fatimo Adebanjo",
      "Omokolade Awosanya",
      "Samuel Oyeneye"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27512v1",
    "abstract": "Machine learning models typically assume that training and test data follow the same distribution, an assumption that often fails in real-world scenarios due to distribution shifts. This issue is especially pronounced in low-resource settings, where data scarcity and limited domain diversity hinder robust generalization. Domain generalization (DG) approaches address this challenge by learning features that remain invariant across domains, often using causal mechanisms to improve model robustness. In this study, we examine two distinct causal DG techniques in low-resource natural language tasks. First, we investigate a causal data augmentation (CDA) approach that automatically generates counterfactual examples to improve robustness to spurious correlations. We apply this method to sentiment classification on the NaijaSenti Twitter corpus, expanding the training data with semantically equivalent paraphrases to simulate controlled distribution shifts. Second, we explore an invariant causal representation learning (ICRL) approach using the DINER framework, originally proposed for debiasing aspect-based sentiment analysis. We adapt DINER to a multilingual setting. Our findings demonstrate that both approaches enhance robustness to unseen domains: counterfactual data augmentation yields consistent cross-domain accuracy gains in sentiment classification, while causal representation learning with DINER improves out-of-distribution performance in multilingual sentiment analysis, albeit with varying gains across languages.",
    "fetched_at": "2025-11-05T02:19:05.052619Z"
  },
  {
    "id": "2510.27516v1",
    "title": "BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for   Scalable and Efficient Text Summarization",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Desta Haileselassie Hagos",
      "Legand L. Burge",
      "Anietie Andy",
      "Anis Yazidi",
      "Vladimir Vlassov"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27516v1",
    "abstract": "Transformer-based architectures have advanced text summarization, yet their quadratic complexity limits scalability on long documents. This paper introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a novel framework that combines sparse attention, adaptive spans, and bilinear attention to address these limitations. Sparse attention reduces computational costs by focusing on the most relevant parts of the input, while adaptive spans dynamically adjust the attention ranges. Bilinear attention complements both by modeling complex token interactions within this refined context. BiSparse-AAS consistently outperforms state-of-the-art baselines in both extractive and abstractive summarization tasks, achieving average ROUGE improvements of about 68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance on OpenWebText and Gigaword datasets. By addressing efficiency, scalability, and long-sequence modeling, BiSparse-AAS provides a unified, practical solution for real-world text summarization applications.",
    "fetched_at": "2025-11-05T02:19:05.052566Z"
  },
  {
    "id": "2510.27517v1",
    "title": "Learning Sparse Approximate Inverse Preconditioners for Conjugate   Gradient Solvers on GPUs",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA"
    ],
    "authors": [
      "Zherui Yang",
      "Zhehao Li",
      "Kangbo Lyu",
      "Yixuan Li",
      "Tao Du",
      "Ligang Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27517v1",
    "abstract": "The conjugate gradient solver (CG) is a prevalent method for solving symmetric and positive definite linear systems Ax=b, where effective preconditioners are crucial for fast convergence. Traditional preconditioners rely on prescribed algorithms to offer rigorous theoretical guarantees, while limiting their ability to exploit optimization from data. Existing learning-based methods often utilize Graph Neural Networks (GNNs) to improve the performance and speed up the construction. However, their reliance on incomplete factorization leads to significant challenges: the associated triangular solve hinders GPU parallelization in practice, and introduces long-range dependencies which are difficult for GNNs to model. To address these issues, we propose a learning-based method to generate GPU-friendly preconditioners, particularly using GNNs to construct Sparse Approximate Inverse (SPAI) preconditioners, which avoids triangular solves and requires only two matrix-vector products at each CG step. The locality of matrix-vector product is compatible with the local propagation mechanism of GNNs. The flexibility of GNNs also allows our approach to be applied in a wide range of scenarios. Furthermore, we introduce a statistics-based scale-invariant loss function. Its design matches CG's property that the convergence rate depends on the condition number, rather than the absolute scale of A, leading to improved performance of the learned preconditioner. Evaluations on three PDE-derived datasets and one synthetic dataset demonstrate that our method outperforms standard preconditioners (Diagonal, IC, and traditional SPAI) and previous learning-based preconditioners on GPUs. We reduce solution time on GPUs by 40%-53% (68%-113% faster), along with better condition numbers and superior generalization performance. Source code available at https://github.com/Adversarr/LearningSparsePreconditioner4GPU",
    "fetched_at": "2025-11-05T02:19:05.052512Z"
  },
  {
    "id": "2510.27522v1",
    "title": "Leveraging Generic Time Series Foundation Models for EEG Classification",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Théo Gnassounou",
      "Yessin Moakher",
      "Shifeng Xie",
      "Vasilii Feofanov",
      "Ievgen Redko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27522v1",
    "abstract": "Foundation models for time series are emerging as powerful general-purpose backbones, yet their potential for domain-specific biomedical signals such as electroencephalography (EEG) remains rather unexplored. In this work, we investigate the applicability a recently proposed time series classification foundation model, to a different EEG tasks such as motor imagery classification and sleep stage prediction. We test two pretraining regimes: (a) pretraining on heterogeneous real-world time series from multiple domains, and (b) pretraining on purely synthetic data. We find that both variants yield strong performance, consistently outperforming EEGNet, a widely used convolutional baseline, and CBraMod, the most recent EEG-specific foundation model. These results suggest that generalist time series foundation models, even when pretrained on data of non-neural origin or on synthetic signals, can transfer effectively to EEG. Our findings highlight the promise of leveraging cross-domain pretrained models for brain signal analysis, suggesting that EEG may benefit from advances in the broader time series literature.",
    "fetched_at": "2025-11-05T02:19:05.052451Z"
  },
  {
    "id": "2510.27525v1",
    "title": "Active transfer learning for structural health monitoring",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "J. Poole",
      "N. Dervilis",
      "K. Worden",
      "P. Gardner",
      "V. Giglioni",
      "R. S. Mills",
      "A. J. Hughes"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27525v1",
    "abstract": "Data for training structural health monitoring (SHM) systems are often expensive and/or impractical to obtain, particularly for labelled data. Population-based SHM (PBSHM) aims to address this limitation by leveraging data from multiple structures. However, data from different structures will follow distinct distributions, potentially leading to large generalisation errors for models learnt via conventional machine learning methods. To address this issue, transfer learning -- in the form of domain adaptation (DA) -- can be used to align the data distributions. Most previous approaches have only considered \\emph{unsupervised} DA, where no labelled target data are available; they do not consider how to incorporate these technologies in an online framework -- updating as labels are obtained throughout the monitoring campaign. This paper proposes a Bayesian framework for DA in PBSHM, that can improve unsupervised DA mappings using a limited quantity of labelled target data. In addition, this model is integrated into an active sampling strategy to guide inspections to select the most informative observations to label -- leading to further reductions in the required labelled data to learn a target classifier. The effectiveness of this methodology is evaluated on a population of experimental bridges. Specifically, this population includes data corresponding to several damage states, as well as, a comprehensive set of environmental conditions. It is found that combining transfer learning and active learning can improve data efficiency when learning classification models in label-scarce scenarios. This result has implications for data-informed operation and maintenance of structures, suggesting a reduction in inspections over the operational lifetime of a structure -- and therefore a reduction in operational costs -- can be achieved.",
    "fetched_at": "2025-11-05T02:19:05.052401Z"
  },
  {
    "id": "2510.27527v1",
    "title": "TetraJet-v2: Accurate NVFP4 Training for Large Language Models with   Oscillation Suppression and Outlier Control",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuxiang Chen",
      "Xiaoming Xu",
      "Pengle Zhang",
      "Michael Beyer",
      "Martin Rapp",
      "Jun Zhu",
      "Jianfei Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27527v1",
    "abstract": "Large Language Models (LLMs) training is prohibitively expensive, driving interest in low-precision fully-quantized training (FQT). While novel 4-bit formats like NVFP4 offer substantial efficiency gains, achieving near-lossless training at such low precision remains challenging. We introduce TetraJet-v2, an end-to-end 4-bit FQT method that leverages NVFP4 for activations, weights, and gradients in all linear layers. We identify two critical issues hindering low-precision LLM training: weight oscillation and outliers. To address these, we propose: 1) an unbiased double-block quantization method for NVFP4 linear layers, 2) OsciReset, an algorithm to suppress weight oscillation, and 3) OutControl, an algorithm to retain outlier accuracy. TetraJet-v2 consistently outperforms prior FP4 training methods on pre-training LLMs across varying model sizes up to 370M and data sizes up to 200B tokens, reducing the performance gap to full-precision training by an average of 51.3%.",
    "fetched_at": "2025-11-05T02:19:05.052338Z"
  },
  {
    "id": "2510.27530v1",
    "title": "Representing Classical Compositions through Implication-Realization   Temporal-Gestalt Graphs",
    "date": "2025-10-31",
    "tags": [
      "cs.SD",
      "SD",
      "cs.LG",
      "LG",
      "cs.SI",
      "SI",
      "H.5.5; G.2.2; I.5.4",
      "4"
    ],
    "authors": [
      "A. V. Bomediano",
      "R. J. Conanan",
      "L. D. Santuyo",
      "A. Coronel"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27530v1",
    "abstract": "Understanding the structural and cognitive underpinnings of musical compositions remains a key challenge in music theory and computational musicology. While traditional methods focus on harmony and rhythm, cognitive models such as the Implication-Realization (I-R) model and Temporal Gestalt theory offer insight into how listeners perceive and anticipate musical structure. This study presents a graph-based computational approach that operationalizes these models by segmenting melodies into perceptual units and annotating them with I-R patterns. These segments are compared using Dynamic Time Warping and organized into k-nearest neighbors graphs to model intra- and inter-segment relationships.   Each segment is represented as a node in the graph, and nodes are further labeled with melodic expectancy values derived from Schellenberg's two-factor I-R model-quantifying pitch proximity and pitch reversal at the segment level. This labeling enables the graphs to encode both structural and cognitive information, reflecting how listeners experience musical tension and resolution.   To evaluate the expressiveness of these graphs, we apply the Weisfeiler-Lehman graph kernel to measure similarity between and within compositions. Results reveal statistically significant distinctions between intra- and inter-graph structures. Segment-level analysis via multidimensional scaling confirms that structural similarity at the graph level reflects perceptual similarity at the segment level. Graph2vec embeddings and clustering demonstrate that these representations capture stylistic and structural features that extend beyond composer identity.   These findings highlight the potential of graph-based methods as a structured, cognitively informed framework for computational music analysis, enabling a more nuanced understanding of musical structure and style through the lens of listener perception.",
    "fetched_at": "2025-11-05T02:19:05.052279Z"
  },
  {
    "id": "2510.27532v1",
    "title": "SQLSpace: A Representation Space for Text-to-SQL to Discover and   Mitigate Robustness Gaps",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Neha Srikanth",
      "Victor Bursztyn",
      "Puneet Mathur",
      "Ani Nenkova"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27532v1",
    "abstract": "We introduce SQLSpace, a human-interpretable, generalizable, compact representation for text-to-SQL examples derived with minimal human intervention. We demonstrate the utility of these representations in evaluation with three use cases: (i) closely comparing and contrasting the composition of popular text-to-SQL benchmarks to identify unique dimensions of examples they evaluate, (ii) understanding model performance at a granular level beyond overall accuracy scores, and (iii) improving model performance through targeted query rewriting based on learned correctness estimation. We show that SQLSpace enables analysis that would be difficult with raw examples alone: it reveals compositional differences between benchmarks, exposes performance patterns obscured by accuracy alone, and supports modeling of query success.",
    "fetched_at": "2025-11-05T02:19:05.052222Z"
  },
  {
    "id": "2510.27535v1",
    "title": "Patient-Centered Summarization Framework for AI Clinical Summarization:   A Mixed-Methods Design",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Maria Lizarazo Jimenez",
      "Ana Gabriela Claros",
      "Kieran Green",
      "David Toro-Tobon",
      "Felipe Larios",
      "Sheena Asthana",
      "Camila Wenczenovicz",
      "Kerly Guevara Maldonado",
      "Luis Vilatuna-Andrango",
      "Cristina Proano-Velez",
      "Satya Sai Sri Bandi",
      "Shubhangi Bagewadi",
      "Megan E. Branda",
      "Misk Al Zahidy",
      "Saturnino Luz",
      "Mirella Lapata",
      "Juan P. Brito",
      "Oscar J. Ponce-Ponte"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27535v1",
    "abstract": "Large Language Models (LLMs) are increasingly demonstrating the potential to reach human-level performance in generating clinical summaries from patient-clinician conversations. However, these summaries often focus on patients' biology rather than their preferences, values, wishes, and concerns. To achieve patient-centered care, we propose a new standard for Artificial Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries (PCS). Our objective was to develop a framework to generate PCS that capture patient values and ensure clinical utility and to assess whether current open-source LLMs can achieve human-level performance in this task. We used a mixed-methods process. Two Patient and Public Involvement groups (10 patients and 8 clinicians) in the United Kingdom participated in semi-structured interviews exploring what personal and contextual information should be included in clinical summaries and how it should be structured for clinical use. Findings informed annotation guidelines used by eight clinicians to create gold-standard PCS from 88 atrial fibrillation consultations. Sixteen consultations were used to refine a prompt aligned with the guidelines. Five open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients emphasized lifestyle routines, social support, recent stressors, and care values. Clinicians sought concise functional, psychosocial, and emotional context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L 0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B (ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between experts and models, while correctness and patient-centeredness favored human PCS.",
    "fetched_at": "2025-11-05T02:19:05.052178Z"
  },
  {
    "id": "2510.27537v1",
    "title": "AstuteRAG-FQA: Task-Aware Retrieval-Augmented Generation Framework for   Proprietary Data Challenges in Financial Question Answering",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohammad Zahangir Alam",
      "Khandoker Ashik Uz Zaman",
      "Mahdi H. Miraz"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27537v1",
    "abstract": "Retrieval-Augmented Generation (RAG) shows significant promise in knowledge-intensive tasks by improving domain specificity, enhancing temporal relevance, and reducing hallucinations. However, applying RAG to finance encounters critical challenges: restricted access to proprietary datasets, limited retrieval accuracy, regulatory constraints, and sensitive data interpretation. We introduce AstuteRAG-FQA, an adaptive RAG framework tailored for Financial Question Answering (FQA), leveraging task-aware prompt engineering to address these challenges. The framework uses a hybrid retrieval strategy integrating both open-source and proprietary financial data while maintaining strict security protocols and regulatory compliance. A dynamic prompt framework adapts in real time to query complexity, improving precision and contextual relevance. To systematically address diverse financial queries, we propose a four-tier task classification: explicit factual, implicit factual, interpretable rationale, and hidden rationale involving implicit causal reasoning. For each category, we identify key challenges, datasets, and optimization techniques within the retrieval and generation process. The framework incorporates multi-layered security mechanisms including differential privacy, data anonymization, and role-based access controls to protect sensitive financial information. Additionally, AstuteRAG-FQA implements real-time compliance monitoring through automated regulatory validation systems that verify responses against industry standards and legal obligations. We evaluate three data integration techniques - contextual embedding, small model augmentation, and targeted fine-tuning - analyzing their efficiency and feasibility across varied financial environments.",
    "fetched_at": "2025-11-05T02:19:05.052075Z"
  },
  {
    "id": "2510.27543v1",
    "title": "DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and   Multilingual Language Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Malik H. Altakrori",
      "Nizar Habash",
      "Abdelhakim Freihat",
      "Younes Samih",
      "Kirill Chirkunov",
      "Muhammed AbuOdeh",
      "Radu Florian",
      "Teresa Lynn",
      "Preslav Nakov",
      "Alham Fikri Aji"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27543v1",
    "abstract": "We present DialectalArabicMMLU, a new benchmark for evaluating the performance of large language models (LLMs) across Arabic dialects. While recently developed Arabic and multilingual benchmarks have advanced LLM evaluation for Modern Standard Arabic (MSA), dialectal varieties remain underrepresented despite their prevalence in everyday communication. DialectalArabicMMLU extends the MMLU-Redux framework through manual translation and adaptation of 3K multiple-choice question-answer pairs into five major dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of 15K QA pairs across 32 academic and professional domains (22K QA pairs when also including English and MSA). The benchmark enables systematic assessment of LLM reasoning and comprehension beyond MSA, supporting both task-based and linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs (1B-13B parameters) and report substantial performance variation across dialects, revealing persistent gaps in dialectal generalization. DialectalArabicMMLU provides the first unified, human-curated resource for measuring dialectal understanding in Arabic, thus promoting more inclusive evaluation and future model development.",
    "fetched_at": "2025-11-05T02:19:05.052024Z"
  },
  {
    "id": "2510.27545v1",
    "title": "EBT-Policy: Energy Unlocks Emergent Physical Reasoning Capabilities",
    "date": "2025-10-31",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Travis Davies",
      "Yiqi Huang",
      "Alexi Gladstone",
      "Yunxin Liu",
      "Xiang Chen",
      "Heng Ji",
      "Huxian Liu",
      "Luhui Hu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27545v1",
    "abstract": "Implicit policies parameterized by generative models, such as Diffusion Policy, have become the standard for policy learning and Vision-Language-Action (VLA) models in robotics. However, these approaches often suffer from high computational cost, exposure bias, and unstable inference dynamics, which lead to divergence under distribution shifts. Energy-Based Models (EBMs) address these issues by learning energy landscapes end-to-end and modeling equilibrium dynamics, offering improved robustness and reduced exposure bias. Yet, policies parameterized by EBMs have historically struggled to scale effectively. Recent work on Energy-Based Transformers (EBTs) demonstrates the scalability of EBMs to high-dimensional spaces, but their potential for solving core challenges in physically embodied models remains underexplored. We introduce a new energy-based architecture, EBT-Policy, that solves core issues in robotic and real-world settings. Across simulated and real-world tasks, EBT-Policy consistently outperforms diffusion-based policies, while requiring less training and inference computation. Remarkably, on some tasks it converges within just two inference steps, a 50x reduction compared to Diffusion Policy's 100. Moreover, EBT-Policy exhibits emergent capabilities not seen in prior models, such as zero-shot recovery from failed action sequences using only behavior cloning and without explicit retry training. By leveraging its scalar energy for uncertainty-aware inference and dynamic compute allocation, EBT-Policy offers a promising path toward robust, generalizable robot behavior under distribution shifts.",
    "fetched_at": "2025-11-05T02:19:05.051887Z"
  },
  {
    "id": "2510.27552v1",
    "title": "Multilingual BERT language model for medical tasks: Evaluation on   domain-specific adaptation and cross-linguality",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yinghao Luo",
      "Lang Zhou",
      "Amrish Jhingoer",
      "Klaske Vliegenthart Jongbloed",
      "Carlijn Jordans",
      "Ben Werkhoven",
      "Tom Seinen",
      "Erik van Mulligen",
      "Casper Rokx",
      "Yunlei Li"
    ],
    "institution": "Department of Data and Analytics, Erasmus University Medical Center Rotterdam, Department of Internal Medicine, Erasmus University Medical Center Rotterdam, Department of Medical Informatics, Erasmus University Medical Center Rotterdam, Department of Medical Microbiology and Infectious Diseases, Erasmus University Medical Center Rotterdam, Department of Pathology & Clinical Bioinformatics, Erasmus University Medical Center Rotterdam",
    "link": "http://arxiv.org/pdf/2510.27552v1",
    "abstract": "In multilingual healthcare applications, the availability of domain-specific natural language processing(NLP) tools is limited, especially for low-resource languages. Although multilingual bidirectional encoder representations from transformers (BERT) offers a promising motivation to mitigate the language gap, the medical NLP tasks in low-resource languages are still underexplored. Therefore, this study investigates how further pre-training on domain-specific corpora affects model performance on medical tasks, focusing on three languages: Dutch, Romanian and Spanish. In terms of further pre-training, we conducted four experiments to create medical domain models. Then, these models were fine-tuned on three downstream tasks: Automated patient screening in Dutch clinical notes, named entity recognition in Romanian and Spanish clinical notes. Results show that domain adaptation significantly enhanced task performance. Furthermore, further differentiation of domains, e.g. clinical and general biomedical domains, resulted in diverse performances. The clinical domain-adapted model outperformed the more general biomedical domain-adapted model. Moreover, we observed evidence of cross-lingual transferability. Moreover, we also conducted further investigations to explore potential reasons contributing to these performance differences. These findings highlight the feasibility of domain adaptation and cross-lingual ability in medical NLP. Within the low-resource language settings, these findings can provide meaningful guidance for developing multilingual medical NLP systems to mitigate the lack of training data and thereby improve the model performance.",
    "fetched_at": "2025-11-05T02:19:05.051821Z"
  },
  {
    "id": "2510.27554v1",
    "title": "Sybil-Resistant Service Discovery for Agent Economies",
    "date": "2025-10-31",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.SI",
      "SI",
      "68T42, 68R10, 68M14, 68P20, 91D30",
      "H.3.3; H.2.8; I.2.11; K.4.4; G.2.2; C.2.4",
      "4"
    ],
    "authors": [
      "David Shi",
      "Kevin Joo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27554v1",
    "abstract": "x402 enables Hypertext Transfer Protocol (HTTP) services like application programming interfaces (APIs), data feeds, and inference providers to accept cryptocurrency payments for access. As agents increasingly consume these services, discovery becomes critical: which swap interface should an agent trust? Which data provider is the most reliable? We introduce TraceRank, a reputation-weighted ranking algorithm where payment transactions serve as endorsements. TraceRank seeds addresses with precomputed reputation metrics and propagates reputation through payment flows weighted by transaction value and temporal recency. Applied to x402's payment graph, this surfaces services preferred by high-reputation users rather than those with high transaction volume. Our system combines TraceRank with semantic search to respond to natural language queries with high quality results. We argue that reputation propagation resists Sybil attacks by making spam services with many low-reputation payers rank below legitimate services with few high-reputation payers. Ultimately, we aim to construct a search method for x402 enabled services that avoids infrastructure bias and has better performance than purely volume based or semantic methods.",
    "fetched_at": "2025-11-05T02:19:05.051757Z"
  },
  {
    "id": "2510.27556v1",
    "title": "Data-Efficient Domain Adaptation for LLM-based MT using Contrastive   Preference Optimization",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Inacio Vieira",
      "Antonio Castaldo",
      "James O'Doherty",
      "Sheila Castilho"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27556v1",
    "abstract": "LLMs often require adaptation to domain-specific requirements, a process that can be expensive when relying solely on SFT. We present an empirical study on applying CPO to simulate a post-editing workflow for data-efficient domain adaptation. Our approach synthesizes preference pairs by treating the base model's own raw output as the 'rejected' translation and the human-approved TM entry as the 'chosen' one. This method provides direct feedback on the model's current knowledge, guiding it to align with domain-specific standards. Experiments in English-Brazilian Portuguese and English-Korean show that, by using just 14.7k preference pairs, the model achieves performance close to that of a model trained on 160k+ samples with SFT, demonstrating significant data efficiency. Although we showcase its effectiveness in MT, this application of CPO naturally generalizes to other generative tasks where a model's initial drafts can serve as a contrastive signal against a golden reference.",
    "fetched_at": "2025-11-05T02:19:05.051713Z"
  },
  {
    "id": "2510.27558v1",
    "title": "Toward Accurate Long-Horizon Robotic Manipulation: Language-to-Action   with Foundation Models via Scene Graphs",
    "date": "2025-10-31",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sushil Samuel Dinesh",
      "Shinkyu Park"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27558v1",
    "abstract": "This paper presents a framework that leverages pre-trained foundation models for robotic manipulation without domain-specific training. The framework integrates off-the-shelf models, combining multimodal perception from foundation models with a general-purpose reasoning model capable of robust task sequencing. Scene graphs, dynamically maintained within the framework, provide spatial awareness and enable consistent reasoning about the environment. The framework is evaluated through a series of tabletop robotic manipulation experiments, and the results highlight its potential for building robotic manipulation systems directly on top of off-the-shelf foundation models.",
    "fetched_at": "2025-11-05T02:19:05.051667Z"
  },
  {
    "id": "2510.27562v1",
    "title": "Optimal Convergence Analysis of DDPM for General Distributions",
    "date": "2025-10-31",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Yuchen Jiao",
      "Yuchen Zhou",
      "Gen Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27562v1",
    "abstract": "Score-based diffusion models have achieved remarkable empirical success in generating high-quality samples from target data distributions. Among them, the Denoising Diffusion Probabilistic Model (DDPM) is one of the most widely used samplers, generating samples via estimated score functions. Despite its empirical success, a tight theoretical understanding of DDPM -- especially its convergence properties -- remains limited.   In this paper, we provide a refined convergence analysis of the DDPM sampler and establish near-optimal convergence rates under general distributional assumptions. Specifically, we introduce a relaxed smoothness condition parameterized by a constant $L$, which is small for many practical distributions (e.g., Gaussian mixture models). We prove that the DDPM sampler with accurate score estimates achieves a convergence rate of $$\\widetilde{O}\\left(\\frac{d\\min\\{d,L^2\\}}{T^2}\\right)~\\text{in Kullback-Leibler divergence},$$ where $d$ is the data dimension, $T$ is the number of iterations, and $\\widetilde{O}$ hides polylogarithmic factors in $T$. This result substantially improves upon the best-known $d^2/T^2$ rate when $L < \\sqrt{d}$. By establishing a matching lower bound, we show that our convergence analysis is tight for a wide array of target distributions. Moreover, it reveals that DDPM and DDIM share the same dependence on $d$, raising an interesting question of why DDIM often appears empirically faster.",
    "fetched_at": "2025-11-05T02:19:05.051630Z"
  },
  {
    "id": "2510.27565v1",
    "title": "CodeAlignBench: Assessing Code Generation Models on Developer-Preferred   Code Adjustments",
    "date": "2025-10-31",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Forough Mehralian",
      "Ryan Shar",
      "James R. Rae",
      "Alireza Hashemi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27565v1",
    "abstract": "As large language models become increasingly capable of generating code, evaluating their performance remains a complex and evolving challenge. Existing benchmarks primarily focus on functional correctness, overlooking the diversity of real-world coding tasks and developer expectations. To this end, we introduce a multi-language benchmark that evaluates LLM instruction-following capabilities and is extensible to operate on any set of standalone coding problems. Our benchmark evaluates instruction following in two key settings: adherence to pre-defined constraints specified with the initial problem, and the ability to perform refinements based on follow-up instructions. For this paper's analysis, we empirically evaluated our benchmarking pipeline with programming tasks from LiveBench, that are also automatically translated from Python into Java and JavaScript. Our automated benchmark reveals that models exhibit differing levels of performance across multiple dimensions of instruction-following. Our benchmarking pipeline provides a more comprehensive evaluation of code generation models, highlighting their strengths and limitations across languages and generation goals.",
    "fetched_at": "2025-11-05T02:19:05.051584Z"
  },
  {
    "id": "2510.27568v1",
    "title": "SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic   Mathematical Reasoning",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ali Asgarov",
      "Umid Suleymanov",
      "Aadyant Khatri"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27568v1",
    "abstract": "Solving mathematical reasoning problems requires not only accurate access to relevant knowledge but also careful, multi-step thinking. However, current retrieval-augmented models often rely on a single perspective, follow inflexible search strategies, and struggle to effectively combine information from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge Integration for AGentic Mathematical reAsoning), a unified framework that orchestrates specialized agents to independently reason, perform targeted searches, and synthesize findings through a moderator mechanism. Each agent generates hypothetical passages to optimize retrieval for its analytic perspective, ensuring knowledge integration is both context-sensitive and computation-efficient. When evaluated on challenging benchmarks such as MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms both open- and closed-source systems, achieving an absolute performance improvement of 7.4%. Our results demonstrate that multi-agent, on-demand knowledge integration significantly enhances both reasoning accuracy and efficiency, offering a scalable approach for complex, knowledge-intensive problem-solving. We will release the code upon publication.",
    "fetched_at": "2025-11-05T02:19:05.051536Z"
  },
  {
    "id": "2510.27571v1",
    "title": "Towards Universal Video Retrieval: Generalizing Video Embedding via   Synthesized Multimodal Pyramid Curriculum",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zhuoning Guo",
      "Mingxin Li",
      "Yanzhao Zhang",
      "Dingkun Long",
      "Pengjun Xie",
      "Xiaowen Chu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27571v1",
    "abstract": "The prevailing video retrieval paradigm is structurally misaligned, as narrow benchmarks incentivize correspondingly limited data and single-task training. Therefore, universal capability is suppressed due to the absence of a diagnostic evaluation that defines and demands multi-dimensional generalization. To break this cycle, we introduce a framework built on the co-design of evaluation, data, and modeling. First, we establish the Universal Video Retrieval Benchmark (UVRB), a suite of 16 datasets designed not only to measure performance but also to diagnose critical capability gaps across tasks and domains. Second, guided by UVRB's diagnostics, we introduce a scalable synthesis workflow that generates 1.55 million high-quality pairs to populate the semantic space required for universality. Finally, we devise the Modality Pyramid, a curriculum that trains our General Video Embedder (GVE) by explicitly leveraging the latent interconnections within our diverse data. Extensive experiments show GVE achieves state-of-the-art zero-shot generalization on UVRB. In particular, our analysis reveals that popular benchmarks are poor predictors of general ability and that partially relevant retrieval is a dominant but overlooked scenario. Overall, our co-designed framework provides a practical path to escape the limited scope and advance toward truly universal video retrieval.",
    "fetched_at": "2025-11-05T02:19:05.051427Z"
  },
  {
    "id": "2510.27584v2",
    "title": "Image Hashing via Cross-View Code Alignment in the Age of Foundation   Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ilyass Moummad",
      "Kawtar Zaher",
      "Hervé Goëau",
      "Alexis Joly"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27584v2",
    "abstract": "Efficient large-scale retrieval requires representations that are both compact and discriminative. Foundation models provide powerful visual and multimodal embeddings, but nearest neighbor search in these high-dimensional spaces is computationally expensive. Hashing offers an efficient alternative by enabling fast Hamming distance search with binary codes, yet existing approaches often rely on complex pipelines, multi-term objectives, designs specialized for a single learning paradigm, and long training times. We introduce CroVCA (Cross-View Code Alignment), a simple and unified principle for learning binary codes that remain consistent across semantically aligned views. A single binary cross-entropy loss enforces alignment, while coding-rate maximization serves as an anti-collapse regularizer to promote balanced and diverse codes. To implement this, we design HashCoder, a lightweight MLP hashing network with a final batch normalization layer to enforce balanced codes. HashCoder can be used as a probing head on frozen embeddings or to adapt encoders efficiently via LoRA fine-tuning. Across benchmarks, CroVCA achieves state-of-the-art results in just 5 training epochs. At 16 bits, it particularly well-for instance, unsupervised hashing on COCO completes in under 2 minutes and supervised hashing on ImageNet100 in about 3 minutes on a single GPU. These results highlight CroVCA's efficiency, adaptability, and broad applicability.",
    "fetched_at": "2025-11-05T02:19:05.051370Z"
  },
  {
    "id": "2510.27588v1",
    "title": "Learned Static Function Data Structures",
    "date": "2025-10-31",
    "tags": [
      "cs.DS",
      "DS",
      "cs.DB",
      "DB",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Stefan Hermann",
      "Hans-Peter Lehmann",
      "Giorgio Vinciguerra",
      "Stefan Walzer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27588v1",
    "abstract": "We consider the task of constructing a data structure for associating a static set of keys with values, while allowing arbitrary output values for queries involving keys outside the set. Compared to hash tables, these so-called static function data structures do not need to store the key set and thus use significantly less memory. Several techniques are known, with compressed static functions approaching the zero-order empirical entropy of the value sequence. In this paper, we introduce learned static functions, which use machine learning to capture correlations between keys and values. For each key, a model predicts a probability distribution over the values, from which we derive a key-specific prefix code to compactly encode the true value. The resulting codeword is stored in a classic static function data structure. This design allows learned static functions to break the zero-order entropy barrier while still supporting point queries. Our experiments show substantial space savings: up to one order of magnitude on real data, and up to three orders of magnitude on synthetic data.",
    "fetched_at": "2025-11-05T02:19:05.051319Z"
  },
  {
    "id": "2510.27606v1",
    "title": "Spatial-SSRL: Enhancing Spatial Understanding via Self-Supervised   Reinforcement Learning",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yuhong Liu",
      "Beichen Zhang",
      "Yuhang Zang",
      "Yuhang Cao",
      "Long Xing",
      "Xiaoyi Dong",
      "Haodong Duan",
      "Dahua Lin",
      "Jiaqi Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27606v1",
    "abstract": "Spatial understanding remains a weakness of Large Vision-Language Models (LVLMs). Existing supervised fine-tuning (SFT) and recent reinforcement learning with verifiable rewards (RLVR) pipelines depend on costly supervision, specialized tools, or constrained environments that limit scale. We introduce Spatial-SSRL, a self-supervised RL paradigm that derives verifiable signals directly from ordinary RGB or RGB-D images. Spatial-SSRL automatically formulates five pretext tasks that capture 2D and 3D spatial structure: shuffled patch reordering, flipped patch recognition, cropped patch inpainting, regional depth ordering, and relative 3D position prediction. These tasks provide ground-truth answers that are easy to verify and require no human or LVLM annotation. Training on our tasks substantially improves spatial reasoning while preserving general visual capabilities. On seven spatial understanding benchmarks in both image and video settings, Spatial-SSRL delivers average accuracy gains of 4.63% (3B) and 3.89% (7B) over the Qwen2.5-VL baselines. Our results show that simple, intrinsic supervision enables RLVR at scale and provides a practical route to stronger spatial intelligence in LVLMs.",
    "fetched_at": "2025-11-05T02:19:05.051180Z"
  },
  {
    "id": "2510.27610v1",
    "title": "ORGEval: Graph-Theoretic Evaluation of LLMs in Optimization Modeling",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zhuohan Wang",
      "Ziwei Zhu",
      "Ziniu Li",
      "Congliang Chen",
      "Yizhou Han",
      "Yufeng Lin",
      "Zhihang Lin",
      "Angyang Gu",
      "Xinglin Hu",
      "Ruoyu Sun",
      "Tian Ding"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27610v1",
    "abstract": "Formulating optimization problems for industrial applications demands significant manual effort and domain expertise. While Large Language Models (LLMs) show promise in automating this process, evaluating their performance remains difficult due to the absence of robust metrics. Existing solver-based approaches often face inconsistency, infeasibility issues, and high computational costs. To address these issues, we propose ORGEval, a graph-theoretic evaluation framework for assessing LLMs' capabilities in formulating linear and mixed-integer linear programs. ORGEval represents optimization models as graphs, reducing equivalence detection to graph isomorphism testing. We identify and prove a sufficient condition, when the tested graphs are symmetric decomposable (SD), under which the Weisfeiler-Lehman (WL) test is guaranteed to correctly detect isomorphism. Building on this, ORGEval integrates a tailored variant of the WL-test with an SD detection algorithm to evaluate model equivalence. By focusing on structural equivalence rather than instance-level configurations, ORGEval is robust to numerical variations. Experimental results show that our method can successfully detect model equivalence and produce 100\\% consistent results across random parameter configurations, while significantly outperforming solver-based methods in runtime, especially on difficult problems. Leveraging ORGEval, we construct the Bench4Opt dataset and benchmark state-of-the-art LLMs on optimization modeling. Our results reveal that although optimization modeling remains challenging for all LLMs, DeepSeek-V3 and Claude-Opus-4 achieve the highest accuracies under direct prompting, outperforming even leading reasoning models.",
    "fetched_at": "2025-11-05T02:19:05.051114Z"
  },
  {
    "id": "2510.27629v3",
    "title": "Best Practices for Biorisk Evaluations on Open-Weight Bio-Foundation   Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Boyi Wei",
      "Zora Che",
      "Nathaniel Li",
      "Udari Madhushani Sehwag",
      "Jasper Götting",
      "Samira Nedungadi",
      "Julian Michael",
      "Summer Yue",
      "Dan Hendrycks",
      "Peter Henderson",
      "Zifan Wang",
      "Seth Donoughe",
      "Mantas Mazeika"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27629v3",
    "abstract": "Open-weight bio-foundation models present a dual-use dilemma. While holding great promise for accelerating scientific research and drug development, they could also enable bad actors to develop more deadly bioweapons. To mitigate the risk posed by these models, current approaches focus on filtering biohazardous data during pre-training. However, the effectiveness of such an approach remains unclear, particularly against determined actors who might fine-tune these models for malicious use. To address this gap, we propose BioRiskEval, a framework to evaluate the robustness of procedures that are intended to reduce the dual-use capabilities of bio-foundation models. BioRiskEval assesses models' virus understanding through three lenses, including sequence modeling, mutational effects prediction, and virulence prediction. Our results show that current filtering practices may not be particularly effective: Excluded knowledge can be rapidly recovered in some cases via fine-tuning, and exhibits broader generalizability in sequence modeling. Furthermore, dual-use signals may already reside in the pretrained representations, and can be elicited via simple linear probing. These findings highlight the challenges of data filtering as a standalone procedure, underscoring the need for further research into robust safety and security strategies for open-weight bio-foundation models.",
    "fetched_at": "2025-11-05T02:19:05.050809Z"
  },
  {
    "id": "2510.27632v1",
    "title": "Sketch-to-Layout: Sketch-Guided Multimodal Layout Generation",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Riccardo Brioschi",
      "Aleksandr Alekseev",
      "Emanuele Nevali",
      "Berkay Döner",
      "Omar El Malki",
      "Blagoj Mitrevski",
      "Leandro Kieliger",
      "Mark Collier",
      "Andrii Maksai",
      "Jesse Berent",
      "Claudiu Musat",
      "Efi Kokiopoulou"
    ],
    "institution": "Google, DeepMind",
    "link": "http://arxiv.org/pdf/2510.27632v1",
    "abstract": "Graphic layout generation is a growing research area focusing on generating aesthetically pleasing layouts ranging from poster designs to documents. While recent research has explored ways to incorporate user constraints to guide the layout generation, these constraints often require complex specifications which reduce usability. We introduce an innovative approach exploiting user-provided sketches as intuitive constraints and we demonstrate empirically the effectiveness of this new guidance method, establishing the sketch-to-layout problem as a promising research direction, which is currently under-explored. To tackle the sketch-to-layout problem, we propose a multimodal transformer-based solution using the sketch and the content assets as inputs to produce high quality layouts. Since collecting sketch training data from human annotators to train our model is very costly, we introduce a novel and efficient method to synthetically generate training sketches at scale. We train and evaluate our model on three publicly available datasets: PubLayNet, DocLayNet and SlidesVQA, demonstrating that it outperforms state-of-the-art constraint-based methods, while offering a more intuitive design experience. In order to facilitate future sketch-to-layout research, we release O(200k) synthetically-generated sketches for the public datasets above. The datasets are available at https://github.com/google-deepmind/sketch_to_layout.",
    "fetched_at": "2025-11-05T02:19:05.050629Z"
  },
  {
    "id": "2510.27638v1",
    "title": "Panprediction: Optimal Predictions for Any Downstream Task and Loss",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Sivaraman Balakrishnan",
      "Nika Haghtalab",
      "Daniel Hsu",
      "Brian Lee",
      "Eric Zhao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27638v1",
    "abstract": "Supervised learning is classically formulated as training a model to minimize a fixed loss function over a fixed distribution, or task. However, an emerging paradigm instead views model training as extracting enough information from data so that the model can be used to minimize many losses on many downstream tasks. We formalize a mathematical framework for this paradigm, which we call panprediction, and study its statistical complexity. Formally, panprediction generalizes omniprediction and sits upstream from multi-group learning, which respectively focus on predictions that generalize to many downstream losses or many downstream tasks, but not both. Concretely, we design algorithms that learn deterministic and randomized panpredictors with $\\tilde{O}(1/\\varepsilon^3)$ and $\\tilde{O}(1/\\varepsilon^2)$ samples, respectively. Our results demonstrate that under mild assumptions, simultaneously minimizing infinitely many losses on infinitely many tasks can be as statistically easy as minimizing one loss on one task. Along the way, we improve the best known sample complexity guarantee of deterministic omniprediction by a factor of $1/\\varepsilon$, and match all other known sample complexity guarantees of omniprediction and multi-group learning. Our key technical ingredient is a nearly lossless reduction from panprediction to a statistically efficient notion of calibration, called step calibration.",
    "fetched_at": "2025-11-05T02:19:05.050546Z"
  },
  {
    "id": "2510.27640v1",
    "title": "Enhancing software product lines with machine learning components",
    "date": "2025-10-31",
    "tags": [
      "cs.SE",
      "SE",
      "cs.LG",
      "LG",
      "D.2",
      "2"
    ],
    "authors": [
      "Luz-Viviana Cobaleda",
      "Julián Carvajal",
      "Paola Vallejo",
      "Andrés López",
      "Raúl Mazo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27640v1",
    "abstract": "Modern software systems increasingly integrate machine learning (ML) due to its advancements and ability to enhance data-driven decision-making. However, this integration introduces significant challenges for software engineering, especially in software product lines (SPLs), where managing variability and reuse becomes more complex with the inclusion of ML components. Although existing approaches have addressed variability management in SPLs and the integration of ML components in isolated systems, few have explored the intersection of both domains. Specifically, there is limited support for modeling and managing variability in SPLs that incorporate ML components. To bridge this gap, this article proposes a structured framework designed to extend Software Product Line engineering, facilitating the integration of ML components. It facilitates the design of SPLs with ML capabilities by enabling systematic modeling of variability and reuse. The proposal has been partially implemented with the VariaMos tool.",
    "fetched_at": "2025-11-05T02:19:05.050493Z"
  },
  {
    "id": "2510.27641v1",
    "title": "SpecAttn: Speculating Sparse Attention",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Harsh Shah"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27641v1",
    "abstract": "Large Language Models (LLMs) face significant computational bottlenecks during inference due to the quadratic complexity of self-attention mechanisms, particularly as context lengths increase. We introduce SpecAttn, a novel training-free approach that seamlessly integrates with existing speculative decoding techniques to enable efficient sparse attention in pre-trained transformers. Our key insight is to exploit the attention weights already computed by the draft model during speculative decoding to identify important tokens for the target model, eliminating redundant computation while maintaining output quality. SpecAttn employs three core techniques: KL divergence-based layer alignment between draft and target models, a GPU-optimized sorting-free algorithm for top-p token selection from draft attention patterns, and dynamic key-value cache pruning guided by these predictions. By leveraging the computational work already performed in standard speculative decoding pipelines, SpecAttn achieves over 75% reduction in key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19 dataset, significantly outperforming existing sparse attention methods. Our approach demonstrates that speculative execution can be enhanced to provide approximate verification without significant performance degradation.",
    "fetched_at": "2025-11-05T02:19:05.050441Z"
  },
  {
    "id": "2510.27643v1",
    "title": "Bayesian Optimization on Networks",
    "date": "2025-10-31",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG",
      "cs.NA",
      "NA",
      "math.NA",
      "math.OC",
      "OC",
      "stat.CO",
      "CO"
    ],
    "authors": [
      "Wenwen Li",
      "Daniel Sanz-Alonso",
      "Ruiyi Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27643v1",
    "abstract": "This paper studies optimization on networks modeled as metric graphs. Motivated by applications where the objective function is expensive to evaluate or only available as a black box, we develop Bayesian optimization algorithms that sequentially update a Gaussian process surrogate model of the objective to guide the acquisition of query points. To ensure that the surrogates are tailored to the network's geometry, we adopt Whittle-Mat\\'ern Gaussian process prior models defined via stochastic partial differential equations on metric graphs. In addition to establishing regret bounds for optimizing sufficiently smooth objective functions, we analyze the practical case in which the smoothness of the objective is unknown and the Whittle-Mat\\'ern prior is represented using finite elements. Numerical results demonstrate the effectiveness of our algorithms for optimizing benchmark objective functions on a synthetic metric graph and for Bayesian inversion via maximum a posteriori estimation on a telecommunication network.",
    "fetched_at": "2025-11-05T02:19:05.050400Z"
  },
  {
    "id": "2510.27646v1",
    "title": "VessShape: Few-shot 2D blood vessel segmentation by leveraging shape   priors from synthetic images",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Cesar H. Comin",
      "Wesley N. Galvão"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27646v1",
    "abstract": "Semantic segmentation of blood vessels is an important task in medical image analysis, but its progress is often hindered by the scarcity of large annotated datasets and the poor generalization of models across different imaging modalities. A key aspect is the tendency of Convolutional Neural Networks (CNNs) to learn texture-based features, which limits their performance when applied to new domains with different visual characteristics. We hypothesize that leveraging geometric priors of vessel shapes, such as their tubular and branching nature, can lead to more robust and data-efficient models. To investigate this, we introduce VessShape, a methodology for generating large-scale 2D synthetic datasets designed to instill a shape bias in segmentation models. VessShape images contain procedurally generated tubular geometries combined with a wide variety of foreground and background textures, encouraging models to learn shape cues rather than textures. We demonstrate that a model pre-trained on VessShape images achieves strong few-shot segmentation performance on two real-world datasets from different domains, requiring only four to ten samples for fine-tuning. Furthermore, the model exhibits notable zero-shot capabilities, effectively segmenting vessels in unseen domains without any target-specific training. Our results indicate that pre-training with a strong shape bias can be an effective strategy to overcome data scarcity and improve model generalization in blood vessel segmentation.",
    "fetched_at": "2025-11-05T02:19:05.050355Z"
  },
  {
    "id": "2510.27650v1",
    "title": "Imbalanced Classification through the Lens of Spurious Correlations",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Jakob Hackstein",
      "Sidney Bender"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27650v1",
    "abstract": "Class imbalance poses a fundamental challenge in machine learning, frequently leading to unreliable classification performance. While prior methods focus on data- or loss-reweighting schemes, we view imbalance as a data condition that amplifies Clever Hans (CH) effects by underspecification of minority classes. In a counterfactual explanations-based approach, we propose to leverage Explainable AI to jointly identify and eliminate CH effects emerging under imbalance. Our method achieves competitive classification performance on three datasets and demonstrates how CH effects emerge under imbalance, a perspective largely overlooked by existing approaches.",
    "fetched_at": "2025-11-05T02:19:05.050311Z"
  },
  {
    "id": "2510.27651v1",
    "title": "Information-Theoretic Greedy Layer-wise Training for Traffic Sign   Recognition",
    "date": "2025-10-31",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shuyan Lyu",
      "Zhanzimo Wu",
      "Junliang Du"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27651v1",
    "abstract": "Modern deep neural networks (DNNs) are typically trained with a global cross-entropy loss in a supervised end-to-end manner: neurons need to store their outgoing weights; training alternates between a forward pass (computation) and a top-down backward pass (learning) which is biologically implausible. Alternatively, greedy layer-wise training eliminates the need for cross-entropy loss and backpropagation. By avoiding the computation of intermediate gradients and the storage of intermediate outputs, it reduces memory usage and helps mitigate issues such as vanishing or exploding gradients. However, most existing layer-wise training approaches have been evaluated only on relatively small datasets with simple deep architectures. In this paper, we first systematically analyze the training dynamics of popular convolutional neural networks (CNNs) trained by stochastic gradient descent (SGD) through an information-theoretic lens. Our findings reveal that networks converge layer-by-layer from bottom to top and that the flow of information adheres to a Markov information bottleneck principle. Building on these observations, we propose a novel layer-wise training approach based on the recently developed deterministic information bottleneck (DIB) and the matrix-based R\\'enyi's $\\alpha$-order entropy functional. Specifically, each layer is trained jointly with an auxiliary classifier that connects directly to the output layer, enabling the learning of minimal sufficient task-relevant representations. We empirically validate the effectiveness of our training procedure on CIFAR-10 and CIFAR-100 using modern deep CNNs and further demonstrate its applicability to a practical task involving traffic sign recognition. Our approach not only outperforms existing layer-wise training baselines but also achieves performance comparable to SGD.",
    "fetched_at": "2025-11-05T02:19:05.050276Z"
  },
  {
    "id": "2510.27655v1",
    "title": "Community Detection on Model Explanation Graphs for Explainable AI",
    "date": "2025-10-31",
    "tags": [
      "cs.SI",
      "SI",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ehsan Moradi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27655v1",
    "abstract": "Feature-attribution methods (e.g., SHAP, LIME) explain individual predictions but often miss higher-order structure: sets of features that act in concert. We propose Modules of Influence (MoI), a framework that (i) constructs a model explanation graph from per-instance attributions, (ii) applies community detection to find feature modules that jointly affect predictions, and (iii) quantifies how these modules relate to bias, redundancy, and causality patterns. Across synthetic and real datasets, MoI uncovers correlated feature groups, improves model debugging via module-level ablations, and localizes bias exposure to specific modules. We release stability and synergy metrics, a reference implementation, and evaluation protocols to benchmark module discovery in XAI.",
    "fetched_at": "2025-11-05T02:19:05.050225Z"
  },
  {
    "id": "2510.27663v1",
    "title": "Bayesian model selection and misspecification testing in imaging inverse   problems only from noisy and partial measurements",
    "date": "2025-10-31",
    "tags": [
      "eess.IV",
      "IV",
      "cs.LG",
      "LG",
      "stat.ME",
      "ME",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Tom Sprunck",
      "Marcelo Pereyra",
      "Tobias Liaudat"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27663v1",
    "abstract": "Modern imaging techniques heavily rely on Bayesian statistical models to address difficult image reconstruction and restoration tasks. This paper addresses the objective evaluation of such models in settings where ground truth is unavailable, with a focus on model selection and misspecification diagnosis. Existing unsupervised model evaluation methods are often unsuitable for computational imaging due to their high computational cost and incompatibility with modern image priors defined implicitly via machine learning models. We herein propose a general methodology for unsupervised model selection and misspecification detection in Bayesian imaging sciences, based on a novel combination of Bayesian cross-validation and data fission, a randomized measurement splitting technique. The approach is compatible with any Bayesian imaging sampler, including diffusion and plug-and-play samplers. We demonstrate the methodology through experiments involving various scoring rules and types of model misspecification, where we achieve excellent selection and detection accuracy with a low computational cost.",
    "fetched_at": "2025-11-05T02:19:05.050143Z"
  },
  {
    "id": "2510.27671v1",
    "title": "MolChord: Structure-Sequence Alignment for Protein-Guided Drug Design",
    "date": "2025-10-31",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Wei Zhang",
      "Zekun Guo",
      "Yingce Xia",
      "Peiran Jin",
      "Shufang Xie",
      "Tao Qin",
      "Xiang-Yang Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27671v1",
    "abstract": "Structure-based drug design (SBDD), which maps target proteins to candidate molecular ligands, is a fundamental task in drug discovery. Effectively aligning protein structural representations with molecular representations, and ensuring alignment between generated drugs and their pharmacological properties, remains a critical challenge. To address these challenges, we propose MolChord, which integrates two key techniques: (1) to align protein and molecule structures with their textual descriptions and sequential representations (e.g., FASTA for proteins and SMILES for molecules), we leverage NatureLM, an autoregressive model unifying text, small molecules, and proteins, as the molecule generator, alongside a diffusion-based structure encoder; and (2) to guide molecules toward desired properties, we curate a property-aware dataset by integrating preference data and refine the alignment process using Direct Preference Optimization (DPO). Experimental results on CrossDocked2020 demonstrate that our approach achieves state-of-the-art performance on key evaluation metrics, highlighting its potential as a practical tool for SBDD.",
    "fetched_at": "2025-11-05T02:19:05.050097Z"
  },
  {
    "id": "2510.27672v1",
    "title": "Culture Cartography: Mapping the Landscape of Cultural Knowledge",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Caleb Ziems",
      "William Held",
      "Jane Yu",
      "Amir Goldberg",
      "David Grusky",
      "Diyi Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27672v1",
    "abstract": "To serve global users safely and productively, LLMs need culture-specific knowledge that might not be learned during pre-training. How do we find such knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The most common solutions are single-initiative: either researchers define challenging questions that users passively answer (traditional annotation), or users actively produce data that researchers structure as benchmarks (knowledge extraction). The process would benefit from mixed-initiative collaboration, where users guide the process to meaningfully reflect their cultures, and LLMs steer the process towards more challenging questions that meet the researcher's goals. We propose a mixed-initiative methodology called CultureCartography. Here, an LLM initializes annotation with questions for which it has low-confidence answers, making explicit both its prior knowledge and the gaps therein. This allows a human respondent to fill these gaps and steer the model towards salient topics through direct edits. We implement this methodology as a tool called CultureExplorer. Compared to a baseline where humans answer LLM-proposed questions, we find that CultureExplorer more effectively produces knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B by up to 19.2% on related culture benchmarks.",
    "fetched_at": "2025-11-05T02:19:05.050037Z"
  },
  {
    "id": "2510.27675v1",
    "title": "On Selecting Few-Shot Examples for LLM-based Code Vulnerability   Detection",
    "date": "2025-10-31",
    "tags": [
      "cs.SE",
      "SE",
      "cs.CR",
      "CR",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Md Abdul Hannan",
      "Ronghao Ni",
      "Chi Zhang",
      "Limin Jia",
      "Ravi Mangal",
      "Corina S. Pasareanu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27675v1",
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities for many coding tasks, including summarization, translation, completion, and code generation. However, detecting code vulnerabilities remains a challenging task for LLMs. An effective way to improve LLM performance is in-context learning (ICL) - providing few-shot examples similar to the query, along with correct answers, can improve an LLM's ability to generate correct solutions. However, choosing the few-shot examples appropriately is crucial to improving model performance. In this paper, we explore two criteria for choosing few-shot examples for ICL used in the code vulnerability detection task. The first criterion considers if the LLM (consistently) makes a mistake or not on a sample with the intuition that LLM performance on a sample is informative about its usefulness as a few-shot example. The other criterion considers similarity of the examples with the program under query and chooses few-shot examples based on the $k$-nearest neighbors to the given sample. We perform evaluations to determine the benefits of these criteria individually as well as under various combinations, using open-source models on multiple datasets.",
    "fetched_at": "2025-11-05T02:19:05.049965Z"
  },
  {
    "id": "2510.27679v1",
    "title": "Dark-Field X-Ray Imaging Significantly Improves Deep-Learning based   Detection of Synthetic Early-Stage Lung Tumors in Preclinical Models",
    "date": "2025-10-31",
    "tags": [
      "physics.med-ph",
      "med-ph",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG",
      "eess.IV",
      "IV",
      "physics.optics",
      "optics"
    ],
    "authors": [
      "Joyoni Dey",
      "Hunter C. Meyer",
      "Murtuza S. Taqi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27679v1",
    "abstract": "Low-dose computed tomography (LDCT) is the current standard for lung cancer screening, yet its adoption and accessibility remain limited. Many regions lack LDCT infrastructure, and even among those screened, early-stage cancer detection often yield false positives, as shown in the National Lung Screening Trial (NLST) with a sensitivity of 93.8 percent and a false-positive rate of 26.6 percent. We aim to investigate whether X-ray dark-field imaging (DFI) radiograph, a technique sensitive to small-angle scatter from alveolar microstructure and less susceptible to organ shadowing, can significantly improve early-stage lung tumor detection when coupled with deep-learning segmentation. Using paired attenuation (ATTN) and DFI radiograph images of euthanized mouse lungs, we generated realistic synthetic tumors with irregular boundaries and intensity profiles consistent with physical lung contrast. A U-Net segmentation network was trained on small patches using either ATTN, DFI, or a combination of ATTN and DFI channels. Results show that the DFI-only model achieved a true-positive detection rate of 83.7 percent, compared with 51 percent for ATTN-only, while maintaining comparable specificity (90.5 versus 92.9 percent). The combined ATTN and DFI input achieved 79.6 percent sensitivity and 97.6 percent specificity. In conclusion, DFI substantially improves early-tumor detectability in comparison to standard attenuation radiography and shows potential as an accessible, low-cost, low-dose alternative for pre-clinical or limited-resource screening where LDCT is unavailable.",
    "fetched_at": "2025-11-05T02:19:05.049905Z"
  },
  {
    "id": "2510.27680v1",
    "title": "PETAR: Localized Findings Generation with Mask-Aware Vision-Language   Modeling for PET Automated Reporting",
    "date": "2025-10-31",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Danyal Maqbool",
      "Changhee Lee",
      "Zachary Huemann",
      "Samuel D. Church",
      "Matthew E. Larson",
      "Scott B. Perlman",
      "Tomas A. Romero",
      "Joshua D. Warner",
      "Meghan Lubner",
      "Xin Tie",
      "Jameson Merkow",
      "Junjie Hu",
      "Steve Y. Cho",
      "Tyler J. Bradshaw"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27680v1",
    "abstract": "Recent advances in vision-language models (VLMs) have enabled impressive multimodal reasoning, yet most medical applications remain limited to 2D imaging. In this work, we extend VLMs to 3D positron emission tomography and computed tomography (PET/CT), a domain characterized by large volumetric data, small and dispersed lesions, and lengthy radiology reports. We introduce a large-scale dataset comprising over 11,000 lesion-level descriptions paired with 3D segmentations from more than 5,000 PET/CT exams, extracted via a hybrid rule-based and large language model (LLM) pipeline. Building upon this dataset, we propose PETAR-4B, a 3D mask-aware vision-language model that integrates PET, CT, and lesion contours for spatially grounded report generation. PETAR bridges global contextual reasoning with fine-grained lesion awareness, producing clinically coherent and localized findings. Comprehensive automated and human evaluations demonstrate that PETAR substantially improves PET/CT report generation quality, advancing 3D medical vision-language understanding.",
    "fetched_at": "2025-11-05T02:19:05.049849Z"
  },
  {
    "id": "2510.27688v1",
    "title": "Continuous Autoregressive Language Models",
    "date": "2025-10-31",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chenze Shao",
      "Darren Li",
      "Fandong Meng",
      "Jie Zhou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.27688v1",
    "abstract": "The efficiency of large language models (LLMs) is fundamentally limited by their sequential, token-by-token generation process. We argue that overcoming this bottleneck requires a new design axis for LLM scaling: increasing the semantic bandwidth of each generative step. To this end, we introduce Continuous Autoregressive Language Models (CALM), a paradigm shift from discrete next-token prediction to continuous next-vector prediction. CALM uses a high-fidelity autoencoder to compress a chunk of K tokens into a single continuous vector, from which the original tokens can be reconstructed with over 99.9\\% accuracy. This allows us to model language as a sequence of continuous vectors instead of discrete tokens, which reduces the number of generative steps by a factor of K. The paradigm shift necessitates a new modeling toolkit; therefore, we develop a comprehensive likelihood-free framework that enables robust training, evaluation, and controllable sampling in the continuous domain. Experiments show that CALM significantly improves the performance-compute trade-off, achieving the performance of strong discrete baselines at a significantly lower computational cost. More importantly, these findings establish next-vector prediction as a powerful and scalable pathway towards ultra-efficient language models. Code: https://github.com/shaochenze/calm. Project: https://shaochenze.github.io/blog/2025/CALM.",
    "fetched_at": "2025-11-05T02:19:05.049752Z"
  },
  {
    "id": "2510.26114v1",
    "title": "OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script   Research",
    "date": "2025-10-30",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Caoshuo Li",
      "Zengmao Ding",
      "Xiaobin Hu",
      "Bang Li",
      "Donghao Luo",
      "Xu Peng",
      "Taisong Jin",
      "Yongge Liu",
      "Shengwei Han",
      "Jing Yang",
      "Xiaoping He",
      "Feng Gao",
      "AndyPian Wu",
      "SevenShu",
      "Chaoyang Wang",
      "Chengjie Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26114v1",
    "abstract": "As one of the earliest writing systems, Oracle Bone Script (OBS) preserves the cultural and intellectual heritage of ancient civilizations. However, current OBS research faces two major challenges: (1) the interpretation of OBS involves a complex workflow comprising multiple serial and parallel sub-tasks, and (2) the efficiency of OBS information organization and retrieval remains a critical bottleneck, as scholars often spend substantial effort searching for, compiling, and managing relevant resources. To address these challenges, we present OracleAgent, the first agent system designed for the structured management and retrieval of OBS-related information. OracleAgent seamlessly integrates multiple OBS analysis tools, empowered by large language models (LLMs), and can flexibly orchestrate these components. Additionally, we construct a comprehensive domain-specific multimodal knowledge base for OBS, which is built through a rigorous multi-year process of data collection, cleaning, and expert annotation. The knowledge base comprises over 1.4M single-character rubbing images and 80K interpretation texts. OracleAgent leverages this resource through its multimodal tools to assist experts in retrieval tasks of character, document, interpretation text, and rubbing image. Extensive experiments demonstrate that OracleAgent achieves superior performance across a range of multimodal reasoning and generation tasks, surpassing leading mainstream multimodal large language models (MLLMs) (e.g., GPT-4o). Furthermore, our case study illustrates that OracleAgent can effectively assist domain experts, significantly reducing the time cost of OBS research. These results highlight OracleAgent as a significant step toward the practical deployment of OBS-assisted research and automated interpretation systems.",
    "fetched_at": "2025-11-06T02:19:05.293795Z"
  },
  {
    "id": "2510.26125v2",
    "title": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging   Long-tail Scenarios",
    "date": "2025-10-30",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Runsheng Xu",
      "Hubert Lin",
      "Wonseok Jeon",
      "Hao Feng",
      "Yuliang Zou",
      "Liting Sun",
      "John Gorman",
      "Kate Tolstaya",
      "Sarah Tang",
      "Brandyn White",
      "Ben Sapp",
      "Mingxing Tan",
      "Jyh-Jing Hwang",
      "Dragomir Anguelov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26125v2",
    "abstract": "Vision-based end-to-end (E2E) driving has garnered significant interest in the research community due to its scalability and synergy with multimodal large language models (MLLMs). However, current E2E driving benchmarks primarily feature nominal scenarios, failing to adequately test the true potential of these systems. Furthermore, existing open-loop evaluation metrics often fall short in capturing the multi-modal nature of driving or effectively evaluating performance in long-tail scenarios. To address these gaps, we introduce the Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021 driving segments (approximately 12 hours), specifically curated for challenging long-tail scenarios that that are rare in daily life with an occurring frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the high-level routing information, ego states, and 360-degree camera views from 8 surrounding cameras. To evaluate the E2E driving performance on these long-tail situations, we propose a novel open-loop evaluation metric: Rater Feedback Score (RFS). Unlike conventional metrics that measure the distance between predicted way points and the logs, RFS measures how closely the predicted trajectory matches rater-annotated trajectory preference labels. We have released rater preference labels for all WOD-E2E validation set segments, while the held out test set labels have been used for the 2025 WOD-E2E Challenge. Through our work, we aim to foster state of the art research into generalizable, robust, and safe end-to-end autonomous driving agents capable of handling complex real-world situations.",
    "fetched_at": "2025-11-06T02:19:05.293699Z"
  },
  {
    "id": "2510.26144v1",
    "title": "The FM Agent",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Annan Li",
      "Chufan Wu",
      "Zengle Ge",
      "Yee Hin Chong",
      "Zhinan Hou",
      "Lizhe Cao",
      "Cheng Ju",
      "Jianmin Wu",
      "Huaiming Li",
      "Haobo Zhang",
      "Shenghao Feng",
      "Mo Zhao",
      "Fengzhi Qiu",
      "Rui Yang",
      "Mengmeng Zhang",
      "Wenyi Zhu",
      "Yingying Sun",
      "Quan Sun",
      "Shunhao Yan",
      "Danyu Liu",
      "Dawei Yin",
      "Dou Shen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26144v1",
    "abstract": "Large language models (LLMs) are catalyzing the development of autonomous AI research agents for scientific and engineering discovery. We present FM Agent, a novel and general-purpose multi-agent framework that leverages a synergistic combination of LLM-based reasoning and large-scale evolutionary search to address complex real-world challenges. The core of FM Agent integrates several key innovations: 1) a cold-start initialization phase incorporating expert guidance, 2) a novel evolutionary sampling strategy for iterative optimization, 3) domain-specific evaluators that combine correctness, effectiveness, and LLM-supervised feedback, and 4) a distributed, asynchronous execution infrastructure built on Ray. Demonstrating broad applicability, our system has been evaluated across diverse domains, including operations research, machine learning, GPU kernel optimization, and classical mathematical problems. FM Agent reaches state-of-the-art results autonomously, without human interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\\%), 43.56\\% on MLE-Bench (+4.0pp), up to 20x speedups on KernelBench, and establishes new state-of-the-art(SOTA) results on several classical mathematical problems. Beyond academic benchmarks, FM Agent shows considerable promise for both large-scale enterprise R\\&D workflows and fundamental scientific research, where it can accelerate innovation, automate complex discovery processes, and deliver substantial engineering and scientific advances with broader societal impact.",
    "fetched_at": "2025-11-06T02:19:05.293614Z"
  },
  {
    "id": "2510.26242v1",
    "title": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for   Generalizable Traffic Signal Control with Emergency Vehicles",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xinhang Li",
      "Qing Guo",
      "Junyu Chen",
      "Zheng Guo",
      "Shengzhe Xu",
      "Lei Li",
      "Lin Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26242v1",
    "abstract": "With increasing urban traffic complexity, Traffic Signal Control (TSC) is essential for optimizing traffic flow and improving road safety. Large Language Models (LLMs) emerge as promising approaches for TSC. However, they are prone to hallucinations in emergencies, leading to unreliable decisions that may cause substantial delays for emergency vehicles. Moreover, diverse intersection types present substantial challenges for traffic state encoding and cross-intersection training, limiting generalization across heterogeneous intersections. Therefore, this paper proposes Retrieval Augmented Generation (RAG)-enhanced distributed LLM agents with Emergency response for Generalizable TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning framework, which dynamically adjusts reasoning depth based on the emergency scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to distill specific knowledge and guidance from historical cases, enhancing the reliability and rationality of agents' emergency decisions. Secondly, this paper designs a type-agnostic traffic representation and proposes a Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3 adaptively samples training experience from diverse intersections with environment feedback-based priority and fine-tunes LLM agents with a designed reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies across heterogeneous intersections. On three real-world road networks with 17 to 177 heterogeneous intersections, extensive experiments show that REG-TSC reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle waiting time by 83.16%, outperforming other state-of-the-art methods.",
    "fetched_at": "2025-11-06T02:19:05.293324Z"
  },
  {
    "id": "2511.00096v1",
    "title": "Urban-MAS: Human-Centered Urban Prediction with LLM-Based Multi-Agent   System",
    "date": "2025-10-30",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Shangyu Lou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00096v1",
    "abstract": "Urban Artificial Intelligence (Urban AI) has advanced human-centered urban tasks such as perception prediction and human dynamics. Large Language Models (LLMs) can integrate multimodal inputs to address heterogeneous data in complex urban systems but often underperform on domain-specific tasks. Urban-MAS, an LLM-based Multi-Agent System (MAS) framework, is introduced for human-centered urban prediction under zero-shot settings. It includes three agent types: Predictive Factor Guidance Agents, which prioritize key predictive factors to guide knowledge extraction and enhance the effectiveness of compressed urban knowledge in LLMs; Reliable UrbanInfo Extraction Agents, which improve robustness by comparing multiple outputs, validating consistency, and re-extracting when conflicts occur; and Multi-UrbanInfo Inference Agents, which integrate extracted multi-source information across dimensions for prediction. Experiments on running-amount prediction and urban perception across Tokyo, Milan, and Seattle demonstrate that Urban-MAS substantially reduces errors compared to single-LLM baselines. Ablation studies indicate that Predictive Factor Guidance Agents are most critical for enhancing predictive performance, positioning Urban-MAS as a scalable paradigm for human-centered urban AI prediction. Code is available on the project website:https://github.com/THETUREHOOHA/UrbanMAS",
    "fetched_at": "2025-11-06T02:19:05.293145Z"
  },
  {
    "id": "2510.26328v1",
    "title": "Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt   Injections",
    "date": "2025-10-30",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "David Schmotz",
      "Sahar Abdelnabi",
      "Maksym Andriushchenko"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26328v1",
    "abstract": "Enabling continual learning in LLMs remains a key unresolved research challenge. In a recent announcement, a frontier LLM company made a step towards this by introducing Agent Skills, a framework that equips agents with new knowledge based on instructions stored in simple markdown files. Although Agent Skills can be a very useful tool, we show that they are fundamentally insecure, since they enable trivially simple prompt injections. We demonstrate how to hide malicious instructions in long Agent Skill files and referenced scripts to exfiltrate sensitive data, such as internal files or passwords. Importantly, we show how to bypass system-level guardrails of a popular coding agent: a benign, task-specific approval with the \"Don't ask again\" option can carry over to closely related but harmful actions. Overall, we conclude that despite ongoing research efforts and scaling model capabilities, frontier LLMs remain vulnerable to very simple prompt injections in realistic scenarios. Our code is available at https://github.com/aisa-group/promptinject-agent-skills.",
    "fetched_at": "2025-11-06T02:19:05.293105Z"
  },
  {
    "id": "2510.26352v1",
    "title": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic   Teams for Multi-Agent Collaboration",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kotaro Furuya",
      "Yuichi Kitagawa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26352v1",
    "abstract": "While a multi-agent approach based on large language models (LLMs) represents a promising strategy to surpass the capabilities of single models, its success is critically dependent on synergistic team composition. However, forming optimal teams is a significant challenge, as the inherent opacity of most models obscures the internal characteristics necessary for effective collaboration. In this paper, we propose an interaction-centric framework for automatic team composition that does not require any prior knowledge including their internal architectures, training data, or task performances. Our method constructs a \"language model graph\" that maps relationships between models from the semantic coherence of pairwise conversations, and then applies community detection to identify synergistic model clusters. Our experiments with diverse LLMs demonstrate that the proposed method discovers functionally coherent groups that reflect their latent specializations. Priming conversations with specific topics identified synergistic teams which outperform random baselines on downstream benchmarks and achieve comparable accuracy to that of manually-curated teams based on known model specializations. Our findings provide a new basis for the automated design of collaborative multi-agent LLM teams.",
    "fetched_at": "2025-11-06T02:19:05.293063Z"
  },
  {
    "id": "2510.26494v1",
    "title": "Simulating and Experimenting with Social Media Mobilization Using LLM   Agents",
    "date": "2025-10-30",
    "tags": [
      "cs.SI",
      "SI",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sadegh Shirani",
      "Mohsen Bayati"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26494v1",
    "abstract": "Online social networks have transformed the ways in which political mobilization messages are disseminated, raising new questions about how peer influence operates at scale. Building on the landmark 61-million-person Facebook experiment \\citep{bond201261}, we develop an agent-based simulation framework that integrates real U.S. Census demographic distributions, authentic Twitter network topology, and heterogeneous large language model (LLM) agents to examine the effect of mobilization messages on voter turnout. Each simulated agent is assigned demographic attributes, a personal political stance, and an LLM variant (\\texttt{GPT-4.1}, \\texttt{GPT-4.1-Mini}, or \\texttt{GPT-4.1-Nano}) reflecting its political sophistication. Agents interact over realistic social network structures, receiving personalized feeds and dynamically updating their engagement behaviors and voting intentions. Experimental conditions replicate the informational and social mobilization treatments of the original Facebook study. Across scenarios, the simulator reproduces qualitative patterns observed in field experiments, including stronger mobilization effects under social message treatments and measurable peer spillovers. Our framework provides a controlled, reproducible environment for testing counterfactual designs and sensitivity analyses in political mobilization research, offering a bridge between high-validity field experiments and flexible computational modeling.\\footnote{Code and data available at https://github.com/CausalMP/LLM-SocioPol}",
    "fetched_at": "2025-11-06T02:19:05.293018Z"
  },
  {
    "id": "2510.26585v1",
    "title": "Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems",
    "date": "2025-10-30",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fulin Lin",
      "Shaowen Chen",
      "Ruishan Fang",
      "Hongwei Wang",
      "Tao Lin"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26585v1",
    "abstract": "While Multi-Agent Systems (MAS) excel at complex tasks, their growing autonomy with operational complexity often leads to critical inefficiencies, such as excessive token consumption and failures arising from misinformation. Existing methods primarily focus on post-hoc failure attribution, lacking proactive, real-time interventions to enhance robustness and efficiency. To this end, we introduce SupervisorAgent, a lightweight and modular framework for runtime, adaptive supervision that operates without altering the base agent's architecture. Triggered by an LLM-free adaptive filter, SupervisorAgent intervenes at critical junctures to proactively correct errors, guide inefficient behaviors, and purify observations. On the challenging GAIA benchmark, SupervisorAgent reduces the token consumption of the Smolagent framework by an average of 29.45% without compromising its success rate. Extensive experiments across five additional benchmarks (math reasoning, code generation, and question answering) and various SoTA foundation models validate the broad applicability and robustness of our approach. The code is available at https://github.com/LINs-lab/SupervisorAgent.",
    "fetched_at": "2025-11-06T02:19:05.292843Z"
  },
  {
    "id": "2510.26852v1",
    "title": "CATArena: Evaluation of LLM Agents through Iterative Tournament   Competitions",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Lingyue Fu",
      "Xin Ding",
      "Yaoming Zhu",
      "Shao Zhang",
      "Lin Qiu",
      "Weiwen Liu",
      "Weinan Zhang",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Jiaxin Ding",
      "Yong Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26852v1",
    "abstract": "Large Language Model (LLM) agents have evolved from basic text generation to autonomously completing complex tasks through interaction with external tools. However, current benchmarks mainly assess end-to-end performance in fixed scenarios, restricting evaluation to specific skills and suffering from score saturation and growing dependence on expert annotation as agent capabilities improve. In this work, we emphasize the importance of learning ability, including both self-improvement and peer-learning, as a core driver for agent evolution toward human-level intelligence. We propose an iterative, competitive peer-learning framework, which allows agents to refine and optimize their strategies through repeated interactions and feedback, thereby systematically evaluating their learning capabilities. To address the score saturation issue in current benchmarks, we introduce CATArena, a tournament-style evaluation platform featuring four diverse board and card games with open-ended scoring. By providing tasks without explicit upper score limits, CATArena enables continuous and dynamic evaluation of rapidly advancing agent capabilities. Experimental results and analyses involving both minimal and commercial code agents demonstrate that CATArena provides reliable, stable, and scalable benchmarking for core agent abilities, particularly learning ability and strategy coding.",
    "fetched_at": "2025-11-06T02:19:05.292793Z"
  },
  {
    "id": "2510.26603v1",
    "title": "Agentic AI Home Energy Management System: A Large Language Model   Framework for Residential Load Scheduling",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA",
      "cs.SY",
      "SY",
      "eess.SY"
    ],
    "authors": [
      "Reda El Makroum",
      "Sebastian Zwickl-Bernhard",
      "Lukas Kranzl"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2510.26603v1",
    "abstract": "The electricity sector transition requires substantial increases in residential demand response capacity, yet Home Energy Management Systems (HEMS) adoption remains limited by user interaction barriers requiring translation of everyday preferences into technical parameters. While large language models have been applied to energy systems as code generators and parameter extractors, no existing implementation deploys LLMs as autonomous coordinators managing the complete workflow from natural language input to multi-appliance scheduling. This paper presents an agentic AI HEMS where LLMs autonomously coordinate multi-appliance scheduling from natural language requests to device control, achieving optimal scheduling without example demonstrations. A hierarchical architecture combining one orchestrator with three specialist agents uses the ReAct pattern for iterative reasoning, enabling dynamic coordination without hardcoded workflows while integrating Google Calendar for context-aware deadline extraction. Evaluation across three open-source models using real Austrian day-ahead electricity prices reveals substantial capability differences. Llama-3.3-70B successfully coordinates all appliances across all scenarios to match cost-optimal benchmarks computed via mixed-integer linear programming, while other models achieve perfect single-appliance performance but struggle to coordinate all appliances simultaneously. Progressive prompt engineering experiments demonstrate that analytical query handling without explicit guidance remains unreliable despite models' general reasoning capabilities. We open-source the complete system including orchestration logic, agent prompts, tools, and web interfaces to enable reproducibility, extension, and future research.",
    "fetched_at": "2025-11-06T02:19:05.292720Z"
  },
  {
    "id": "2510.26854v1",
    "title": "Inverse Knowledge Search over Verifiable Reasoning: Synthesizing a   Scientific Encyclopedia from a Long Chains-of-Thought Knowledge Base",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yu Li",
      "Yuan Huang",
      "Tao Wang",
      "Caiyu Fan",
      "Xiansheng Cai",
      "Sihan Hu",
      "Xinzijian Liu",
      "Cheng Shi",
      "Mingjun Xu",
      "Zhen Wang",
      "Yan Wang",
      "Xiangqi Jin",
      "Tianhan Zhang",
      "Linfeng Zhang",
      "Lei Wang",
      "Youjin Deng",
      "Pan Zhang",
      "Weijie Sun",
      "Xingyu Li",
      "Weinan E",
      "Linfeng Zhang",
      "Zhiyuan Yao",
      "Kun Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26854v1",
    "abstract": "Most scientific materials compress reasoning, presenting conclusions while omitting the derivational chains that justify them. This compression hinders verification by lacking explicit, step-wise justifications and inhibits cross-domain links by collapsing the very pathways that establish the logical and causal connections between concepts. We introduce a scalable framework that decompresses scientific reasoning, constructing a verifiable Long Chain-of-Thought (LCoT) knowledge base and projecting it into an emergent encyclopedia, SciencePedia. Our pipeline operationalizes an endpoint-driven, reductionist strategy: a Socratic agent, guided by a curriculum of around 200 courses, generates approximately 3 million first-principles questions. To ensure high fidelity, multiple independent solver models generate LCoTs, which are then rigorously filtered by prompt sanitization and cross-model answer consensus, retaining only those with verifiable endpoints. This verified corpus powers the Brainstorm Search Engine, which performs inverse knowledge search -- retrieving diverse, first-principles derivations that culminate in a target concept. This engine, in turn, feeds the Plato synthesizer, which narrates these verified chains into coherent articles. The initial SciencePedia comprises approximately 200,000 fine-grained entries spanning mathematics, physics, chemistry, biology, engineering, and computation. In evaluations across six disciplines, Plato-synthesized articles (conditioned on retrieved LCoTs) exhibit substantially higher knowledge-point density and significantly lower factual error rates than an equally-prompted baseline without retrieval (as judged by an external LLM). Built on this verifiable LCoT knowledge base, this reasoning-centric approach enables trustworthy, cross-domain scientific synthesis at scale and establishes the foundation for an ever-expanding encyclopedia.",
    "fetched_at": "2025-11-06T02:19:05.292665Z"
  },
  {
    "id": "2510.26615v2",
    "title": "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual   Document Understanding",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yiqiao Jin",
      "Rachneet Kaur",
      "Zhen Zeng",
      "Sumitra Ganesh",
      "Srijan Kumar"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26615v2",
    "abstract": "Multi-page visual documents such as manuals, brochures, presentations, and posters convey key information through layout, colors, icons, and cross-slide references. While large language models (LLMs) offer opportunities in document understanding, current systems struggle with complex, multi-page visual documents, particularly in fine-grained reasoning over elements and pages. We introduce SlideAgent, a versatile agentic framework for understanding multi-modal, multi-page, and multi-layout documents, especially slide decks. SlideAgent employs specialized agents and decomposes reasoning into three specialized levels-global, page, and element-to construct a structured, query-agnostic representation that captures both overarching themes and detailed visual or textual cues. During inference, SlideAgent selectively activates specialized agents for multi-level reasoning and integrates their outputs into coherent, context-aware answers. Extensive experiments show that SlideAgent achieves significant improvement over both proprietary (+7.9 overall) and open-source models (+9.8 overall).",
    "fetched_at": "2025-11-06T02:19:05.292535Z"
  },
  {
    "id": "2510.26702v1",
    "title": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope   Matching",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Majed El Helou",
      "Chiara Troiani",
      "Benjamin Ryder",
      "Jean Diaconu",
      "Hervé Muyal",
      "Marcelo Yannuzzi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26702v1",
    "abstract": "Authorizing Large Language Model driven agents to dynamically invoke tools and access protected resources introduces significant risks, since current methods for delegating authorization grant overly broad permissions and give access to tools allowing agents to operate beyond the intended task scope. We introduce and assess a delegated authorization model enabling authorization servers to semantically inspect access requests to protected resources, and issue access tokens constrained to the minimal set of scopes necessary for the agents' assigned tasks. Given the unavailability of datasets centered on delegated authorization flows, particularly including both semantically appropriate and inappropriate scope requests for a given task, we introduce ASTRA, a dataset and data generation pipeline for benchmarking semantic matching between tasks and scopes. Our experiments show both the potential and current limitations of model-based matching, particularly as the number of scopes needed for task completion increases. Our results highlight the need for further research into semantic matching techniques enabling intent-aware authorization for multi-agent and tool-augmented applications, including fine-grained control, such as Task-Based Access Control (TBAC).",
    "fetched_at": "2025-11-06T02:19:05.292385Z"
  },
  {
    "id": "2510.26790v1",
    "title": "Gistify! Codebase-Level Understanding via Runtime Execution",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Hyunji Lee",
      "Minseon Kim",
      "Chinmay Singh",
      "Matheus Pereira",
      "Atharv Sonwane",
      "Isadora White",
      "Elias Stengel-Eskin",
      "Mohit Bansal",
      "Zhengyan Shi",
      "Alessandro Sordoni",
      "Marc-Alexandre Côté",
      "Xingdi Yuan",
      "Lucas Caccia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26790v1",
    "abstract": "As coding agents are increasingly deployed in large codebases, the need to automatically design challenging, codebase-level evaluation is central. We propose Gistify, a task where a coding LLM must create a single, minimal, self-contained file that can reproduce a specific functionality of a codebase. The coding LLM is given full access to a codebase along with a specific entrypoint (e.g., a python command), and the generated file must replicate the output of the same command ran under the full codebase, while containing only the essential components necessary to execute the provided command. Success on Gistify requires both structural understanding of the codebase, accurate modeling of its execution flow as well as the ability to produce potentially large code patches. Our findings show that current state-of-the-art models struggle to reliably solve Gistify tasks, especially ones with long executions traces.",
    "fetched_at": "2025-11-06T02:19:05.292330Z"
  },
  {
    "id": "2510.26913v1",
    "title": "FlowMesh: A Service Fabric for Composable LLM Workflows",
    "date": "2025-10-30",
    "tags": [
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Junyi Shen",
      "Noppanat Wadlom",
      "Lingfeng Zhou",
      "Dequan Wang",
      "Xu Miao",
      "Lei Fang",
      "Yao Lu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26913v1",
    "abstract": "AI deployment increasingly resembles a pipeline of data transformation, fine-tuning, and agent interactions rather than a monolithic LLM job; recent examples include RLHF/RLAIF training and agentic workflows. To cope with this shift, we propose FlowMesh, a multi-tenant service fabric that executes and optimizes these workloads as one shared service instead of isolated pipelines. It decomposes workflows into fine-grained operators with recorded lineage, enabling de-duplication of work across users and batching requests on the same hardware while preserving per-workflow provenance. A global control plane maintains a cluster-wide pool of ready operators and uses a single utility function to pick both the batch and the worker, balancing throughput, cost, and data locality on heterogeneous GPUs. The data plane is an elastic fleet of stateless workers backed by a content-addressable store, enabling rapid, automatic scale-out, safe retry after preemption, and portability across managed clusters such as Kubernetes and geo-distributed GPU marketplaces such as Vast.ai. Compared with baseline solutions, FlowMesh achieves up to 3.8x cost reduction and 2.0x lower energy usage, provides a similar or better latency profile, and remains efficient under dynamic and failure-prone conditions.",
    "fetched_at": "2025-11-06T02:19:05.292256Z"
  },
  {
    "id": "2510.27016v1",
    "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI   Services",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jayden Serenari",
      "Stephen Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.27016v1",
    "abstract": "With the increasing use of conversational AI systems, there is growing concern over privacy leaks, especially when users share sensitive personal data in interactions with Large Language Models (LLMs). Conversations shared with these models may contain Personally Identifiable Information (PII), which, if exposed, could lead to security breaches or identity theft. To address this challenge, we present the Local Optimizations for Pseudonymization with Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a semantically-aware privacy agent designed to safeguard sensitive PII data when using remote LLMs. Unlike prior work that often degrade response quality, our approach dynamically replaces sensitive PII entities in user prompts with semantically consistent pseudonyms, preserving the contextual integrity of conversations. Once the model generates its response, the pseudonyms are automatically depseudonymized, ensuring the user receives an accurate, privacy-preserving output. We evaluate our approach using real-world conversations sourced from ShareGPT, which we further augment and annotate to assess whether named entities are contextually relevant to the model's response. Our results show that LOPSIDED reduces semantic utility errors by a factor of 5 compared to baseline techniques, all while enhancing privacy.",
    "fetched_at": "2025-11-06T02:19:05.292200Z"
  },
  {
    "id": "2510.26037v1",
    "title": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled   Structured Reasoning",
    "date": "2025-10-30",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Kaiwen Zhou",
      "Ahmed Elgohary",
      "A S M Iftekhar",
      "Amin Saied"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26037v1",
    "abstract": "The ability of LLM agents to plan and invoke tools exposes them to new safety risks, making a comprehensive red-teaming system crucial for discovering vulnerabilities and ensuring their safe deployment. We present SIRAJ: a generic red-teaming framework for arbitrary black-box LLM agents. We employ a dynamic two-step process that starts with an agent definition and generates diverse seed test cases that cover various risk outcomes, tool-use trajectories, and risk sources. Then, it iteratively constructs and refines model-based adversarial attacks based on the execution trajectories of former attempts. To optimize the red-teaming cost, we present a model distillation approach that leverages structured forms of a teacher model's reasoning to train smaller models that are equally effective. Across diverse evaluation agent settings, our seed test case generation approach yields 2 -- 2.5x boost to the coverage of risk outcomes and tool-calling trajectories. Our distilled 8B red-teamer model improves attack success rate by 100%, surpassing the 671B Deepseek-R1 model. Our ablations and analyses validate the effectiveness of the iterative framework, structured reasoning, and the generalization of our red-teamer models.",
    "fetched_at": "2025-11-06T02:19:03.473689Z"
  },
  {
    "id": "2510.26040v1",
    "title": "Accelerating Real-World Overtaking in F1TENTH Racing Employing   Reinforcement Learning Methods",
    "date": "2025-10-30",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Emily Steiner",
      "Daniel van der Spuy",
      "Futian Zhou",
      "Afereti Pama",
      "Minas Liarokapis",
      "Henry Williams"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26040v1",
    "abstract": "While autonomous racing performance in Time-Trial scenarios has seen significant progress and development, autonomous wheel-to-wheel racing and overtaking are still severely limited. These limitations are particularly apparent in real-life driving scenarios where state-of-the-art algorithms struggle to safely or reliably complete overtaking manoeuvres. This is important, as reliable navigation around other vehicles is vital for safe autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful opportunity for developing wheel-to-wheel racing algorithms on a standardised physical platform. The competition format makes it possible to evaluate overtaking and wheel-to-wheel racing algorithms against the state-of-the-art. This research presents a novel racing and overtaking agent capable of learning to reliably navigate a track and overtake opponents in both simulation and reality. The agent was deployed on an F1Tenth vehicle and competed against opponents running varying competitive algorithms in the real world. The results demonstrate that the agent's training against opponents enables deliberate overtaking behaviours with an overtaking rate of 87% compared 56% for an agent trained just to race.",
    "fetched_at": "2025-11-06T02:19:03.473640Z"
  },
  {
    "id": "2510.26089v1",
    "title": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle   Routing",
    "date": "2025-10-30",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Fazel Arasteh",
      "Arian Haghparast",
      "Manos Papagelis"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26089v1",
    "abstract": "Traffic congestion in urban road networks leads to longer trip times and higher emissions, especially during peak periods. While the Shortest Path First (SPF) algorithm is optimal for a single vehicle in a static network, it performs poorly in dynamic, multi-vehicle settings, often worsening congestion by routing all vehicles along identical paths. We address dynamic vehicle routing through a multi-agent reinforcement learning (MARL) framework for coordinated, network-aware fleet navigation. We first propose Adaptive Navigation (AN), a decentralized MARL model where each intersection agent provides routing guidance based on (i) local traffic and (ii) neighborhood state modeled using Graph Attention Networks (GAT). To improve scalability in large networks, we further propose Hierarchical Hub-based Adaptive Navigation (HHAN), an extension of AN that assigns agents only to key intersections (hubs). Vehicles are routed hub-to-hub under agent control, while SPF handles micro-routing within each hub region. For hub coordination, HHAN adopts centralized training with decentralized execution (CTDE) under the Attentive Q-Mixing (A-QMIX) framework, which aggregates asynchronous vehicle decisions via attention. Hub agents use flow-aware state features that combine local congestion and predictive dynamics for proactive routing. Experiments on synthetic grids and real urban maps (Toronto, Manhattan) show that AN reduces average travel time versus SPF and learning baselines, maintaining 100% routing success. HHAN scales to networks with hundreds of intersections, achieving up to 15.9% improvement under heavy traffic. These findings highlight the potential of network-constrained MARL for scalable, coordinated, and congestion-aware routing in intelligent transportation systems.",
    "fetched_at": "2025-11-06T02:19:03.473572Z"
  },
  {
    "id": "2510.26098v1",
    "title": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in   GUI Tasks",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Chenrui Shi",
      "Zedong Yu",
      "Zhi Gao",
      "Ruining Feng",
      "Enqi Liu",
      "Yuwei Wu",
      "Yunde Jia",
      "Liuyu Xiang",
      "Zhaofeng He",
      "Qing Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26098v1",
    "abstract": "Large vision language models (VLMs) have advanced graphical user interface (GUI) task automation but still lag behind humans. We hypothesize this gap stems from missing core GUI knowledge, which existing training schemes (such as supervised fine tuning and reinforcement learning) alone cannot fully address. By analyzing common failure patterns in GUI task execution, we distill GUI knowledge into three dimensions: (1) interface perception, knowledge about recognizing widgets and system states; (2) interaction prediction, knowledge about reasoning action state transitions; and (3) instruction understanding, knowledge about planning, verifying, and assessing task completion progress. We further introduce GUI Knowledge Bench, a benchmark with multiple choice and yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux, IOS) and 292 applications. Our evaluation shows that current VLMs identify widget functions but struggle with perceiving system states, predicting actions, and verifying task completion. Experiments on real world GUI tasks further validate the close link between GUI knowledge and task success. By providing a structured framework for assessing GUI knowledge, our work supports the selection of VLMs with greater potential prior to downstream training and provides insights for building more capable GUI agents.",
    "fetched_at": "2025-11-06T02:19:03.473499Z"
  },
  {
    "id": "2510.26163v1",
    "title": "Exploring Dissatisfaction in Bus Route Reduction through LLM-Calibrated   Agent-Based Modeling",
    "date": "2025-10-30",
    "tags": [
      "cs.CY",
      "CY",
      "I.6.3; J.1; J.4",
      "4"
    ],
    "authors": [
      "Qiumeng Li",
      "Xinxi Yang",
      "Suhong Zhou"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26163v1",
    "abstract": "As emerging mobility modes continue to expand, many cities face declining bus ridership, increasing fiscal pressure to sustain underutilized routes, and growing inefficiencies in resource allocation. This study employs an agent-based modelling (ABM) approach calibrated through a large language model (LLM) using few-shot learning to examine how progressive bus route cutbacks affect passenger dissatisfaction across demographic groups and overall network resilience. Using IC-card data from Beijing's Huairou District, the LLM-calibrated ABM estimated passenger sensitivity parameters related to travel time, waiting, transfers, and crowding. Results show that the structural configuration of the bus network exerts a stronger influence on system stability than capacity or operational factors. The elimination of high-connectivity routes led to an exponential rise in total dissatisfaction, particularly among passengers with disabilities and older adults. The evolution of dissatisfaction exhibited three distinct phases - stable, transitional, and critical. Through the analysis of each stage, this study found that the continuous bus route reduction scenario exhibits three-stage thresholds. Once these thresholds are crossed, even a small reduction in routes may lead to a significant loss of passenger flow. Research highlights the nonlinear response of user sentiment to service reductions and underscore the importance of maintaining structural critical routes and providing stable services to vulnerable groups for equitable and resilient transport planning.",
    "fetched_at": "2025-11-06T02:19:03.473430Z"
  },
  {
    "id": "2510.26167v1",
    "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient   Reasoning",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Renhao Li",
      "Jianhong Tu",
      "Yang Su",
      "Hamid Alinejad-Rokny",
      "Derek F. Wong",
      "Junyang Lin",
      "Min Yang"
    ],
    "institution": "OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2510.26167v1",
    "abstract": "Reward models (RMs) play a critical role in aligning large language models (LLMs) with human preferences. Yet in the domain of tool learning, the lack of RMs specifically designed for function-calling tasks has limited progress toward more capable agentic AI. We introduce ToolRM, a family of lightweight generative RMs tailored for general tool-use scenarios. To build these models, we propose a novel pipeline that constructs pairwise preference data using rule-based scoring and multidimensional sampling. This yields ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique tasks that supports reinforcement learning with verifiable feedback. To evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on the agentic evaluation suite BFCL. Trained on our constructed data, models from the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward judgments. Beyond training objectives, ToolRM generalizes to broader critique tasks, including Best-of-N sampling and self-correction. Experiments on ACEBench highlight its effectiveness and efficiency, enabling inference-time scaling and reducing output token usage by over 66%. We release data and model checkpoints to facilitate future research.",
    "fetched_at": "2025-11-06T02:19:03.473382Z"
  },
  {
    "id": "2510.26172v1",
    "title": "Linking Heterogeneous Data with Coordinated Agent Flows for Social Media   Analysis",
    "date": "2025-10-30",
    "tags": [
      "cs.HC",
      "HC",
      "cs.AI",
      "AI",
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Shifu Chen",
      "Dazhen Deng",
      "Zhihong Xu",
      "Sijia Xu",
      "Tai-Quan Peng",
      "Yingcai Wu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26172v1",
    "abstract": "Social media platforms generate massive volumes of heterogeneous data, capturing user behaviors, textual content, temporal dynamics, and network structures. Analyzing such data is crucial for understanding phenomena such as opinion dynamics, community formation, and information diffusion. However, discovering insights from this complex landscape is exploratory, conceptually challenging, and requires expertise in social media mining and visualization. Existing automated approaches, though increasingly leveraging large language models (LLMs), remain largely confined to structured tabular data and cannot adequately address the heterogeneity of social media analysis. We present SIA (Social Insight Agents), an LLM agent system that links heterogeneous multi-modal data -- including raw inputs (e.g., text, network, and behavioral data), intermediate outputs, mined analytical results, and visualization artifacts -- through coordinated agent flows. Guided by a bottom-up taxonomy that connects insight types with suitable mining and visualization techniques, SIA enables agents to plan and execute coherent analysis strategies. To ensure multi-modal integration, it incorporates a data coordinator that unifies tabular, textual, and network data into a consistent flow. Its interactive interface provides a transparent workflow where users can trace, validate, and refine the agent's reasoning, supporting both adaptability and trustworthiness. Through expert-centered case studies and quantitative evaluation, we show that SIA effectively discovers diverse and meaningful insights from social media while supporting human-agent collaboration in complex analytical tasks.",
    "fetched_at": "2025-11-06T02:19:03.473322Z"
  },
  {
    "id": "2510.26236v1",
    "title": "PHUMA: Physically-Grounded Humanoid Locomotion Dataset",
    "date": "2025-10-30",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Kyungmin Lee",
      "Sibeen Kim",
      "Minho Park",
      "Hyunseung Kim",
      "Dongyoon Hwang",
      "Hojoon Lee",
      "Jaegul Choo"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26236v1",
    "abstract": "Motion imitation is a promising approach for humanoid locomotion, enabling agents to acquire humanlike behaviors. Existing methods typically rely on high-quality motion capture datasets such as AMASS, but these are scarce and expensive, limiting scalability and diversity. Recent studies attempt to scale data collection by converting large-scale internet videos, exemplified by Humanoid-X. However, they often introduce physical artifacts such as floating, penetration, and foot skating, which hinder stable imitation. In response, we introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that leverages human video at scale, while addressing physical artifacts through careful data curation and physics-constrained retargeting. PHUMA enforces joint limits, ensures ground contact, and eliminates foot skating, producing motions that are both large-scale and physically reliable. We evaluated PHUMA in two sets of conditions: (i) imitation of unseen motion from self-recorded test videos and (ii) path following with pelvis-only guidance. In both cases, PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant gains in imitating diverse motions. The code is available at https://davian-robotics.github.io/PHUMA.",
    "fetched_at": "2025-11-06T02:19:03.473263Z"
  },
  {
    "id": "2510.26270v1",
    "title": "Graph-Enhanced Policy Optimization in LLM Agent Training",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiazhen Yuan",
      "Wei Zhao",
      "Zhengbiao Bai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26270v1",
    "abstract": "Group based reinforcement learning (RL) has shown impressive results on complex reasoning and mathematical tasks. Yet, when applied to train multi-turn, interactive LLM agents, these methods often suffer from structural blindness-the inability to exploit the underlying connectivity of the environment. This manifests in three critical challenges: (1) inefficient, unguided exploration, (2) imprecise credit assignment due to overlooking pivotal states, and (3) myopic planning caused by static reward discounting. We address these issues with Graph-Enhanced Policy Optimization (GEPO), which dynamically constructs a state-transition graph from agent experience and employs graph-theoretic centrality to provide three synergistic learning signals: (1)structured intrinsic rewards that guide exploration toward high-impact states, (2) a graph-enhanced advantage function for topology-aware credit assignment, and (3) a dynamic discount factor adapted to each state's strategic value. On the ALFWorld, WebShop, and a proprietary Workbench benchmarks, GEPO demonstrates strong performance, achieving absolute success rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These results highlight that explicitly modeling environmental structure is a robust, generalizable strategy for advancing LLM agent training.",
    "fetched_at": "2025-11-06T02:19:03.473209Z"
  },
  {
    "id": "2510.26287v1",
    "title": "Empowering RepoQA-Agent based on Reinforcement Learning Driven by   Monte-carlo Tree Search",
    "date": "2025-10-30",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Guochang Li",
      "Yuchen Liu",
      "Zhen Qin",
      "Yunkun Wang",
      "Jianping Zhong",
      "Chen Zhi",
      "Binhua Li",
      "Fei Huang",
      "Yongbin Li",
      "Shuiguang Deng"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26287v1",
    "abstract": "Repository-level software engineering tasks require large language models (LLMs) to efficiently navigate and extract information from complex codebases through multi-turn tool interactions. Existing approaches face significant limitations: training-free, in-context learning methods struggle to guide agents effectively in tool utilization and decision-making based on environmental feedback, while training-based approaches typically rely on costly distillation from larger LLMs, introducing data compliance concerns in enterprise environments. To address these challenges, we introduce RepoSearch-R1, a novel agentic reinforcement learning framework driven by Monte-carlo Tree Search (MCTS). This approach allows agents to generate diverse, high-quality reasoning trajectories via self-training without requiring model distillation or external supervision. Based on RepoSearch-R1, we construct a RepoQA-Agent specifically designed for repository question-answering tasks. Comprehensive evaluation on repository question-answering tasks demonstrates that RepoSearch-R1 achieves substantial improvements of answer completeness: 16.0% enhancement over no-retrieval methods, 19.5% improvement over iterative retrieval methods, and 33% increase in training efficiency compared to general agentic reinforcement learning approaches. Our cold-start training methodology eliminates data compliance concerns while maintaining robust exploration diversity and answer completeness across repository-level reasoning tasks.",
    "fetched_at": "2025-11-06T02:19:03.473166Z"
  },
  {
    "id": "2510.26363v1",
    "title": "Towards Reinforcement Learning Based Log Loading Automation",
    "date": "2025-10-30",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Ilya Kurinov",
      "Miroslav Ivanov",
      "Grzegorz Orzechowski",
      "Aki Mikkola"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26363v1",
    "abstract": "Forestry forwarders play a central role in mechanized timber harvesting by picking up and moving logs from the felling site to a processing area or a secondary transport vehicle. Forwarder operation is challenging and physically and mentally exhausting for the operator who must control the machine in remote areas for prolonged periods of time. Therefore, even partial automation of the process may reduce stress on the operator. This study focuses on continuing previous research efforts in application of reinforcement learning agents in automating log handling process, extending the task from grasping which was studied in previous research to full log loading operation. The resulting agent will be capable to automate a full loading procedure from locating and grappling to transporting and delivering the log to a forestry forwarder bed. To train the agent, a trailer type forestry forwarder simulation model in NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario were developed. With reinforcement learning agents and a curriculum learning approach, the trained agent may be a stepping stone towards application of reinforcement learning agents in automation of the forestry forwarder. The agent learnt grasping a log in a random position from grapple's random position and transport it to the bed with 94% success rate of the best performing agent.",
    "fetched_at": "2025-11-06T02:19:03.473098Z"
  },
  {
    "id": "2510.26389v1",
    "title": "Adaptive Context Length Optimization with Low-Frequency Truncation for   Multi-Agent Reinforcement Learning",
    "date": "2025-10-30",
    "tags": [
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Wenchang Duan",
      "Yaoliang Yu",
      "Jiwan He",
      "Yi Shi"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2510.26389v1",
    "abstract": "Recently, deep multi-agent reinforcement learning (MARL) has demonstrated promising performance for solving challenging tasks, such as long-term dependencies and non-Markovian environments. Its success is partly attributed to conditioning policies on large fixed context length. However, such large fixed context lengths may lead to limited exploration efficiency and redundant information. In this paper, we propose a novel MARL framework to obtain adaptive and effective contextual information. Specifically, we design a central agent that dynamically optimizes context length via temporal gradient analysis, enhancing exploration to facilitate convergence to global optima in MARL. Furthermore, to enhance the adaptive optimization capability of the context length, we present an efficient input representation for the central agent, which effectively filters redundant information. By leveraging a Fourier-based low-frequency truncation method, we extract global temporal trends across decentralized agents, providing an effective and efficient representation of the MARL environment. Extensive experiments demonstrate that the proposed method achieves state-of-the-art (SOTA) performance on long-term dependency tasks, including PettingZoo, MiniGrid, Google Research Football (GRF), and StarCraft Multi-Agent Challenge v2 (SMACv2).",
    "fetched_at": "2025-11-06T02:19:03.473051Z"
  },
  {
    "id": "2510.26423v1",
    "title": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis",
    "date": "2025-10-30",
    "tags": [
      "cs.SE",
      "SE",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Dong Huang",
      "Mingzhe Du",
      "Jie M. Zhang",
      "Zheng Lin",
      "Meng Luo",
      "Qianru Zhang",
      "See-Kiong Ng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26423v1",
    "abstract": "Test oracle generation in non-regression testing is a longstanding challenge in software engineering, where the goal is to produce oracles that can accurately determine whether a function under test (FUT) behaves as intended for a given input. In this paper, we introduce Nexus, a novel multi-agent framework to address this challenge. Nexus generates test oracles by leveraging a diverse set of specialized agents that synthesize test oracles through a structured process of deliberation, validation, and iterative self-refinement. During the deliberation phase, a panel of four specialist agents, each embodying a distinct testing philosophy, collaboratively critiques and refines an initial set of test oracles. Then, in the validation phase, Nexus generates a plausible candidate implementation of the FUT and executes the proposed oracles against it in a secure sandbox. For any oracle that fails this execution-based check, Nexus activates an automated selfrefinement loop, using the specific runtime error to debug and correct the oracle before re-validation. Our extensive evaluation on seven diverse benchmarks demonstrates that Nexus consistently and substantially outperforms state-of-theart baselines. For instance, Nexus improves the test-level oracle accuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The improved accuracy also significantly enhances downstream tasks: the bug detection rate of GPT4.1-Mini generated test oracles on HumanEval increases from 90.91% to 95.45% for Nexus compared to baselines, and the success rate of automated program repair improves from 35.23% to 69.32%.",
    "fetched_at": "2025-11-06T02:19:03.473004Z"
  },
  {
    "id": "2510.26438v2",
    "title": "An Impulse Control Approach to Market Making in a Hawkes LOB Market",
    "date": "2025-10-30",
    "tags": [
      "q-fin.TR",
      "TR",
      "q-fin.CP",
      "CP"
    ],
    "authors": [
      "Konark Jain",
      "Nick Firoozye",
      "Jonathan Kochems",
      "Philip Treleaven"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26438v2",
    "abstract": "We study the optimal Market Making problem in a Limit Order Book (LOB) market simulated using a high-fidelity, mutually exciting Hawkes process. Departing from traditional Brownian-driven mid-price models, our setup captures key microstructural properties such as queue dynamics, inter-arrival clustering, and endogenous price impact. Recognizing the realistic constraint that market makers cannot update strategies at every LOB event, we formulate the control problem within an impulse control framework, where interventions occur discretely via limit, cancel, or market orders. This leads to a high-dimensional, non-local Hamilton-Jacobi-Bellman Quasi-Variational Inequality (HJB-QVI), whose solution is analytically intractable and computationally expensive due to the curse of dimensionality. To address this, we propose a novel Reinforcement Learning (RL) approximation inspired by auxiliary control formulations. Using a two-network PPO-based architecture with self-imitation learning, we demonstrate strong empirical performance with limited training, achieving Sharpe ratios above 30 in a realistic simulated LOB. In addition to that, we solve the HJB-QVI using a deep learning method inspired by Sirignano and Spiliopoulos 2018 and compare the performance with the RL agent. Our findings highlight the promise of combining impulse control theory with modern deep RL to tackle optimal execution problems in jump-driven microstructural markets.",
    "fetched_at": "2025-11-06T02:19:03.472944Z"
  },
  {
    "id": "2510.26498v1",
    "title": "A Multi-agent Large Language Model Framework to Automatically Assess   Performance of a Clinical AI Triage Tool",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Adam E. Flanders",
      "Yifan Peng",
      "Luciano Prevedello",
      "Robyn Ball",
      "Errol Colak",
      "Prahlad Menon",
      "George Shih",
      "Hui-Ming Lin",
      "Paras Lakhani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26498v1",
    "abstract": "Purpose: The purpose of this study was to determine if an ensemble of multiple LLM agents could be used collectively to provide a more reliable assessment of a pixel-based AI triage tool than a single LLM.   Methods: 29,766 non-contrast CT head exams from fourteen hospitals were processed by a commercial intracranial hemorrhage (ICH) AI detection tool. Radiology reports were analyzed by an ensemble of eight open-source LLM models and a HIPAA compliant internal version of GPT-4o using a single multi-shot prompt that assessed for presence of ICH. 1,726 examples were manually reviewed. Performance characteristics of the eight open-source models and consensus were compared to GPT-4o. Three ideal consensus LLM ensembles were tested for rating the performance of the triage tool.   Results: The cohort consisted of 29,766 head CTs exam-report pairs. The highest AUC performance was achieved with llama3.3:70b and GPT-4o (AUC= 0.78). The average precision was highest for Llama3.3:70b and GPT-4o (AP=0.75 & 0.76). Llama3.3:70b had the highest F1 score (0.81) and recall (0.85), greater precision (0.78), specificity (0.72), and MCC (0.57). Using MCC (95% CI) the ideal combination of LLMs were: Full-9 Ensemble 0.571 (0.552-0.591), Top-3 Ensemble 0.558 (0.537-0.579), Consensus 0.556 (0.539-0.574), and GPT4o 0.522 (0.500-0.543). No statistically significant differences were observed between Top-3, Full-9, and Consensus (p > 0.05).   Conclusion: An ensemble of medium to large sized open-source LLMs provides a more consistent and reliable method to derive a ground truth retrospective evaluation of a clinical AI triage tool over a single LLM alone.",
    "fetched_at": "2025-11-06T02:19:03.472896Z"
  },
  {
    "id": "2510.26536v1",
    "title": "RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable,   and Robust Multi-Robot Collaboration",
    "date": "2025-10-30",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Huajie Tan",
      "Cheng Chi",
      "Xiansheng Chen",
      "Yuheng Ji",
      "Zhongxia Zhao",
      "Xiaoshuai Hao",
      "Yaoxu Lyu",
      "Mingyu Cao",
      "Junkai Zhao",
      "Huaihai Lyu",
      "Enshen Zhou",
      "Ning Chen",
      "Yankai Fu",
      "Cheng Peng",
      "Wei Guo",
      "Dong Liang",
      "Zhuo Chen",
      "Mengsi Lyu",
      "Chenrui He",
      "Yulong Ao",
      "Yonghua Lin",
      "Pengwei Wang",
      "Zhongyuan Wang",
      "Shanghang Zhang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26536v1",
    "abstract": "The proliferation of collaborative robots across diverse tasks and embodiments presents a central challenge: achieving lifelong adaptability, scalable coordination, and robust scheduling in multi-agent systems. Existing approaches, from vision-language-action (VLA) models to hierarchical frameworks, fall short due to their reliance on limited or dividual-agent memory. This fundamentally constrains their ability to learn over long horizons, scale to heterogeneous teams, or recover from failures, highlighting the need for a unified memory representation. To address these limitations, we introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable, and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene geometry, temporal event history, and embodiment profiles into a shared representation. This memory-centric design is integrated into a brain-cerebellum framework, where a high-level brain model performs global planning by retrieving and updating STEM, while low-level controllers execute actions locally. This closed loop between cognition, memory, and execution enables dynamic task allocation, fault-tolerant collaboration, and consistent state synchronization. We conduct extensive experiments spanning complex coordination tasks in restaurants, supermarkets, and households. Our results demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous embodiments, validating its effectiveness in enabling lifelong, scalable, and robust multi-robot collaboration. Project website: https://flagopen.github.io/RoboOS/",
    "fetched_at": "2025-11-06T02:19:03.472825Z"
  },
  {
    "id": "2510.26575v1",
    "title": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization",
    "date": "2025-10-30",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kun Luo",
      "Hongjin Qian",
      "Zheng Liu",
      "Ziyi Xia",
      "Shitao Xiao",
      "Siqi Bao",
      "Jun Zhao",
      "Kang Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26575v1",
    "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) is a promising approach for enhancing agentic deep search. However, its application is often hindered by low \\textbf{Reward Density} in deep search scenarios, where agents expend significant exploratory costs for infrequent and often null final rewards. In this paper, we formalize this challenge as the \\textbf{Reward Density Optimization} problem, which aims to improve the reward obtained per unit of exploration cost. This paper introduce \\textbf{InfoFlow}, a systematic framework that tackles this problem from three aspects. 1) \\textbf{Subproblem decomposition}: breaking down long-range tasks to assign process rewards, thereby providing denser learning signals. 2) \\textbf{Failure-guided hints}: injecting corrective guidance into stalled trajectories to increase the probability of successful outcomes. 3) \\textbf{Dual-agent refinement}: employing a dual-agent architecture to offload the cognitive burden of deep exploration. A refiner agent synthesizes the search history, which effectively compresses the researcher's perceived trajectory, thereby reducing exploration cost and increasing the overall reward density. We evaluate InfoFlow on multiple agentic search benchmarks, where it significantly outperforms strong baselines, enabling lightweight LLMs to achieve performance comparable to advanced proprietary LLMs.",
    "fetched_at": "2025-11-06T02:19:03.472710Z"
  },
  {
    "id": "2510.26578v1",
    "title": "Two-Timescale Optimization Framework for IAB-Enabled Heterogeneous UAV   Networks",
    "date": "2025-10-30",
    "tags": [
      "eess.SY",
      "SY",
      "cs.SY"
    ],
    "authors": [
      "Jikang Deng",
      "Hui Zhou",
      "Mohamed-Slim Alouini"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26578v1",
    "abstract": "In post-disaster scenarios, the rapid deployment of adequate communication infrastructure is essential to support disaster search, rescue, and recovery operations. To achieve this, uncrewed aerial vehicle (UAV) has emerged as a promising solution for emergency communication due to its low cost and deployment flexibility. However, conventional untethered UAV (U-UAV) is constrained by size, weight, and power (SWaP) limitations, making it incapable of maintaining the operation of a macro base station. To address this limitation, we propose a heterogeneous UAV-based framework that integrates tethered UAV (T-UAV) and U-UAVs, where U-UAVs are utilized to enhance the throughput of cell-edge ground user equipments (G-UEs) and guarantee seamless connectivity during G-UEs' mobility to safe zones. It is noted that the integrated access and backhaul (IAB) technique is adopted to support the wireless backhaul of U-UAVs. Accordingly, we formulate a two-timescale joint user scheduling and trajectory control optimization problem, aiming to maximize the downlink throughput under asymmetric traffic demands and G-UEs' mobility. To solve the formulated problem, we proposed a two-timescale multi-agent deep deterministic policy gradient (TTS-MADDPG) algorithm based on the centralized training and distributed execution paradigm. Numerical results show that the proposed algorithm outperforms other benchmarks, including the two-timescale multi-agent proximal policy optimization (TTS-MAPPO) algorithm and MADDPG scheduling method, with robust and higher throughput. Specifically, the proposed algorithm obtains up to 12.2\\% average throughput gain compared to the MADDPG scheduling method.",
    "fetched_at": "2025-11-06T02:19:03.472648Z"
  },
  {
    "id": "2510.26610v1",
    "title": "A DRL-Empowered Multi-Level Jamming Approach for Secure Semantic   Communication",
    "date": "2025-10-30",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Weixuan Chen",
      "Qianqian Yang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26610v1",
    "abstract": "Semantic communication (SemCom) aims to transmit only task-relevant information, thereby improving communication efficiency but also exposing semantic information to potential eavesdropping. In this paper, we propose a deep reinforcement learning (DRL)-empowered multi-level jamming approach to enhance the security of SemCom systems over MIMO fading wiretap channels. This approach combines semantic layer jamming, achieved by encoding task-irrelevant text, and physical layer jamming, achieved by encoding random Gaussian noise. These two-level jamming signals are superposed with task-relevant semantic information to protect the transmitted semantics from eavesdropping. A deep deterministic policy gradient (DDPG) algorithm is further introduced to dynamically design and optimize the precoding matrices for both taskrelevant semantic information and multi-level jamming signals, aiming to enhance the legitimate user's image reconstruction while degrading the eavesdropper's performance. To jointly train the SemCom model and the DDPG agent, we propose an alternating optimization strategy where the two modules are updated iteratively. Experimental results demonstrate that, compared with both the encryption-based (ESCS) and encoded jammer-based (EJ) benchmarks, our method achieves comparable security while improving the legitimate user's peak signalto-noise ratio (PSNR) by up to approximately 0.6 dB.",
    "fetched_at": "2025-11-06T02:19:03.472601Z"
  },
  {
    "id": "2510.26658v1",
    "title": "The Era of Agentic Organization: Learning to Organize with Language   Models",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zewen Chi",
      "Li Dong",
      "Qingxiu Dong",
      "Yaru Hao",
      "Xun Wu",
      "Shaohan Huang",
      "Furu Wei"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26658v1",
    "abstract": "We envision a new era of AI, termed agentic organization, where agents solve complex problems by working collaboratively and concurrently, enabling outcomes beyond individual intelligence. To realize this vision, we introduce asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large language models, which organizes the internal thinking process into concurrently executable structures. Specifically, we propose a thinking protocol where an organizer dynamically assigns sub-queries to workers, merges intermediate knowledge, and produces coherent solutions. More importantly, the thinking structure in this protocol can be further optimized through reinforcement learning. Experiments demonstrate that AsyncThink achieves 28% lower inference latency compared to parallel thinking while improving accuracy on mathematical reasoning. Moreover, AsyncThink generalizes its learned asynchronous thinking capabilities, effectively tackling unseen tasks without additional training.",
    "fetched_at": "2025-11-06T02:19:03.472558Z"
  },
  {
    "id": "2510.26699v1",
    "title": "Using Copilot Agent Mode to Automate Library Migration: A Quantitative   Assessment",
    "date": "2025-10-30",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Aylton Almeida",
      "Laerte Xavier",
      "Marco Tulio Valente"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26699v1",
    "abstract": "Keeping software systems up to date is essential to avoid technical debt, security vulnerabilities, and the rigidity typical of legacy systems. However, updating libraries and frameworks remains a time consuming and error-prone process. Recent advances in Large Language Models (LLMs) and agentic coding systems offer new opportunities for automating such maintenance tasks. In this paper, we evaluate the update of a well-known Python library, SQLAlchemy, across a dataset of ten client applications. For this task, we use the Github's Copilot Agent Mode, an autonomous AI systema capable of planning and executing multi-step migration workflows. To assess the effectiveness of the automated migration, we also introduce Migration Coverage, a metric that quantifies the proportion of API usage points correctly migrated. The results of our study show that the LLM agent was capable of migrating functionalities and API usages between SQLAlchemy versions (migration coverage: 100%, median), but failed to maintain the application functionality, leading to a low test-pass rate (39.75%, median).",
    "fetched_at": "2025-11-06T02:19:03.472492Z"
  },
  {
    "id": "2510.26740v1",
    "title": "A General Incentives-Based Framework for Fairness in Multi-agent   Resource Allocation",
    "date": "2025-10-30",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ashwin Kumar",
      "William Yeoh"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26740v1",
    "abstract": "We introduce the General Incentives-based Framework for Fairness (GIFF), a novel approach for fair multi-agent resource allocation that infers fair decision-making from standard value functions. In resource-constrained settings, agents optimizing for efficiency often create inequitable outcomes. Our approach leverages the action-value (Q-)function to balance efficiency and fairness without requiring additional training. Specifically, our method computes a local fairness gain for each action and introduces a counterfactual advantage correction term to discourage over-allocation to already well-off agents. This approach is formalized within a centralized control setting, where an arbitrator uses the GIFF-modified Q-values to solve an allocation problem.   Empirical evaluations across diverse domains, including dynamic ridesharing, homelessness prevention, and a complex job allocation task-demonstrate that our framework consistently outperforms strong baselines and can discover far-sighted, equitable policies. The framework's effectiveness is supported by a theoretical foundation; we prove its fairness surrogate is a principled lower bound on the true fairness improvement and that its trade-off parameter offers monotonic tuning. Our findings establish GIFF as a robust and principled framework for leveraging standard reinforcement learning components to achieve more equitable outcomes in complex multi-agent systems.",
    "fetched_at": "2025-11-06T02:19:03.472447Z"
  },
  {
    "id": "2510.26782v1",
    "title": "Clone Deterministic 3D Worlds with Geometrically-Regularized World   Models",
    "date": "2025-10-30",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Zaishuo Xia",
      "Yukuan Lu",
      "Xinyi Li",
      "Yifan Xu",
      "Yubei Chen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26782v1",
    "abstract": "A world model is an internal model that simulates how the world evolves. Given past observations and actions, it predicts the future of both the embodied agent and its environment. Accurate world models are essential for enabling agents to think, plan, and reason effectively in complex, dynamic settings. Despite rapid progress, current world models remain brittle and degrade over long horizons. We argue that a central cause is representation quality: exteroceptive inputs (e.g., images) are high-dimensional, and lossy or entangled latents make dynamics learning unnecessarily hard. We therefore ask whether improving representation learning alone can substantially improve world-model performance. In this work, we take a step toward building a truly accurate world model by addressing a fundamental yet open problem: constructing a model that can fully clone and overfit to a deterministic 3D world. We propose Geometrically-Regularized World Models (GRWM), which enforces that consecutive points along a natural sensory trajectory remain close in latent representation space. This approach yields significantly improved latent representations that align closely with the true topology of the environment. GRWM is plug-and-play, requires only minimal architectural modification, scales with trajectory length, and is compatible with diverse latent generative backbones. Across deterministic 3D settings and long-horizon prediction tasks, GRWM significantly increases rollout fidelity and stability. Analyses show that its benefits stem from learning a latent manifold with superior geometric structure. These findings support a clear takeaway: improving representation learning is a direct and useful path to robust world models, delivering reliable long-horizon predictions without enlarging the dynamics module.",
    "fetched_at": "2025-11-06T02:19:03.472403Z"
  },
  {
    "id": "2510.26787v1",
    "title": "Remote Labor Index: Measuring AI Automation of Remote Work",
    "date": "2025-10-30",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Mantas Mazeika",
      "Alice Gatti",
      "Cristina Menghini",
      "Udari Madhushani Sehwag",
      "Shivam Singhal",
      "Yury Orlovskiy",
      "Steven Basart",
      "Manasi Sharma",
      "Denis Peskoff",
      "Elaine Lau",
      "Jaehyuk Lim",
      "Lachlan Carroll",
      "Alice Blair",
      "Vinaya Sivakumar",
      "Sumana Basu",
      "Brad Kenstler",
      "Yuntao Ma",
      "Julian Michael",
      "Xiaoke Li",
      "Oliver Ingebretsen",
      "Aditya Mehta",
      "Jean Mottola",
      "John Teichmann",
      "Kevin Yu",
      "Zaina Shaik",
      "Adam Khoja",
      "Richard Ren",
      "Jason Hausenloy",
      "Long Phan",
      "Ye Htet",
      "Ankit Aich",
      "Tahseen Rabbani",
      "Vivswan Shah",
      "Andriy Novykov",
      "Felix Binder",
      "Kirill Chugunov",
      "Luis Ramirez",
      "Matias Geralnik",
      "Hernán Mesura",
      "Dean Lee",
      "Ed-Yeremai Hernandez Cardona",
      "Annette Diamond",
      "Summer Yue",
      "Alexandr Wang",
      "Bing Liu",
      "Ernesto Hernandez",
      "Dan Hendrycks"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26787v1",
    "abstract": "AIs have made rapid progress on research-oriented benchmarks of knowledge and reasoning, but it remains unclear how these gains translate into economic value and automation. To measure this, we introduce the Remote Labor Index (RLI), a broadly multi-sector benchmark comprising real-world, economically valuable projects designed to evaluate end-to-end agent performance in practical settings. AI agents perform near the floor on RLI, with the highest-performing agent achieving an automation rate of 2.5%. These results help ground discussions of AI automation in empirical evidence, setting a common basis for tracking AI impacts and enabling stakeholders to proactively navigate AI-driven labor automation.",
    "fetched_at": "2025-11-06T02:19:03.472346Z"
  },
  {
    "id": "2510.26887v1",
    "title": "The Denario project: Deep knowledge AI agents for scientific discovery",
    "date": "2025-10-30",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Francisco Villaescusa-Navarro",
      "Boris Bolliet",
      "Pablo Villanueva-Domingo",
      "Adrian E. Bayer",
      "Aidan Acquah",
      "Chetana Amancharla",
      "Almog Barzilay-Siegal",
      "Pablo Bermejo",
      "Camille Bilodeau",
      "Pablo Cárdenas Ramírez",
      "Miles Cranmer",
      "Urbano L. França",
      "ChangHoon Hahn",
      "Yan-Fei Jiang",
      "Raul Jimenez",
      "Jun-Young Lee",
      "Antonio Lerario",
      "Osman Mamun",
      "Thomas Meier",
      "Anupam A. Ojha",
      "Pavlos Protopapas",
      "Shimanto Roy",
      "David N. Spergel",
      "Pedro Tarancón-Álvarez",
      "Ujjwal Tiwari",
      "Matteo Viel",
      "Digvijay Wadekar",
      "Chi Wang",
      "Bonny Y. Wang",
      "Licong Xu",
      "Yossi Yovel",
      "Shuwen Yue",
      "Wen-Han Zhou",
      "Qiyao Zhu",
      "Jiajun Zou",
      "Íñigo Zubeldia"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.26887v1",
    "abstract": "We present Denario, an AI multi-agent system designed to serve as a scientific research assistant. Denario can perform many different tasks, such as generating ideas, checking the literature, developing research plans, writing and executing code, making plots, and drafting and reviewing a scientific paper. The system has a modular architecture, allowing it to handle specific tasks, such as generating an idea, or carrying out end-to-end scientific analysis using Cmbagent as a deep-research backend. In this work, we describe in detail Denario and its modules, and illustrate its capabilities by presenting multiple AI-generated papers generated by it in many different scientific disciplines such as astrophysics, biology, biophysics, biomedical informatics, chemistry, material science, mathematical physics, medicine, neuroscience and planetary science. Denario also excels at combining ideas from different disciplines, and we illustrate this by showing a paper that applies methods from quantum physics and machine learning to astrophysical data. We report the evaluations performed on these papers by domain experts, who provided both numerical scores and review-like feedback. We then highlight the strengths, weaknesses, and limitations of the current system. Finally, we discuss the ethical implications of AI-driven research and reflect on how such technology relates to the philosophy of science. We publicly release the code at https://github.com/AstroPilot-AI/Denario. A Denario demo can also be run directly on the web at https://huggingface.co/spaces/astropilot-ai/Denario, and the full app will be deployed on the cloud.",
    "fetched_at": "2025-11-06T02:19:03.472161Z"
  },
  {
    "id": "2511.00112v1",
    "title": "Real-DRL: Teach and Learn in Reality",
    "date": "2025-10-30",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yanbing Mao",
      "Yihao Cai",
      "Lui Sha"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2511.00112v1",
    "abstract": "This paper introduces the Real-DRL framework for safety-critical autonomous systems, enabling runtime learning of a deep reinforcement learning (DRL) agent to develop safe and high-performance action policies in real plants (i.e., real physical systems to be controlled), while prioritizing safety! The Real-DRL consists of three interactive components: a DRL-Student, a PHY-Teacher, and a Trigger. The DRL-Student is a DRL agent that innovates in the dual self-learning and teaching-to-learn paradigm and the real-time safety-informed batch sampling. On the other hand, PHY-Teacher is a physics-model-based design of action policies that focuses solely on safety-critical functions. PHY-Teacher is novel in its real-time patch for two key missions: i) fostering the teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of real plants. The Trigger manages the interaction between the DRL-Student and the PHY-Teacher. Powered by the three interactive components, the Real-DRL can effectively address safety challenges that arise from the unknown unknowns and the Sim2Real gap. Additionally, Real-DRL notably features i) assured safety, ii) automatic hierarchy learning (i.e., safety-first learning and then high-performance learning), and iii) safety-informed batch sampling to address the learning experience imbalance caused by corner cases. Experiments with a real quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole system, along with comparisons and ablation studies, demonstrate the Real-DRL's effectiveness and unique features.",
    "fetched_at": "2025-11-06T02:19:03.472002Z"
  },
  {
    "id": "2510.26125v1",
    "title": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging   Long-tail Scenarios",
    "date": "2025-10-30",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Runsheng Xu",
      "Hubert Lin",
      "Wonseok Jeon",
      "Hao Feng",
      "Yuliang Zou",
      "Liting Sun",
      "John Gorman",
      "Kate Tolstaya",
      "Sarah Tang",
      "Brandyn White",
      "Ben Sapp",
      "Mingxing Tan",
      "Jyh-Jing Hwang",
      "Drago Anguelov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26125v1",
    "abstract": "Vision-based end-to-end (E2E) driving has garnered significant interest in the research community due to its scalability and synergy with multimodal large language models (MLLMs). However, current E2E driving benchmarks primarily feature nominal scenarios, failing to adequately test the true potential of these systems. Furthermore, existing open-loop evaluation metrics often fall short in capturing the multi-modal nature of driving or effectively evaluating performance in long-tail scenarios. To address these gaps, we introduce the Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021 driving segments (approximately 12 hours), specifically curated for challenging long-tail scenarios that that are rare in daily life with an occurring frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the high-level routing information, ego states, and 360-degree camera views from 8 surrounding cameras. To evaluate the E2E driving performance on these long-tail situations, we propose a novel open-loop evaluation metric: Rater Feedback Score (RFS). Unlike conventional metrics that measure the distance between predicted way points and the logs, RFS measures how closely the predicted trajectory matches rater-annotated trajectory preference labels. We have released rater preference labels for all WOD-E2E validation set segments, while the held out test set labels have been used for the 2025 WOD-E2E Challenge. Through our work, we aim to foster state of the art research into generalizable, robust, and safe end-to-end autonomous driving agents capable of handling complex real-world situations.",
    "fetched_at": "2025-11-05T02:19:00.097296Z"
  },
  {
    "id": "2510.25232v1",
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded   Approach and Dataset for Psychiatric Comorbidity",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Tianxi Wan",
      "Jiaming Luo",
      "Siyuan Chen",
      "Kunyao Lan",
      "Jianhua Chen",
      "Haiyang Geng",
      "Mengyue Wu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25232v1",
    "abstract": "Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct PsyCoTalk, the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.",
    "fetched_at": "2025-11-05T02:19:02.085714Z"
  },
  {
    "id": "2510.25269v1",
    "title": "The influence of the random numbers quality on the results in stochastic   simulations and machine learning",
    "date": "2025-10-29",
    "tags": [
      "cs.PF",
      "PF"
    ],
    "authors": [
      "Benjamin A. Antunes"
    ],
    "institution": "LIRMM | DALI",
    "link": "http://arxiv.org/pdf/2510.25269v1",
    "abstract": "Pseudorandom number generators (PRNGs) are ubiquitous in stochastic simulations and machine learning (ML), where they drive sampling, parameter initialization, regularization, and data shuffling. While widely used, the potential impact of PRNG statistical quality on computational results remains underexplored. In this study, we investigate whether differences in PRNG quality, as measured by standard statistical test suites, can influence outcomes in representative stochastic applications. Seven PRNGs were evaluated, ranging from low-quality linear congruential generators (LCGs) with known statistical deficiencies to high-quality generators such as Mersenne Twister, PCG, and Philox. We applied these PRNGs to four distinct tasks: an epidemiological agent-based model (ABM), two independent from-scratch MNIST classification implementations (Python/NumPy and C++), and a reinforcement learning (RL) CartPole environment. Each experiment was repeated 30 times per generator using fixed seeds to ensure reproducibility, and outputs were compared using appropriate statistical analyses. Results show that very poor statistical quality, as in the ''bad'' LCG failing 125 TestU01 Crush tests, produces significant deviations in ABM epidemic dynamics, reduces MNIST classification accuracy, and severely degrades RL performance. In contrast, mid-and good-quality LCGs-despite failing a limited number of Crush or BigCrush tests-performed comparably to top-tier PRNGs in most tasks, with the RL experiment being the primary exception where performance scaled with statistical quality. Our findings indicate that, once a generator meets a sufficient statistical robustness threshold, its family or design has negligible impact on outcomes for most workloads, allowing selection to be guided by performance and implementation considerations. However, the use of low-quality PRNGs in sensitive stochastic computations can introduce substantial and systematic errors.",
    "fetched_at": "2025-11-05T02:19:02.085653Z"
  },
  {
    "id": "2510.25271v1",
    "title": "Adaptive Design of mmWave Initial Access Codebooks using Reinforcement   Learning",
    "date": "2025-10-29",
    "tags": [
      "cs.NI",
      "NI"
    ],
    "authors": [
      "Sabrine Aroua",
      "Christos Anastasios Bovolis",
      "Bo Göransson",
      "Anastasios Giovanidis",
      "Mathieu Leconte",
      "Apostolos Destounis"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25271v1",
    "abstract": "Initial access (IA) is the process by which user equipment (UE) establishes its first connection with a base station. In 5G systems, particularly at millimeter-wave frequencies, IA integrates beam management to support highly directional transmissions. The base station employs a codebook of beams for the transmission of Synchronization Signal Blocks (SSBs), which are periodically swept to detect and connect users. The design of this SSB codebook is critical for ensuring reliable, wide-area coverage. In current networks, SSB codebooks are meticulously engineered by domain experts. While these expert-defined codebooks provide a robust baseline, they lack flexibility in dynamic or heterogeneous environments where user distributions vary, limiting their overall effectiveness. This paper proposes a hybrid Reinforcement Learning (RL) framework for adaptive SSB codebook design. Building on top of expert knowledge, the RL agent leverages a pool of expert-designed SSB beams and learns to adaptively select or combine them based on real-time feedback. This enables the agent to dynamically tailor codebooks to the actual environment, without requiring explicit user location information, while always respecting practical beam constraints. Simulation results demonstrate that, on average, the proposed approach improves user connectivity by 10.8$\\%$ compared to static expert configurations. These findings highlight the potential of combining expert knowledge with data-driven optimization to achieve more intelligent, flexible, and resilient beam management in next-generation wireless networks.",
    "fetched_at": "2025-11-05T02:19:02.085628Z"
  },
  {
    "id": "2510.25340v1",
    "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
    "date": "2025-10-29",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Beiwen Zhang",
      "Yongheng Liang",
      "Hejun Wu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25340v1",
    "abstract": "Multi-agent reinforcement learning (MARl) has achieved strong results in cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc teamwork (AHT) relaxes this by allowing collaboration with unknown partners, yet existing variants still presume shared conventions. We introduce Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple mutually unfamiliar groups of uncontrolled teammates. To address this, we propose MARs, which builds a sparse skeleton graph and applies relational modeling to capture cross-group dvnamics. Experiments on MPE and starCralt ll show that MARs outperforms MARL and AHT baselines while converging faster.",
    "fetched_at": "2025-11-05T02:19:02.085448Z"
  },
  {
    "id": "2510.25445v1",
    "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and   Future Directions",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Mohamad Abou Ali",
      "Fadi Dornaika"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25445v1",
    "abstract": "Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to a fragmented understanding, often conflating modern neural systems with outdated symbolic models -- a practice known as conceptual retrofitting. This survey cuts through this confusion by introducing a novel dual-paradigm framework that categorizes agentic systems into two distinct lineages: the Symbolic/Classical (relying on algorithmic planning and persistent state) and the Neural/Generative (leveraging stochastic generation and prompt-driven orchestration). Through a systematic PRISMA-based review of 90 studies (2018--2025), we provide a comprehensive analysis structured around this framework across three dimensions: (1) the theoretical foundations and architectural principles defining each paradigm; (2) domain-specific implementations in healthcare, finance, and robotics, demonstrating how application constraints dictate paradigm selection; and (3) paradigm-specific ethical and governance challenges, revealing divergent risks and mitigation strategies. Our analysis reveals that the choice of paradigm is strategic: symbolic systems dominate safety-critical domains (e.g., healthcare), while neural systems prevail in adaptive, data-rich environments (e.g., finance). Furthermore, we identify critical research gaps, including a significant deficit in governance models for symbolic systems and a pressing need for hybrid neuro-symbolic architectures. The findings culminate in a strategic roadmap arguing that the future of Agentic AI lies not in the dominance of one paradigm, but in their intentional integration to create systems that are both adaptable and reliable. This work provides the essential conceptual toolkit to guide future research, development, and policy toward robust and trustworthy hybrid intelligent systems.",
    "fetched_at": "2025-11-05T02:19:02.085293Z"
  },
  {
    "id": "2510.25496v1",
    "title": "Dynamic Beamforming and Power Allocation in ISAC via Deep Reinforcement   Learning",
    "date": "2025-10-29",
    "tags": [
      "eess.SP",
      "SP"
    ],
    "authors": [
      "Duc Nguyen Dao",
      "André B. J. Kokkeler",
      "Haibin Zhang",
      "Yang Miao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25496v1",
    "abstract": "Integrated Sensing and Communication (ISAC) is a key enabler in 6G networks, where sensing and communication capabilities are designed to complement and enhance each other. One of the main challenges in ISAC lies in resource allocation, which becomes computationally demanding in dynamic environments requiring real-time adaptation. In this paper, we propose a Deep Reinforcement Learning (DRL)-based approach for dynamic beamforming and power allocation in ISAC systems. The DRL agent interacts with the environment and learns optimal strategies through trial and error, guided by predefined rewards. Simulation results show that the DRL-based solution converges within 2000 episodes and achieves up to 80\\% of the spectral efficiency of a semidefinite relaxation (SDR) benchmark. More importantly, it offers a significant improvement in runtime performance, achieving decision times of around 20 ms compared to 4500 ms for the SDR method. Furthermore, compared with a Deep Q-Network (DQN) benchmark employing discrete beamforming, the proposed approach achieves approximately 30\\% higher sum-rate with comparable runtime. These results highlight the potential of DRL for enabling real-time, high-performance ISAC in dynamic scenarios.",
    "fetched_at": "2025-11-05T02:19:02.085241Z"
  },
  {
    "id": "2510.25529v1",
    "title": "Off-policy Reinforcement Learning with Model-based Exploration   Augmentation",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Likun Wang",
      "Xiangteng Zhang",
      "Yinuo Wang",
      "Guojian Zhan",
      "Wenxuan Wang",
      "Haoyu Gao",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ],
    "institution": "DeepMind, OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2510.25529v1",
    "abstract": "Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.",
    "fetched_at": "2025-11-05T02:19:02.085195Z"
  },
  {
    "id": "2510.25572v2",
    "title": "On the instability of local learning algorithms: Q-learning can fail in   infinite state spaces",
    "date": "2025-10-29",
    "tags": [
      "math.PR",
      "PR"
    ],
    "authors": [
      "Urtzi Ayesta",
      "Sergey Foss",
      "Matthieu Jonckheere",
      "Vittorio Puricelli"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25572v2",
    "abstract": "We investigate the challenges of applying model-free reinforcement learning algorithms, like online Q-learning, to infinite state space Markov Decision Processes (MDPs). We first introduce the notion of Local Learning Processes (LLPs), where agents make decisions based solely on local information, and we show that Q-learning can be seen as a specific instance of an LLP. Using renewal techniques, we analyze LLPs and demonstrate their instability under certain drift and initial conditions, revealing fundamental limitations in infinite state spaces. In particular, we show that while asymptotically optimal in finite settings, Q-learning can face instability and strict sub-optimality in infinite spaces. Our findings are illustrated through queueing system examples drawn from load balancing and server allocation. The study underscores the need for new theoretical frameworks and suggests future research into nonlocal Q-learning variants.",
    "fetched_at": "2025-11-05T02:19:02.085132Z"
  },
  {
    "id": "2510.25650v1",
    "title": "Collision avoidance and path finding in a robotic mobile fulfillment   system using multi-objective meta-heuristics",
    "date": "2025-10-29",
    "tags": [
      "cs.RO",
      "RO",
      "math.OC",
      "OC"
    ],
    "authors": [
      "Ahmad Kokhahi",
      "Mary Kurz"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.25650v1",
    "abstract": "Multi-Agent Path Finding (MAPF) has gained significant attention, with most research focusing on minimizing collisions and travel time. This paper also considers energy consumption in the path planning of automated guided vehicles (AGVs). It addresses two main challenges: i) resolving collisions between AGVs and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy that takes both energy use and travel time into account. For task assignment, we present two multi-objective algorithms: Non-Dominated Sorting Genetic Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative evaluations show that these proposed methods perform better than existing approaches in both collision avoidance and task assignment.",
    "fetched_at": "2025-11-05T02:19:02.084959Z"
  },
  {
    "id": "2510.25679v1",
    "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement   Learning",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "physics.flu-dyn",
      "flu-dyn"
    ],
    "authors": [
      "Federica Tonti",
      "Ricardo Vinuesa"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25679v1",
    "abstract": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for delivery and surveillance purposes. In this work, we develop an optimal navigation strategy based on Deep Reinforcement Learning. The environment is represented by a three-dimensional high-fidelity simulation of an urban flow, characterized by turbulence and recirculation zones. The algorithm presented here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture, giving the agent richer information about the turbulent flow field in which it navigates. The results are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO combined with Long Short Term Memory (LSTM) cells and a traditional navigation algorithm. The obtained results show a significant increase in the success rate (SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the classical Zermelo's navigation algorithm, paving the way to a completely reimagined UAV landscape in complex urban environments.",
    "fetched_at": "2025-11-05T02:19:02.084864Z"
  },
  {
    "id": "2510.25889v1",
    "title": "$π_\\texttt{RL}$: Online RL Fine-tuning for Flow-based   Vision-Language-Action Models",
    "date": "2025-10-29",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Kang Chen",
      "Zhihao Liu",
      "Tonghe Zhang",
      "Zhen Guo",
      "Si Xu",
      "Hao Lin",
      "Hongzhi Zang",
      "Quanlu Zhang",
      "Zhaofei Yu",
      "Guoliang Fan",
      "Tiejun Huang",
      "Yu Wang",
      "Chao Yu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25889v1",
    "abstract": "Vision-Language-Action (VLA) models enable robots to understand and perform complex tasks from multimodal input. Although recent work explores using reinforcement learning (RL) to automate the laborious data collection process in scaling supervised fine-tuning (SFT), applying large-scale RL to flow-based VLAs (e.g., $\\pi_0$, $\\pi_{0.5}$) remains challenging due to intractable action log-likelihoods from iterative denoising.   We address this challenge with $\\pi_{\\text{RL}}$, an open-source framework for training flow-based VLAs in parallel simulation. $\\pi_{\\text{RL}}$ implements two RL algorithms: (1) {Flow-Noise} models the denoising process as a discrete-time MDP with a learnable noise network for exact log-likelihood computation. (2) {Flow-SDE} integrates denoising with agent-environment interaction, formulating a two-layer MDP that employs ODE-to-SDE conversion for efficient RL exploration.   We evaluate $\\pi_{\\text{RL}}$ on LIBERO and ManiSkill benchmarks. On LIBERO, $\\pi_{\\text{RL}}$ boosts few-shot SFT models $\\pi_0$ and $\\pi_{0.5}$ from 57.6% to 97.6% and from 77.1% to 98.3%, respectively. In ManiSkill, we train $\\pi_{\\text{RL}}$ in 320 parallel environments, improving $\\pi_0$ from 41.6% to 85.7% and $\\pi_{0.5}$ from 40.0% to 84.8% across 4352 pick-and-place tasks, demonstrating scalable multitask RL under heterogeneous simulation.   Overall, $\\pi_{\\text{RL}}$ achieves significant performance gains and stronger generalization over SFT-models, validating the effectiveness of online RL for flow-based VLAs.",
    "fetched_at": "2025-11-05T02:19:02.084653Z"
  },
  {
    "id": "2510.25929v1",
    "title": "Multi-Agent Reinforcement Learning for Market Making: Competition   without Collusion",
    "date": "2025-10-29",
    "tags": [
      "cs.MA",
      "MA",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ziyi Wang",
      "Carmine Ventre",
      "Maria Polukarov"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25929v1",
    "abstract": "Algorithmic collusion has emerged as a central question in AI: Will the interaction between different AI agents deployed in markets lead to collusion? More generally, understanding how emergent behavior, be it a cartel or market dominance from more advanced bots, affects the market overall is an important research question.   We propose a hierarchical multi-agent reinforcement learning framework to study algorithmic collusion in market making. The framework includes a self-interested market maker (Agent~A), which is trained in an uncertain environment shaped by an adversary, and three bottom-layer competitors: the self-interested Agent~B1 (whose objective is to maximize its own PnL), the competitive Agent~B2 (whose objective is to minimize the PnL of its opponent), and the hybrid Agent~B$^\\star$, which can modulate between the behavior of the other two. To analyze how these agents shape the behavior of each other and affect market outcomes, we propose interaction-level metrics that quantify behavioral asymmetry and system-level dynamics, while providing signals potentially indicative of emergent interaction patterns.   Experimental results show that Agent~B2 secures dominant performance in a zero-sum setting against B1, aggressively capturing order flow while tightening average spreads, thus improving market execution efficiency. In contrast, Agent~B$^\\star$ exhibits a self-interested inclination when co-existing with other profit-seeking agents, securing dominant market share through adaptive quoting, yet exerting a milder adverse impact on the rewards of Agents~A and B1 compared to B2. These findings suggest that adaptive incentive control supports more sustainable strategic co-existence in heterogeneous agent environments and offers a structured lens for evaluating behavioral design in algorithmic trading systems.",
    "fetched_at": "2025-11-05T02:19:02.084512Z"
  },
  {
    "id": "2510.25951v1",
    "title": "Estimating cognitive biases with attention-aware inverse planning",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Sounak Banerjee",
      "Daphne Cornelisse",
      "Deepak Gopinath",
      "Emily Sumner",
      "Jonathan DeCastro",
      "Guy Rosman",
      "Eugene Vinitsky",
      "Mark K. Ho"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25951v1",
    "abstract": "People's goal-directed behaviors are influenced by their cognitive biases, and autonomous systems that interact with people should be aware of this. For example, people's attention to objects in their environment will be biased in a way that systematically affects how they perform everyday tasks such as driving to work. Here, building on recent work in computational cognitive science, we formally articulate the attention-aware inverse planning problem, in which the goal is to estimate a person's attentional biases from their actions. We demonstrate how attention-aware inverse planning systematically differs from standard inverse reinforcement learning and how cognitive biases can be inferred from behavior. Finally, we present an approach to attention-aware inverse planning that combines deep reinforcement learning with computational cognitive modeling. We use this approach to infer the attentional strategies of RL agents in real-life driving scenarios selected from the Waymo Open Dataset, demonstrating the scalability of estimating cognitive biases with attention-aware inverse planning.",
    "fetched_at": "2025-11-05T02:19:02.084462Z"
  },
  {
    "id": "2510.25092v1",
    "title": "SeeingEye: Agentic Information Flow Unlocks Multimodal Reasoning In   Text-only LLMs",
    "date": "2025-10-29",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Weijia Zhang",
      "Zijia Liu",
      "Haoru Li",
      "Haoqi Chen",
      "Jiaxuan You"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25092v1",
    "abstract": "Recent advances in text-only large language models (LLMs), such as DeepSeek-R1, demonstrate remarkable reasoning ability. However, these models remain fragile or entirely incapable when extended to multi-modal tasks. Existing approaches largely rely on single-form captions, which lack diversity and often fail to adapt across different types of Visual Question Answering (VQA) benchmarks. As a result, they provide no principled or efficient channel for transmitting fine-grained visual information. We introduce Seeing Eye, a modular framework that unlocks multimodal reasoning in text-only LLMs through an agent-based small VLM translator. This translator acts as a perception agent: it can invoke specialized tools (e.g., OCR and crop) and iteratively distill multimodal inputs into structured intermediate representations (SIRs) tailored to the question. These SIRs are then passed to the text-only LLM, which serves as a reasoning agent. Crucially, the translator and reasoner engage in multi-round feedback and interaction, enabling the extraction of targeted visual details and yielding more confident answers. Experiments on knowledge-intensive VQA benchmarks, including MMMU and MIA-Bench, demonstrate that Seeing Eye not only reduces inference cost but also surpasses much larger end-to-end VLMs. For example, an instantiation combining a 3B-parameter vision translator with an 8B-parameter language reasoner outperforms a monolithic 32B VLM on challenging knowledge-based questions. Our results highlight that decoupling perception from reasoning via agent information flow offers a scalable and plug-and-play pathway to multimodal reasoning, allowing strong text-only LLMs to fully leverage their reasoning capabilities. Code is available at: https://github.com/ulab-uiuc/SeeingEye",
    "fetched_at": "2025-11-05T02:19:00.099233Z"
  },
  {
    "id": "2510.25101v1",
    "title": "KnowCoder-A1: Incentivizing Agentic Reasoning Capability with Outcome   Supervision for KBQA",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zhuo Chen",
      "Fei Wang",
      "Zixuan Li",
      "Zhao Zhang",
      "Weiwei Ding",
      "Chuanguang Yang",
      "Yongjun Xu",
      "Xiaolong Jin",
      "Jiafeng Guo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25101v1",
    "abstract": "Knowledge Base Question Answering (KBQA) aims to answer natural-language questions over a structured Knowledge Base (KB). Recent work improves KBQA by adopting an agentic reasoning paradigm, in which Large Language Models (LLMs) iteratively decompose a question, generate its corresponding logical queries, and interact with the KB to derive the answer. However, these methods typically fine-tune LLMs on reasoning trajectories synthesized via process supervision, which offers weak incentives for exploration and thus fails to strengthen the agentic reasoning ability. In this paper, we propose KnowCoder-A1, an LLM that can autonomously perform agentic reasoning on KBs to obtain answers. To incentivize autonomous exploration, KnowCoder-A1 trains the LLM under outcome-only supervision via a multi-stage curriculum reinforcement learning with an easy-to-hard curriculum. To establish foundational agentic capabilities, KnowCoder-A1 first fine-tunes the LLM on a small set of high-quality trajectories obtained through outcome-based rejection sampling. Then, to alleviate the reward sparsity inherent in outcome-only supervision, it applies multi-stage curriculum RL with reward schedules that progress from easy to hard. Trained with outcome-only supervision, KnowCoder-A1 exhibits powerful reasoning behaviors and consistently outperforms prior approaches across three mainstream datasets. Notably, on the zero-shot subset of GrailQA, KnowCoder-A1 achieves up to an 11.1% relative improvement while using only one-twelfth of the training data, demonstrating strong agentic reasoning capabilities.",
    "fetched_at": "2025-11-05T02:19:00.099178Z"
  },
  {
    "id": "2510.25110v1",
    "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in   Multi-Agent, Long-Form Debates",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yun-Shiuan Chuang",
      "Ruixuan Tu",
      "Chengtao Dai",
      "Smit Vasani",
      "Binwei Yao",
      "Michael Henry Tessler",
      "Sijia Yang",
      "Dhavan Shah",
      "Robert Hawkins",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25110v1",
    "abstract": "Accurately modeling opinion change through social interactions is crucial for addressing issues like misinformation and polarization. While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics. Current LLM role-play setups often produce unnatural dynamics (e.g., premature convergence), without an empirical benchmark to measure authentic human opinion trajectories. To bridge this gap, we introduce DEBATE, the first large-scale empirical benchmark explicitly designed to evaluate the authenticity of the interaction between multi-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions. Using DEBATE, we systematically evaluate and identify critical discrepancies between simulated and authentic group dynamics. We further demonstrate DEBATE's utility for aligning LLMs with human behavior through supervised fine-tuning, achieving improvements in surface-level metrics (e.g., ROUGE-L and message length) while highlighting limitations in deeper semantic alignment (e.g., semantic similarity). Our findings highlight both the potential and current limitations of role-playing LLM agents for realistically simulating human-like social dynamics.",
    "fetched_at": "2025-11-05T02:19:00.099107Z"
  },
  {
    "id": "2510.25160v2",
    "title": "Model-Document Protocol for AI Search",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Hongjin Qian",
      "Zheng Liu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25160v2",
    "abstract": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.   We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.   As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
    "fetched_at": "2025-11-05T02:19:00.099029Z"
  },
  {
    "id": "2510.25179v1",
    "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Juan Ren",
      "Mark Dras",
      "Usman Naseem"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25179v1",
    "abstract": "Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by introducing Agentic Moderation, a model-agnostic framework that leverages specialised agents to defend multimodal systems against jailbreak attacks. Unlike prior approaches that apply as a static layer over inputs or outputs and provide only binary classifications (safe or unsafe), our method integrates dynamic, cooperative agents, including Shield, Responder, Evaluator, and Reflector, to achieve context-aware and interpretable moderation. Extensive experiments across five datasets and four representative Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF), and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable, and well-balanced safety performance. By harnessing the flexibility and reasoning capacity of agentic architectures, Agentic Moderation provides modular, scalable, and fine-grained safety enforcement, highlighting the broader potential of agentic systems as a foundation for automated safety governance.",
    "fetched_at": "2025-11-05T02:19:00.098967Z"
  },
  {
    "id": "2510.25189v1",
    "title": "AgentCyTE: Leveraging Agentic AI to Generate Cybersecurity Training &   Experimentation Scenarios",
    "date": "2025-10-29",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "Ana M. Rodriguez",
      "Jaime Acosta",
      "Anantaa Kotal",
      "Aritran Piplai"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25189v1",
    "abstract": "Designing realistic and adaptive networked threat scenarios remains a core challenge in cybersecurity research and training, still requiring substantial manual effort. While large language models (LLMs) show promise for automated synthesis, unconstrained generation often yields configurations that fail validation or execution. We present AgentCyTE, a framework integrating LLM-based reasoning with deterministic, schema-constrained network emulation to generate and refine executable threat environments. Through an agentic feedback loop, AgentCyTE observes scenario outcomes, validates correctness, and iteratively enhances realism and consistency. This hybrid approach preserves LLM flexibility while enforcing structural validity, enabling scalable, data-driven experimentation and reliable scenario generation for threat modeling and adaptive cybersecurity training. Our framework can be accessed at: https://github.com/AnantaaKotal/AgentCyTE",
    "fetched_at": "2025-11-05T02:19:00.098923Z"
  },
  {
    "id": "2510.25223v2",
    "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of   Industrial Event Log Data",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kun Ouyang",
      "Haoyu Wang",
      "Dong Fang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25223v2",
    "abstract": "Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.",
    "fetched_at": "2025-11-05T02:19:00.098879Z"
  },
  {
    "id": "2510.25224v1",
    "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents   in multi-party negotiation",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ziyi Liu",
      "Bahar Sarrafzadeh",
      "Pei Zhou",
      "Longqi Yang",
      "Jieyu Zhao",
      "Ashish Sharma"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25224v1",
    "abstract": "While Large Language Models (LLMs) are increasingly used in agentic frameworks to assist individual users, there is a growing need for agents that can proactively manage complex, multi-party collaboration. Systematic evaluation methods for such proactive agents remain scarce, limiting progress in developing AI that can effectively support multiple people together. Negotiation offers a demanding testbed for this challenge, requiring socio-cognitive intelligence to navigate conflicting interests between multiple participants and multiple topics and build consensus. Here, we present ProMediate, the first framework for evaluating proactive AI mediator agents in complex, multi-topic, multi-party negotiations. ProMediate consists of two core components: (i) a simulation testbed based on realistic negotiation cases and theory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and ProMediate-Hard), with a plug-and-play proactive AI mediator grounded in socio-cognitive mediation theories, capable of flexibly deciding when and how to intervene; and (ii) a socio-cognitive evaluation framework with a new suite of metrics to measure consensus changes, intervention latency, mediator effectiveness, and intelligence. Together, these components establish a systematic framework for assessing the socio-cognitive intelligence of proactive AI agents in multi-party settings. Our results show that a socially intelligent mediator agent outperforms a generic baseline, via faster, better-targeted interventions. In the ProMediate-Hard setting, our social mediator increases consensus change by 3.6 percentage points compared to the generic baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response (15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous, theory-grounded testbed to advance the development of proactive, socially intelligent agents.",
    "fetched_at": "2025-11-05T02:19:00.098829Z"
  },
  {
    "id": "2510.25320v1",
    "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement   Learning",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jiaqi Wu",
      "Qinlao Zhao",
      "Zefeng Chen",
      "Kai Qin",
      "Yifei Zhao",
      "Xueqian Wang",
      "Yuhang Yao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25320v1",
    "abstract": "Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: https://github.com/WJQ7777/Graph-Agent-Planning.",
    "fetched_at": "2025-11-05T02:19:00.098764Z"
  },
  {
    "id": "2510.25333v1",
    "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared   Memories",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yilong Lai",
      "Yipin Yang",
      "Jialong Wu",
      "Fengran Mo",
      "Zhenglin Wang",
      "Ting Liang",
      "Jianguo Lin",
      "Keping Yang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25333v1",
    "abstract": "Recent years have witnessed the rapid development of LLM-based agents, which shed light on using language agents to solve complex real-world problems. A prominent application lies in business agents, which interact with databases and internal knowledge bases via tool calls to fulfill diverse user requirements. However, this domain is characterized by intricate data relationships and a wide range of heterogeneous tasks, from statistical data queries to knowledge-based question-answering. To address these challenges, we propose CRMWeaver, a novel approach that enhances business agents in such complex settings. To acclimate the agentic model to intricate business environments, we employ a synthesis data generation and RL-based paradigm during training, which significantly improves the model's ability to handle complex data and varied tasks. During inference, a shared memories mechanism is introduced, prompting the agent to learn from task guidelines in similar problems, thereby further boosting its effectiveness and generalization, especially in unseen scenarios. We validate the efficacy of our approach on the CRMArena-Pro dataset, where our lightweight model achieves competitive results in both B2B and B2C business scenarios, underscoring its practical value for real-world applications.",
    "fetched_at": "2025-11-05T02:19:00.098702Z"
  },
  {
    "id": "2510.25381v2",
    "title": "CGM-Led Multimodal Tracking with Chatbot Support: An Autoethnography in   Sub-Health",
    "date": "2025-10-29",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Dongyijie Primo Pan",
      "Lan Luo",
      "Yike Wang",
      "Pan Hui"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.25381v2",
    "abstract": "Metabolic disorders present a pressing global health challenge, with China carrying the world's largest burden. While continuous glucose monitoring (CGM) has transformed diabetes care, its potential for supporting sub-health populations -- such as individuals who are overweight, prediabetic, or anxious -- remains underexplored. At the same time, large language models (LLMs) are increasingly used in health coaching, yet CGM is rarely incorporated as a first-class signal. To address this gap, we conducted a six-week autoethnography, combining CGM with multimodal indicators captured via common digital devices and a chatbot that offered personalized reflections and explanations of glucose fluctuations. Our findings show how CGM-led, data-first multimodal tracking, coupled with conversational support, shaped everyday practices of diet, activity, stress, and wellbeing. This work contributes to HCI by extending CGM research beyond clinical diabetes and demonstrating how LLM-driven agents can support preventive health and reflection in at-risk populations.",
    "fetched_at": "2025-11-05T02:19:00.098641Z"
  },
  {
    "id": "2510.25421v1",
    "title": "Small Talk, Big Impact? LLM-based Conversational Agents to Mitigate   Passive Fatigue in Conditional Automated Driving",
    "date": "2025-10-29",
    "tags": [
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Lewis Cockram",
      "Yueteng Yu",
      "Jorge Pardo",
      "Xiaomeng Li",
      "Andry Rakotonirainy",
      "Jonny Kuo",
      "Sebastien Demmel",
      "Mike Lenné",
      "Ronald Schroeter"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25421v1",
    "abstract": "Passive fatigue during conditional automated driving can compromise driver readiness and safety. This paper presents findings from a test-track study with 40 participants in a real-world rural automated driving scenario. In this scenario, a Large Language Model (LLM) based conversational agent (CA) was designed to check in with drivers and re-engage them with their surroundings. Drawing on in-car video recordings, sleepiness ratings and interviews, we analysed how drivers interacted with the agent and how these interactions shaped alertness. Users found the CA helpful for supporting vigilance during passive fatigue. Thematic analysis of acceptability further revealed three user preference profiles that implicate future intention to use CAs. Positioning empirically observed profiles within existing CA archetype frameworks highlights the need for adaptive design sensitive to diverse user groups. This work underscores the potential of CAs as proactive Human-Machine Interface (HMI) interventions, demonstrating how natural language can support context-aware interaction during automated driving.",
    "fetched_at": "2025-11-05T02:19:00.098596Z"
  },
  {
    "id": "2510.25423v1",
    "title": "What Challenges Do Developers Face in AI Agent Systems? An Empirical   Study on Stack Overflow",
    "date": "2025-10-29",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Ali Asgari",
      "Annibale Panichella",
      "Pouria Derakhshanfar",
      "Mitchell Olsthoorn"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25423v1",
    "abstract": "AI agents have rapidly gained popularity across research and industry as systems that extend large language models with additional capabilities to plan, use tools, remember, and act toward specific goals. Yet despite their promise, developers face persistent and often underexplored challenges when building, deploying, and maintaining these emerging systems. To identify these challenges, we study developer discussions on Stack Overflow, the world's largest developer-focused Q and A platform with about 60 million questions and answers and 30 million users. We construct a taxonomy of developer challenges through tag expansion and filtering, apply LDA-MALLET for topic modeling, and manually validate and label the resulting themes. Our analysis reveals seven major areas of recurring issues encompassing 77 distinct technical challenges related to runtime integration, dependency management, orchestration complexity, and evaluation reliability. We further quantify topic popularity and difficulty to identify which issues are most common and hardest to resolve, map the tools and programming languages used in agent development, and track their evolution from 2021 to 2025 in relation to major AI model and framework releases. Finally, we present the implications of our results, offering concrete guidance for practitioners, researchers, and educators on agent reliability and developer support.",
    "fetched_at": "2025-11-05T02:19:00.098533Z"
  },
  {
    "id": "2510.25441v1",
    "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline   Logs",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Fei Wei",
      "Daoyuan Chen",
      "Ce Wang",
      "Yilun Huang",
      "Yushuo Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25441v1",
    "abstract": "Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn attributes or rely on brittle, high-cost user simulators, creating a persistent ``reality gap''. To bridge this gap, we introduce \\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and deploying proactive dialogue agents \\textit{directly from offline expert data}, bypassing the need to model complex user dynamics. Our key insight is to reframe the offline policy learning problem by leveraging the \\textbf{observed future} of each expert trajectory. This allows us to infer a dense, turn-by-turn reward signal grounded in the expert's revealed strategy, decomposing the intractable long-horizon problem into a series of supervised learning tasks, and training a policy to output a structured \\texttt{(action, state_assessment)} tuple, governing both \\textbf{what to ask} and, crucially, \\textbf{when to stop}. To ensure reward fidelity, our Automated Grader Calibration pipeline systematically purges noise from the LLM-based reward model with minimal human supervision. Empirically, we demonstrate the efficacy of \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying sizes up to 32B. Our approach culminates in the successful deployment of LLMs into a live, large-scale online AI service. In rigorous in-house evaluations, our model was launched and achieved performance even superior to human experts, proving our framework's ability to translate offline data into tangible, real-world impact. We hope this work provides a practical and economically viable blueprint for transforming passive LLMs into proactive, goal-oriented LLM applications.",
    "fetched_at": "2025-11-05T02:19:00.098484Z"
  },
  {
    "id": "2510.25588v1",
    "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM   Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Atmaram Yarlagadda",
      "Anita H. Clayton",
      "Preston Samuel",
      "Christopher K. Rhea",
      "Sachin Shetty"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2510.25588v1",
    "abstract": "The diagnosis of most mental disorders, including psychiatric evaluations, primarily depends on dialogues between psychiatrists and patients. This subjective process can lead to variability in diagnoses across clinicians and patients, resulting in inconsistencies and challenges in achieving reliable outcomes. To address these issues and standardize psychiatric diagnoses, we propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System for the clinical diagnosis of mental disorders. Our approach leverages fine-tuned LLMs trained on conversational datasets involving psychiatrist-patient interactions focused on mental health conditions (e.g., depression). The diagnostic predictions from individual models are aggregated through a consensus-based decision-making process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method for deploying LLM agents that orchestrate communication between the LLM consortium and the reasoning LLM, ensuring transparency, reliability, and responsible AI across the entire diagnostic workflow. Experimental results demonstrate the transformative potential of combining fine-tuned LLMs with a reasoning model to create a robust and highly accurate diagnostic system for mental health assessment. A prototype of the proposed platform, integrating three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia, USA. To the best of our knowledge, this work represents the first application of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical mental health diagnosis paving the way for next-generation AI-powered eHealth systems aimed at standardizing psychiatric diagnoses.",
    "fetched_at": "2025-11-05T02:19:00.098417Z"
  },
  {
    "id": "2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under   Information Asymmetry",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25595v1",
    "abstract": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "fetched_at": "2025-11-05T02:19:00.098355Z"
  },
  {
    "id": "2510.25612v1",
    "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Amit Giloni",
      "Chiara Picardi",
      "Roy Betser",
      "Shamik Bose",
      "Aishvariya Priya Rathina Sabapathy",
      "Roman Vainshtein"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25612v1",
    "abstract": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system, is an autonomous system that assembles several LLM-based agents to work collaboratively towards a shared goal. The high autonomy, widespread adoption, and growing interest in such AAWs highlight the need for a deeper understanding of their operations, from both quality and security aspects. To this day, there are no existing methods to assess the influence of each agent on the AAW's final output. Adopting techniques from related fields is not feasible since existing methods perform only static structural analysis, which is unsuitable for inference time execution. We present Counterfactual-based Agent Influence Ranker (CAIR) - the first method for assessing the influence level of each agent on the AAW's output and determining which agents are the most influential. By performing counterfactual analysis, CAIR provides a task-agnostic analysis that can be used both offline and at inference time. We evaluate CAIR using an AAWs dataset of our creation, containing 30 different use cases with 230 different functionalities. Our evaluation showed that CAIR produces consistent rankings, outperforms baseline methods, and can easily enhance the effectiveness and relevancy of downstream tasks.",
    "fetched_at": "2025-11-05T02:19:00.098292Z"
  },
  {
    "id": "2510.25616v1",
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD   Generalization",
    "date": "2025-10-29",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Nikita Kachaev",
      "Mikhail Kolosov",
      "Daniil Zelezetsky",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25616v1",
    "abstract": "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: https://blind-vla-paper.github.io",
    "fetched_at": "2025-11-05T02:19:00.098233Z"
  },
  {
    "id": "2510.25668v1",
    "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence   Gathering in Long Documents",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MM",
      "MM"
    ],
    "authors": [
      "Tianyu Yang",
      "Terry Ruas",
      "Yijun Tian",
      "Jan Philip Wahle",
      "Daniel Kurzawe",
      "Bela Gipp"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25668v1",
    "abstract": "Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.",
    "fetched_at": "2025-11-05T02:19:00.098179Z"
  },
  {
    "id": "2510.25694v1",
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in   Software Engineering Agents",
    "date": "2025-10-29",
    "tags": [
      "cs.SE",
      "SE",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Xin Zhang",
      "Yangning Li",
      "Di Yin",
      "Xing Sun",
      "Ying Shen",
      "Philip S. Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25694v1",
    "abstract": "Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.",
    "fetched_at": "2025-11-05T02:19:00.098119Z"
  },
  {
    "id": "2510.26832v1",
    "title": "Simulating hashtag dynamics with networked groups of generative agents",
    "date": "2025-10-29",
    "tags": [
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Abha Jha",
      "J. Hunter Priniski",
      "Carolyn Steinle",
      "Fred Morstatter"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.26832v1",
    "abstract": "Networked environments shape how information embedded in narratives influences individual and group beliefs and behavior. This raises key questions about how group communication around narrative media impacts belief formation and how such mechanisms contribute to the emergence of consensus or polarization. Language data from generative agents offer insight into how naturalistic forms of narrative interactions (such as hashtag generation) evolve in response to social rewards within networked communication settings. To investigate this, we developed an agent-based modeling and simulation framework composed of networks of interacting Large Language Model (LLM) agents. We benchmarked the simulations of four state-of-the-art LLMs against human group behaviors observed in a prior network experiment (Study 1) and against naturally occurring hashtags from Twitter (Study 2). Quantitative metrics of network coherence (e.g., entropy of a group's responses) reveal that while LLMs can approximate human-like coherence in sanitized domains (Study 1's experimental data), effective integration of background knowledge and social context in more complex or politically sensitive narratives likely requires careful and structured prompting.",
    "fetched_at": "2025-11-05T02:19:00.098050Z"
  },
  {
    "id": "2510.25743v1",
    "title": "Agentic Economic Modeling",
    "date": "2025-10-29",
    "tags": [
      "econ.EM",
      "EM"
    ],
    "authors": [
      "Bohan Zhang",
      "Jiaxuan Li",
      "Ali Hortaçsu",
      "Xiaoyang Ye",
      "Victor Chernozhukov",
      "Angelo Ni",
      "Edward Huang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25743v1",
    "abstract": "We introduce Agentic Economic Modeling (AEM), a framework that aligns synthetic LLM choices with small-sample human evidence for reliable econometric inference. AEM first generates task-conditioned synthetic choices via LLMs, then learns a bias-correction mapping from task features and raw LLM choices to human-aligned choices, upon which standard econometric estimators perform inference to recover demand elasticities and treatment effects.We validate AEM in two experiments. In a large scale conjoint study with millions of observations, using only 10% of the original data to fit the correction model lowers the error of the demand-parameter estimates, while uncorrected LLM choices even increase the errors. In a regional field experiment, a mixture model calibrated on 10% of geographic regions estimates an out-of-domain treatment effect of -65\\pm10 bps, closely matching the full human experiment (-60\\pm8 bps).Under time-wise extrapolation, training with only day-one human data yields -24 bps (95% CI: [-26, -22], p<1e-5),improving over the human-only day-one baseline (-17 bps, 95% CI: [-43, +9], p=0.2049).These results demonstrate AEM's potential to improve RCT efficiency and establish a foundation method for LLM-based counterfactual generation.",
    "fetched_at": "2025-11-05T02:19:00.097964Z"
  },
  {
    "id": "2510.25758v1",
    "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological   Counseling",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Chiyuan Ma",
      "Qianning Wang",
      "Zheng Zhang",
      "Fei Ma",
      "Laizhong Cui",
      "Qi Tian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25758v1",
    "abstract": "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at https://0mwwm0.github.io/TheraMind/.",
    "fetched_at": "2025-11-05T02:19:00.097907Z"
  },
  {
    "id": "2510.25850v1",
    "title": "Debate2Create: Robot Co-design via Large Language Model Debates",
    "date": "2025-10-29",
    "tags": [
      "cs.RO",
      "RO",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kevin Qiu",
      "Marek Cygan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25850v1",
    "abstract": "Automating the co-design of a robot's morphology and control is a long-standing challenge due to the vast design space and the tight coupling between body and behavior. We introduce Debate2Create (D2C), a framework in which large language model (LLM) agents engage in a structured dialectical debate to jointly optimize a robot's design and its reward function. In each round, a design agent proposes targeted morphological modifications, and a control agent devises a reward function tailored to exploit the new design. A panel of pluralistic judges then evaluates the design-control pair in simulation and provides feedback that guides the next round of debate. Through iterative debates, the agents progressively refine their proposals, producing increasingly effective robot designs. Notably, D2C yields diverse and specialized morphologies despite no explicit diversity objective. On a quadruped locomotion benchmark, D2C discovers designs that travel 73% farther than the default, demonstrating that structured LLM-based debate can serve as a powerful mechanism for emergent robot co-design. Our results suggest that multi-agent debate, when coupled with physics-grounded feedback, is a promising new paradigm for automated robot design.",
    "fetched_at": "2025-11-05T02:19:00.097843Z"
  },
  {
    "id": "2510.25863v2",
    "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI",
    "date": "2025-10-29",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ken Huang",
      "Kyriakos Rock Lambros",
      "Jerry Huang",
      "Yasir Mehmood",
      "Hammad Atta",
      "Joshua Beck",
      "Vineeth Sai Narajala",
      "Muhammad Zeeshan Baig",
      "Muhammad Aziz Ul Haq",
      "Nadeem Shahzad",
      "Bhavya Gupta"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25863v2",
    "abstract": "This paper introduces the Agentic AI Governance Assurance & Trust Engine (AAGATE), a Kubernetes-native control plane designed to address the unique security and governance challenges posed by autonomous, language-model-driven agents in production. Recognizing the limitations of traditional Application Security (AppSec) tooling for improvisational, machine-speed systems, AAGATE operationalizes the NIST AI Risk Management Framework (AI RMF). It integrates specialized security frameworks for each RMF function: the Agentic AI Threat Modeling MAESTRO framework for Map, a hybrid of OWASP's AIVSS and SEI's SSVC for Measure, and the Cloud Security Alliance's Agentic AI Red Teaming Guide for Manage. By incorporating a zero-trust service mesh, an explainable policy engine, behavioral analytics, and decentralized accountability hooks, AAGATE provides a continuous, verifiable governance solution for agentic AI, enabling safe, accountable, and scalable deployment. The framework is further extended with DIRF for digital identity rights, LPCI defenses for logic-layer injection, and QSAF monitors for cognitive degradation, ensuring governance spans systemic, adversarial, and ethical risks.",
    "fetched_at": "2025-11-05T02:19:00.097802Z"
  },
  {
    "id": "2510.25914v1",
    "title": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Ngoc Phuoc An Vo",
      "Manish Kesarwani",
      "Ruchi Mahindru",
      "Chandrasekhar Narayanaswami"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25914v1",
    "abstract": "FinOps (Finance + Operations) represents an operational framework and cultural practice which maximizes cloud business value through collaborative financial accountability across engineering, finance, and business teams. FinOps practitioners face a fundamental challenge: billing data arrives in heterogeneous formats, taxonomies, and metrics from multiple cloud providers and internal systems which eventually lead to synthesizing actionable insights, and making time-sensitive decisions. To address this challenge, we propose leveraging autonomous, goal-driven AI agents for FinOps automation. In this paper, we built a FinOps agent for a typical use-case for IT infrastructure and cost optimization. We built a system simulating a realistic end-to-end industry process starting with retrieving data from various sources to consolidating and analyzing the data to generate recommendations for optimization. We defined a set of metrics to evaluate our agent using several open-source and close-source language models and it shows that the agent was able to understand, plan, and execute tasks as well as an actual FinOps practitioner.",
    "fetched_at": "2025-11-05T02:19:00.097728Z"
  },
  {
    "id": "2510.25941v1",
    "title": "RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic   Pipeline",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL",
      "I.2",
      "2"
    ],
    "authors": [
      "André V. Duarte",
      "Xuying li",
      "Bin Zeng",
      "Arlindo L. Oliveira",
      "Lei Li",
      "Zhuo Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25941v1",
    "abstract": "If we cannot inspect the training data of a large language model (LLM), how can we ever know what it has seen? We believe the most compelling evidence arises when the model itself freely reproduces the target content. As such, we propose RECAP, an agentic pipeline designed to elicit and verify memorized training data from LLM outputs. At the heart of RECAP is a feedback-driven loop, where an initial extraction attempt is evaluated by a secondary language model, which compares the output against a reference passage and identifies discrepancies. These are then translated into minimal correction hints, which are fed back into the target model to guide subsequent generations. In addition, to address alignment-induced refusals, RECAP includes a jailbreaking module that detects and overcomes such barriers. We evaluate RECAP on EchoTrace, a new benchmark spanning over 30 full books, and the results show that RECAP leads to substantial gains over single-iteration approaches. For instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text extraction improved from 0.38 to 0.47 - a nearly 24% increase.",
    "fetched_at": "2025-11-05T02:19:00.097678Z"
  },
  {
    "id": "2510.25992v1",
    "title": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise   Reasoning",
    "date": "2025-10-29",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yihe Deng",
      "I-Hung Hsu",
      "Jun Yan",
      "Zifeng Wang",
      "Rujun Han",
      "Gufeng Zhang",
      "Yanfei Chen",
      "Wei Wang",
      "Tomas Pfister",
      "Chen-Yu Lee"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.25992v1",
    "abstract": "Large Language Models (LLMs) often struggle with problems that require multi-step reasoning. For small-scale open-source models, Reinforcement Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to overfit long demonstrations through rigid token-by-token imitation. To address this gap, we propose Supervised Reinforcement Learning (SRL), a framework that reformulates problem solving as generating a sequence of logical \"actions\". SRL trains the model to generate an internal reasoning monologue before committing to each action. It provides smoother rewards based on the similarity between the model's actions and expert actions extracted from the SFT dataset in a step-wise manner. This supervision offers richer learning signals even when all rollouts are incorrect, while encouraging flexible reasoning guided by expert demonstrations. As a result, SRL enables small models to learn challenging problems previously unlearnable by SFT or RLVR. Moreover, initializing training with SRL before refining with RLVR yields the strongest overall performance. Beyond reasoning benchmarks, SRL generalizes effectively to agentic software engineering tasks, establishing it as a robust and versatile training framework for reasoning-oriented LLMs.",
    "fetched_at": "2025-11-05T02:19:00.097624Z"
  },
  {
    "id": "2510.25997v1",
    "title": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal   Text-to-SQL",
    "date": "2025-10-29",
    "tags": [
      "cs.AI",
      "AI",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Manu Redd",
      "Tao Zhe",
      "Dongjie Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.25997v1",
    "abstract": "Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing access to structured data, allowing users to query databases without learning SQL. Yet existing systems struggle with realistic spatio-temporal queries, where success requires aligning vague user phrasing with schema-specific categories, handling temporal reasoning, and choosing appropriate outputs. We present an agentic pipeline that extends a naive text-to-SQL baseline (llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The agent can plan, decompose, and adapt queries through schema inspection, SQL generation, execution, and visualization tools. We evaluate on 35 natural-language queries over the NYC and Tokyo check-in dataset, covering spatial, temporal, and multi-dataset reasoning. The agent achieves substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and enhances usability through maps, plots, and structured natural-language summaries. Crucially, our design enables more natural human-database interaction, supporting users who lack SQL expertise, detailed schema knowledge, or prompting skill. We conclude that agentic orchestration, rather than stronger SQL generators alone, is a promising foundation for interactive geospatial assistants.",
    "fetched_at": "2025-11-05T02:19:00.097554Z"
  },
  {
    "id": "2510.24698v1",
    "title": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Baixuan Li",
      "Dingchu Zhang",
      "Jialong Wu",
      "Wenbiao Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liwen Zhang",
      "Haiyang Shen",
      "Runnan Fang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24698v1",
    "abstract": "Parallel thinking expands exploration breadth, complementing the deep exploration of information-seeking (IS) agents to further enhance problem-solving capability. However, conventional parallel thinking faces two key challenges in this setting: inefficiency from repeatedly rolling out from scratch, and difficulty in integrating long-horizon reasoning trajectories during answer generation, as limited context capacity prevents full consideration of the reasoning process. To address these issues, we propose ParallelMuse, a two-stage paradigm designed for deep IS agents. The first stage, Functionality-Specified Partial Rollout, partitions generated sequences into functional regions and performs uncertainty-guided path reuse and branching to enhance exploration efficiency. The second stage, Compressed Reasoning Aggregation, exploits reasoning redundancy to losslessly compress information relevant to answer derivation and synthesize a coherent final answer. Experiments across multiple open-source agents and benchmarks demonstrate up to 62% performance improvement with a 10--30% reduction in exploratory token consumption.",
    "fetched_at": "2025-10-29T10:17:29.261795Z"
  },
  {
    "id": "2510.24700v1",
    "title": "Greedy Sampling Is Provably Efficient for RLHF",
    "date": "2025-10-28",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.IT",
      "IT",
      "math.IT",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Di Wu",
      "Chengshuai Shi",
      "Jing Yang",
      "Cong Shen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24700v1",
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has emerged as a key technique for post-training large language models. Despite its empirical success, the theoretical understanding of RLHF is still limited, as learning the KL-regularized target with only preference feedback poses additional challenges compared with canonical RL. Existing works mostly study the reward-based Bradley-Terry (BT) preference model, and extend classical designs utilizing optimism or pessimism. This work, instead, considers the general preference model (whose practical relevance has been observed recently) and obtains performance guarantees with major, order-wise improvements over existing ones. Surprisingly, these results are derived from algorithms that directly use the empirical estimates (i.e., greedy sampling), as opposed to constructing optimistic or pessimistic estimates in previous works. This insight has a deep root in the unique structural property of the optimal policy class under the KL-regularized target, and we further specialize it to the BT model, highlighting the surprising sufficiency of greedy sampling in RLHF.",
    "fetched_at": "2025-10-29T10:17:29.261725Z"
  },
  {
    "id": "2510.24706v1",
    "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality   Games?",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Shuqing Li",
      "Jiayi Yan",
      "Chenyu Niu",
      "Jen-tse Huang",
      "Yun Peng",
      "Wenxuan Wang",
      "Yepang Liu",
      "Michael R. Lyu"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2510.24706v1",
    "abstract": "Virtual Reality (VR) games require players to translate high-level semantic actions into precise device manipulations using controllers and head-mounted displays (HMDs). While humans intuitively perform this translation based on common sense and embodied understanding, whether Large Language Models (LLMs) can effectively replicate this ability remains underexplored. This paper introduces a benchmark, ComboBench, evaluating LLMs' capability to translate semantic actions into VR device manipulation sequences across 262 scenarios from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II, and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o, Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against annotated ground truth and human performance. Our results reveal that while top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition capabilities, they still struggle with procedural reasoning and spatial understanding compared to humans. Performance varies significantly across games, suggesting sensitivity to interaction complexity. Few-shot examples substantially improve performance, indicating potential for targeted enhancement of LLMs' VR manipulation capabilities. We release all materials at https://sites.google.com/view/combobench.",
    "fetched_at": "2025-10-29T10:17:29.261337Z"
  },
  {
    "id": "2510.24707v1",
    "title": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25   Evaluation Shared Task",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Juraj Juraska",
      "Tobias Domhan",
      "Mara Finkelstein",
      "Tetsuji Nakagawa",
      "Geza Kovacs",
      "Daniel Deutsch",
      "Pidong Wang",
      "Markus Freitag"
    ],
    "institution": "Google",
    "link": "http://arxiv.org/pdf/2510.24707v1",
    "abstract": "In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.",
    "fetched_at": "2025-10-29T10:17:29.261273Z"
  },
  {
    "id": "2510.24709v1",
    "title": "Does Object Binding Naturally Emerge in Large Pretrained Vision   Transformers?",
    "date": "2025-10-28",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "q-bio.NC",
      "NC"
    ],
    "authors": [
      "Yihao Li",
      "Saeed Salehi",
      "Lyle Ungar",
      "Konrad P. Kording"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24709v1",
    "abstract": "Object binding, the brain's ability to bind the many features that collectively represent an object into a coherent whole, is central to human cognition. It groups low-level perceptual features into high-level object representations, stores those objects efficiently and compositionally in memory, and supports human reasoning about individual object instances. While prior work often imposes object-centric attention (e.g., Slot Attention) explicitly to probe these benefits, it remains unclear whether this ability naturally emerges in pre-trained Vision Transformers (ViTs). Intuitively, they could: recognizing which patches belong to the same object should be useful for downstream prediction and thus guide attention. Motivated by the quadratic nature of self-attention, we hypothesize that ViTs represent whether two patches belong to the same object, a property we term IsSameObject. We decode IsSameObject from patch embeddings across ViT layers using a similarity probe, which reaches over 90% accuracy. Crucially, this object-binding capability emerges reliably in self-supervised ViTs (DINO, MAE, CLIP), but markedly weaker in ImageNet-supervised models, suggesting that binding is not a trivial architectural artifact, but an ability acquired through specific pretraining objectives. We further discover that IsSameObject is encoded in a low-dimensional subspace on top of object features, and that this signal actively guides attention. Ablating IsSameObject from model activations degrades downstream performance and works against the learning objective, implying that emergent object binding naturally serves the pretraining objective. Our findings challenge the view that ViTs lack object binding and highlight how symbolic knowledge of \"which parts belong together\" emerges naturally in a connectionist system.",
    "fetched_at": "2025-10-29T10:17:29.261210Z"
  },
  {
    "id": "2510.24710v1",
    "title": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel   Optimization",
    "date": "2025-10-28",
    "tags": [
      "math.OC",
      "OC",
      "cs.IT",
      "IT",
      "cs.LG",
      "LG",
      "math.IT",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Wei Shen",
      "Jiawei Zhang",
      "Minhui Huang",
      "Cong Shen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24710v1",
    "abstract": "We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\\epsilon^{-3}\\log(\\epsilon^{-1}))$ to $O(\\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.",
    "fetched_at": "2025-10-29T10:17:29.261151Z"
  },
  {
    "id": "2510.24718v1",
    "title": "Generative View Stitching",
    "date": "2025-10-28",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Chonghyuk Song",
      "Michal Stary",
      "Boyuan Chen",
      "George Kopanas",
      "Vincent Sitzmann"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24718v1",
    "abstract": "Autoregressive video diffusion models are capable of long rollouts that are stable and consistent with history, but they are unable to guide the current generation with conditioning from the future. In camera-guided video generation with a predefined camera trajectory, this limitation leads to collisions with the generated scene, after which autoregression quickly collapses. To address this, we propose Generative View Stitching (GVS), which samples the entire sequence in parallel such that the generated scene is faithful to every part of the predefined camera trajectory. Our main contribution is a sampling algorithm that extends prior work on diffusion stitching for robot planning to video generation. While such stitching methods usually require a specially trained model, GVS is compatible with any off-the-shelf video model trained with Diffusion Forcing, a prevalent sequence diffusion framework that we show already provides the affordances necessary for stitching. We then introduce Omni Guidance, a technique that enhances the temporal consistency in stitching by conditioning on both the past and future, and that enables our proposed loop-closing mechanism for delivering long-range coherence. Overall, GVS achieves camera-guided video generation that is stable, collision-free, frame-to-frame consistent, and closes loops for a variety of predefined camera paths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best viewed as videos at https://andrewsonga.github.io/gvs.",
    "fetched_at": "2025-10-29T10:17:29.261086Z"
  },
  {
    "id": "2510.24151v1",
    "title": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning   Questions from Semi-structured Data",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Bingsen Qiu",
      "Zijian Liu",
      "Xiao Liu",
      "Haoshen Yang",
      "Zeren Gao",
      "Bingjie Wang",
      "Feier Zhang",
      "Yixuan Qin",
      "Chunyan Li"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24151v1",
    "abstract": "Building training-ready multi-hop question answering (QA) datasets that truly stress a model's retrieval and reasoning abilities remains highly challenging recently. While there have been a few recent evaluation datasets that capture the characteristics of hard-to-search but easy-to-verify problems -- requiring the integration of ambiguous, indirect, and cross-domain cues -- these data resources remain scarce and are mostly designed for evaluation, making them unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL). Meanwhile, manually curating non-trivially retrievable questions -- where answers cannot be found through a single direct query but instead require multi-hop reasoning over oblique and loosely connected evidence -- incurs prohibitive human costs and fails to scale, creating a critical data bottleneck for training high-capability retrieval-and-reasoning agents.   To address this, we present an automated framework for generating high-difficulty, training-ready multi-hop questions from semi-structured knowledge sources. The system (i) grows diverse, logically labeled evidence clusters through Natural Language Inference (NLI)-based relation typing and diversity-aware expansion; (ii) applies reverse question construction to compose oblique cues so that isolated signals are underinformative but their combination uniquely identifies the target entity; and (iii) enforces quality with a two-step evaluation pipeline that combines multi-model consensus filtering with structured constraint decomposition and evidence-based matching. The result is a scalable process that yields complex, retrieval-resistant yet verifiable questions suitable for SFT/RL training as well as challenging evaluation, substantially reducing human curation effort while preserving the difficulty profile of strong evaluation benchmarks.",
    "fetched_at": "2025-10-29T10:17:26.629832Z"
  },
  {
    "id": "2510.24432v1",
    "title": "Fill in the Blanks: Accelerating Q-Learning with a Handful of   Demonstrations in Sparse Reward Settings",
    "date": "2025-10-28",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Seyed Mahdi Basiri Azad",
      "Joschka Boedecker"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24432v1",
    "abstract": "Reinforcement learning (RL) in sparse-reward environments remains a significant challenge due to the lack of informative feedback. We propose a simple yet effective method that uses a small number of successful demonstrations to initialize the value function of an RL agent. By precomputing value estimates from offline demonstrations and using them as targets for early learning, our approach provides the agent with a useful prior over promising actions. The agent then refines these estimates through standard online interaction. This hybrid offline-to-online paradigm significantly reduces the exploration burden and improves sample efficiency in sparse-reward settings. Experiments on benchmark tasks demonstrate that our method accelerates convergence and outperforms standard baselines, even with minimal or suboptimal demonstration data.",
    "fetched_at": "2025-10-29T10:17:26.629416Z"
  },
  {
    "id": "2510.24515v1",
    "title": "Stochastic Prize-Collecting Games: Strategic Planning in Multi-Robot   Systems",
    "date": "2025-10-28",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Malintha Fernando",
      "Petter Ögren",
      "Silun Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24515v1",
    "abstract": "The Team Orienteering Problem (TOP) generalizes many real-world multi-robot scheduling and routing tasks that occur in autonomous mobility, aerial logistics, and surveillance applications. While many flavors of the TOP exist for planning in multi-robot systems, they assume that all the robots cooperate toward a single objective; thus, they do not extend to settings where the robots compete in reward-scarce environments. We propose Stochastic Prize-Collecting Games (SPCG) as an extension of the TOP to plan in the presence of self-interested robots operating on a graph, under energy constraints and stochastic transitions. A theoretical study on complete and star graphs establishes that there is a unique pure Nash equilibrium in SPCGs that coincides with the optimal routing solution of an equivalent TOP given a rank-based conflict resolution rule. This work proposes two algorithms: Ordinal Rank Search (ORS) to obtain the ''ordinal rank'' --one's effective rank in temporarily-formed local neighborhoods during the games' stages, and Fictitious Ordinal Response Learning (FORL) to obtain best-response policies against one's senior-rank opponents. Empirical evaluations conducted on road networks and synthetic graphs under both dynamic and stationary prize distributions show that 1) the state-aliasing induced by OR-conditioning enables learning policies that scale more efficiently to large team sizes than those trained with the global index, and 2) Policies trained with FORL generalize better to imbalanced prize distributions than those with other multi-agent training methods. Finally, the learned policies in the SPCG achieved between 87% and 95% optimality compared to an equivalent TOP solution obtained by mixed-integer linear programming.",
    "fetched_at": "2025-10-29T10:17:26.629377Z"
  },
  {
    "id": "2510.24628v1",
    "title": "\"Mm, Wat?\" Detecting Other-initiated Repair Requests in Dialogue",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Anh Ngo",
      "Nicolas Rollet",
      "Catherine Pelachaud",
      "Chloe Clavel"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24628v1",
    "abstract": "Maintaining mutual understanding is a key component in human-human conversation to avoid conversation breakdowns, in which repair, particularly Other-Initiated Repair (OIR, when one speaker signals trouble and prompts the other to resolve), plays a vital role. However, Conversational Agents (CAs) still fail to recognize user repair initiation, leading to breakdowns or disengagement. This work proposes a multimodal model to automatically detect repair initiation in Dutch dialogues by integrating linguistic and prosodic features grounded in Conversation Analysis. The results show that prosodic cues complement linguistic features and significantly improve the results of pretrained text and audio embeddings, offering insights into how different features interact. Future directions include incorporating visual cues, exploring multilingual and cross-context corpora to assess the robustness and generalizability.",
    "fetched_at": "2025-10-29T10:17:26.629300Z"
  },
  {
    "id": "2510.24663v1",
    "title": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan   DAGs",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yifu Lu",
      "Shengjie Liu",
      "Li Dong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24663v1",
    "abstract": "Agentic tool use has gained traction with the rise of agentic tool calling, yet most existing work overlooks the complexity of multi-turn tool interactions. We introduce OrchDAG, a synthetic data generation pipeline that models tool execution as directed acyclic graphs (DAGs) with controllable complexity. Using this dataset, we benchmark model performance and propose a graph-based reward to enhance RLVR training. Experiments show that the dataset presents a challenging but solvable benchmark, and the proposed reward is effective when combined with GRPO-style algorithms, highlighting the importance of leveraging topological structure and data complexity in multi-turn tool use.",
    "fetched_at": "2025-10-29T10:17:26.629108Z"
  },
  {
    "id": "2510.24690v1",
    "title": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework   for In-Context Planning",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Shengjie Liu",
      "Li Dong",
      "Zhenyu Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24690v1",
    "abstract": "We present a framework for uncovering and exploiting dependencies among tools and documents to enhance exemplar artifact generation. Our method begins by constructing a tool knowledge graph from tool schemas,including descriptions, arguments, and output payloads, using a DeepResearch-inspired analysis. In parallel, we derive a complementary knowledge graph from internal documents and SOPs, which is then fused with the tool graph. To generate exemplar plans, we adopt a deep-sparse integration strategy that aligns structural tool dependencies with procedural knowledge. Experiments demonstrate that this unified framework effectively models tool interactions and improves plan generation, underscoring the benefits of linking tool graphs with domain knowledge graphs for tool-augmented reasoning and planning.",
    "fetched_at": "2025-10-29T10:17:26.629066Z"
  },
  {
    "id": "2510.24014v1",
    "title": "TEXT2DB: Integration-Aware Information Extraction with Large Language   Model Agents",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yizhu Jiao",
      "Sha Li",
      "Sizhe Zhou",
      "Heng Ji",
      "Jiawei Han"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24014v1",
    "abstract": "The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE TEXT2DB that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for what to extract and adapting to the given DB/KB schema for how to extract on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation. Source code: https://github.com/yzjiao/Text2DB",
    "fetched_at": "2025-10-29T10:17:25.314328Z"
  },
  {
    "id": "2510.24030v1",
    "title": "Human Machine Social Hybrid Intelligence:A Collaborative Decision Making   Framework for Large Model Agent Groups and Human Experts",
    "date": "2025-10-28",
    "tags": [
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Ahmet Akkaya Melih",
      "Yamuna Singh",
      "Kunal L. Agarwal",
      "Priya Mukherjee",
      "Kiran Pattnaik",
      "Hanuman Bhatia"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24030v1",
    "abstract": "The rapid advancements in large foundation models and multi-agent systems offer unprecedented capabilities, yet current Human-in-the-Loop (HiTL) paradigms inadequately integrate human expertise, often leading to cognitive overload and decision-making bottlenecks in complex, high-stakes environments. We propose the \"Human-Machine Social Hybrid Intelligence\" (HMS-HI) framework, a novel architecture designed for deep, collaborative decision-making between groups of human experts and LLM-powered AI agents. HMS-HI is built upon three core pillars: (1) a \\textbf{Shared Cognitive Space (SCS)} for unified, multi-modal situational awareness and structured world modeling; (2) a \\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns tasks to the most suitable agent (human or AI) based on capabilities and workload; and (3) a \\textbf{Cross-Species Trust Calibration (CSTC)} protocol that fosters transparency, accountability, and mutual adaptation through explainable declarations and structured feedback. Validated in a high-fidelity urban emergency response simulation, HMS-HI significantly reduced civilian casualties by 72\\% and cognitive load by 70\\% compared to traditional HiTL approaches, demonstrating superior decision quality, efficiency, and human-AI trust. An ablation study confirms the critical contribution of each module, highlighting that engineered trust and shared context are foundational for scalable, synergistic human-AI collaboration.",
    "fetched_at": "2025-10-29T10:17:25.314275Z"
  },
  {
    "id": "2510.24051v1",
    "title": "Pie: A Programmable Serving System for Emerging LLM Applications",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "In Gim",
      "Zhiyao Ma",
      "Seung-seob Lee",
      "Lin Zhong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24051v1",
    "abstract": "Emerging large language model (LLM) applications involve diverse reasoning strategies and agentic workflows, straining the capabilities of existing serving systems built on a monolithic token generation loop. This paper introduces Pie, a programmable LLM serving system designed for flexibility and efficiency. Pie decomposes the traditional generation loop into fine-grained service handlers exposed via an API and delegates control of the generation process to user-provided programs, called inferlets. This enables applications to implement new KV cache strategies, bespoke generation logic, and seamlessly integrate computation and I/O-entirely within the application, without requiring modifications to the serving system. Pie executes inferlets using WebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows Pie matches state-of-the-art performance on standard tasks (3-12% latency overhead) while significantly improving latency and throughput (1.3x-3.4x higher) on agentic workflows by enabling application-specific optimizations.",
    "fetched_at": "2025-10-29T10:17:25.314219Z"
  },
  {
    "id": "2510.24109v1",
    "title": "PFEA: An LLM-based High-Level Natural Language Planning and Feedback   Embodied Agent for Human-Centered AI",
    "date": "2025-10-28",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Wenbin Ding",
      "Jun Chen",
      "Mingjia Chen",
      "Fei Xie",
      "Qi Mao",
      "Philip Dames"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24109v1",
    "abstract": "The rapid advancement of Large Language Models (LLMs) has marked a significant breakthrough in Artificial Intelligence (AI), ushering in a new era of Human-centered Artificial Intelligence (HAI). HAI aims to better serve human welfare and needs, thereby placing higher demands on the intelligence level of robots, particularly in aspects such as natural language interaction, complex task planning, and execution. Intelligent agents powered by LLMs have opened up new pathways for realizing HAI. However, existing LLM-based embodied agents often lack the ability to plan and execute complex natural language control tasks online. This paper explores the implementation of intelligent robotic manipulating agents based on Vision-Language Models (VLMs) in the physical world. We propose a novel embodied agent framework for robots, which comprises a human-robot voice interaction module, a vision-language agent module and an action execution module. The vision-language agent itself includes a vision-based task planner, a natural language instruction converter, and a task performance feedback evaluator. Experimental results demonstrate that our agent achieves a 28\\% higher average task success rate in both simulated and real environments compared to approaches relying solely on LLM+CLIP, significantly improving the execution success rate of high-level natural language instruction tasks.",
    "fetched_at": "2025-10-29T10:17:25.314174Z"
  },
  {
    "id": "2510.24126v1",
    "title": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Vivek Kalyan",
      "Martin Andrews"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24126v1",
    "abstract": "Large Language Model (LLM) agents can leverage multiple turns and tools to solve complex tasks, with prompt-based approaches achieving strong performance. This work demonstrates that Reinforcement Learning (RL) can push capabilities significantly further by learning from experience. Through experiments on a legal document search benchmark, we show that our RL-trained 14 Billion parameter model outperforms frontier class models (85% vs 78% accuracy). In addition, we explore turn-restricted regimes, during training and at test-time, that show these agents achieve better results if allowed to operate over longer multi-turn horizons.",
    "fetched_at": "2025-10-29T10:17:25.314118Z"
  },
  {
    "id": "2510.24161v1",
    "title": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and   Cross-Embodiment Learning",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MM",
      "MM",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Wentao Tan",
      "Bowen Wang",
      "Heng Zhi",
      "Chenyu Liu",
      "Zhe Li",
      "Jian Liu",
      "Zengrong Lin",
      "Yukun Dai",
      "Yipeng Chen",
      "Wenjie Yang",
      "Enci Xie",
      "Hao Xue",
      "Baixu Ji",
      "Chen Xu",
      "Zhibin Wang",
      "Tianshi Wang",
      "Lei Zhu",
      "Heng Tao Shen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24161v1",
    "abstract": "Multimodal large language models (MLLMs) have advanced vision-language reasoning and are increasingly deployed in embodied agents. However, significant limitations remain: MLLMs generalize poorly across digital-physical spaces and embodiments; vision-language-action models (VLAs) produce low-level actions yet lack robust high-level embodied reasoning; and most embodied large language models (ELLMs) are constrained to digital-space with poor generalization to the physical world. Thus, unified models that operate seamlessly across digital and physical spaces while generalizing across embodiments and tasks remain absent. We introduce the \\textbf{Boundless Large Model (BLM$_1$)}, a multimodal spatial foundation model that preserves instruction following and reasoning, incorporates embodied knowledge, and supports robust cross-embodiment control. BLM$_1$ integrates three key capabilities -- \\textit{cross-space transfer, cross-task learning, and cross-embodiment generalization} -- via a two-stage training paradigm. Stage I injects embodied knowledge into the MLLM through curated digital corpora while maintaining language competence. Stage II trains a policy module through an intent-bridging interface that extracts high-level semantics from the MLLM to guide control, without fine-tuning the MLLM backbone. This process is supported by a self-collected cross-embodiment demonstration suite spanning four robot embodiments and six progressively challenging tasks. Evaluations across digital and physical benchmarks show that a single BLM$_1$ instance outperforms four model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving $\\sim\\!\\textbf{6%}$ gains in digital tasks and $\\sim\\!\\textbf{3%}$ in physical tasks.",
    "fetched_at": "2025-10-29T10:17:25.314083Z"
  },
  {
    "id": "2510.24168v1",
    "title": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Weihua Cheng",
      "Ersheng Ni",
      "Wenlong Wang",
      "Yifei Sun",
      "Junming Liu",
      "Wangyu Shen",
      "Yirong Chen",
      "Botian Shi",
      "Ding Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24168v1",
    "abstract": "The rapid progress of Large Language Models (LLMs) and their multimodal extensions (MLLMs) has enabled agentic systems capable of perceiving and acting across diverse environments. A challenging yet impactful frontier is the development of GUI agents, which must navigate complex desktop and web interfaces while maintaining robustness and generalization. Existing paradigms typically model tasks as long-chain executions, concatenating historical trajectories into the context. While approaches such as Mirage and GTA1 refine planning or introduce multi-branch action selection, they remain constrained by two persistent issues: Dependence on historical trajectories, which amplifies error propagation. And Local exploration bias, where \"decision-first, observation-later\" mechanisms overlook critical interface cues. We introduce the Memory-Driven GUI Agent (MGA), which reframes GUI interaction around the principle of observe first, then decide. MGA models each step as an independent, context-rich environment state represented by a triad: current screenshot, task-agnostic spatial information, and a dynamically updated structured memory. Experiments on OSworld benchmarks, real desktop applications (Chrome, VSCode, VLC), and cross-task transfer demonstrate that MGA achieves substantial gains in robustness, generalization, and efficiency compared to state-of-the-art baselines. The code is publicly available at: {https://anonymous.4open.science/r/MGA-3571}.",
    "fetched_at": "2025-10-29T10:17:25.313985Z"
  },
  {
    "id": "2510.24251v1",
    "title": "GRAPHIA: Harnessing Social Graph Data to Enhance LLM-Based Social   Simulation",
    "date": "2025-10-28",
    "tags": [
      "cs.SI",
      "SI"
    ],
    "authors": [
      "Jiarui Ji",
      "Zehua Zhang",
      "Zhewei Wei",
      "Bin Tong",
      "Guan Wang",
      "Bo Zheng"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24251v1",
    "abstract": "Large language models (LLMs) have shown promise in simulating human-like social behaviors. Social graphs provide high-quality supervision signals that encode both local interactions and global network structure, yet they remain underutilized for LLM training. To address this gap, we propose Graphia, the first general LLM-based social graph simulation framework that leverages graph data as supervision for LLM post-training via reinforcement learning. With GNN-based structural rewards, Graphia trains specialized agents to predict whom to interact with (destination selection) and how to interact (edge generation), followed by designed graph generation pipelines. We evaluate Graphia under two settings: Transductive Dynamic Graph Generation (TDGG), a micro-level task with our proposed node-wise interaction alignment metrics; and Inductive Dynamic Graph Generation (IDGG), a macro-level task with our proposed metrics for aligning emergent network properties. On three real-world networks, Graphia improves micro-level alignment by 6.1% in the composite destination selection score, 12% in edge classification accuracy, and 27.9% in edge content BERTScore over the strongest baseline. For macro-level alignment, it achieves 41.11% higher structural similarity and 32.98% better replication of social phenomena such as power laws and echo chambers. Graphia also supports counterfactual simulation, generating plausible behavioral shifts under platform incentives. Our results show that social graphs can serve as high-quality supervision signals for LLM post-training, closing the gap between agent behaviors and network dynamics for LLM-based simulation. Code is available at https://github.com/Ji-Cather/Graphia.git.",
    "fetched_at": "2025-10-29T10:17:25.313920Z"
  },
  {
    "id": "2510.24259v1",
    "title": "Can LLMs Translate Human Instructions into a Reinforcement Learning   Agent's Internal Emergent Symbolic Representation?",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Ziqi Ma",
      "Sao Mai Nguyen",
      "Philippe Xu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24259v1",
    "abstract": "Emergent symbolic representations are critical for enabling developmental learning agents to plan and generalize across tasks. In this work, we investigate whether large language models (LLMs) can translate human natural language instructions into the internal symbolic representations that emerge during hierarchical reinforcement learning. We apply a structured evaluation framework to measure the translation performance of commonly seen LLMs -- GPT, Claude, Deepseek and Grok -- across different internal symbolic partitions generated by a hierarchical reinforcement learning algorithm in the Ant Maze and Ant Fall environments. Our findings reveal that although LLMs demonstrate some ability to translate natural language into a symbolic representation of the environment dynamics, their performance is highly sensitive to partition granularity and task complexity. The results expose limitations in current LLMs capacity for representation alignment, highlighting the need for further research on robust alignment between language and internal agent representations.",
    "fetched_at": "2025-10-29T10:17:25.313863Z"
  },
  {
    "id": "2510.24284v1",
    "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and   Scaling MCP Tools",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Wenhao Wang",
      "Peizhi Niu",
      "Zhao Xu",
      "Zhaoyu Chen",
      "Jian Du",
      "Yaxin Du",
      "Xianghe Pang",
      "Keduan Huang",
      "Yanfeng Wang",
      "Qiang Yan",
      "Siheng Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24284v1",
    "abstract": "Large Language Models (LLMs) increasingly rely on external tools to perform complex, realistic tasks, yet their ability to utilize the rapidly expanding Model Contextual Protocol (MCP) ecosystem remains limited. Existing MCP research covers few servers, depends on costly manual curation, and lacks training support, hindering progress toward real-world deployment. To overcome these limitations, we introduce MCP-Flow, an automated web-agent-driven pipeline for large-scale server discovery, data synthesis, and model training. MCP-Flow collects and filters data from 1166 servers and 11536 tools, producing 68733 high-quality instruction-function call pairs and 6439 trajectories, far exceeding prior work in scale and diversity. Extensive experiments demonstrate MCP-Flow's effectiveness in driving superior MCP tool selection, function-call generation, and enhanced agentic task performance. MCP-Flow thus provides a scalable foundation for advancing LLM agents' proficiency in real-world MCP environments. MCP-Flow is publicly available at \\href{https://github.com/wwh0411/MCP-Flow}{https://github.com/wwh0411/MCP-Flow}.",
    "fetched_at": "2025-10-29T10:17:25.313816Z"
  },
  {
    "id": "2510.24303v1",
    "title": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental   Forecasting",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Deniz Gorur",
      "Antoni Rago",
      "Francesca Toni"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24303v1",
    "abstract": "Judgmental forecasting is the task of making predictions about future events based on human judgment. This task can be seen as a form of claim verification, where the claim corresponds to a future event and the task is to assess the plausibility of that event. In this paper, we propose a novel multi-agent framework for claim verification, whereby different agents may disagree on claim veracity and bring specific evidence for and against the claims, represented as quantitative bipolar argumentation frameworks (QBAFs). We then instantiate the framework for supporting claim verification, with a variety of agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an existing approach for claim verification that generates and evaluates QBAFs; (2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM) from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents, extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of arguments from external sources. Finally, we conduct experiments with two standard judgmental forecasting datasets, with instances of our framework with two or three agents, empowered by six different base LLMs. We observe that combining evidence from agents can improve forecasting accuracy, especially in the case of three agents, while providing an explainable combination of evidence for claim verification.",
    "fetched_at": "2025-10-29T10:17:25.313748Z"
  },
  {
    "id": "2510.24317v1",
    "title": "Cybersecurity AI Benchmark (CAIBench): A Meta-Benchmark for Evaluating   Cybersecurity AI Agents",
    "date": "2025-10-28",
    "tags": [
      "cs.CR",
      "CR"
    ],
    "authors": [
      "María Sanz-Gómez",
      "Víctor Mayoral-Vilches",
      "Francesco Balassone",
      "Luis Javier Navarrete-Lozano",
      "Cristóbal R. J. Veas Chavez",
      "Maite del Mundo de Torres"
    ],
    "institution": "Meta, MIT",
    "link": "http://arxiv.org/pdf/2510.24317v1",
    "abstract": "Cybersecurity spans multiple interconnected domains, complicating the development of meaningful, labor-relevant benchmarks. Existing benchmarks assess isolated skills rather than integrated performance. We find that pre-trained knowledge of cybersecurity in LLMs does not imply attack and defense abilities, revealing a gap between knowledge and capability. To address this limitation, we present the Cybersecurity AI Benchmark (CAIBench), a modular meta-benchmark framework that allows evaluating LLM models and agents across offensive and defensive cybersecurity domains, taking a step towards meaningfully measuring their labor-relevance. CAIBench integrates five evaluation categories, covering over 10,000 instances: Jeopardy-style CTFs, Attack and Defense CTFs, Cyber Range exercises, knowledge benchmarks, and privacy assessments. Key novel contributions include systematic simultaneous offensive-defensive evaluation, robotics-focused cybersecurity challenges (RCTF2), and privacy-preserving performance assessment (CyberPII-Bench). Evaluation of state-of-the-art AI models reveals saturation on security knowledge metrics (~70\\% success) but substantial degradation in multi-step adversarial (A\\&D) scenarios (20-40\\% success), or worse in robotic targets (22\\% success). The combination of framework scaffolding and LLM model choice significantly impacts performance; we find that proper matches improve up to 2.6$\\times$ variance in Attack and Defense CTFs. These results demonstrate a pronounced gap between conceptual knowledge and adaptive capability, emphasizing the need for a meta-benchmark.",
    "fetched_at": "2025-10-29T10:17:25.313699Z"
  },
  {
    "id": "2510.24339v1",
    "title": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science   Automation",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yunxuan Jiang",
      "Silan Hu",
      "Xiaoning Wang",
      "Yuanyuan Zhang",
      "Xiangyu Chang"
    ],
    "institution": "Beijing Baixingkefu Network Technology Co., Ltd., School of Computing, National University of Singapore, School of Data Science and Media Intelligence, Communication University of China, School of Management, Xi'an Jiaotong University",
    "link": "http://arxiv.org/pdf/2510.24339v1",
    "abstract": "Large language models (LLMs) become increasingly integrated into data science workflows for automated system design. However, these LLM-driven data science systems rely solely on the internal reasoning of LLMs, lacking guidance from scientific and theoretical principles. This limits their trustworthiness and robustness, especially when dealing with noisy and complex real-world datasets. This paper provides VDSAgents, a multi-agent system grounded in the Predictability-Computability-Stability (PCS) principles proposed in the Veridical Data Science (VDS) framework. Guided by PCS principles, the system implements a modular workflow for data cleaning, feature engineering, modeling, and evaluation. Each phase is handled by an elegant agent, incorporating perturbation analysis, unit testing, and model validation to ensure both functionality and scientific auditability. We evaluate VDSAgents on nine datasets with diverse characteristics, comparing it with state-of-the-art end-to-end data science systems, such as AutoKaggle and DataInterpreter, using DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the results of AutoKaggle and DataInterpreter, which validates the feasibility of embedding PCS principles into LLM-driven data science automation.",
    "fetched_at": "2025-10-29T10:17:25.313613Z"
  },
  {
    "id": "2510.24358v1",
    "title": "Automatically Benchmarking LLM Code Agents through Agent-Driven   Annotation and Evaluation",
    "date": "2025-10-28",
    "tags": [
      "cs.SE",
      "SE",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Lingyue Fu",
      "Bolun Zhang",
      "Hao Guan",
      "Yaoming Zhu",
      "Lin Qiu",
      "Weiwen Liu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Weinan Zhang",
      "Yong Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24358v1",
    "abstract": "Recent advances in code agents have enabled automated software development at the project level, supported by large language models (LLMs) and widely adopted tools. However, existing benchmarks for code agent evaluation face two major limitations: high annotation cost and expertise requirements, and rigid evaluation metrics that rely primarily on unit tests. To address these challenges, we propose an agent-driven benchmark construction pipeline that leverages human supervision to efficiently generate diverse and challenging project-level tasks. Based on this approach, we introduce PRDBench, a novel benchmark comprising 50 real-world Python projects across 20 domains, each with structured Product Requirement Document (PRD) requirements, comprehensive evaluation criteria, and reference implementations. PRDBench features rich data sources, high task complexity, and flexible metrics. We further employ an Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of various test types beyond unit tests. Extensive experiments on PRDBench demonstrate its effectiveness in assessing the capabilities of both code agents and evaluation agents, providing a scalable and robust framework for annotation and evaluation.",
    "fetched_at": "2025-10-29T10:17:25.313570Z"
  },
  {
    "id": "2510.24390v1",
    "title": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and   Logic-Parallel Content Expansion",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Xianjun Gao",
      "Jianchun Liu",
      "Hongli Xu",
      "Liusheng Huang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24390v1",
    "abstract": "The integration of Large Language Models (LLMs) into real-time Web applications, such as AI-powered search and conversational agents, presents a fundamental Web infrastructure challenge: reconciling the demand for high-quality, complex reasoning with the stringent low-latency and high-throughput requirements of interactive services. Current LLM reasoning, hindered by computationally inefficient sequential generation and rigid reasoning strategies, creates a critical bottleneck for the Web services. Existing approaches typically optimize the LLM reasoning for either efficiency or quality but struggle to achieve both, and thus fail to meet the dual requirements of modern Web platforms. To overcome these limitations, we propose Orion, a novel and efficient reasoning framework that enables dependency-aware query decomposition and logic-parallel content expansion. Concretely, Orion decomposes a single query reasoning process into two synergistic phases: (1) \\textit{key point generation}, which distills logically structured key points through retrieval-augmented few-shot prompting, and (2) \\textit{content parallel expansion}, which concurrently elaborates on these points based on a dependency graph to ensure logical consistency. Furthermore, Orion introduces a pipeline scheduling mechanism that exploits the complementary computational characteristics of the two phases (generation imposes pressure on GPU computing and expansion stresses on GPU memory) across multiple queries, enabling cross-query parallelism and dramatically improving reasoning performance (\\ie, efficiency and quality). Experiments on diverse benchmarks show that Orion not only delivers up to 4.33x higher token generation speed and 3.42x lower answer latency over the baselines but also improves reasoning quality by up to 18.75% through explicitly modeling inter-point dependencies.",
    "fetched_at": "2025-10-29T10:17:25.313503Z"
  },
  {
    "id": "2510.24397v1",
    "title": "APTBench: Benchmarking Agentic Potential of Base LLMs During   Pre-Training",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiarui Qin",
      "Yunjia Xi",
      "Junjie Huang",
      "Renting Rui",
      "Di Yin",
      "Weiwen Liu",
      "Yong Yu",
      "Weinan Zhang",
      "Xing Sun"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24397v1",
    "abstract": "With the rapid development of LLM-based agents, there is a growing trend to incorporate agent-specific data into the pre-training stage of LLMs, aiming to better align LLMs with real-world autonomous task execution. However, current pre-training benchmarks primarily focus on isolated and static skills, e.g., common knowledge or mathematical/code reasoning, and fail to reflect model's agentic capabilities. On the other hand, agent benchmarks are typically designed for post-trained models, requiring multi-turn task execution abilities that base models struggle to support. Thus, there is a compelling need for a benchmark that can evaluate agentic potentials during pre-training and guide the model training more effectively. To address this gap, we propose APTBench, a framework that converts real-world agent tasks and successful trajectories into multiple-choice or text completion questions tailored for base models. It focuses on core agentic abilities, e.g., planning and action, and covers key agent scenarios, software engineering and deep research. Compared to existing general-purpose benchmarks, APTBench offers a more predictive signal of a model's downstream performance as an agent, while remaining significantly more lightweight and cost-effective than full-scale, end-to-end agent evaluations after post-training.",
    "fetched_at": "2025-10-29T10:17:25.313450Z"
  },
  {
    "id": "2510.24411v1",
    "title": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid   Validation in Realistic Workflows",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Qiushi Sun",
      "Mukai Li",
      "Zhoumianze Liu",
      "Zhihui Xie",
      "Fangzhi Xu",
      "Zhangyue Yin",
      "Kanzhi Cheng",
      "Zehao Li",
      "Zichen Ding",
      "Qi Liu",
      "Zhiyong Wu",
      "Zhuosheng Zhang",
      "Ben Kao",
      "Lingpeng Kong"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24411v1",
    "abstract": "Computer-using agents powered by Vision-Language Models (VLMs) have demonstrated human-like capabilities in operating digital environments like mobile platforms. While these agents hold great promise for advancing digital automation, their potential for unsafe operations, such as system compromise and privacy leakage, is raising significant concerns. Detecting these safety concerns across the vast and complex operational space of mobile environments presents a formidable challenge that remains critically underexplored. To establish a foundation for mobile agent safety research, we introduce MobileRisk-Live, a dynamic sandbox environment accompanied by a safety detection benchmark comprising realistic trajectories with fine-grained annotations. Built upon this, we propose OS-Sentinel, a novel hybrid safety detection framework that synergistically combines a Formal Verifier for detecting explicit system-level violations with a VLM-based Contextual Judge for assessing contextual risks and agent actions. Experiments show that OS-Sentinel achieves 10%-30% improvements over existing approaches across multiple metrics. Further analysis provides critical insights that foster the development of safer and more reliable autonomous mobile agents.",
    "fetched_at": "2025-10-29T10:17:25.313386Z"
  },
  {
    "id": "2510.24428v1",
    "title": "CodeWiki: Automated Repository-Level Documentation at Scale",
    "date": "2025-10-28",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Nguyen Hoang Anh",
      "Minh Le-Anh",
      "Bach Le",
      "Nghi D. Q. Bui"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24428v1",
    "abstract": "Developers spend nearly 58% of their time understanding codebases, yet maintaining comprehensive documentation remains challenging due to complexity and manual effort. While recent Large Language Models (LLMs) show promise for function-level documentation, they fail at the repository level, where capturing architectural patterns and cross-module interactions is essential. We introduce CodeWiki, the first open-source framework for holistic repository-level documentation across seven programming languages. CodeWiki employs three innovations: (i) hierarchical decomposition that preserves architectural context, (ii) recursive agentic processing with dynamic delegation, and (iii) synthesis of textual and visual artifacts including architecture diagrams and data flows. We also present CodeWikiBench, the first repository-level documentation benchmark with multi-level rubrics and agentic assessment. CodeWiki achieves 68.79% quality score with proprietary models and 64.80% with open-source alternatives, outperforming existing closed-source systems and demonstrating scalable, accurate documentation for real-world repositories.",
    "fetched_at": "2025-10-29T10:17:25.313299Z"
  },
  {
    "id": "2510.24438v1",
    "title": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated   Islamic Content",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CY",
      "CY",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Abdullah Mushtaq",
      "Rafay Naeem",
      "Ezieddin Elmahjub",
      "Ibrahim Ghaznavi",
      "Shawqi Al-Maliki",
      "Mohamed Abdallah",
      "Ala Al-Fuqaha",
      "Junaid Qadir"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24438v1",
    "abstract": "Large language models are increasingly used for Islamic guidance, but risk misquoting texts, misapplying jurisprudence, or producing culturally inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar on prompts from authentic Islamic blogs. Our dual-agent framework uses a quantitative agent for citation verification and six-dimensional scoring (e.g., Structure, Islamic Consistency, Citations) and a qualitative agent for five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality). GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong performance, models still fall short in reliably producing accurate Islamic content and citations -- a paramount requirement in faith-sensitive writing. GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led qualitative pairwise wins (116/200). Fanar, though trailing, introduces innovations for Islamic and Arabic contexts. This study underscores the need for community-driven benchmarks centering Muslim perspectives, offering an early step toward more reliable AI in Islamic knowledge and other high-stakes domains such as medicine, law, and journalism.",
    "fetched_at": "2025-10-29T10:17:25.313253Z"
  },
  {
    "id": "2510.24442v1",
    "title": "Law in Silico: Simulating Legal Society with LLM-Based Agents",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CY",
      "CY",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Yiding Wang",
      "Yuxuan Chen",
      "Fanxu Meng",
      "Xifan Chen",
      "Xiaolei Yang",
      "Muhan Zhang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24442v1",
    "abstract": "Since real-world legal experiments are often costly or infeasible, simulating legal societies with Artificial Intelligence (AI) systems provides an effective alternative for verifying and developing legal theory, as well as supporting legal administration. Large Language Models (LLMs), with their world knowledge and role-playing capabilities, are strong candidates to serve as the foundation for legal society simulation. However, the application of LLMs to simulate legal systems remains underexplored. In this work, we introduce Law in Silico, an LLM-based agent framework for simulating legal scenarios with individual decision-making and institutional mechanisms of legislation, adjudication, and enforcement. Our experiments, which compare simulated crime rates with real-world data, demonstrate that LLM-based agents can largely reproduce macro-level crime trends and provide insights that align with real-world observations. At the same time, micro-level simulations reveal that a well-functioning, transparent, and adaptive legal system offers better protection of the rights of vulnerable individuals.",
    "fetched_at": "2025-10-29T10:17:25.313182Z"
  },
  {
    "id": "2510.24476v1",
    "title": "Mitigating Hallucination in Large Language Models (LLMs): An   Application-Oriented Survey on RAG, Reasoning, and Agentic Systems",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yihan Li",
      "Xiyuan Fu",
      "Ghanshyam Verma",
      "Paul Buitelaar",
      "Mingming Liu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24476v1",
    "abstract": "Hallucination remains one of the key obstacles to the reliable deployment of large language models (LLMs), particularly in real-world applications. Among various mitigation strategies, Retrieval-Augmented Generation (RAG) and reasoning enhancement have emerged as two of the most effective and widely adopted approaches, marking a shift from merely suppressing hallucinations to balancing creativity and reliability. However, their synergistic potential and underlying mechanisms for hallucination mitigation have not yet been systematically examined. This survey adopts an application-oriented perspective of capability enhancement to analyze how RAG, reasoning enhancement, and their integration in Agentic Systems mitigate hallucinations. We propose a taxonomy distinguishing knowledge-based and logic-based hallucinations, systematically examine how RAG and reasoning address each, and present a unified framework supported by real-world applications, evaluations, and benchmarks.",
    "fetched_at": "2025-10-29T10:17:25.313127Z"
  },
  {
    "id": "2510.24551v1",
    "title": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Gang Chen",
      "Changshuo Liu",
      "Gene Anne Ooi",
      "Marcus Tan",
      "Zhongle Xie",
      "Jianwei Yin",
      "James Wei Luen Yip",
      "Wenqiao Zhang",
      "Jiaqi Zhu",
      "Beng Chin Ooi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24551v1",
    "abstract": "Generative Artificial Intelligence (GenAI) is taking the world by storm. It promises transformative opportunities for advancing and disrupting existing practices, including healthcare. From large language models (LLMs) for clinical note synthesis and conversational assistance to multimodal systems that integrate medical imaging, electronic health records, and genomic data for decision support, GenAI is transforming the practice of medicine and the delivery of healthcare, such as diagnosis and personalized treatments, with great potential in reducing the cognitive burden on clinicians, thereby improving overall healthcare delivery. However, GenAI deployment in healthcare requires an in-depth understanding of healthcare tasks and what can and cannot be achieved. In this paper, we propose a data-centric paradigm in the design and deployment of GenAI systems for healthcare. Specifically, we reposition the data life cycle by making the medical data ecosystem as the foundational substrate for generative healthcare systems. This ecosystem is designed to sustainably support the integration, representation, and retrieval of diverse medical data and knowledge. With effective and efficient data processing pipelines, such as semantic vector search and contextual querying, it enables GenAI-powered operations for upstream model components and downstream clinical applications. Ultimately, it not only supplies foundation models with high-quality, multimodal data for large-scale pretraining and domain-specific fine-tuning, but also serves as a knowledge retrieval backend to support task-specific inference via the agentic layer. The ecosystem enables the deployment of GenAI for high-quality and effective healthcare delivery.",
    "fetched_at": "2025-10-29T10:17:25.313076Z"
  },
  {
    "id": "2510.24591v1",
    "title": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "astro-ph.IM",
      "IM"
    ],
    "authors": [
      "Christine Ye",
      "Sihan Yuan",
      "Suchetha Cooray",
      "Steven Dillmann",
      "Ian L. V. Roque",
      "Dalya Baron",
      "Philipp Frank",
      "Sergio Martin-Alvarez",
      "Nolan Koblischke",
      "Frank J Qu",
      "Diyi Yang",
      "Risa Wechsler",
      "Ioana Ciuca"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24591v1",
    "abstract": "Frontier AI agents show increasing promise as scientific research assistants, and may eventually be useful for extended, open-ended research workflows. However, in order to use agents for novel research, we must first assess the underlying faithfulness and correctness of their work. To evaluate agents as research assistants, we introduce ReplicationBench, an evaluation framework that tests whether agents can replicate entire research papers drawn from the astrophysics literature. Astrophysics, where research relies heavily on archival data and computational study while requiring little real-world experimentation, is a particularly useful testbed for AI agents in scientific research. We split each paper into tasks which require agents to replicate the paper's core contributions, including the experimental setup, derivations, data analysis, and codebase. Each task is co-developed with the original paper authors and targets a key scientific result, enabling objective evaluation of both faithfulness (adherence to original methods) and correctness (technical accuracy of results). ReplicationBench is extremely challenging for current frontier language models: even the best-performing language models score under 20%. We analyze ReplicationBench trajectories in collaboration with domain experts and find a rich, diverse set of failure modes for agents in scientific research. ReplicationBench establishes the first benchmark of paper-scale, expert-validated astrophysics research tasks, reveals insights about agent performance generalizable to other domains of data-driven science, and provides a scalable framework for measuring AI agents' reliability in scientific research.",
    "fetched_at": "2025-10-29T10:17:25.313005Z"
  },
  {
    "id": "2510.24636v1",
    "title": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement   Learning",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Ziyou Hu",
      "Zhengliang Shi",
      "Minghang Zhu",
      "Haitao Li",
      "Teng Sun",
      "Pengjie Ren",
      "Suzan Verberne",
      "Zhaochun Ren"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24636v1",
    "abstract": "Reward models (RMs) have become essential for aligning large language models (LLMs), serving as scalable proxies for human evaluation in both training and inference. However, existing RMs struggle on knowledge-intensive and long-form tasks, where evaluating correctness requires grounding beyond the model's internal knowledge. This limitation hinders them from reliably discriminating subtle quality differences, especially when external evidence is necessary. To address this, we introduce OpenRM, a tool-augmented long-form reward model that systematically judges open-ended responses by invoking external tools to gather relevant evidence. We train OpenRM with Group Relative Policy Optimization (GRPO) on over 27K synthesized pairwise examples generated through a controllable data synthesis framework. The training objective jointly supervises intermediate tool usage and final outcome accuracy, incentivizing our reward model to learn effective evidence-based judgment strategies. Extensive experiments on three newly-collected datasets and two widely-used benchmarks demonstrate that OpenRM substantially outperforms existing reward modeling approaches. As a further step, we integrate OpenRM into both inference-time response selection and training-time data selection. This yields consistent gains in downstream LLM alignment tasks, highlighting the potential of tool-augmented reward models for scaling reliable long-form evaluation.",
    "fetched_at": "2025-10-29T10:17:25.312921Z"
  },
  {
    "id": "2510.24645v1",
    "title": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in   Multi-Turn Function Calling",
    "date": "2025-10-28",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zengzhuang Xu",
      "Bingguang Hao",
      "Zechuan Wang",
      "Yuntao Wen",
      "Maolin Wang",
      "Yang Liu",
      "Long Chen",
      "Dong Wang",
      "Yicheng Chen",
      "Cunyin Peng",
      "Chenyi Zhuang",
      "Jinjie Gu",
      "Leilei Gan",
      "Xiangyu Zhao",
      "Shi Gu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24645v1",
    "abstract": "Function calling (FC) empowers large language models (LLMs) and autonomous agents to interface with external tools, a critical capability for solving complex, real-world problems. As this ability becomes increasingly central to advanced AI systems, the need for high-quality, multi-turn training data to develop and refine it cannot be overstated. Existing data synthesis methods, such as random environment sampling or multi-agent role-playing, are not powerful enough to generate high-quality data in real-world environments. Practical challenges come in three folds: targeted model training, isolation of tool architecture, and multi-turn logical dependency. To address these structural deficiencies, we present FunReason-MT, a novel data synthesis framework for real-world multi-turn tool use. FunReason-MT resolves the complexity barrier in multi-turn FC data by employing 1) Environment-API Graph Interactions to gather varied high-quality trajectories, 2) Advanced Tool-Query Synthesis to simplify hard query construction, and 3) Guided Iterative Chain for sophisticated CoT generation. Evaluations on Berkeley Function-Calling Leaderboard (BFCLv3) demonstrate the power of our framework: a 4B model built upon FunReason-MT generated data achieves state-of-the-art performance among comparable-sized models, outperforming most close-source models. Further performance improvements on BFCLv4 confirm that FunReason-MT provides a reliable and robust source for agentic learning.",
    "fetched_at": "2025-10-29T10:17:25.312855Z"
  },
  {
    "id": "2510.24654v1",
    "title": "Evolving Diagnostic Agents in a Virtual Clinical Environment",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Pengcheng Qiu",
      "Chaoyi Wu",
      "Junwei Liu",
      "Qiaoyu Zheng",
      "Yusheng Liao",
      "Haowen Wang",
      "Yun Yue",
      "Qianrui Fan",
      "Shuai Zhen",
      "Jian Wang",
      "Jinjie Gu",
      "Yanfeng Wang",
      "Ya Zhang",
      "Weidi Xie"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24654v1",
    "abstract": "In this paper, we present a framework for training large language models (LLMs) as diagnostic agents with reinforcement learning, enabling them to manage multi-turn diagnostic processes, adaptively select examinations, and commit to final diagnoses. Unlike instruction-tuned models trained on static case summaries, our method acquires diagnostic strategies through interactive exploration and outcome-based feedback. Our contributions are fourfold: (i) We present DiagGym, a diagnostics world model trained with electronic health records that emits examination outcomes conditioned on patient history and recommended examination, serving as a virtual clinical environment for realistic diagnosis training and evaluation; (ii) We train DiagAgent via end-to-end, multi-turn reinforcement learning to learn diagnostic policies that optimize both information yield and diagnostic accuracy; (iii) We introduce DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated examination recommendations and 99 cases annotated with 973 physician-written rubrics on diagnosis process; (iv) we demonstrate superior performance across diverse diagnostic settings. DiagAgent significantly outperforms 10 state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34% higher diagnostic accuracy and 44.03% improvement in examination recommendation hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic accuracy and 23.09% boost in examination recommendation F1 score. In rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by 7.1% in weighted rubric score. These findings indicate that learning policies in interactive clinical environments confers dynamic and clinically meaningful diagnostic management abilities unattainable through passive training alone.",
    "fetched_at": "2025-10-29T10:17:25.312768Z"
  },
  {
    "id": "2510.24694v1",
    "title": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yida Zhao",
      "Kuan Li",
      "Xixi Wu",
      "Liwen Zhang",
      "Dingchu Zhang",
      "Baixuan Li",
      "Maojia Song",
      "Zhuo Chen",
      "Chenxi Wang",
      "Xinyu Wang",
      "Kewei Tu",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24694v1",
    "abstract": "LLM-based search agents are increasingly trained on entity-centric synthetic data to solve complex, knowledge-intensive tasks. However, prevailing training methods like Group Relative Policy Optimization (GRPO) discard this rich entity information, relying instead on sparse, outcome-based rewards. This critical limitation renders them unable to distinguish informative \"near-miss\" samples-those with substantially correct reasoning but a flawed final answer-from complete failures, thus discarding valuable learning signals. We address this by leveraging the very entities discarded during training. Our empirical analysis reveals a strong positive correlation between the number of ground-truth entities identified during an agent's reasoning process and final answer accuracy. Building on this insight, we introduce Entity-aware Group Relative Policy Optimization (E-GRPO), a novel framework that formulates a dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect samples proportional to their entity match rate, enabling the model to effectively learn from these \"near-misses\". Experiments on diverse question-answering (QA) and deep research benchmarks show that E-GRPO consistently and significantly outperforms the GRPO baseline. Furthermore, our analysis reveals that E-GRPO not only achieves superior accuracy but also induces more efficient reasoning policies that require fewer tool calls, demonstrating a more effective and sample-efficient approach to aligning search agents.",
    "fetched_at": "2025-10-29T10:17:25.312681Z"
  },
  {
    "id": "2510.24695v1",
    "title": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with   ZPD-Guided Data Synthesis",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Xuanzhong Chen",
      "Zile Qiao",
      "Guoxin Chen",
      "Liangcai Su",
      "Zhen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24695v1",
    "abstract": "Training large language model agents on tasks at the frontier of their capabilities is key to unlocking advanced reasoning. We introduce a data synthesis approach inspired by the educational theory of the Zone of Proximal Development (ZPD), which defines this frontier as tasks an LLM cannot solve alone but can master with guidance. To operationalize this, we present the AgentFrontier Engine, an automated pipeline that synthesizes high-quality, multidisciplinary data situated precisely within the LLM's ZPD. This engine supports both continued pre-training with knowledge-intensive data and targeted post-training on complex reasoning tasks. From the same framework, we derive the ZPD Exam, a dynamic and automated benchmark designed to evaluate agent capabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on our synthesized data, which achieves state-of-the-art results on demanding benchmarks like Humanity's Last Exam, even surpassing some leading proprietary agents. Our work demonstrates that a ZPD-guided approach to data synthesis offers a scalable and effective path toward building more capable LLM agents.",
    "fetched_at": "2025-10-29T10:17:25.312579Z"
  },
  {
    "id": "2510.24697v1",
    "title": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling   Info-Rich Seeking",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Zhengwei Tao",
      "Haiyang Shen",
      "Baixuan Li",
      "Wenbiao Yin",
      "Jialong Wu",
      "Kuan Li",
      "Zhongwang Zhang",
      "Huifeng Yin",
      "Rui Ye",
      "Liwen Zhang",
      "Xinyu Wang",
      "Pengjun Xie",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.24697v1",
    "abstract": "Large Language Model (LLM)-based agents have emerged as a transformative approach for open-ended problem solving, with information seeking (IS) being a core capability that enables autonomous reasoning and decision-making. While prior research has largely focused on improving retrieval depth, we observe that current IS agents often suffer from low search efficiency, which in turn constrains overall performance. A key factor underlying this inefficiency is the sparsity of target entities in training tasks, which limits opportunities for agents to learn and generalize efficient search behaviors. To address these challenges, we propose WebLeaper, a framework for constructing high-coverage IS tasks and generating efficient solution trajectories. We formulate IS as a tree-structured reasoning problem, enabling a substantially larger set of target entities to be embedded within a constrained context. Leveraging curated Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic, Union, and Reverse-Union, to systematically increase both IS efficiency and efficacy. Finally, we curate training trajectories by retaining only those that are simultaneously accurate and efficient, ensuring that the model is optimized for both correctness and search performance. Extensive experiments on both basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp, GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method consistently achieves improvements in both effectiveness and efficiency over strong baselines.",
    "fetched_at": "2025-10-29T10:17:25.312511Z"
  },
  {
    "id": "2510.24699v1",
    "title": "AgentFold: Long-Horizon Web Agents with Proactive Context Management",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Rui Ye",
      "Zhongwang Zhang",
      "Kuan Li",
      "Huifeng Yin",
      "Zhengwei Tao",
      "Yida Zhao",
      "Liangcai Su",
      "Liwen Zhang",
      "Zile Qiao",
      "Xinyu Wang",
      "Pengjun Xie",
      "Fei Huang",
      "Siheng Chen",
      "Jingren Zhou",
      "Yong Jiang"
    ],
    "institution": "OpenAI",
    "link": "http://arxiv.org/pdf/2510.24699v1",
    "abstract": "LLM-based web agents show immense promise for information seeking, yet their effectiveness on long-horizon tasks is hindered by a fundamental trade-off in context management. Prevailing ReAct-based agents suffer from context saturation as they accumulate noisy, raw histories, while methods that fixedly summarize the full history at each step risk the irreversible loss of critical details. Addressing these, we introduce AgentFold, a novel agent paradigm centered on proactive context management, inspired by the human cognitive process of retrospective consolidation. AgentFold treats its context as a dynamic cognitive workspace to be actively sculpted, rather than a passive log to be filled. At each step, it learns to execute a `folding' operation, which manages its historical trajectory at multiple scales: it can perform granular condensations to preserve vital, fine-grained details, or deep consolidations to abstract away entire multi-step sub-tasks. The results on prominent benchmarks are striking: with simple supervised fine-tuning (without continual pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or matches open-source models of a dramatically larger scale, such as the DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like OpenAI's o4-mini.",
    "fetched_at": "2025-10-29T10:17:25.312426Z"
  },
  {
    "id": "2510.24701v1",
    "title": "Tongyi DeepResearch Technical Report",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.IR",
      "IR",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Tongyi DeepResearch Team",
      "Baixuan Li",
      "Bo Zhang",
      "Dingchu Zhang",
      "Fei Huang",
      "Guangyu Li",
      "Guoxin Chen",
      "Huifeng Yin",
      "Jialong Wu",
      "Jingren Zhou",
      "Kuan Li",
      "Liangcai Su",
      "Litu Ou",
      "Liwen Zhang",
      "Pengjun Xie",
      "Rui Ye",
      "Wenbiao Yin",
      "Xinmiao Yu",
      "Xinyu Wang",
      "Xixi Wu",
      "Xuanzhong Chen",
      "Yida Zhao",
      "Zhen Zhang",
      "Zhengwei Tao",
      "Zhongwang Zhang",
      "Zile Qiao",
      "Chenxi Wang",
      "Donglei Yu",
      "Gang Fu",
      "Haiyang Shen",
      "Jiayin Yang",
      "Jun Lin",
      "Junkai Zhang",
      "Kui Zeng",
      "Li Yang",
      "Hailong Yin",
      "Maojia Song",
      "Ming Yan",
      "Peng Xia",
      "Qian Xiao",
      "Rui Min",
      "Ruixue Ding",
      "Runnan Fang",
      "Shaowei Chen",
      "Shen Huang",
      "Shihang Wang",
      "Shihao Cai",
      "Weizhou Shen",
      "Xiaobin Wang",
      "Xin Guan",
      "Xinyu Geng",
      "Yingcheng Shi",
      "Yuning Wu",
      "Zhuo Chen",
      "Zijian Li",
      "Yong Jiang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24701v1",
    "abstract": "We present Tongyi DeepResearch, an agentic large language model, which is specifically designed for long-horizon, deep information-seeking research tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is developed through an end-to-end training framework that combines agentic mid-training and agentic post-training, enabling scalable reasoning and information seeking across complex tasks. We design a highly scalable data synthesis pipeline that is fully automatic, without relying on costly human annotation, and empowers all training stages. By constructing customized environments for each stage, our system enables stable and consistent interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total parameters, with only 3.3 billion activated per token, achieves state-of-the-art performance across a range of agentic deep research benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH, WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We open-source the model, framework, and complete solutions to empower the community.",
    "fetched_at": "2025-10-29T10:17:25.312334Z"
  },
  {
    "id": "2510.24702v1",
    "title": "Agent Data Protocol: Unifying Datasets for Diverse, Effective   Fine-tuning of LLM Agents",
    "date": "2025-10-28",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yueqi Song",
      "Ketan Ramaneti",
      "Zaid Sheikh",
      "Ziru Chen",
      "Boyu Gou",
      "Tianbao Xie",
      "Yiheng Xu",
      "Danyang Zhang",
      "Apurva Gandhi",
      "Fan Yang",
      "Joseph Liu",
      "Tianyue Ou",
      "Zhihao Yuan",
      "Frank Xu",
      "Shuyan Zhou",
      "Xingyao Wang",
      "Xiang Yue",
      "Tao Yu",
      "Huan Sun",
      "Yu Su",
      "Graham Neubig"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.24702v1",
    "abstract": "Public research results on large-scale supervised finetuning of AI agents remain relatively rare, since the collection of agent training data presents unique challenges. In this work, we argue that the bottleneck is not a lack of underlying data sources, but that a large variety of data is fragmented across heterogeneous formats, tools, and interfaces. To this end, we introduce the agent data protocol (ADP), a light-weight representation language that serves as an \"interlingua\" between agent datasets in diverse formats and unified agent training pipelines downstream. The design of ADP is expressive enough to capture a large variety of tasks, including API/tool use, browsing, coding, software engineering, and general agentic workflows, while remaining simple to parse and train on without engineering at a per-dataset level. In experiments, we unified a broad collection of 13 existing agent training datasets into ADP format, and converted the standardized ADP data into training-ready formats for multiple agent frameworks. We performed SFT on these data, and demonstrated an average performance gain of ~20% over corresponding base models, and delivers state-of-the-art or near-SOTA performance on standard coding, browsing, tool use, and research benchmarks, without domain-specific tuning. All code and data are released publicly, in the hope that ADP could help lower the barrier to standardized, scalable, and reproducible agent training.",
    "fetched_at": "2025-10-29T10:17:25.312095Z"
  },
  {
    "id": "2510.23524v1",
    "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and   Learning Paradigms for Sustainable Intelligence",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "KC Santosh",
      "Rodrigue Rizk",
      "Longwei Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23524v1",
    "abstract": "The rapid advancement of Artificial Intelligence (AI) has led to unprecedented computational demands, raising significant environmental and ethical concerns. This paper critiques the prevailing reliance on large-scale, static datasets and monolithic training paradigms, advocating for a shift toward human-inspired, sustainable AI solutions. We introduce a novel framework, Human AI (HAI), which emphasizes incremental learning, carbon-aware optimization, and human-in-the-loop collaboration to enhance adaptability, efficiency, and accountability. By drawing parallels with biological cognition and leveraging dynamic architectures, HAI seeks to balance performance with ecological responsibility. We detail the theoretical foundations, system design, and operational principles that enable AI to learn continuously and contextually while minimizing carbon footprints and human annotation costs. Our approach addresses pressing challenges in active learning, continual adaptation, and energy-efficient model deployment, offering a pathway toward responsible, human-centered artificial intelligence.",
    "fetched_at": "2025-10-28T05:41:46.837102Z"
  },
  {
    "id": "2510.23530v1",
    "title": "Learning Linearity in Audio Consistency Autoencoders via Implicit   Regularization",
    "date": "2025-10-27",
    "tags": [
      "cs.SD",
      "SD",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Bernardo Torres",
      "Manuel Moussallam",
      "Gabriel Meseguer-Brocal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23530v1",
    "abstract": "Audio autoencoders learn useful, compressed audio representations, but their non-linear latent spaces prevent intuitive algebraic manipulation such as mixing or scaling. We introduce a simple training methodology to induce linearity in a high-compression Consistency Autoencoder (CAE) by using data augmentation, thereby inducing homogeneity (equivariance to scalar gain) and additivity (the decoder preserves addition) without altering the model's architecture or loss function. When trained with our method, the CAE exhibits linear behavior in both the encoder and decoder while preserving reconstruction fidelity. We test the practical utility of our learned space on music source composition and separation via simple latent arithmetic. This work presents a straightforward technique for constructing structured latent spaces, enabling more intuitive and efficient audio processing.",
    "fetched_at": "2025-10-28T05:41:46.837057Z"
  },
  {
    "id": "2510.23532v1",
    "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational   Reasoning",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Anirban Das",
      "Irtaza Khalid",
      "Rafael Peñaloza",
      "Steven Schockaert"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23532v1",
    "abstract": "Designing models that can learn to reason in a systematic way is an important and long-standing challenge. In recent years, a wide range of solutions have been proposed for the specific case of systematic relational reasoning, including Neuro-Symbolic approaches, variants of the Transformer architecture, and specialised Graph Neural Networks. However, existing benchmarks for systematic relational reasoning focus on an overly simplified setting, based on the assumption that reasoning can be reduced to composing relational paths. In fact, this assumption is hard-baked into the architecture of several recent models, leading to approaches that can perform well on existing benchmarks but are difficult to generalise to other settings. To support further progress in the field of systematic relational reasoning with neural networks, we introduce NoRA, a new benchmark which adds several levels of difficulty and requires models to go beyond path-based reasoning.",
    "fetched_at": "2025-10-28T05:41:46.837014Z"
  },
  {
    "id": "2510.23534v1",
    "title": "Direct Debiased Machine Learning via Bregman Divergence Minimization",
    "date": "2025-10-27",
    "tags": [
      "econ.EM",
      "EM",
      "cs.LG",
      "LG",
      "math.ST",
      "ST",
      "stat.ME",
      "ME",
      "stat.ML",
      "ML",
      "stat.TH",
      "TH"
    ],
    "authors": [
      "Masahiro Kato"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23534v1",
    "abstract": "We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.",
    "fetched_at": "2025-10-28T05:41:46.836967Z"
  },
  {
    "id": "2510.23536v1",
    "title": "IPQA: A Benchmark for Core Intent Identification in Personalized   Question Answering",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Jieyong Kim",
      "Maryam Amirizaniani",
      "Soojin Yoon",
      "Dongha Lee"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23536v1",
    "abstract": "Intent identification serves as the foundation for generating appropriate responses in personalized question answering (PQA). However, existing benchmarks evaluate only response quality or retrieval performance without directly measuring intent identification capabilities. This gap is critical because without understanding which intents users prioritize, systems cannot generate responses satisfying individual information needs. To address this, we introduce the concept of core intents: intents users prioritize when selecting answers to satisfy their information needs. To evaluate these core intents, we propose IPQA, a benchmark for core Intent identification in Personalized Question Answering. Since users do not explicitly state their prioritized intents, we derive core intents from observable behavior patterns in answer selection, grounded in satisficing theory where users choose answers meeting their acceptance thresholds. We construct a dataset with various domains through systematic filtering, LLM-based annotation, and rigorous quality control combining automated verification with human validation. Experimental evaluations across state-of-the-art language models reveal that current systems struggle with core intent identification in personalized contexts. Models fail to identify core intents from user histories, with performance degrading as question complexity increases. The code and dataset will be made publicly available to facilitate future research in this direction.",
    "fetched_at": "2025-10-28T05:41:46.836858Z"
  },
  {
    "id": "2510.23538v1",
    "title": "JanusCoder: Towards a Foundational Visual-Programmatic Interface for   Code Intelligence",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Qiushi Sun",
      "Jingyang Gong",
      "Yang Liu",
      "Qiaosheng Chen",
      "Lei Li",
      "Kai Chen",
      "Qipeng Guo",
      "Ben Kao",
      "Fei Yuan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23538v1",
    "abstract": "The scope of neural code intelligence is rapidly expanding beyond text-based source code to encompass the rich visual outputs that programs generate. This visual dimension is critical for advanced applications like flexible content generation and precise, program-driven editing of visualizations. However, progress has been impeded by the scarcity of high-quality multimodal code data, a bottleneck stemming from challenges in synthesis and quality assessment. To address these challenges, we make contributions from both a data and modeling perspective. We first introduce a complete synthesis toolkit that leverages reciprocal synergies between data modalities to efficiently produce a large-scale, high-quality corpus spanning from standard charts to complex interactive web UIs and code-driven animations. Leveraging this toolkit, we construct JanusCode-800K, the largest multimodal code corpus to date. This powers the training of our models, JanusCoder and JanusCoderV, which establish a visual-programmatic interface for generating code from textual instructions, visual inputs, or a combination of both. Our unified model is a departure from existing approaches that build specialized models for isolated tasks. Extensive experiments on both text-centric and vision-centric coding tasks demonstrate the superior performance of the JanusCoder series, with our 7B to 14B scale models approaching or even exceeding the performance of commercial models. Furthermore, extensive analysis provides key insights into harmonizing programmatic logic with its visual expression. Our code and checkpoints will are available at https://github.com/InternLM/JanusCoder.",
    "fetched_at": "2025-10-28T05:41:46.836808Z"
  },
  {
    "id": "2510.23544v1",
    "title": "LimRank: Less is More for Reasoning-Intensive Information Reranking",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.IR",
      "IR"
    ],
    "authors": [
      "Tingyu Song",
      "Yilun Zhao",
      "Siyue Zhang",
      "Chen Zhao",
      "Arman Cohan"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23544v1",
    "abstract": "Existing approaches typically rely on large-scale fine-tuning to adapt LLMs for information reranking tasks, which is computationally expensive. In this work, we demonstrate that modern LLMs can be effectively adapted using only minimal, high-quality supervision. To enable this, we design LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating diverse, challenging, and realistic reranking examples. Using this synthetic data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and FollowIR for instruction-following retrieval. Our experiments demonstrate that LIMRANK achieves competitive performance, while being trained on less than 5% of the data typically used in prior work. Further ablation studies demonstrate the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization capabilities of LIMRANK across downstream tasks, including scientific literature search and retrieval-augmented generation for knowledge-intensive problem solving.",
    "fetched_at": "2025-10-28T05:41:46.836738Z"
  },
  {
    "id": "2510.23553v1",
    "title": "OntoPret: An Ontology for the Interpretation of Human Behavior",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Alexis Ellis",
      "Stacie Severyn",
      "Fjollë Novakazi",
      "Hadi Banaee",
      "Cogan Shimizu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23553v1",
    "abstract": "As human machine teaming becomes central to paradigms like Industry 5.0, a critical need arises for machines to safely and effectively interpret complex human behaviors. A research gap currently exists between techno centric robotic frameworks, which often lack nuanced models of human behavior, and descriptive behavioral ontologies, which are not designed for real time, collaborative interpretation. This paper addresses this gap by presenting OntoPret, an ontology for the interpretation of human behavior. Grounded in cognitive science and a modular engineering methodology, OntoPret provides a formal, machine processable framework for classifying behaviors, including task deviations and deceptive actions. We demonstrate its adaptability across two distinct use cases manufacturing and gameplay and establish the semantic foundations necessary for advanced reasoning about human intentions.",
    "fetched_at": "2025-10-28T05:41:46.836689Z"
  },
  {
    "id": "2510.23554v1",
    "title": "A U-Net and Transformer Pipeline for Multilingual Image Translation",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CL",
      "CL",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Siddharth Sahay",
      "Radhika Agarwal"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23554v1",
    "abstract": "This paper presents an end-to-end multilingual translation pipeline that integrates a custom U-Net for text detection, the Tesseract engine for text recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for Neural Machine Translation (NMT). Our approach first utilizes a U-Net model, trained on a synthetic dataset , to accurately segment and detect text regions from an image. These detected regions are then processed by Tesseract to extract the source text. This extracted text is fed into a custom Transformer model trained from scratch on a multilingual parallel corpus spanning 5 languages. Unlike systems reliant on monolithic pre-trained models, our architecture emphasizes full customization and adaptability. The system is evaluated on its text detection accuracy, text recognition quality, and translation performance via BLEU scores. The complete pipeline demonstrates promising results, validating the viability of a custom-built system for translating text directly from images.",
    "fetched_at": "2025-10-28T05:41:46.836642Z"
  },
  {
    "id": "2510.23558v1",
    "title": "ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language   Models",
    "date": "2025-10-27",
    "tags": [
      "cs.SD",
      "SD",
      "cs.CL",
      "CL",
      "eess.AS",
      "AS"
    ],
    "authors": [
      "Bohan Li",
      "Wenbin Huang",
      "Yuhang Qiu",
      "Yiwei Guo",
      "Hankun Wang",
      "Zhihan Li",
      "Jing Peng",
      "Ziyang Ma",
      "Xie Chen",
      "Kai Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23558v1",
    "abstract": "Large Audio Language Models (LALMs), which couple acoustic perception with large language models (LLMs) to extract and understand diverse information from audio, have attracted intense interest from both academic and industrial communities. However, existing LALMs are highly sensitive to how instructions are phrased, affecting both (i) instruction-following rates and (ii) task performance. Yet, no existing benchmarks offer a systematic and comprehensive evaluation of this sensitivity. We introduce ISA-Bench, a dynamic benchmark evaluating instruction sensitivity for LALMs along three axes: instruction description, output format, and task composition. We assess recent open-source and proprietary LALMs using ISA-Bench, profiling both compliance and accuracy under controlled instruction variations. Experimental results reveal that even state-of-the-art LALMs suffer significant instruction sensitivity, leading to degraded performance on fundamental audio understanding tasks. To mitigate this issue, we fine-tune Qwen2-Audio on a specifically constructed complex instruction-variant dataset, achieving a marked improvement in instruction-following performance. However, this also induces nontrivial catastrophic forgetting: the model loses some previously mastered task capabilities when exposed to new instruction styles. Our benchmark provides a standardized basis for assessing and improving instruction sensitivity in LALMs, underscoring the need for instruction-robust audio understanding in real-world pipelines.",
    "fetched_at": "2025-10-28T05:41:46.836539Z"
  },
  {
    "id": "2510.23576v1",
    "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility",
    "date": "2025-10-27",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Anqi Li",
      "Zhiyong Wang",
      "Jiazhao Zhang",
      "Minghan Li",
      "Yunpeng Qi",
      "Zhibo Chen",
      "Zhizheng Zhang",
      "He Wang"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.23576v1",
    "abstract": "Urban micromobility applications, such as delivery robots, demand reliable navigation across large-scale urban environments while following long-horizon route instructions. This task is particularly challenging due to the dynamic and unstructured nature of real-world city areas, yet most existing navigation methods remain tailored to short-scale and controllable scenarios. Effective urban micromobility requires two complementary levels of navigation skills: low-level capabilities such as point-goal reaching and obstacle avoidance, and high-level capabilities, such as route-visual alignment. To this end, we propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework designed for scalable urban navigation. Our method explicitly aligns noisy route waypoints with visual observations during execution, and subsequently plans trajectories to drive the robot. To enable UrbanVLA to master both levels of navigation, we employ a two-stage training pipeline. The process begins with Supervised Fine-Tuning (SFT) using simulated environments and trajectories parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on a mixture of simulation and real-world data, which enhances the model's safety and adaptability in real-world settings. Experiments demonstrate that UrbanVLA surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban. Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both scalability to large-scale urban environments and robustness against real-world uncertainties.",
    "fetched_at": "2025-10-28T05:41:46.836315Z"
  },
  {
    "id": "2510.23578v1",
    "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a   Two-Wave Survey Study",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Joachim Baumann",
      "Aleksandra Urman",
      "Ulrich Leicht-Deobald",
      "Zachary J. Roman",
      "Anikó Hannák",
      "Markus Christen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23578v1",
    "abstract": "The rapid adoption of generative artificial intelligence (GenAI) technologies has led many organizations to integrate AI into their products and services, often without considering user preferences. Yet, public attitudes toward AI use, especially in impactful decision-making scenarios, are underexplored. Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488) representative of the Swiss population, we examine shifts in public attitudes toward AI before and after the launch of ChatGPT. We find that the GenAI boom is significantly associated with reduced public acceptance of AI (see Figure 1) and increased demand for human oversight in various decision-making contexts. The proportion of respondents finding AI \"not acceptable at all\" increased from 23% to 30%, while support for human-only decision-making rose from 18% to 26%. These shifts have amplified existing social inequalities in terms of widened educational, linguistic, and gender gaps post-boom. Our findings challenge industry assumptions about public readiness for AI deployment and highlight the critical importance of aligning technological development with evolving public preferences.",
    "fetched_at": "2025-10-28T05:41:46.836244Z"
  },
  {
    "id": "2510.23581v1",
    "title": "Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human   Animation",
    "date": "2025-10-27",
    "tags": [
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Junyoung Seo",
      "Rodrigo Mira",
      "Alexandros Haliassos",
      "Stella Bounareli",
      "Honglie Chen",
      "Linh Tran",
      "Seungryong Kim",
      "Zoe Landgraf",
      "Jie Shen"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23581v1",
    "abstract": "Audio-driven human animation models often suffer from identity drift during temporal autoregressive generation, where characters gradually lose their identity over time. One solution is to generate keyframes as intermediate temporal anchors that prevent degradation, but this requires an additional keyframe generation stage and can restrict natural motion dynamics. To address this, we propose Lookahead Anchoring, which leverages keyframes from future timesteps ahead of the current generation window, rather than within it. This transforms keyframes from fixed boundaries into directional beacons: the model continuously pursues these future anchors while responding to immediate audio cues, maintaining consistent identity through persistent guidance. This also enables self-keyframing, where the reference image serves as the lookahead target, eliminating the need for keyframe generation entirely. We find that the temporal lookahead distance naturally controls the balance between expressivity and consistency: larger distances allow for greater motion freedom, while smaller ones strengthen identity adherence. When applied to three recent human animation models, Lookahead Anchoring achieves superior lip synchronization, identity preservation, and visual quality, demonstrating improved temporal conditioning across several different architectures. Video results are available at the following link: https://lookahead-anchoring.github.io.",
    "fetched_at": "2025-10-28T05:41:46.836188Z"
  },
  {
    "id": "2510.23585v1",
    "title": "Hope Speech Detection in Social Media English Corpora: Performance of   Traditional and Transformer Models",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Luis Ramos",
      "Hiram Calvo",
      "Olga Kolesnikova"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23585v1",
    "abstract": "The identification of hope speech has become a promised NLP task, considering the need to detect motivational expressions of agency and goal-directed behaviour on social media platforms. This proposal evaluates traditional machine learning models and fine-tuned transformers for a previously split hope speech dataset as train, development and test set. On development test, a linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM with RBF kernel reached 0.77, and Na\\\"ive Bayes hit 0.75. Transformer models delivered better results, the best model achieved weighted precision of 0.82, weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80 accuracy. These results suggest that while optimally configured traditional machine learning models remain agile, transformer architectures detect some subtle semantics of hope to achieve higher precision and recall in hope speech detection, suggesting that larges transformers and LLMs could perform better in small datasets.",
    "fetched_at": "2025-10-28T05:41:46.836121Z"
  },
  {
    "id": "2510.23590v1",
    "title": "Lightweight Robust Direct Preference Optimization",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Cheol Woo Kim",
      "Shresth Verma",
      "Mauricio Tec",
      "Milind Tambe"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23590v1",
    "abstract": "Direct Preference Optimization (DPO) has become a popular method for fine-tuning large language models (LLMs) due to its stability and simplicity. However, it is also known to be sensitive to noise in the data and prone to overfitting. Recent works have proposed using distributionally robust optimization (DRO) to address potential noise and distributional shift in the data. However, these methods often suffer from excessive conservatism and high computational cost. We propose DPO-PRO (DPO with Preference Robustness), a robust fine-tuning algorithm based on DPO which accounts for uncertainty in the preference distribution through a lightweight DRO formulation. Unlike prior DRO-based variants, DPO-PRO focuses solely on uncertainty in preferences, avoiding unnecessary conservatism and incurring negligible computational overhead. We further show that DPO-PRO is equivalent to a regularized DPO objective that penalizes model overconfidence under weak preference signals. We evaluate DPO-PRO on standard alignment benchmarks and a real-world public health task. Experimental results show that our method consistently improves robustness to noisy preference signals compared to existing DPO variants.",
    "fetched_at": "2025-10-28T05:41:46.835954Z"
  },
  {
    "id": "2510.23596v1",
    "title": "Think Twice: Branch-and-Rethink Reasoning Reward Model",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yizhu Jiao",
      "Jiaqi Zeng",
      "Julien Veron Vialard",
      "Oleksii Kuchaiev",
      "Jiawei Han",
      "Olivier Delalleau"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23596v1",
    "abstract": "Large language models (LLMs) increasingly rely on thinking models that externalize intermediate steps and allocate extra test-time compute, with think-twice strategies showing that a deliberate second pass can elicit stronger reasoning. In contrast, most reward models (RMs) still compress many quality dimensions into a single scalar in one shot, a design that induces judgment diffusion: attention spreads across evaluation criteria, yielding diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a two-turn RM that transfers the think-twice principle to reward modeling. Turn 1 performs adaptive branching, selecting a small set of instance-critical dimensions (such as factuality and safety) and sketching concise, evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a targeted reread that tests those hypotheses and scrutinizes only what matters most. We train with GRPO-style reinforcement learning over structured two-turn traces using a simple binary outcome reward with strict format checks, making the approach compatible with standard RLHF pipelines. By converting all-at-oncescoringintofocused, second-lookreasoning, BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet consequential errors while remaining practical and scalable. Experimental results demonstrate that our model achieves state-of-the-art performance on three challenging reward modeling benchmarks across diverse domains. The code and the model will be released soon.",
    "fetched_at": "2025-10-28T05:41:46.835843Z"
  },
  {
    "id": "2510.23605v1",
    "title": "Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with   Progressive Texture Infilling",
    "date": "2025-10-27",
    "tags": [
      "cs.CV",
      "CV",
      "cs.AI",
      "AI",
      "cs.GR",
      "GR",
      "cs.LG",
      "LG",
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Shuhong Zheng",
      "Ashkan Mirzaei",
      "Igor Gilitschenski"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23605v1",
    "abstract": "Current 3D/4D generation methods are usually optimized for photorealism, efficiency, and aesthetics. However, they often fail to preserve the semantic identity of the subject across different viewpoints. Adapting generation methods with one or few images of a specific subject (also known as Personalization or Subject-driven generation) allows generating visual content that align with the identity of the subject. However, personalized 3D/4D generation is still largely underexplored. In this work, we introduce TIRE (Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation. It takes an initial 3D asset produced by an existing 3D generative model as input and uses video tracking to identify the regions that need to be modified. Then, we adopt a subject-driven 2D inpainting model for progressively infilling the identified regions. Finally, we resplat the modified 2D multi-view observations back to 3D while still maintaining consistency. Extensive experiments demonstrate that our approach significantly improves identity preservation in 3D/4D generation compared to state-of-the-art methods. Our project website is available at https://zsh2000.github.io/track-inpaint-resplat.github.io/.",
    "fetched_at": "2025-10-28T05:41:46.835705Z"
  },
  {
    "id": "2510.23606v1",
    "title": "Variational Masked Diffusion Models",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Yichi Zhang",
      "Alex Schwing",
      "Zhizhen Zhao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23606v1",
    "abstract": "Masked diffusion models have recently emerged as a flexible framework for discrete generative modeling. However, a key limitation of standard masked diffusion is its inability to effectively capture dependencies among tokens that are predicted concurrently, leading to degraded generation quality when dependencies among tokens are important. To explicitly model dependencies among tokens, we propose Variational Masked Diffusion (VMD), a framework that introduces latent variables into the masked diffusion process. Through controlled experiments on synthetic datasets, we demonstrate that VMD successfully learns dependencies that conventional masked diffusion fails to capture. We further validate the effectiveness of our approach on Sudoku puzzles and text datasets, where learning of dependencies among tokens improves global consistency. Across these domains, VMD enhances both generation quality and dependency awareness, highlighting the value of integrating variational inference into masked diffusion. Our code is available at: https://riccizz.github.io/VMD.",
    "fetched_at": "2025-10-28T05:41:46.835640Z"
  },
  {
    "id": "2510.22963v1",
    "title": "CompressionAttack: Exploiting Prompt Compression as a New Attack Surface   in LLM-Powered Agents",
    "date": "2025-10-27",
    "tags": [
      "cs.CR",
      "CR",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Zesen Liu",
      "Zhixiang Zhang",
      "Yuchong Xie",
      "Dongdong She"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.22963v1",
    "abstract": "LLM-powered agents often use prompt compression to reduce inference costs, but this introduces a new security risk. Compression modules, which are optimized for efficiency rather than safety, can be manipulated by adversarial inputs, causing semantic drift and altering LLM behavior. This work identifies prompt compression as a novel attack surface and presents CompressionAttack, the first framework to exploit it. CompressionAttack includes two strategies: HardCom, which uses discrete adversarial edits for hard compression, and SoftCom, which performs latent-space perturbations for soft compression. Experiments on multiple LLMs show up to 80% attack success and 98% preference flips, while remaining highly stealthy and transferable. Case studies in VSCode Cline and Ollama confirm real-world impact, and current defenses prove ineffective, highlighting the need for stronger protections.",
    "fetched_at": "2025-10-28T05:41:45.732016Z"
  },
  {
    "id": "2510.22967v1",
    "title": "MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality   Evaluation in LLMs",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yucheng Ning",
      "Xixun Lin",
      "Fang Fang",
      "Yanan Cao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.22967v1",
    "abstract": "The widespread adoption of Large Language Models (LLMs) raises critical concerns about the factual accuracy of their outputs, especially in high-risk domains such as biomedicine, law, and education. Existing evaluation methods for short texts often fail on long-form content due to complex reasoning chains, intertwined perspectives, and cumulative information. To address this, we propose a systematic approach integrating large-scale long-form datasets, multi-agent verification mechanisms, and weighted evaluation metrics. We construct LongHalluQA, a Chinese long-form factuality dataset; and develop MAD-Fact, a debate-based multi-agent verification system. We introduce a fact importance hierarchy to capture the varying significance of claims in long-form texts. Experiments on two benchmarks show that larger LLMs generally maintain higher factual consistency, while domestic models excel on Chinese content. Our work provides a structured framework for evaluating and enhancing factual reliability in long-form LLM outputs, guiding their safe deployment in sensitive domains.",
    "fetched_at": "2025-10-28T05:41:45.731972Z"
  },
  {
    "id": "2510.22977v1",
    "title": "The Reasoning Trap: How Enhancing LLM Reasoning Amplifies Tool   Hallucination",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "I.2",
      "2"
    ],
    "authors": [
      "Chenlong Yin",
      "Zeyang Sha",
      "Shiwen Cui",
      "Changhua Meng"
    ],
    "institution": "OpenAI, MIT",
    "link": "http://arxiv.org/pdf/2510.22977v1",
    "abstract": "Enhancing the reasoning capabilities of Large Language Models (LLMs) is a key strategy for building Agents that \"think then act.\" However, recent observations, like OpenAI's o3, suggest a paradox: stronger reasoning often coincides with increased hallucination, yet no prior work has systematically examined whether reasoning enhancement itself causes tool hallucination. To address this gap, we pose the central question: Does strengthening reasoning increase tool hallucination? To answer this, we introduce SimpleToolHalluBench, a diagnostic benchmark measuring tool hallucination in two failure modes: (i) no tool available, and (ii) only distractor tools available. Through controlled experiments, we establish three key findings. First, we demonstrate a causal relationship: progressively enhancing reasoning through RL increases tool hallucination proportionally with task performance gains. Second, this effect transcends overfitting - training on non-tool tasks (e.g., mathematics) still amplifies subsequent tool hallucination. Third, the effect is method-agnostic, appearing when reasoning is instilled via supervised fine-tuning and when it is merely elicited at inference by switching from direct answers to step-by-step thinking. We also evaluate mitigation strategies including Prompt Engineering and Direct Preference Optimization (DPO), revealing a fundamental reliability-capability trade-off: reducing hallucination consistently degrades utility. Mechanistically, Reasoning RL disproportionately collapses tool-reliability-related representations, and hallucinations surface as amplified divergences concentrated in late-layer residual streams. These findings reveal that current reasoning enhancement methods inherently amplify tool hallucination, highlighting the need for new training objectives that jointly optimize for capability and reliability.",
    "fetched_at": "2025-10-28T05:41:45.731925Z"
  },
  {
    "id": "2510.23011v1",
    "title": "LangLingual: A Personalised, Exercise-oriented English Language Learning   Tool Leveraging Large Language Models",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.CY",
      "CY"
    ],
    "authors": [
      "Sammriddh Gupta",
      "Sonit Singh",
      "Aditya Joshi",
      "Mira Kim"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23011v1",
    "abstract": "Language educators strive to create a rich experience for learners, while they may be restricted in the extend of feedback and practice they can provide. We present the design and development of LangLingual, a conversational agent built using the LangChain framework and powered by Large Language Models. The system is specifically designed to provide real-time, grammar-focused feedback, generate context-aware language exercises and track learner proficiency over time. The paper discusses the architecture, implementation and evaluation of LangLingual in detail. The results indicate strong usability, positive learning outcomes and encouraging learner engagement.",
    "fetched_at": "2025-10-28T05:41:45.731773Z"
  },
  {
    "id": "2510.23032v1",
    "title": "P1GPT: a multi-agent LLM workflow module for multi-modal financial   information analysis",
    "date": "2025-10-27",
    "tags": [
      "cs.CE",
      "CE"
    ],
    "authors": [
      "Chen-Che Lu",
      "Yun-Cheng Chou",
      "Teng-Ruei Chen"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23032v1",
    "abstract": "Recent advances in large language models (LLMs) have enabled multi-agent reasoning systems capable of collaborative decision-making. However, in financial analysis, most frameworks remain narrowly focused on either isolated single-agent predictors or loosely connected analyst ensembles, and they lack a coherent reasoning workflow that unifies diverse data modalities. We introduce P1GPT, a layered multi-agent LLM framework for multi-modal financial information analysis and interpretable trading decision support. Unlike prior systems that emulate trading teams through role simulation, P1GPT implements a structured reasoning pipeline that systematically fuses technical, fundamental, and news-based insights through coordinated agent communication and integration-time synthesis. Backtesting on multi-modal datasets across major U.S. equities demonstrates that P1GPT achieves superior cumulative and risk-adjusted returns, maintains low drawdowns, and provides transparent causal rationales. These findings suggest that structured reasoning workflows, rather than agent role imitation, offer a scalable path toward explainable and trustworthy financial AI systems.",
    "fetched_at": "2025-10-28T05:41:45.731731Z"
  },
  {
    "id": "2510.23127v1",
    "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular   Understanding in Scientific LLMs",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Kai Zhuang",
      "Jiawei Zhang",
      "Yumou Liu",
      "Hanqun Cao",
      "Chunbin Gu",
      "Mengdi Liu",
      "Zhangyang Gao",
      "Zitong Jerry Wang",
      "Xuanhe Zhou",
      "Pheng-Ann Heng",
      "Lijun Wu",
      "Conghui He",
      "Cheng Tan"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23127v1",
    "abstract": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising frontier for accelerating biological discovery. However, these models face a fundamental challenge when processing raw biomolecular sequences: the tokenization dilemma. Whether treating sequences as a specialized language, risking the loss of functional motif information, or as a separate modality, introducing formidable alignment challenges, current strategies fundamentally limit their reasoning capacity. We challenge this sequence-centric paradigm by positing that a more effective strategy is to provide Sci-LLMs with high-level structured context derived from established bioinformatics tools, thereby bypassing the need to interpret low-level noisy sequence data directly. Through a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we tested three input modes: sequence-only, context-only, and a combination of both. Our findings are striking: the context-only approach consistently and substantially outperforms all other modes. Even more revealing, the inclusion of the raw sequence alongside its high-level context consistently degrades performance, indicating that raw sequences act as informational noise, even for models with specialized tokenization schemes. These results suggest that the primary strength of existing Sci-LLMs lies not in their nascent ability to interpret biomolecular syntax from scratch, but in their profound capacity for reasoning over structured, human-readable knowledge. Therefore, we argue for reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines over expert knowledge. This work lays the foundation for a new class of hybrid scientific AI agents, repositioning the developmental focus from direct sequence interpretation towards high-level knowledge synthesis. The code is available at github.com/opendatalab-raise-dev/CoKE.",
    "fetched_at": "2025-10-28T05:41:45.731627Z"
  },
  {
    "id": "2510.23245v1",
    "title": "Multi-Stakeholder Alignment in LLM-Powered Collaborative AI Systems: A   Multi-Agent Framework for Intelligent Tutoring",
    "date": "2025-10-27",
    "tags": [
      "cs.HC",
      "HC",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Alexandre P Uchoa",
      "Carlo E T Oliveira",
      "Claudia L R Motta",
      "Daniel Schneider"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23245v1",
    "abstract": "The integration of Large Language Models into Intelligent Tutoring Systems pre-sents significant challenges in aligning with diverse and often conflicting values from students, parents, teachers, and institutions. Existing architectures lack for-mal mechanisms for negotiating these multi-stakeholder tensions, creating risks in accountability and bias. This paper introduces the Advisory Governance Layer (AGL), a non-intrusive, multi-agent framework designed to enable distributed stakeholder participation in AI governance. The AGL employs specialized agents representing stakeholder groups to evaluate pedagogical actions against their spe-cific policies in a privacy-preserving manner, anticipating future advances in per-sonal assistant technology that will enhance stakeholder value expression. Through a novel policy taxonomy and conflict-resolution protocols, the frame-work provides structured, auditable governance advice to the ITS without altering its core pedagogical decision-making. This work contributes a reference architec-ture and technical specifications for aligning educational AI with multi-stakeholder values, bridging the gap between high-level ethical principles and practical implementation.",
    "fetched_at": "2025-10-28T05:41:45.731433Z"
  },
  {
    "id": "2510.23408v1",
    "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream   Processing Pipelines",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.DC",
      "DC",
      "cs.ET",
      "ET",
      "cs.LG",
      "LG",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Abolfazl Younesi",
      "Zahra Najafabadi Samani",
      "Thomas Fahringer"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23408v1",
    "abstract": "Data pipelines are essential in stream processing as they enable the efficient collection, processing, and delivery of real-time data, supporting rapid data analysis. In this paper, we present AutoStreamPipe, a novel framework that employs Large Language Models (LLMs) to automate the design, generation, and deployment of stream processing pipelines. AutoStreamPipe bridges the semantic gap between high-level user intent and platform-specific implementations across distributed stream processing systems for structured multi-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an extended version of GoT. AutoStreamPipe combines resilient execution strategies, advanced query analysis, and HGoT to deliver pipelines with good accuracy. Experimental evaluations on diverse pipelines demonstrate that AutoStreamPipe significantly reduces development time (x6.3) and error rates (x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM code-generation methods.",
    "fetched_at": "2025-10-28T05:41:45.731229Z"
  },
  {
    "id": "2510.22907v1",
    "title": "Language Server CLI Empowers Language Agents with Process Rewards",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.PL",
      "PL",
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Yifan Zhang",
      "Lanser Contributors"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.22907v1",
    "abstract": "Large language models routinely hallucinate APIs and mislocalize edits, while language servers compute verified, IDE-grade facts about real code. We present Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language Server Protocol (LSP) server for coding agents and CI, exposing deterministic, replayable workflows. Our position is that language servers provide not only structural information (definitions, references, types, diagnostics) but also an actionable process reward: machine-checked, step-wise signals that align an agent's planning loop with program reality. In this work, Lanser-CLI contributes: (i) a robust addressing scheme beyond brittle \"file:line:col\" via a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a principled relocation algorithm; (ii) deterministic Analysis Bundles that normalize Language Server responses and capture environment/capability metadata with stable content hashes; (iii) a safety envelope for mutating operations (rename, code actions) with preview, workspace jails, and Git-aware, transactional apply; and (iv) a process-reward functional derived from Language Server facts (diagnostic deltas, disambiguation confidence, and safe-apply checks) that is computable online and replayable offline. We formalize determinism under frozen snapshots and establish a monotonicity property for the process reward, making it suitable for process supervision and counterfactual analysis. Project Page: https://github.com/yifanzhang-pro/lanser-cli",
    "fetched_at": "2025-10-28T05:41:44.624048Z"
  },
  {
    "id": "2510.22940v1",
    "title": "RL-AUX: Reinforcement Learning for Auxiliary Task Generation",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Judah Goldfeder",
      "Matthew So",
      "Hod Lipson"
    ],
    "institution": "Meta",
    "link": "http://arxiv.org/pdf/2510.22940v1",
    "abstract": "Auxiliary Learning (AL) is a special case of Multi-task Learning (MTL) in which a network trains on auxiliary tasks to improve performance on its main task. This technique is used to improve generalization and, ultimately, performance on the network's main task. AL has been demonstrated to improve performance across multiple domains, including navigation, image classification, and natural language processing. One weakness of AL is the need for labeled auxiliary tasks, which can require human effort and domain expertise to generate. Meta Learning techniques have been used to solve this issue by learning an additional auxiliary task generation network that can create helpful tasks for the primary network. The most prominent techniques rely on Bi-Level Optimization, which incurs computational cost and increased code complexity. To avoid the need for Bi-Level Optimization, we present an RL-based approach to dynamically create auxiliary tasks. In this framework, an RL agent is tasked with selecting auxiliary labels for every data point in a training set. The agent is rewarded when their selection improves the performance on the primary task. We also experiment with learning optimal strategies for weighing the auxiliary loss per data point. On the 20-Superclass CIFAR100 problem, our RL approach outperforms human-labeled auxiliary tasks and performs as well as a prominent Bi-Level Optimization technique. Our weight learning approaches significantly outperform all of these benchmarks. For example, a Weight-Aware RL-based approach helps the VGG16 architecture achieve 80.9% test accuracy while the human-labeled auxiliary task setup achieved 75.53%. The goal of this work is to (1) prove that RL is a viable approach to dynamically generate auxiliary tasks and (2) demonstrate that per-sample auxiliary task weights can be learned alongside the auxiliary task labels and can achieve strong results.",
    "fetched_at": "2025-10-28T05:41:44.624004Z"
  },
  {
    "id": "2510.22969v1",
    "title": "Multi-Agent Conditional Diffusion Model with Mean Field Communication as   Wireless Resource Allocation Planner",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Kechen Meng",
      "Sinuo Zhang",
      "Rongpeng Li",
      "Xiangming Meng",
      "Chan Wang",
      "Ming Lei",
      "Zhifeng Zhao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.22969v1",
    "abstract": "In wireless communication systems, efficient and adaptive resource allocation plays a crucial role in enhancing overall Quality of Service (QoS). While centralized Multi-Agent Reinforcement Learning (MARL) frameworks rely on a central coordinator for policy training and resource scheduling, they suffer from scalability issues and privacy risks. In contrast, the Distributed Training with Decentralized Execution (DTDE) paradigm enables distributed learning and decision-making, but it struggles with non-stationarity and limited inter-agent cooperation, which can severely degrade system performance. To overcome these challenges, we propose the Multi-Agent Conditional Diffusion Model Planner (MA-CDMP) for decentralized communication resource management. Built upon the Model-Based Reinforcement Learning (MBRL) paradigm, MA-CDMP employs Diffusion Models (DMs) to capture environment dynamics and plan future trajectories, while an inverse dynamics model guides action generation, thereby alleviating the sample inefficiency and slow convergence of conventional DTDE methods. Moreover, to approximate large-scale agent interactions, a Mean-Field (MF) mechanism is introduced as an assistance to the classifier in DMs. This design mitigates inter-agent non-stationarity and enhances cooperation with minimal communication overhead in distributed settings. We further theoretically establish an upper bound on the distributional approximation error introduced by the MF-based diffusion generation, guaranteeing convergence stability and reliable modeling of multi-agent stochastic dynamics. Extensive experiments demonstrate that MA-CDMP consistently outperforms existing MARL baselines in terms of average reward and QoS metrics, showcasing its scalability and practicality for real-world wireless network optimization.",
    "fetched_at": "2025-10-28T05:41:44.623956Z"
  },
  {
    "id": "2510.22986v1",
    "title": "CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with   LLMs",
    "date": "2025-10-27",
    "tags": [
      "cs.SE",
      "SE",
      "cs.DC",
      "DC",
      "cs.MA",
      "MA"
    ],
    "authors": [
      "Junjie Huang",
      "Minghua He",
      "Jinyang Liu",
      "Yintong Huo",
      "Domenico Bianculli",
      "Michael R. Lyu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.22986v1",
    "abstract": "Log-based anomaly detection (LogAD) is critical for maintaining the reliability and availability of large-scale online service systems. While machine learning, deep learning, and large language models (LLMs)-based methods have advanced the LogAD, they often suffer from limited interpretability, high inference costs, and extensive preprocessing requirements, limiting their practicality for real-time, high-volume log analysis. In contrast, rule-based systems offer efficiency and transparency, but require significant manual effort and are difficult to scale across diverse and evolving environments. In this paper, We present CodeAD, a novel framework that automatically synthesizes lightweight Python rule functions for LogAD using LLMs. CodeAD introduces a hierarchical clustering and anchor-grounded sampling strategy to construct representative contrastive log windows, enabling LLMs to discern discriminative anomaly patterns. To ensure robustness and generalizability, CodeAD employs an agentic workflow that iteratively generates, tests, repairs, and refines the rules until it meets correctness and abstraction requirements. The synthesized rules are interpretable, lightweight, and directly executable on raw logs, supporting efficient and transparent online anomaly detection. Our comprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird) demonstrate that CodeAD achieves an average absolute improvement of 3.6% F1 score over the state-of-the-art baselines, while processing large datasets up to 4x faster and at a fraction of the cost (total LLM invocation cost under 4 USD per dataset). These results highlight CodeAD as a practical and scalable solution for online monitoring systems, enabling interpretable, efficient, and automated LogAD in real-world environment.",
    "fetched_at": "2025-10-28T05:41:44.623894Z"
  },
  {
    "id": "2510.23010v1",
    "title": "TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term   Memory for Scalable Code Generation",
    "date": "2025-10-27",
    "tags": [
      "cs.SE",
      "SE"
    ],
    "authors": [
      "Ming-Tung Shen",
      "Yuh-Jzer Joung"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23010v1",
    "abstract": "Agentic code generation requires large language models (LLMs) capable of complex context management and multi-step reasoning. Prior multi-agent frameworks attempt to address these challenges through collaboration, yet they often suffer from rigid workflows and high reasoning recovery costs. To overcome these limitations, we propose TALM (Tree-Structured Multi-Agent Framework with Long-Term Memory), a dynamic framework that integrates structured task decomposition, localized re-reasoning, and long-term memory mechanisms. TALM employs an extensible tree-based collaboration structure. The parent-child relationships, when combined with a divide-and-conquer strategy, enhance reasoning flexibility and enable efficient error correction across diverse task scopes. Furthermore, a long-term memory module enables semantic querying and integration of prior knowledge, supporting implicit self-improvement through experience reuse. Experimental results on HumanEval, BigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently delivers strong reasoning performance and high token efficiency, highlighting its robustness and practical utility in complex code generation tasks.",
    "fetched_at": "2025-10-28T05:41:44.623835Z"
  },
  {
    "id": "2510.23038v1",
    "title": "Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated   Reinforcement Learning",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Ran Xu",
      "Jingjing Chen",
      "Jiayu Ye",
      "Yu Wu",
      "Jun Yan",
      "Carl Yang",
      "Hongkun Yu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23038v1",
    "abstract": "Large Language Models (LLMs) are widely used as judges to evaluate response quality, providing a scalable alternative to human evaluation. However, most LLM judges operate solely on intrinsic text-based reasoning, limiting their ability to verify complex constraints or perform accurate computation. Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks, we propose TIR-Judge, an end-to-end RL framework for training LLM judges that integrates a code executor for precise evaluation. TIR-Judge is built on three principles: (i) diverse training across verifiable and non-verifiable domains, (ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii) iterative RL that bootstraps directly from the initial model without distillation. On seven public benchmarks, TIR-Judge surpasses strong reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and achieves listwise performance comparable to Claude-Opus-4 despite having only 8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled judge trajectories, matches the performance of distilled variants, demonstrating that tool-augmented judges can self-evolve through iterative reinforcement learning.",
    "fetched_at": "2025-10-28T05:41:44.623795Z"
  },
  {
    "id": "2510.23053v1",
    "title": "AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for   Multi-UAV Cooperative Mobile Edge Computing",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.DC",
      "DC"
    ],
    "authors": [
      "Zhiyu Wang",
      "Suman Raj",
      "Rajkumar Buyya"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23053v1",
    "abstract": "Multiple Unmanned Aerial Vehicles (UAVs) cooperative Mobile Edge Computing (MEC) systems face critical challenges in coordinating trajectory planning, task offloading, and resource allocation while ensuring Quality of Service (QoS) under dynamic and uncertain environments. Existing approaches suffer from limited scalability, slow convergence, and inefficient knowledge sharing among UAVs, particularly when handling large-scale IoT device deployments with stringent deadline constraints. This paper proposes AirFed, a novel federated graph-enhanced multi-agent reinforcement learning framework that addresses these challenges through three key innovations. First, we design dual-layer dynamic Graph Attention Networks (GATs) that explicitly model spatial-temporal dependencies among UAVs and IoT devices, capturing both service relationships and collaborative interactions within the network topology. Second, we develop a dual-Actor single-Critic architecture that jointly optimizes continuous trajectory control and discrete task offloading decisions. Third, we propose a reputation-based decentralized federated learning mechanism with gradient-sensitive adaptive quantization, enabling efficient and robust knowledge sharing across heterogeneous UAVs. Extensive experiments demonstrate that AirFed achieves 42.9% reduction in weighted cost compared to state-of-the-art baselines, attains over 99% deadline satisfaction and 94.2% IoT device coverage rate, and reduces communication overhead by 54.5%. Scalability analysis confirms robust performance across varying UAV numbers, IoT device densities, and system scales, validating AirFed's practical applicability for large-scale UAV-MEC deployments.",
    "fetched_at": "2025-10-28T05:41:44.623738Z"
  },
  {
    "id": "2510.23076v1",
    "title": "Periodic event-triggered impulsive control for fully heterogeneous   stochastic multi-agent systems with a time-varying topology",
    "date": "2025-10-27",
    "tags": [
      "math.DS",
      "DS"
    ],
    "authors": [
      "Xuetao Yang",
      "Ruilu An",
      "Quanxin Zhu"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23076v1",
    "abstract": "In this paper, we focus on a periodic event-triggered impulsive control (PETIC) for fully heterogeneous stochastic multi-agent systems (MASs) with a time-varying topology. Firstly, a novel time-varying topology is established by incorporating the energy consumption of each agent. This topology enables active adjustment of the information interaction intensity between agents. Secondly, to address the difficulties that agents with different dimensions cannot communicate in fully heterogeneous stochastic MASs, a virtual state space is designed. According to the above framework, novel PETICs with/without actuation delays are presented to achieve the mean-square exponential consensus of fully heterogeneous stochastic MASs. Finally, the effectiveness of the proposed methods is verified through a numerical simulation of unmanned aerial vehicles and unmanned ground vehicles.",
    "fetched_at": "2025-10-28T05:41:44.623689Z"
  },
  {
    "id": "2510.23148v1",
    "title": "Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement   Learning in BabyAI",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "eess.IV",
      "IV",
      "I.2.6; I.2.9; I.5.4",
      "4"
    ],
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23148v1",
    "abstract": "Deep reinforcement learning agents often struggle when tasks require understanding both vision and language. Conventional architectures typically isolate perception (for example, CNN-based visual encoders) from decision-making (policy networks). This separation can be inefficient, since the policy's failures do not directly help the perception module learn what is important. To address this, we implement the Perception-Decision Interleaving Transformer (PDiT) architecture introduced by Mao et al. (2023), a model that alternates between perception and decision layers within a single transformer. This interleaving allows feedback from decision-making to refine perceptual features dynamically. In addition, we integrate a contrastive loss inspired by CLIP to align textual mission embeddings with visual scene features. We evaluate the PDiT encoders on the BabyAI GoToLocal environment and find that the approach achieves more stable rewards and stronger alignment compared to a standard PPO baseline. The results suggest that interleaved transformer encoders are a promising direction for developing more integrated autonomous agents.",
    "fetched_at": "2025-10-28T05:41:44.623644Z"
  },
  {
    "id": "2510.23182v1",
    "title": "SI-Bench: Benchmarking Social Intelligence of Large Language Models in   Human-to-Human Conversations",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Shuai Huang",
      "Wenxuan Zhao",
      "Jun Gao"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23182v1",
    "abstract": "As large language models (LLMs) develop anthropomorphic abilities, they are increasingly being deployed as autonomous agents to interact with humans. However, evaluating their performance in realistic and complex social interactions remains a significant challenge. Most previous research built datasets through simulated agent-to-agent interactions, which fails to capture the authentic linguistic styles and relational dynamics found in real human conversations. To address this gap, we introduce SI-Bench, a novel benchmark designed to evaluate aspects of social intelligence in LLMs. Grounded in broad social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues collected from a social networking application. We further selected a subset of 312 dialogues for manual annotation across 8 major models. The experiments show that SOTA models have surpassed the human expert in process reasoning under complex social situations, yet they still fall behind humans in reply quality. Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the performance of LLMs in social dialogue tasks. All datasets are openly available at https://github.com/SI-Bench/SI-Bench.git.",
    "fetched_at": "2025-10-28T05:41:44.623581Z"
  },
  {
    "id": "2510.23190v1",
    "title": "Evaluation of Vision-LLMs in Surveillance Video",
    "date": "2025-10-27",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Pascal Benschop",
      "Cristian Meo",
      "Justin Dauwels",
      "Jelte P. Mense"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23190v1",
    "abstract": "The widespread use of cameras in our society has created an overwhelming amount of video data, far exceeding the capacity for human monitoring. This presents a critical challenge for public safety and security, as the timely detection of anomalous or criminal events is crucial for effective response and prevention. The ability for an embodied agent to recognize unexpected events is fundamentally tied to its capacity for spatial reasoning. This paper investigates the spatial reasoning of vision-language models (VLMs) by framing anomalous action recognition as a zero-shot, language-grounded task, addressing the embodied perception challenge of interpreting dynamic 3D scenes from sparse 2D video. Specifically, we investigate whether small, pre-trained vision--LLMs can act as spatially-grounded, zero-shot anomaly detectors by converting video into text descriptions and scoring labels via textual entailment. We evaluate four open models on UCF-Crime and RWF-2000 under prompting and privacy-preserving conditions. Few-shot exemplars can improve accuracy for some models, but may increase false positives, and privacy filters -- especially full-body GAN transforms -- introduce inconsistencies that degrade accuracy. These results chart where current vision--LLMs succeed (simple, spatially salient events) and where they falter (noisy spatial cues, identity obfuscation). Looking forward, we outline concrete paths to strengthen spatial grounding without task-specific training: structure-aware prompts, lightweight spatial memory across clips, scene-graph or 3D-pose priors during description, and privacy methods that preserve action-relevant geometry. This positions zero-shot, language-grounded pipelines as adaptable building blocks for embodied, real-world video understanding. Our implementation for evaluating VLMs is publicly available at: https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition",
    "fetched_at": "2025-10-28T05:41:44.623537Z"
  },
  {
    "id": "2510.23216v1",
    "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a   Sample-Efficient Reinforcement Learning Approach",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Jean-Philippe Barrette-LaPierre",
      "Florian Fuchs",
      "Brady Chen",
      "Micheal Jones",
      "Linus Gisslén"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23216v1",
    "abstract": "While several high profile video games have served as testbeds for Deep Reinforcement Learning (DRL), this technique has rarely been employed by the game industry for crafting authentic AI behaviors. Previous research focuses on training super-human agents with large models, which is impractical for game studios with limited resources aiming for human-like agents. This paper proposes a sample-efficient DRL method tailored for training and fine-tuning agents in industrial settings such as the video game industry. Our method improves sample efficiency of value-based DRL by leveraging pre-collected data and increasing network plasticity. We evaluate our method training a goalkeeper agent in EA SPORTS FC 25, one of the best-selling football simulations today. Our agent outperforms the game's built-in AI by 10% in ball saving rate. Ablation studies show that our method trains agents 50% faster compared to standard DRL methods. Finally, qualitative evaluation from domain experts indicates that our approach creates more human-like gameplay compared to hand-crafted agents. As a testimony of the impact of the approach, the method is intended to replace the hand-crafted counterpart in next iterations of the series.",
    "fetched_at": "2025-10-28T05:41:44.623484Z"
  },
  {
    "id": "2510.23272v1",
    "title": "Code Aesthetics with Agentic Reward Feedback",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL"
    ],
    "authors": [
      "Bang Xiao",
      "Lingjie Jiang",
      "Shaohan Huang",
      "Tengchao Lv",
      "Yupan Huang",
      "Xun Wu",
      "Lei Cui",
      "Furu Wei"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23272v1",
    "abstract": "Large Language Models (LLMs) have become valuable assistants for developers in code-related tasks. While LLMs excel at traditional programming tasks such as code generation and bug fixing, they struggle with visually-oriented coding tasks, often producing suboptimal aesthetics. In this paper, we introduce a new pipeline to enhance the aesthetic quality of LLM-generated code. We first construct AesCode-358K, a large-scale instruction-tuning dataset focused on code aesthetics. Next, we propose agentic reward feedback, a multi-agent system that evaluates executability, static aesthetics, and interactive aesthetics. Building on this, we develop GRPO-AR, which integrates these signals into the GRPO algorithm for joint optimization of functionality and code aesthetics. Finally, we develop OpenDesign, a benchmark for assessing code aesthetics. Experimental results show that combining supervised fine-tuning on AesCode-358K with reinforcement learning using agentic reward feedback significantly improves performance on OpenDesign and also enhances results on existing benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o and GPT-4.1, and achieves performance comparable to large open-source models with 480B-685B parameters, underscoring the effectiveness of our approach.",
    "fetched_at": "2025-10-28T05:41:44.623426Z"
  },
  {
    "id": "2510.23304v1",
    "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Riccardo Romanello",
      "Daniele Lizzio Bosco",
      "Jacopo Cossio",
      "Dusan Sutulovic",
      "Giuseppe Serra",
      "Carla Piazza",
      "Paolo Burelli"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23304v1",
    "abstract": "CNOT gates are fundamental to quantum computing, as they facilitate entanglement, a crucial resource for quantum algorithms. Certain classes of quantum circuits are constructed exclusively from CNOT gates. Given their widespread use, it is imperative to minimise the number of CNOT gates employed. This problem, known as CNOT minimisation, remains an open challenge, with its computational complexity yet to be fully characterised. In this work, we introduce a novel reinforcement learning approach to address this task. Instead of training multiple reinforcement learning agents for different circuit sizes, we use a single agent up to a fixed size $m$. Matrices of sizes different from m are preprocessed using either embedding or Gaussian striping. To assess the efficacy of our approach, we trained an agent with m = 8, and evaluated it on matrices of size n that range from 3 to 15. The results we obtained show that our method overperforms the state-of-the-art algorithm as the value of n increases.",
    "fetched_at": "2025-10-28T05:41:44.623358Z"
  },
  {
    "id": "2510.23340v1",
    "title": "Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by   Projecting User Awareness across Future Timesteps",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.HC",
      "HC"
    ],
    "authors": [
      "Anwesha Das",
      "John Duff",
      "Jörg Hoffmann",
      "Vera Demberg"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23340v1",
    "abstract": "Adaptive agent design offers a way to improve human-AI collaboration on time-sensitive tasks in rapidly changing environments. In such cases, to ensure the human maintains an accurate understanding of critical task elements, an assistive agent must not only identify the highest priority information but also estimate how and when this information can be communicated most effectively, given that human attention represents a zero-sum cognitive resource where focus on one message diminishes awareness of other or upcoming information. We introduce a theoretical framework for adaptive signalling which meets these challenges by using principles of rational communication, formalised as Bayesian reference resolution using the Rational Speech Act (RSA) modelling framework, to plan a sequence of messages which optimise timely alignment between user belief and a dynamic environment. The agent adapts message specificity and timing to the particulars of a user and scenario based on projections of how prior-guided interpretation of messages will influence attention to the interface and subsequent belief update, across several timesteps out to a fixed horizon. In a comparison to baseline methods, we show that this effectiveness depends crucially on combining multi-step planning with a realistic model of user awareness. As the first application of RSA for communication in a dynamic environment, and for human-AI interaction in general, we establish theoretical foundations for pragmatic communication in human-agent teams, highlighting how insights from cognitive science can be capitalised to inform the design of assistive agents.",
    "fetched_at": "2025-10-28T05:41:44.623298Z"
  },
  {
    "id": "2510.23397v1",
    "title": "VideoTG-R1: Boosting Video Temporal Grounding via Curriculum   Reinforcement Learning on Reflected Boundary Annotations",
    "date": "2025-10-27",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Lu Dong",
      "Haiyu Zhang",
      "Han Lin",
      "Ziang Yan",
      "Xiangyu Zeng",
      "Hongjie Zhang",
      "Yifei Huang",
      "Yi Wang",
      "Zhen-Hua Ling",
      "Limin Wang",
      "Yali Wang"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23397v1",
    "abstract": "Video temporal grounding (VTG) aims to locate precise segments in videos based on language queries, which is a fundamental challenge in video understanding. While recent Multimodal Large Language Models (MLLMs) have shown promise in tackling VTG through reinforcement learning (RL), they overlook the challenges arising from both the quality and difficulty of training samples. (1) Partially annotated samples. Many samples contain relevant segments beyond the annotated interval, introducing ambiguous supervision. (2) Hard-to-ground samples. Samples with poor zero-shot performance produce consistently low and indistinguishable rewards during RL training, exhibiting no clear preference among multiple outputs and thus hindering learning efficiency. To address these challenges, we propose VideoTG-R1, a novel curriculum RL framework with reflected boundary annotations, enabling data-efficient training. Specifically, we propose a Boundary Reflection Agent that utilizes MLLMs to predict query-relevant timestamps outside the annotated intervals, allowing us to identify and filter out partially annotated samples, thereby reducing ambiguity. Furthermore, we introduce a Difficulty Estimation Agent to assess the training difficulty of each sample and design a curriculum RL strategy that dynamically masks the videos of hard-to-ground samples according to the training steps, easing the training difficulty and providing clearer preference. Experiments on the VTG and grounded VideoQA tasks demonstrate the effectiveness of our method. Remarkably, with only 10% of the training samples and 21% of the computational budget, VideoTG-R1 outperforms full-data counterparts under both group relative policy optimization (GRPO) and supervised fine-tuning (SFT). The code is available at https://github.com/ldong1111/VideoTG-R1.",
    "fetched_at": "2025-10-28T05:41:44.623189Z"
  },
  {
    "id": "2510.23424v1",
    "title": "Causal Deep Q Network",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Elouanes Khelifi",
      "Amir Saki",
      "Usef Faghihi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23424v1",
    "abstract": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement learning tasks. However, their reliance on associative learning often leads to the acquisition of spurious correlations, hindering their problem-solving capabilities. In this paper, we introduce a novel approach to integrate causal principles into DQNs, leveraging the PEACE (Probabilistic Easy vAriational Causal Effect) formula for estimating causal effects. By incorporating causal reasoning during training, our proposed framework enhances the DQN's understanding of the underlying causal structure of the environment, thereby mitigating the influence of confounding factors and spurious correlations. We demonstrate that integrating DQNs with causal capabilities significantly enhances their problem-solving capabilities without compromising performance. Experimental results on standard benchmark environments showcase that our approach outperforms conventional DQNs, highlighting the effectiveness of causal reasoning in reinforcement learning. Overall, our work presents a promising avenue for advancing the capabilities of deep reinforcement learning agents through principled causal inference.",
    "fetched_at": "2025-10-28T05:41:44.623110Z"
  },
  {
    "id": "2510.23476v1",
    "title": "Human-AI Collaborative Uncertainty Quantification",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.HC",
      "HC",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Sima Noorani",
      "Shayan Kiyani",
      "George Pappas",
      "Hamed Hassani"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23476v1",
    "abstract": "AI predictive systems are increasingly embedded in decision making pipelines, shaping high stakes choices once made solely by humans. Yet robust decisions under uncertainty still rely on capabilities that current AI lacks: domain knowledge not captured by data, long horizon context, and reasoning grounded in the physical world. This gap has motivated growing efforts to design collaborative frameworks that combine the complementary strengths of humans and AI. This work advances this vision by identifying the fundamental principles of Human AI collaboration within uncertainty quantification, a key component of reliable decision making. We introduce Human AI Collaborative Uncertainty Quantification, a framework that formalizes how an AI model can refine a human expert's proposed prediction set with two goals: avoiding counterfactual harm, ensuring the AI does not degrade correct human judgments, and complementarity, enabling recovery of correct outcomes the human missed. At the population level, we show that the optimal collaborative prediction set follows an intuitive two threshold structure over a single score function, extending a classical result in conformal prediction. Building on this insight, we develop practical offline and online calibration algorithms with provable distribution free finite sample guarantees. The online method adapts to distribution shifts, including human behavior evolving through interaction with AI, a phenomenon we call Human to AI Adaptation. Experiments across image classification, regression, and text based medical decision making show that collaborative prediction sets consistently outperform either agent alone, achieving higher coverage and smaller set sizes across various conditions.",
    "fetched_at": "2025-10-28T05:41:44.623042Z"
  },
  {
    "id": "2510.23535v1",
    "title": "Sequential Multi-Agent Dynamic Algorithm Configuration",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Chen Lu",
      "Ke Xue",
      "Lei Yuan",
      "Yao Wang",
      "Yaoyuan Wang",
      "Sheng Fu",
      "Chao Qian"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23535v1",
    "abstract": "Dynamic algorithm configuration (DAC) is a recent trend in automated machine learning, which can dynamically adjust the algorithm's configuration during the execution process and relieve users from tedious trial-and-error tuning tasks. Recently, multi-agent reinforcement learning (MARL) approaches have improved the configuration of multiple heterogeneous hyperparameters, making various parameter configurations for complex algorithms possible. However, many complex algorithms have inherent inter-dependencies among multiple parameters (e.g., determining the operator type first and then the operator's parameter), which are, however, not considered in previous approaches, thus leading to sub-optimal results. In this paper, we propose the sequential multi-agent DAC (Seq-MADAC) framework to address this issue by considering the inherent inter-dependencies of multiple parameters. Specifically, we propose a sequential advantage decomposition network, which can leverage action-order information through sequential advantage decomposition. Experiments from synthetic functions to the configuration of multi-objective optimization algorithms demonstrate Seq-MADAC's superior performance over state-of-the-art MARL methods and show strong generalization across problem classes. Seq-MADAC establishes a new paradigm for the widespread dependency-aware automated algorithm configuration. Our code is available at https://github.com/lamda-bbo/seq-madac.",
    "fetched_at": "2025-10-28T05:41:44.622882Z"
  },
  {
    "id": "2510.23458v1",
    "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Litu Ou",
      "Kuan Li",
      "Huifeng Yin",
      "Liwen Zhang",
      "Zhongwang Zhang",
      "Xixi Wu",
      "Rui Ye",
      "Zile Qiao",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23458v1",
    "abstract": "Confidence in LLMs is a useful indicator of model uncertainty and answer reliability. Existing work mainly focused on single-turn scenarios, while research on confidence in complex multi-turn interactions is limited. In this paper, we investigate whether LLM-based search agents have the ability to communicate their own confidence through verbalized confidence scores after long sequences of actions, a significantly more challenging task compared to outputting confidence in a single interaction. Experimenting on open-source agentic models, we first find that models exhibit much higher task accuracy at high confidence while having near-zero accuracy when confidence is low. Based on this observation, we propose Test-Time Scaling (TTS) methods that use confidence scores to determine answer quality, encourage the model to try again until reaching a satisfactory confidence level. Results show that our proposed methods significantly reduce token consumption while demonstrating competitive performance compared to baseline fixed budget TTS methods.",
    "fetched_at": "2025-10-28T05:41:43.501730Z"
  },
  {
    "id": "2510.23487v1",
    "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI   and the Chomsky Hierarchy",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.FL",
      "FL"
    ],
    "authors": [
      "Roham Koohestani",
      "Ziyou Li",
      "Anton Podkopaev",
      "Maliheh Izadi"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23487v1",
    "abstract": "This paper establishes a formal equivalence between the architectural classes of modern agentic AI systems and the abstract machines of the Chomsky hierarchy. We posit that the memory architecture of an AI agent is the definitive feature determining its computational power and that it directly maps it to a corresponding class of automaton. Specifically, we demonstrate that simple reflex agents are equivalent to Finite Automata, hierarchical task-decomposition agents are equivalent to Pushdown Automata, and agents employing readable/writable memory for reflection are equivalent to TMs. This Automata-Agent Framework provides a principled methodology for right-sizing agent architectures to optimize computational efficiency and cost. More critically, it creates a direct pathway to formal verification, enables the application of mature techniques from automata theory to guarantee agent safety and predictability. By classifying agents, we can formally delineate the boundary between verifiable systems and those whose behavior is fundamentally undecidable. We address the inherent probabilistic nature of LLM-based agents by extending the framework to probabilistic automata that allow quantitative risk analysis. The paper concludes by outlining an agenda for developing static analysis tools and grammars for agentic frameworks.",
    "fetched_at": "2025-10-28T05:41:43.501653Z"
  },
  {
    "id": "2510.23509v1",
    "title": "Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation   World Model",
    "date": "2025-10-27",
    "tags": [
      "cs.RO",
      "RO"
    ],
    "authors": [
      "Weizheng Wang",
      "Obi Ike",
      "Soyun Choi",
      "Sungeun Hong",
      "Byung-Cheol Min"
    ],
    "institution": "Google, MIT",
    "link": "http://arxiv.org/pdf/2510.23509v1",
    "abstract": "Social robot navigation increasingly relies on large language models for reasoning, path planning, and enabling movement in dynamic human spaces. However, relying solely on LLMs for planning often leads to unpredictable and unsafe behaviors, especially in dynamic human spaces, due to limited physical grounding and weak logical consistency. In this work, we introduce NaviWM, a socially-aware robot Navigation World Model that augments LLM reasoning with a structured world model and a logic-driven chain-of-thought process. NaviWM consists of two main components: (1) a spatial-temporal world model that captures the positions, velocities, and activities of agents in the environment, and (2) a deductive reasoning module that guides LLMs through a multi-step, logic-based inference process. This integration enables the robot to generate navigation decisions that are both socially compliant and physically safe, under well-defined constraints such as personal space, collision avoidance, and timing. Unlike previous methods based on prompting or fine-tuning, NaviWM encodes social norms as first-order logic, enabling interpretable and verifiable reasoning. Experiments show that NaviWM improves success rates and reduces social violations, particularly in crowded environments. These results demonstrate the benefit of combining formal reasoning with LLMs for robust social navigation. Additional experimental details and demo videos for this work can be found at: https://sites.google.com/view/NaviWM.",
    "fetched_at": "2025-10-28T05:41:43.501571Z"
  },
  {
    "id": "2510.23557v1",
    "title": "Minimizing Human Intervention in Online Classification",
    "date": "2025-10-27",
    "tags": [
      "stat.ML",
      "ML",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "William Réveillard",
      "Vasileios Saketos",
      "Alexandre Proutiere",
      "Richard Combes"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23557v1",
    "abstract": "We introduce and study an online problem arising in question answering systems. In this problem, an agent must sequentially classify user-submitted queries represented by $d$-dimensional embeddings drawn i.i.d. from an unknown distribution. The agent may consult a costly human expert for the correct label, or guess on her own without receiving feedback. The goal is to minimize regret against an oracle with free expert access. When the time horizon $T$ is at least exponential in the embedding dimension $d$, one can learn the geometry of the class regions: in this regime, we propose the Conservative Hull-based Classifier (CHC), which maintains convex hulls of expert-labeled queries and calls the expert as soon as a query lands outside all known hulls. CHC attains $\\mathcal{O}(\\log^d T)$ regret in $T$ and is minimax optimal for $d=1$. Otherwise, the geometry cannot be reliably learned without additional distributional assumptions. We show that when the queries are drawn from a subgaussian mixture, for $T \\le e^d$, a Center-based Classifier (CC) achieves regret proportional to $N\\log{N}$ where $N$ is the number of labels. To bridge these regimes, we introduce the Generalized Hull-based Classifier (GHC), a practical extension of CHC that allows for more aggressive guessing via a tunable threshold parameter. Our approach is validated with experiments, notably on real-world question-answering datasets using embeddings derived from state-of-the-art large language models.",
    "fetched_at": "2025-10-28T05:41:43.501516Z"
  },
  {
    "id": "2510.23564v1",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI",
      "cs.CL",
      "CL",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Huixue Su",
      "Yufan Zhao",
      "Yifan Wu",
      "Mingyi Deng",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Lingxiao Tang",
      "Yingchao Li",
      "Yuyu Luo",
      "Bang Liu",
      "Chenglin Wu"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23564v1",
    "abstract": "Real-world tasks require decisions at varying granularities, and humans excel at this by leveraging a unified cognitive representation where planning is fundamentally understood as a high-level form of action. However, current Large Language Model (LLM)-based agents lack this crucial capability to operate fluidly across decision granularities. This limitation stems from existing paradigms that enforce a rigid separation between high-level planning and low-level action, which impairs dynamic adaptability and limits generalization. We propose ReCode (Recursive Code Generation), a novel paradigm that addresses this limitation by unifying planning and action within a single code representation. In this representation, ReCode treats high-level plans as abstract placeholder functions, which the agent then recursively decomposes into finer-grained sub-functions until reaching primitive actions. This recursive approach dissolves the rigid boundary between plan and action, enabling the agent to dynamically control its decision granularity. Furthermore, the recursive structure inherently generates rich, multi-granularity training data, enabling models to learn hierarchical decision-making processes. Extensive experiments show ReCode significantly surpasses advanced baselines in inference performance and demonstrates exceptional data efficiency in training, validating our core insight that unifying planning and action through recursive code generation is a powerful and effective approach to achieving universal granularity control. The code is available at https://github.com/FoundationAgents/ReCode.",
    "fetched_at": "2025-10-28T05:41:43.501465Z"
  },
  {
    "id": "2510.23569v1",
    "title": "EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT",
    "date": "2025-10-27",
    "tags": [
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Baoqi Pei",
      "Yifei Huang",
      "Jilan Xu",
      "Yuping He",
      "Guo Chen",
      "Fei Wu",
      "Yu Qiao",
      "Jiangmiao Pang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23569v1",
    "abstract": "Egocentric video reasoning centers on an unobservable agent behind the camera who dynamically shapes the environment, requiring inference of hidden intentions and recognition of fine-grained interactions. This core challenge limits current multimodal large language models MLLMs, which excel at visible event reasoning but lack embodied, first-person understanding. To bridge this gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust egocentric reasoning capabilities through spatio-temporal chain-of-thought supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M, a large-scale egocentric QA dataset constructed from 13M diverse egocentric video clips. This dataset features multi-minute segments annotated with detailed CoT rationales and dense hand-object grounding. Second, we employ SFT on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning RFT to further enhance spatio-temporal localization. Experimental results show that EgoThinker outperforms existing methods across multiple egocentric benchmarks, while achieving substantial improvements in fine-grained spatio-temporal localization tasks. Full code and data are released at https://github.com/InternRobotics/EgoThinker.",
    "fetched_at": "2025-10-28T05:41:43.501381Z"
  },
  {
    "id": "2510.23571v1",
    "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim   Translation",
    "date": "2025-10-27",
    "tags": [
      "cs.RO",
      "RO",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yash Jangir",
      "Yidi Zhang",
      "Kashu Yamazaki",
      "Chenyu Zhang",
      "Kuan-Hsun Tu",
      "Tsung-Wei Ke",
      "Lei Ke",
      "Yonatan Bisk",
      "Katerina Fragkiadaki"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23571v1",
    "abstract": "The pursuit of robot generalists - instructable agents capable of performing diverse tasks across diverse environments - demands rigorous and scalable evaluation. Yet real-world testing of robot policies remains fundamentally constrained: it is labor-intensive, slow, unsafe at scale, and difficult to reproduce. Existing simulation benchmarks are similarly limited, as they train and test policies within the same synthetic domains and cannot assess models trained from real-world demonstrations or alternative simulation environments. As policies expand in scope and complexity, these barriers only intensify, since defining \"success\" in robotics often hinges on nuanced human judgments of execution quality. In this paper, we introduce a new benchmarking framework that overcomes these challenges by shifting VLA evaluation into large-scale simulated environments augmented with online human feedback. Leveraging advances in vision-language models, 2D-to-3D generative modeling, and differentiable rendering, our approach automatically converts video demonstrations from widely used robot datasets into simulated counterparts. Within these digital twins, we assess VLA policies using both automated VLM-guided scoring and scalable human preference judgments collected from crowdworkers, transforming human involvement from tedious scene setup, resetting, and safety supervision into lightweight preference comparisons. To measure robustness, we systematically perturb simulated environments along multiple axes, such as textures and object placements, stress-testing policy generalization under controlled variation. The result is a continuously evolving, reproducible, and scalable benchmark for real-world trained robot manipulation policies, addressing a critical missing capability in today's robotics landscape.",
    "fetched_at": "2025-10-28T05:41:43.501318Z"
  },
  {
    "id": "2510.23587v1",
    "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?",
    "date": "2025-10-27",
    "tags": [
      "cs.DB",
      "DB",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yizhang Zhu",
      "Liangwei Wang",
      "Chenyu Yang",
      "Xiaotian Lin",
      "Boyan Li",
      "Wei Zhou",
      "Xinyu Liu",
      "Zhangyang Peng",
      "Tianqi Luo",
      "Yu Li",
      "Chengliang Chai",
      "Chong Chen",
      "Shimin Di",
      "Ju Fan",
      "Ji Sun",
      "Nan Tang",
      "Fugee Tsung",
      "Jiannan Wang",
      "Chenglin Wu",
      "Yanwei Xu",
      "Shaolei Zhang",
      "Yong Zhang",
      "Xuanhe Zhou",
      "Guoliang Li",
      "Yuyu Luo"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23587v1",
    "abstract": "The rapid advancement of large language models (LLMs) has spurred the emergence of data agents--autonomous systems designed to orchestrate Data + AI ecosystems for tackling complex data-related tasks. However, the term \"data agent\" currently suffers from terminological ambiguity and inconsistent adoption, conflating simple query responders with sophisticated autonomous architectures. This terminological ambiguity fosters mismatched user expectations, accountability challenges, and barriers to industry growth. Inspired by the SAE J3016 standard for driving automation, this survey introduces the first systematic hierarchical taxonomy for data agents, comprising six levels that delineate and trace progressive shifts in autonomy, from manual operations (L0) to a vision of generative, fully autonomous data agents (L5), thereby clarifying capability boundaries and responsibility allocation. Through this lens, we offer a structured review of existing research arranged by increasing autonomy, encompassing specialized data agents for data management, preparation, and analysis, alongside emerging efforts toward versatile, comprehensive systems with enhanced autonomy. We further analyze critical evolutionary leaps and technical gaps for advancing data agents, especially the ongoing L2-to-L3 transition, where data agents evolve from procedural execution to autonomous orchestration. Finally, we conclude with a forward-looking roadmap, envisioning the advent of proactive, generative data agents.",
    "fetched_at": "2025-10-28T05:41:43.501241Z"
  },
  {
    "id": "2510.23595v1",
    "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Yixing Chen",
      "Yiding Wang",
      "Siqi Zhu",
      "Haofei Yu",
      "Tao Feng",
      "Muhan Zhan",
      "Mostofa Patwary",
      "Jiaxuan You"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23595v1",
    "abstract": "Reinforcement Learning (RL) has demonstrated significant potential in enhancing the reasoning capabilities of large language models (LLMs). However, the success of RL for LLMs heavily relies on human-curated datasets and verifiable rewards, which limit their scalability and generality. Recent Self-Play RL methods, inspired by the success of the paradigm in games and Go, aim to enhance LLM reasoning capabilities without human-annotated data. However, their methods primarily depend on a grounded environment for feedback (e.g., a Python interpreter or a game engine); extending them to general domains remains challenging. To address these challenges, we propose Multi-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in solving diverse tasks, including mathematics, reasoning, and general knowledge Q&A. The core design of MAE is based on a triplet of interacting agents (Proposer, Solver, Judge) that are instantiated from a single LLM, and applies reinforcement learning to optimize their behaviors. The Proposer generates questions, the Solver attempts solutions, and the Judge evaluates both while co-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves an average improvement of 4.54% on multiple benchmarks. These results highlight MAE as a scalable, data-efficient method for enhancing the general reasoning abilities of LLMs with minimal reliance on human-curated supervision.",
    "fetched_at": "2025-10-28T05:41:43.501113Z"
  },
  {
    "id": "2510.23601v1",
    "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Jiahao Qiu",
      "Xuan Qi",
      "Hongru Wang",
      "Xinzhe Juan",
      "Yimin Wang",
      "Zelin Zhao",
      "Jiayi Geng",
      "Jiacheng Guo",
      "Peihang Li",
      "Jingzhe Shi",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23601v1",
    "abstract": "Large language models (LLMs) have been shown to perform better when scaffolded into agents with memory, tools, and feedback. Beyond this, self-evolving agents have emerged, but current work largely limits adaptation to prompt rewriting or failure retries. Therefore, we present ALITA-G, a self-evolution framework that transforms a general-purpose agent into a domain expert by systematically generating, abstracting, and curating Model Context Protocol (MCP) tools. In this framework, a generalist agent executes a curated suite of target-domain tasks and synthesizes candidate MCPs from successful trajectories. These are then abstracted to parameterized primitives and consolidated into an MCP Box. At inference time, ALITA-G performs retrieval-augmented MCP selection with the help of each tool's descriptions and use cases, before executing an agent equipped with the MCP Executor. Across several benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains strong gains while reducing computation costs. On GAIA validation, it achieves 83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result while reducing mean tokens per example by approximately 15% relative to a strong baseline agent. ALITA-G thus provides a principled pathway from generalist capability to reusable, domain-specific competence, improving both accuracy and efficiency on complex reasoning tasks.",
    "fetched_at": "2025-10-28T05:41:43.501026Z"
  },
  {
    "id": "2510.23449v1",
    "title": "Schrodinger Neural Network and Uncertainty Quantification: Quantum   Machine",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "M. M. Hammad"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23449v1",
    "abstract": "We introduce the Schrodinger Neural Network (SNN), a principled architecture for conditional density estimation and uncertainty quantification inspired by quantum mechanics. The SNN maps each input to a normalized wave function on the output domain and computes predictive probabilities via the Born rule. The SNN departs from standard parametric likelihood heads by learning complex coefficients of a spectral expansion (e . g ., Chebyshev polynomials) whose squared modulus yields the conditional density $p(y|x)=\\left| \\psi _x(y)\\right| {}^2$ with analytic normalization. This representation confers three practical advantages: positivity and exact normalization by construction, native multimodality through interference among basis modes without explicit mixture bookkeeping, and yields closed-form (or efficiently computable) functionals$-$such as moments and several calibration diagnostics$-$as quadratic forms in coefficient space. We develop the statistical and computational foundations of the SNN, including (i) training by exact maximum-likelihood with unit-sphere coefficient parameterization, (ii) physics-inspired quadratic regularizers (kinetic and potential energies) motivated by uncertainty relations between localization and spectral complexity, (iii) scalable low-rank and separable extensions for multivariate outputs, (iv) operator-based extensions that represent observables, constraints, and weak labels as self-adjoint matrices acting on the amplitude space, and (v) a comprehensive framework for evaluating multimodal predictions. The SNN provides a coherent, tractable framework to elevate probabilistic prediction from point estimates to physically inspired amplitude-based distributions.",
    "fetched_at": "2025-10-28T03:51:07.300853Z"
  },
  {
    "id": "2510.23451v1",
    "title": "Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with   Free-Form Preferences",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI",
      "cs.CV",
      "CV"
    ],
    "authors": [
      "Zhuoran Jin",
      "Hongbang Yuan",
      "Kejian Zhu",
      "Jiachun Li",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23451v1",
    "abstract": "Reward models (RMs) play a critical role in aligning AI behaviors with human preferences, yet they face two fundamental challenges: (1) Modality Imbalance, where most RMs are mainly focused on text and image modalities, offering limited support for video, audio, and other modalities; and (2) Preference Rigidity, where training on fixed binary preference pairs fails to capture the complexity and diversity of personalized preferences. To address the above challenges, we propose Omni-Reward, a step toward generalist omni-modal reward modeling with support for free-form preferences, consisting of: (1) Evaluation: We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form preferences, covering nine tasks across five modalities including text, image, video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal preference dataset comprising 248K general preference pairs and 69K instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We propose Omni-RewardModel, which includes both discriminative and generative RMs, and achieves strong performance on Omni-RewardBench as well as other widely used reward modeling benchmarks.",
    "fetched_at": "2025-10-28T03:51:07.300802Z"
  },
  {
    "id": "2510.23453v1",
    "title": "What are the odds? Risk and uncertainty about AI existential risk",
    "date": "2025-10-27",
    "tags": [
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Marco Grossi"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23453v1",
    "abstract": "This work is a commentary of the article \\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a Taxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and Hawthorne. It is not just a commentary though, but a useful reminder of the philosophical limitations of \\say{linear} models of risk. The article will focus on the model employed by the authors: first, I discuss some differences between standard Swiss Cheese models and this one. I then argue that in a situation of epistemic indifference the probability of P(D) is higher than what one might first suggest, given the structural relationships between layers. I then distinguish between risk and uncertainty, and argue that any estimation of P(D) is structurally affected by two kinds of uncertainty: option uncertainty and state-space uncertainty. Incorporating these dimensions of uncertainty into our qualitative discussion on AI existential risk can provide a better understanding of the likeliness of P(D).",
    "fetched_at": "2025-10-28T03:51:07.300728Z"
  },
  {
    "id": "2510.23455v1",
    "title": "SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Khoa Nguyen",
      "Khang Tran",
      "NhatHai Phan",
      "Cristian Borcea",
      "Rouming Jin",
      "Issa Khalil"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23455v1",
    "abstract": "This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel training algorithm to leverage the geographic information of mobile users in Federated Learning (FL). SGFusion maps the data collected by mobile devices onto geographical zones and trains one FL model per zone, which adapts well to the data and behaviors of users in that zone. SGFusion models the local data-based correlation among geographical zones as a hierarchical random graph (HRG) optimized by Markov Chain Monte Carlo sampling. At each training step, every zone fuses its local gradient with gradients derived from a small set of other zones sampled from the HRG. This approach enables knowledge fusion and sharing among geographical zones in a probabilistic and stochastic gradient fusion process with self-attention weights, such that \"more similar\" zones have \"higher probabilities\" of sharing gradients with \"larger attention weights.\" SGFusion remarkably improves model utility without introducing undue computational cost. Extensive theoretical and empirical results using a heart-rate prediction dataset collected across 6 countries show that models trained with SGFusion converge with upper-bounded expected errors and significantly improve utility in all countries compared to existing approaches without notable cost in system scalability.",
    "fetched_at": "2025-10-28T03:51:07.300692Z"
  },
  {
    "id": "2510.23463v1",
    "title": "Differential Privacy as a Perk: Federated Learning over Multiple-Access   Fading Channels with a Multi-Antenna Base Station",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.CR",
      "CR",
      "stat.ML",
      "ML"
    ],
    "authors": [
      "Hao Liang",
      "Haifeng Wen",
      "Kaishun Wu",
      "Hong Xing"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23463v1",
    "abstract": "Federated Learning (FL) is a distributed learning paradigm that preserves privacy by eliminating the need to exchange raw data during training. In its prototypical edge instantiation with underlying wireless transmissions enabled by analog over-the-air computing (AirComp), referred to as \\emph{over-the-air FL (AirFL)}, the inherent channel noise plays a unique role of \\emph{frenemy} in the sense that it degrades training due to noisy global aggregation while providing a natural source of randomness for privacy-preserving mechanisms, formally quantified by \\emph{differential privacy (DP)}. It remains, nevertheless, challenging to effectively harness such channel impairments, as prior arts, under assumptions of either simple channel models or restricted types of loss functions, mostly considering (local) DP enhancement with a single-round or non-convergent bound on privacy loss. In this paper, we study AirFL over multiple-access fading channels with a multi-antenna base station (BS) subject to user-level DP requirements. Despite a recent study, which claimed in similar settings that artificial noise (AN) must be injected to ensure DP in general, we demonstrate, on the contrary, that DP can be gained as a \\emph{perk} even \\emph{without} employing any AN. Specifically, we derive a novel bound on DP that converges under general bounded-domain assumptions on model parameters, along with a convergence bound with general smooth and non-convex loss functions. Next, we optimize over receive beamforming and power allocations to characterize the optimal convergence-privacy trade-offs, which also reveal explicit conditions in which DP is achievable without compromising training. Finally, our theoretical findings are validated by extensive numerical results.",
    "fetched_at": "2025-10-28T03:51:07.300558Z"
  },
  {
    "id": "2510.23464v1",
    "title": "Evaluating Large Language Models for Stance Detection on Financial   Targets from SEC Filing Reports and Earnings Call Transcripts",
    "date": "2025-10-27",
    "tags": [
      "cs.CL",
      "CL",
      "cs.AI",
      "AI"
    ],
    "authors": [
      "Nikesh Gyawali",
      "Doina Caragea",
      "Alex Vasenkov",
      "Cornelia Caragea"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23464v1",
    "abstract": "Financial narratives from U.S. Securities and Exchange Commission (SEC) filing reports and quarterly earnings call transcripts (ECTs) are very important for investors, auditors, and regulators. However, their length, financial jargon, and nuanced language make fine-grained analysis difficult. Prior sentiment analysis in the financial domain required a large, expensive labeled dataset, making the sentence-level stance towards specific financial targets challenging. In this work, we introduce a sentence-level corpus for stance detection focused on three core financial metrics: debt, earnings per share (EPS), and sales. The sentences were extracted from Form 10-K annual reports and ECTs, and labeled for stance (positive, negative, neutral) using the advanced ChatGPT-o3-pro model under rigorous human validation. Using this corpus, we conduct a systematic evaluation of modern large language models (LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting strategies. Our results show that few-shot with CoT prompting performs best compared to supervised baselines, and LLMs' performance varies across the SEC and ECT datasets. Our findings highlight the practical viability of leveraging LLMs for target-specific stance in the financial domain without requiring extensive labeled data.",
    "fetched_at": "2025-10-28T03:51:07.300493Z"
  },
  {
    "id": "2510.23469v1",
    "title": "Adaptive Dual Prompting: Hierarchical Debiasing for Fairness-aware Graph   Neural Networks",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Yuhan Yang",
      "Xingbo Fu",
      "Jundong Li"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23469v1",
    "abstract": "In recent years, pre-training Graph Neural Networks (GNNs) through self-supervised learning on unlabeled graph data has emerged as a widely adopted paradigm in graph learning. Although the paradigm is effective for pre-training powerful GNN models, the objective gap often exists between pre-training and downstream tasks. To bridge this gap, graph prompting adapts pre-trained GNN models to specific downstream tasks with extra learnable prompts while keeping the pre-trained GNN models frozen. As recent graph prompting methods largely focus on enhancing model utility on downstream tasks, they often overlook fairness concerns when designing prompts for adaptation. In fact, pre-trained GNN models will produce discriminative node representations across demographic subgroups, as downstream graph data inherently contains biases in both node attributes and graph structures. To address this issue, we propose an Adaptive Dual Prompting (ADPrompt) framework that enhances fairness for adapting pre-trained GNN models to downstream tasks. To mitigate attribute bias, we design an Adaptive Feature Rectification module that learns customized attribute prompts to suppress sensitive information at the input layer, reducing bias at the source. Afterward, we propose an Adaptive Message Calibration module that generates structure prompts at each layer, which adjust the message from neighboring nodes to enable dynamic and soft calibration of the information flow. Finally, ADPrompt jointly optimizes the two prompting modules to adapt the pre-trained GNN while enhancing fairness. We conduct extensive experiments on four datasets with four pre-training strategies to evaluate the performance of ADPrompt. The results demonstrate that our proposed ADPrompt outperforms seven baseline methods on node classification tasks.",
    "fetched_at": "2025-10-28T03:51:07.300433Z"
  },
  {
    "id": "2510.23471v1",
    "title": "Robust Decision Making with Partially Calibrated Forecasts",
    "date": "2025-10-27",
    "tags": [
      "stat.ML",
      "ML",
      "cs.AI",
      "AI",
      "cs.LG",
      "LG"
    ],
    "authors": [
      "Shayan Kiyani",
      "Hamed Hassani",
      "George Pappas",
      "Aaron Roth"
    ],
    "institution": "",
    "link": "http://arxiv.org/pdf/2510.23471v1",
    "abstract": "Calibration has emerged as a foundational goal in ``trustworthy machine learning'', in part because of its strong decision theoretic semantics. Independent of the underlying distribution, and independent of the decision maker's utility function, calibration promises that amongst all policies mapping predictions to actions, the uniformly best policy is the one that ``trusts the predictions'' and acts as if they were correct. But this is true only of \\emph{fully calibrated} forecasts, which are tractable to guarantee only for very low dimensional prediction problems. For higher dimensional prediction problems (e.g. when outcomes are multiclass), weaker forms of calibration have been studied that lack these decision theoretic properties. In this paper we study how a conservative decision maker should map predictions endowed with these weaker (``partial'') calibration guarantees to actions, in a way that is robust in a minimax sense: i.e. to maximize their expected utility in the worst case over distributions consistent with the calibration guarantees. We characterize their minimax optimal decision rule via a duality argument, and show that surprisingly, ``trusting the predictions and acting accordingly'' is recovered in this minimax sense by \\emph{decision calibration} (and any strictly stronger notion of calibration), a substantially weaker and more tractable condition than full calibration. For calibration guarantees that fall short of decision calibration, the minimax optimal decision rule is still efficiently computable, and we provide an empirical evaluation of a natural one that applies to any regression model solved to optimize squared error.",
    "fetched_at": "2025-10-28T03:51:07.300365Z"
  },
  {
    "id": "2510.23472v1",
    "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
    "date": "2025-10-27",
    "tags": [
      "cs.LG",
      "LG",
      "cs.AI",
      "AI",
      "cs.AR",
      "AR",
      "cs.NE",
      "NE"
    ],
    "authors": [
      "Ke Xue",
      "Ruo-Tong Chen",
      "Rong-Xi Tan",
      "Xi Lin",
      "Yunqi Shi",
      "Siyuan Xu",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "institution": "MIT",
    "link": "http://arxiv.org/pdf/2510.23472v1",
    "abstract": "Chip placement is a vital stage in modern chip design as it has a substantial impact on the subsequent processes and the overall quality of the final chip. The use of black-box optimization (BBO) for chip placement has a history of several decades. However, early efforts were limited by immature problem formulations and inefficient algorithm designs. Recent progress has shown the effectiveness and efficiency of BBO for chip placement, proving its potential to achieve state-of-the-art results. Despite these advancements, the field lacks a unified, BBO-specific benchmark for thoroughly assessing various problem formulations and BBO algorithms. To fill this gap, we propose BBOPlace-Bench, the first benchmark designed specifically for evaluating and developing BBO algorithms for chip placement tasks. It integrates three problem formulations of BBO for chip placement, and offers a modular, decoupled, and flexible framework that enables users to seamlessly implement, test, and compare their own algorithms. BBOPlace-Bench integrates a wide variety of existing BBO algorithms, including simulated annealing (SA), evolutionary algorithms (EAs), and Bayesian optimization (BO). Experimental results show that the problem formulations of mask-guided optimization and hyperparameter optimization exhibit superior performance than the sequence pair problem formulation, while EAs demonstrate better overall performance than SA and BO, especially in high-dimensional search spaces, and also achieve state-of-the-art performance compared to the mainstream chip placement methods. BBOPlace-Bench not only facilitates the development of efficient BBO-driven solutions for chip placement but also broadens the practical application scenarios (which are urgently needed) for the BBO community. The code of BBOPlace-Bench is available at https://github.com/lamda-bbo/BBOPlace-Bench.",
    "fetched_at": "2025-10-28T03:51:07.300296Z"
  }
]